ÊúÄÈÅ©ÂåñÂØæË±°: trend
[32m[I 2025-01-01 19:03:32,590][0m A new study created in memory with name: no-name-21f89666-fdfa-4359-baf7-5310363ef445[0m
Non-A100 GPU detected, using math or mem efficient attention if input tensor is on cuda
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
[33m[W 2025-01-01 19:07:00,849][0m Trial 0 failed with parameters: {'observation_period_num': 160, 'train_rates': 0.9679103218417209, 'learning_rate': 6.810462891290453e-05, 'batch_size': 80, 'step_size': 12, 'gamma': 0.802350664384702} because of the following error: KeyboardInterrupt().[0m
Traceback (most recent call last):
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/roop_optuna.py", line 550, in <lambda>
    study.optimize(lambda trial: objective(trial, component, depth, dim), n_trials=30) #check
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/roop_optuna.py", line 113, in objective
    model, _, valid_loss = train(
                           ^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/src/train.py", line 43, in train
    total_loss_train += loss.item() * data.size(0)
                        ^^^^^^^^^^^
KeyboardInterrupt
[33m[W 2025-01-01 19:07:00,854][0m Trial 0 failed with value None.[0m
Traceback (most recent call last):
  File "/data/student/k2110261/Multi-iTransformer/roop_optuna.py", line 550, in <module>
    study.optimize(lambda trial: objective(trial, component, depth, dim), n_trials=30) #check
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/study.py", line 475, in optimize
    _optimize(
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 63, in _optimize
    _optimize_sequential(
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 160, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 248, in _run_trial
    raise func_err
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/roop_optuna.py", line 550, in <lambda>
    study.optimize(lambda trial: objective(trial, component, depth, dim), n_trials=30) #check
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/roop_optuna.py", line 113, in objective
    model, _, valid_loss = train(
                           ^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/src/train.py", line 43, in train
    total_loss_train += loss.item() * data.size(0)
                        ^^^^^^^^^^^
KeyboardInterrupt
