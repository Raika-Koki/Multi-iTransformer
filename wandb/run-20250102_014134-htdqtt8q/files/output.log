最適化対象: trend
[32m[I 2025-01-02 01:41:35,131][0m A new study created in memory with name: no-name-3def3f74-bff8-4771-abf2-b54b5863f8ef[0m
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
[32m[I 2025-01-02 01:42:31,838][0m Trial 0 finished with value: 1.8443289262881362 and parameters: {'observation_period_num': 123, 'train_rates': 0.7717694220613364, 'learning_rate': 1.3019546204544922e-06, 'batch_size': 80, 'step_size': 11, 'gamma': 0.877902114751189}. Best is trial 0 with value: 1.8443289262881362.[0m
trend の最適ハイパーパラメータが見つかりました
最適化対象: seasonal_0
[32m[I 2025-01-02 01:42:31,839][0m A new study created in memory with name: no-name-4b25d360-55cb-4113-bdf4-44fb98f561c6[0m
[32m[I 2025-01-02 01:43:23,238][0m Trial 0 finished with value: 0.6675941045813336 and parameters: {'observation_period_num': 213, 'train_rates': 0.7421941972310057, 'learning_rate': 3.343612045407806e-05, 'batch_size': 161, 'step_size': 1, 'gamma': 0.771481835068276}. Best is trial 0 with value: 0.6675941045813336.[0m
seasonal_0 の最適ハイパーパラメータが見つかりました
最適化対象: seasonal_1
[32m[I 2025-01-02 01:43:23,239][0m A new study created in memory with name: no-name-1efda5a2-6ef4-4175-9d30-dd3a138ab0fc[0m
[32m[I 2025-01-02 01:44:10,332][0m Trial 0 finished with value: 0.9222978062759665 and parameters: {'observation_period_num': 149, 'train_rates': 0.6185178671881884, 'learning_rate': 2.012398679678823e-05, 'batch_size': 131, 'step_size': 1, 'gamma': 0.9654670267185674}. Best is trial 0 with value: 0.9222978062759665.[0m
seasonal_1 の最適ハイパーパラメータが見つかりました
最適化対象: seasonal_2
[32m[I 2025-01-02 01:44:10,333][0m A new study created in memory with name: no-name-6dc1ba18-c5a9-4ab7-8b9b-d1506995dc94[0m
[32m[I 2025-01-02 01:44:58,901][0m Trial 0 finished with value: 1.1573422615828752 and parameters: {'observation_period_num': 136, 'train_rates': 0.6351625209675184, 'learning_rate': 5.455745998387574e-05, 'batch_size': 90, 'step_size': 9, 'gamma': 0.7738855990084066}. Best is trial 0 with value: 1.1573422615828752.[0m
seasonal_2 の最適ハイパーパラメータが見つかりました
最適化対象: seasonal_3
[32m[I 2025-01-02 01:44:58,902][0m A new study created in memory with name: no-name-f81118b8-7be6-4ada-ac2b-4ac8111ff8af[0m
[32m[I 2025-01-02 01:45:51,605][0m Trial 0 finished with value: 0.5266065777634545 and parameters: {'observation_period_num': 217, 'train_rates': 0.7957834707664783, 'learning_rate': 3.4937923916113735e-05, 'batch_size': 256, 'step_size': 12, 'gamma': 0.9732865488121086}. Best is trial 0 with value: 0.5266065777634545.[0m
seasonal_3 の最適ハイパーパラメータが見つかりました
最適化対象: resid
[32m[I 2025-01-02 01:45:51,606][0m A new study created in memory with name: no-name-837dd606-5c23-48c4-8aca-2a8d9b9d5601[0m
[32m[I 2025-01-02 01:46:47,386][0m Trial 0 finished with value: 1.7308745275278317 and parameters: {'observation_period_num': 172, 'train_rates': 0.8617549723277145, 'learning_rate': 1.431719083272598e-06, 'batch_size': 239, 'step_size': 13, 'gamma': 0.7707571518458657}. Best is trial 0 with value: 1.7308745275278317.[0m
resid の最適ハイパーパラメータが見つかりました
最適ハイパーパラメータが best_hyperparameters_AMZN_iTransformer.json に保存されました
Training trend component with params: {'observation_period_num': 123, 'train_rates': 0.7717694220613364, 'learning_rate': 1.3019546204544922e-06, 'batch_size': 80, 'step_size': 11, 'gamma': 0.877902114751189}
Epoch 1/1, trend Loss: 0.5585 | 1.0608
Training seasonal_0 component with params: {'observation_period_num': 213, 'train_rates': 0.7421941972310057, 'learning_rate': 3.343612045407806e-05, 'batch_size': 161, 'step_size': 1, 'gamma': 0.771481835068276}
Traceback (most recent call last):
  File "/data/student/k2110261/Multi-iTransformer/roop_optuna.py", line 616, in <module>
    models[comp], train_loss, valid_loss = train(
                                           ^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/src/train.py", line 40, in train
    loss.backward()  # 逆伝播
    ^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
