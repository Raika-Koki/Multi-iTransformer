Using device: cuda
[*********************100%***********************]  1 of 1 completed
Ticker            AAPL
Date
2012-05-18   15.978592
2012-05-21   16.909508
2012-05-22   16.779659
2012-05-23   17.189083
2012-05-24   17.031216
...                ...
2023-05-24  170.546951
2023-05-25  171.688309
2023-05-26  174.109940
2023-05-30  175.965897
2023-05-31  175.916260

[2776 rows x 1 columns]
/data/student/k2110261/Multi-iTransformer/optunademo.py:97: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.
  df = df.fillna(method='ffill')  # ÂâçÊó•„ÅÆ„Éá„Éº„Çø„Çí‰ΩøÁî®„Åó„Å¶Ë£úÂÆå
Price         BB_Upper    BB_Lower   BB_Middle      MACD MACD_Signal MACD_Diff        RSI      SMA_50     SMA_200
Ticker
Date
2023-05-24  175.360193  165.081601  170.220897  2.332938    2.724338 -0.391400  55.867138  164.409243  150.685264
2023-05-25  175.401883  165.517550  170.459717  2.209841    2.621439 -0.411598  58.637763  164.810427  150.729038
2023-05-26  175.825123  165.688242  170.756683  2.281393    2.553429 -0.272037  63.826661  165.203354  150.763580
2023-05-30  176.541937  165.759878  171.150907  2.459507    2.534645 -0.075138  67.220690  165.650248  150.811107
2023-05-31  177.020406  166.168960  171.594683  2.567066    2.541129  0.025937  67.039523  166.048576  150.840554
AAPL null values:
0
DTWEXBGS null values:
0
VIXCLS null values:
0
DFII10 null values:
0
T10Y2Y null values:
0
Volume null values:
0
BB_Upper null values:
0
BB_Lower null values:
0
BB_Middle null values:
0
MACD null values:
0
MACD_Signal null values:
0
MACD_Diff null values:
0
RSI null values:
0
SMA_50 null values:
0
SMA_200 null values:
0
[32m[I 2024-11-18 15:18:42,516][0m A new study created in memory with name: no-name-7985f89d-30dd-4b4b-bfd9-b7ad1abd2f6b[0m
Non-A100 GPU detected, using math or mem efficient attention if input tensor is on cuda
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
[32m[I 2024-11-18 15:18:45,282][0m Trial 0 finished with value: 1.212751922837223 and parameters: {'observation_period_num': 104, 'train_rates': 0.6979182763570029, 'learning_rate': 0.0007131213567832647, 'batch_size': 154, 'step_size': 15, 'gamma': 0.815900921192467, 'depth': 3, 'dim': 116}. Best is trial 0 with value: 1.212751922837223.[0m
[32m[I 2024-11-18 15:18:45,282][0m A new study created in memory with name: no-name-82e28392-eba9-40dd-ac1a-d36888102074[0m
[32m[I 2024-11-18 15:18:46,661][0m Trial 0 finished with value: 0.8087589740753174 and parameters: {'observation_period_num': 167, 'train_rates': 0.9698162877568499, 'learning_rate': 7.375514472449227e-05, 'batch_size': 186, 'step_size': 9, 'gamma': 0.7511586586641267, 'depth': 5, 'dim': 248}. Best is trial 0 with value: 0.8087589740753174.[0m
[32m[I 2024-11-18 15:18:46,661][0m A new study created in memory with name: no-name-4e21ee1a-0aa1-4985-ba6c-88c139f4441e[0m
[32m[I 2024-11-18 15:18:48,228][0m Trial 0 finished with value: 0.40477924906846247 and parameters: {'observation_period_num': 81, 'train_rates': 0.8150328278708547, 'learning_rate': 0.0007479447684643987, 'batch_size': 70, 'step_size': 12, 'gamma': 0.8017415849593689, 'depth': 4, 'dim': 243}. Best is trial 0 with value: 0.40477924906846247.[0m
Best hyperparameters (trend): {'observation_period_num': 104, 'train_rates': 0.6979182763570029, 'learning_rate': 0.0007131213567832647, 'batch_size': 154, 'step_size': 15, 'gamma': 0.815900921192467, 'depth': 3, 'dim': 116}
Best hyperparameters (seasonal): {'observation_period_num': 167, 'train_rates': 0.9698162877568499, 'learning_rate': 7.375514472449227e-05, 'batch_size': 186, 'step_size': 9, 'gamma': 0.7511586586641267, 'depth': 5, 'dim': 248}
Best hyperparameters (resid): {'observation_period_num': 81, 'train_rates': 0.8150328278708547, 'learning_rate': 0.0007479447684643987, 'batch_size': 70, 'step_size': 12, 'gamma': 0.8017415849593689, 'depth': 4, 'dim': 243}
Epoch 1/100, (Training | Validation) Trend Loss: 0.7181 | 1.3254, Seasonal Loss: 0.5445 | 0.5580, Residual Loss: 0.5232 | 0.4633
Epoch 2/100, (Training | Validation) Trend Loss: 0.3079 | 0.7889, Seasonal Loss: 0.5286 | 0.6231, Residual Loss: 0.2021 | 0.4966
Epoch 3/100, (Training | Validation) Trend Loss: 0.3092 | 0.6378, Seasonal Loss: 0.4266 | 0.4731, Residual Loss: 0.1563 | 0.3622
Epoch 4/100, (Training | Validation) Trend Loss: 0.1974 | 0.6011, Seasonal Loss: 0.4730 | 0.3996, Residual Loss: 0.1139 | 0.2887
Epoch 5/100, (Training | Validation) Trend Loss: 0.1431 | 0.4692, Seasonal Loss: 0.2798 | 0.4421, Residual Loss: 0.0931 | 0.2755
Epoch 6/100, (Training | Validation) Trend Loss: 0.1441 | 0.4400, Seasonal Loss: 0.2803 | 0.3393, Residual Loss: 0.0838 | 0.2649
Epoch 7/100, (Training | Validation) Trend Loss: 0.1425 | 0.4038, Seasonal Loss: 0.2336 | 0.3940, Residual Loss: 0.0999 | 0.2615
Epoch 8/100, (Training | Validation) Trend Loss: 0.1236 | 0.3610, Seasonal Loss: 0.2403 | 0.2956, Residual Loss: 0.0955 | 0.2023
Epoch 9/100, (Training | Validation) Trend Loss: 0.1091 | 0.3322, Seasonal Loss: 0.1928 | 0.3205, Residual Loss: 0.0848 | 0.3203
Epoch 10/100, (Training | Validation) Trend Loss: 0.0992 | 0.3037, Seasonal Loss: 0.1890 | 0.2665, Residual Loss: 0.0816 | 0.2074
Traceback (most recent call last):
  File "/data/student/k2110261/Multi-iTransformer/optunademo.py", line 343, in <module>
    model_resid, train_loss_resid, valid_loss_resid = train(
                                                      ^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/src/train.py", line 40, in train
    loss.backward()  # ÈÄÜ‰ºùÊí≠
    ^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
