[32m[I 2025-02-05 09:32:09,644][0m A new study created in memory with name: no-name-958d86b4-81bc-4ecc-8b4e-f10eab6aa568[0m
[32m[I 2025-02-05 09:32:46,487][0m Trial 0 finished with value: 0.6163182999164554 and parameters: {'observation_period_num': 46, 'train_rates': 0.6143835663544769, 'learning_rate': 1.0645666874913375e-06, 'batch_size': 126, 'step_size': 14, 'gamma': 0.942426407908251}. Best is trial 0 with value: 0.6163182999164554.[0m
Early stopping at epoch 66
[32m[I 2025-02-05 09:33:11,586][0m Trial 1 finished with value: 0.16319512313520404 and parameters: {'observation_period_num': 39, 'train_rates': 0.9273048112521702, 'learning_rate': 0.0007824126589657411, 'batch_size': 161, 'step_size': 1, 'gamma': 0.807428794312182}. Best is trial 1 with value: 0.16319512313520404.[0m
[32m[I 2025-02-05 09:33:37,230][0m Trial 2 finished with value: 0.4382018149179439 and parameters: {'observation_period_num': 77, 'train_rates': 0.6323219071056375, 'learning_rate': 1.0617610411785847e-05, 'batch_size': 192, 'step_size': 15, 'gamma': 0.8170807022984196}. Best is trial 1 with value: 0.16319512313520404.[0m
[32m[I 2025-02-05 09:34:01,420][0m Trial 3 finished with value: 0.7767611097645115 and parameters: {'observation_period_num': 220, 'train_rates': 0.8249931188686512, 'learning_rate': 2.1449532758909595e-06, 'batch_size': 234, 'step_size': 9, 'gamma': 0.766760729070138}. Best is trial 1 with value: 0.16319512313520404.[0m
[32m[I 2025-02-05 09:34:28,139][0m Trial 4 finished with value: 1.0605863332748413 and parameters: {'observation_period_num': 85, 'train_rates': 0.944935274523075, 'learning_rate': 2.395062405695456e-06, 'batch_size': 241, 'step_size': 15, 'gamma': 0.8052728307808337}. Best is trial 1 with value: 0.16319512313520404.[0m
[32m[I 2025-02-05 09:34:53,105][0m Trial 5 finished with value: 0.4601767511967704 and parameters: {'observation_period_num': 210, 'train_rates': 0.6080739151158089, 'learning_rate': 2.54399786237249e-05, 'batch_size': 186, 'step_size': 10, 'gamma': 0.8007769739427754}. Best is trial 1 with value: 0.16319512313520404.[0m
[32m[I 2025-02-05 09:35:20,062][0m Trial 6 finished with value: 0.24447986052653334 and parameters: {'observation_period_num': 133, 'train_rates': 0.7096692454811991, 'learning_rate': 0.0008130989456039156, 'batch_size': 193, 'step_size': 5, 'gamma': 0.9325002892320075}. Best is trial 1 with value: 0.16319512313520404.[0m
[32m[I 2025-02-05 09:38:24,383][0m Trial 7 finished with value: 0.22663172022046812 and parameters: {'observation_period_num': 243, 'train_rates': 0.8479509028478946, 'learning_rate': 0.00021391079792609089, 'batch_size': 27, 'step_size': 3, 'gamma': 0.9575841571127908}. Best is trial 1 with value: 0.16319512313520404.[0m
[32m[I 2025-02-05 09:39:48,743][0m Trial 8 finished with value: 0.19839702968327505 and parameters: {'observation_period_num': 239, 'train_rates': 0.8058813622867651, 'learning_rate': 0.000696710249756174, 'batch_size': 58, 'step_size': 2, 'gamma': 0.9382145193174635}. Best is trial 1 with value: 0.16319512313520404.[0m
[32m[I 2025-02-05 09:40:46,034][0m Trial 9 finished with value: 0.23181026939965466 and parameters: {'observation_period_num': 119, 'train_rates': 0.7140195716832475, 'learning_rate': 0.0002437833264721322, 'batch_size': 84, 'step_size': 12, 'gamma': 0.903896089701141}. Best is trial 1 with value: 0.16319512313520404.[0m
[32m[I 2025-02-05 09:41:29,088][0m Trial 10 finished with value: 0.10105592757463455 and parameters: {'observation_period_num': 13, 'train_rates': 0.9861463527234744, 'learning_rate': 7.460662685799071e-05, 'batch_size': 146, 'step_size': 5, 'gamma': 0.8589711344485167}. Best is trial 10 with value: 0.10105592757463455.[0m
[32m[I 2025-02-05 09:42:12,608][0m Trial 11 finished with value: 0.06946288794279099 and parameters: {'observation_period_num': 8, 'train_rates': 0.9796330584488345, 'learning_rate': 9.499330925168241e-05, 'batch_size': 149, 'step_size': 6, 'gamma': 0.8595840454412516}. Best is trial 11 with value: 0.06946288794279099.[0m
[32m[I 2025-02-05 09:43:05,586][0m Trial 12 finished with value: 0.07156579196453094 and parameters: {'observation_period_num': 9, 'train_rates': 0.9664551235237647, 'learning_rate': 7.57122405213451e-05, 'batch_size': 118, 'step_size': 6, 'gamma': 0.8665167640948707}. Best is trial 11 with value: 0.06946288794279099.[0m
[32m[I 2025-02-05 09:44:10,709][0m Trial 13 finished with value: 0.046237906256061514 and parameters: {'observation_period_num': 9, 'train_rates': 0.8979172883165665, 'learning_rate': 7.207799625758677e-05, 'batch_size': 90, 'step_size': 6, 'gamma': 0.8695267629821416}. Best is trial 13 with value: 0.046237906256061514.[0m
[32m[I 2025-02-05 09:45:26,668][0m Trial 14 finished with value: 0.20745670297225557 and parameters: {'observation_period_num': 156, 'train_rates': 0.8829971650921574, 'learning_rate': 1.9203546206923785e-05, 'batch_size': 72, 'step_size': 7, 'gamma': 0.8486346163337712}. Best is trial 13 with value: 0.046237906256061514.[0m
[32m[I 2025-02-05 09:46:25,309][0m Trial 15 finished with value: 0.13542256557156104 and parameters: {'observation_period_num': 54, 'train_rates': 0.898536482831866, 'learning_rate': 9.293731186377411e-05, 'batch_size': 97, 'step_size': 4, 'gamma': 0.9886784653021526}. Best is trial 13 with value: 0.046237906256061514.[0m
[32m[I 2025-02-05 09:48:40,846][0m Trial 16 finished with value: 0.14921885542571545 and parameters: {'observation_period_num': 87, 'train_rates': 0.8889059364283614, 'learning_rate': 7.947182061099617e-06, 'batch_size': 40, 'step_size': 8, 'gamma': 0.8971450269398342}. Best is trial 13 with value: 0.046237906256061514.[0m
[32m[I 2025-02-05 09:49:31,347][0m Trial 17 finished with value: 0.15266297617352304 and parameters: {'observation_period_num': 6, 'train_rates': 0.7539462128110638, 'learning_rate': 0.0002598095936112446, 'batch_size': 105, 'step_size': 10, 'gamma': 0.8930825693739873}. Best is trial 13 with value: 0.046237906256061514.[0m
[32m[I 2025-02-05 09:50:09,059][0m Trial 18 finished with value: 0.2493005313783744 and parameters: {'observation_period_num': 174, 'train_rates': 0.9240064716711053, 'learning_rate': 4.082198238330915e-05, 'batch_size': 157, 'step_size': 7, 'gamma': 0.8378732563723809}. Best is trial 13 with value: 0.046237906256061514.[0m
[32m[I 2025-02-05 09:50:53,591][0m Trial 19 finished with value: 0.053977675698790466 and parameters: {'observation_period_num': 33, 'train_rates': 0.8633197662786528, 'learning_rate': 0.00011305355898391543, 'batch_size': 133, 'step_size': 12, 'gamma': 0.7732328836010697}. Best is trial 13 with value: 0.046237906256061514.[0m
[32m[I 2025-02-05 09:52:28,279][0m Trial 20 finished with value: 0.05669383220891985 and parameters: {'observation_period_num': 36, 'train_rates': 0.8526619599894533, 'learning_rate': 4.250636583186683e-05, 'batch_size': 57, 'step_size': 12, 'gamma': 0.7508023259442532}. Best is trial 13 with value: 0.046237906256061514.[0m
[32m[I 2025-02-05 09:54:02,072][0m Trial 21 finished with value: 0.06236947815812809 and parameters: {'observation_period_num': 32, 'train_rates': 0.8548496661964967, 'learning_rate': 4.3820050353675626e-05, 'batch_size': 58, 'step_size': 12, 'gamma': 0.7544388885380431}. Best is trial 13 with value: 0.046237906256061514.[0m
[32m[I 2025-02-05 09:58:07,614][0m Trial 22 finished with value: 0.21796255963558406 and parameters: {'observation_period_num': 63, 'train_rates': 0.7617311389645355, 'learning_rate': 0.0001592009447444042, 'batch_size': 20, 'step_size': 12, 'gamma': 0.780526787605092}. Best is trial 13 with value: 0.046237906256061514.[0m
[32m[I 2025-02-05 09:59:07,184][0m Trial 23 finished with value: 0.20331198085247773 and parameters: {'observation_period_num': 108, 'train_rates': 0.8506161039799626, 'learning_rate': 1.416559493966038e-05, 'batch_size': 93, 'step_size': 13, 'gamma': 0.7761312736160273}. Best is trial 13 with value: 0.046237906256061514.[0m
[32m[I 2025-02-05 10:00:22,421][0m Trial 24 finished with value: 0.33591752300500105 and parameters: {'observation_period_num': 29, 'train_rates': 0.7885571858576694, 'learning_rate': 5.861732114557195e-06, 'batch_size': 70, 'step_size': 10, 'gamma': 0.7504362354430896}. Best is trial 13 with value: 0.046237906256061514.[0m
[32m[I 2025-02-05 10:01:11,120][0m Trial 25 finished with value: 0.06932741424666261 and parameters: {'observation_period_num': 69, 'train_rates': 0.871964398674492, 'learning_rate': 0.0003730337497271906, 'batch_size': 119, 'step_size': 11, 'gamma': 0.8298534164348705}. Best is trial 13 with value: 0.046237906256061514.[0m
[32m[I 2025-02-05 10:03:03,285][0m Trial 26 finished with value: 0.057520052439855696 and parameters: {'observation_period_num': 27, 'train_rates': 0.9127707004065154, 'learning_rate': 4.137658979385406e-05, 'batch_size': 51, 'step_size': 8, 'gamma': 0.7830111069703664}. Best is trial 13 with value: 0.046237906256061514.[0m
[32m[I 2025-02-05 10:04:13,462][0m Trial 27 finished with value: 0.0596482110559009 and parameters: {'observation_period_num': 49, 'train_rates': 0.8247603323838705, 'learning_rate': 0.0001364797369070812, 'batch_size': 78, 'step_size': 13, 'gamma': 0.8817027918577982}. Best is trial 13 with value: 0.046237906256061514.[0m
[32m[I 2025-02-05 10:05:10,707][0m Trial 28 finished with value: 0.08276517327342714 and parameters: {'observation_period_num': 29, 'train_rates': 0.95249152265771, 'learning_rate': 5.197826673769563e-05, 'batch_size': 104, 'step_size': 9, 'gamma': 0.7897121265468446}. Best is trial 13 with value: 0.046237906256061514.[0m
[32m[I 2025-02-05 10:05:50,163][0m Trial 29 finished with value: 0.32708626208978836 and parameters: {'observation_period_num': 101, 'train_rates': 0.7691419095804767, 'learning_rate': 2.6129211138137715e-05, 'batch_size': 133, 'step_size': 14, 'gamma': 0.7637634657948869}. Best is trial 13 with value: 0.046237906256061514.[0m
[32m[I 2025-02-05 10:08:12,141][0m Trial 30 finished with value: 0.10211951627023888 and parameters: {'observation_period_num': 53, 'train_rates': 0.8275142976845024, 'learning_rate': 0.0004255453335228367, 'batch_size': 37, 'step_size': 14, 'gamma': 0.8227963485041887}. Best is trial 13 with value: 0.046237906256061514.[0m
[32m[I 2025-02-05 10:10:03,453][0m Trial 31 finished with value: 0.05812103149012057 and parameters: {'observation_period_num': 28, 'train_rates': 0.9067532404462983, 'learning_rate': 3.574923860845097e-05, 'batch_size': 52, 'step_size': 8, 'gamma': 0.7887327998529536}. Best is trial 13 with value: 0.046237906256061514.[0m
[32m[I 2025-02-05 10:12:18,159][0m Trial 32 finished with value: 0.043848743593569176 and parameters: {'observation_period_num': 20, 'train_rates': 0.9265722482307743, 'learning_rate': 6.037577334278801e-05, 'batch_size': 43, 'step_size': 9, 'gamma': 0.7719547842932489}. Best is trial 32 with value: 0.043848743593569176.[0m
[32m[I 2025-02-05 10:12:55,914][0m Trial 33 finished with value: 0.08394943395949374 and parameters: {'observation_period_num': 44, 'train_rates': 0.9324320263709465, 'learning_rate': 0.00011984881634654982, 'batch_size': 170, 'step_size': 11, 'gamma': 0.7654923086012105}. Best is trial 32 with value: 0.043848743593569176.[0m
[32m[I 2025-02-05 10:15:13,102][0m Trial 34 finished with value: 0.06066083487208563 and parameters: {'observation_period_num': 18, 'train_rates': 0.866905907358016, 'learning_rate': 1.741927135853794e-05, 'batch_size': 40, 'step_size': 11, 'gamma': 0.8116697998137246}. Best is trial 32 with value: 0.043848743593569176.[0m
[32m[I 2025-02-05 10:15:41,779][0m Trial 35 finished with value: 0.15306247770786285 and parameters: {'observation_period_num': 67, 'train_rates': 0.9422814528477135, 'learning_rate': 7.324346181607281e-05, 'batch_size': 216, 'step_size': 9, 'gamma': 0.7989294739558696}. Best is trial 32 with value: 0.043848743593569176.[0m
[32m[I 2025-02-05 10:17:00,383][0m Trial 36 finished with value: 0.05863577340772043 and parameters: {'observation_period_num': 41, 'train_rates': 0.8353964366455955, 'learning_rate': 5.7333192209951055e-05, 'batch_size': 68, 'step_size': 13, 'gamma': 0.7725268824704714}. Best is trial 32 with value: 0.043848743593569176.[0m
[32m[I 2025-02-05 10:17:48,489][0m Trial 37 finished with value: 0.06790325588395006 and parameters: {'observation_period_num': 83, 'train_rates': 0.8020520117720827, 'learning_rate': 0.00018831874855828687, 'batch_size': 115, 'step_size': 15, 'gamma': 0.918955910498485}. Best is trial 32 with value: 0.043848743593569176.[0m
[32m[I 2025-02-05 10:18:41,685][0m Trial 38 finished with value: 0.21323224476666428 and parameters: {'observation_period_num': 20, 'train_rates': 0.6539410373857653, 'learning_rate': 2.4919867066140955e-05, 'batch_size': 89, 'step_size': 9, 'gamma': 0.9561580337233879}. Best is trial 32 with value: 0.043848743593569176.[0m
[32m[I 2025-02-05 10:21:42,827][0m Trial 39 finished with value: 0.274302778840065 and parameters: {'observation_period_num': 43, 'train_rates': 0.8717952690633, 'learning_rate': 3.8723714371349485e-06, 'batch_size': 30, 'step_size': 7, 'gamma': 0.7591032642805668}. Best is trial 32 with value: 0.043848743593569176.[0m
Early stopping at epoch 56
[32m[I 2025-02-05 10:22:08,841][0m Trial 40 finished with value: 0.5143342205286026 and parameters: {'observation_period_num': 147, 'train_rates': 0.9113613547193828, 'learning_rate': 0.00010945064699240455, 'batch_size': 131, 'step_size': 1, 'gamma': 0.8017312068795521}. Best is trial 32 with value: 0.043848743593569176.[0m
[32m[I 2025-02-05 10:24:11,001][0m Trial 41 finished with value: 0.056361349448561665 and parameters: {'observation_period_num': 23, 'train_rates': 0.9151077133534782, 'learning_rate': 5.555616683756279e-05, 'batch_size': 47, 'step_size': 8, 'gamma': 0.7830721651206412}. Best is trial 32 with value: 0.043848743593569176.[0m
[32m[I 2025-02-05 10:29:15,374][0m Trial 42 finished with value: 0.03868229733641848 and parameters: {'observation_period_num': 19, 'train_rates': 0.8857859420663504, 'learning_rate': 6.11592446346366e-05, 'batch_size': 18, 'step_size': 6, 'gamma': 0.7505784934713715}. Best is trial 42 with value: 0.03868229733641848.[0m
[32m[I 2025-02-05 10:33:42,106][0m Trial 43 finished with value: 0.052330690458416936 and parameters: {'observation_period_num': 19, 'train_rates': 0.9576297051695258, 'learning_rate': 5.54604378796162e-05, 'batch_size': 22, 'step_size': 5, 'gamma': 0.7937279689647512}. Best is trial 42 with value: 0.03868229733641848.[0m
[32m[I 2025-02-05 10:37:48,022][0m Trial 44 finished with value: 0.04534408347360019 and parameters: {'observation_period_num': 7, 'train_rates': 0.9608912631785415, 'learning_rate': 7.019449828846072e-05, 'batch_size': 24, 'step_size': 4, 'gamma': 0.7949649553918037}. Best is trial 42 with value: 0.03868229733641848.[0m
[32m[I 2025-02-05 10:42:43,085][0m Trial 45 finished with value: 0.06737220381294284 and parameters: {'observation_period_num': 13, 'train_rates': 0.9626845501058471, 'learning_rate': 2.878791403493199e-05, 'batch_size': 20, 'step_size': 4, 'gamma': 0.7954405644622394}. Best is trial 42 with value: 0.03868229733641848.[0m
[32m[I 2025-02-05 10:48:43,004][0m Trial 46 finished with value: 0.03309251368045807 and parameters: {'observation_period_num': 16, 'train_rates': 0.9373460025990539, 'learning_rate': 8.015635363711241e-05, 'batch_size': 16, 'step_size': 5, 'gamma': 0.8191184243106815}. Best is trial 46 with value: 0.03309251368045807.[0m
[32m[I 2025-02-05 10:51:52,008][0m Trial 47 finished with value: 0.04817955301517678 and parameters: {'observation_period_num': 5, 'train_rates': 0.9346908443544805, 'learning_rate': 7.645434708961522e-05, 'batch_size': 31, 'step_size': 3, 'gamma': 0.8111965054678729}. Best is trial 46 with value: 0.03309251368045807.[0m
[32m[I 2025-02-05 10:57:21,052][0m Trial 48 finished with value: 0.18860676610956387 and parameters: {'observation_period_num': 193, 'train_rates': 0.9823440810187222, 'learning_rate': 0.0003237639151964825, 'batch_size': 17, 'step_size': 6, 'gamma': 0.8440119968337412}. Best is trial 46 with value: 0.03309251368045807.[0m
[32m[I 2025-02-05 11:00:04,615][0m Trial 49 finished with value: 0.06138997654245479 and parameters: {'observation_period_num': 60, 'train_rates': 0.8911118040147309, 'learning_rate': 0.00015940615981606092, 'batch_size': 34, 'step_size': 4, 'gamma': 0.8242457625438685}. Best is trial 46 with value: 0.03309251368045807.[0m
ÊúÄÈÅ©„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åó„Åü
ÊúÄÈÅ©„Å™„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„Åå best_hyperparameters_GOOG_iTransformer_noMSTL.json „Å´‰øùÂ≠ò„Åï„Çå„Åæ„Åó„Åü
Epoch 1/300, Loss: 0.2796 | 0.1788
Epoch 2/300, Loss: 0.1289 | 0.1454
Epoch 3/300, Loss: 0.1136 | 0.1322
Epoch 4/300, Loss: 0.1057 | 0.1002
Epoch 5/300, Loss: 0.1020 | 0.0895
Epoch 6/300, Loss: 0.0982 | 0.0788
Epoch 7/300, Loss: 0.0957 | 0.0746
Epoch 8/300, Loss: 0.0928 | 0.0714
Epoch 9/300, Loss: 0.0897 | 0.0684
Epoch 10/300, Loss: 0.0876 | 0.0660
Epoch 11/300, Loss: 0.0850 | 0.0629
Epoch 12/300, Loss: 0.0831 | 0.0611
Epoch 13/300, Loss: 0.0812 | 0.0592
Epoch 14/300, Loss: 0.0793 | 0.0570
Epoch 15/300, Loss: 0.0780 | 0.0555
Epoch 16/300, Loss: 0.0767 | 0.0544
Epoch 17/300, Loss: 0.0759 | 0.0534
Epoch 18/300, Loss: 0.0752 | 0.0524
Epoch 19/300, Loss: 0.0745 | 0.0518
Epoch 20/300, Loss: 0.0739 | 0.0511
Epoch 21/300, Loss: 0.0735 | 0.0504
Epoch 22/300, Loss: 0.0733 | 0.0497
Epoch 23/300, Loss: 0.0731 | 0.0490
Epoch 24/300, Loss: 0.0731 | 0.0483
Epoch 25/300, Loss: 0.0730 | 0.0478
Epoch 26/300, Loss: 0.0724 | 0.0472
Epoch 27/300, Loss: 0.0719 | 0.0470
Epoch 28/300, Loss: 0.0716 | 0.0467
Epoch 29/300, Loss: 0.0712 | 0.0460
Epoch 30/300, Loss: 0.0710 | 0.0458
Epoch 31/300, Loss: 0.0708 | 0.0454
Epoch 32/300, Loss: 0.0706 | 0.0452
Epoch 33/300, Loss: 0.0704 | 0.0450
Epoch 34/300, Loss: 0.0702 | 0.0448
Epoch 35/300, Loss: 0.0700 | 0.0446
Epoch 36/300, Loss: 0.0698 | 0.0445
Epoch 37/300, Loss: 0.0697 | 0.0443
Epoch 38/300, Loss: 0.0696 | 0.0442
Epoch 39/300, Loss: 0.0694 | 0.0441
Epoch 40/300, Loss: 0.0693 | 0.0439
Epoch 41/300, Loss: 0.0692 | 0.0438
Epoch 42/300, Loss: 0.0691 | 0.0437
Epoch 43/300, Loss: 0.0691 | 0.0436
Epoch 44/300, Loss: 0.0690 | 0.0436
Epoch 45/300, Loss: 0.0689 | 0.0435
Epoch 46/300, Loss: 0.0688 | 0.0434
Epoch 47/300, Loss: 0.0688 | 0.0434
Epoch 48/300, Loss: 0.0688 | 0.0433
Epoch 49/300, Loss: 0.0687 | 0.0432
Epoch 50/300, Loss: 0.0687 | 0.0432
Epoch 51/300, Loss: 0.0686 | 0.0431
Epoch 52/300, Loss: 0.0686 | 0.0431
Epoch 53/300, Loss: 0.0686 | 0.0430
Epoch 54/300, Loss: 0.0685 | 0.0430
Epoch 55/300, Loss: 0.0685 | 0.0429
Epoch 56/300, Loss: 0.0685 | 0.0430
Epoch 57/300, Loss: 0.0684 | 0.0429
Epoch 58/300, Loss: 0.0684 | 0.0429
Epoch 59/300, Loss: 0.0684 | 0.0430
Epoch 60/300, Loss: 0.0683 | 0.0429
Epoch 61/300, Loss: 0.0683 | 0.0430
Epoch 62/300, Loss: 0.0682 | 0.0430
Epoch 63/300, Loss: 0.0682 | 0.0429
Epoch 64/300, Loss: 0.0682 | 0.0430
Epoch 65/300, Loss: 0.0681 | 0.0430
Epoch 66/300, Loss: 0.0681 | 0.0430
Epoch 67/300, Loss: 0.0681 | 0.0430
Epoch 68/300, Loss: 0.0681 | 0.0429
Epoch 69/300, Loss: 0.0680 | 0.0429
Epoch 70/300, Loss: 0.0680 | 0.0429
Epoch 71/300, Loss: 0.0680 | 0.0429
Epoch 72/300, Loss: 0.0680 | 0.0429
Epoch 73/300, Loss: 0.0680 | 0.0429
Epoch 74/300, Loss: 0.0679 | 0.0429
Epoch 75/300, Loss: 0.0679 | 0.0429
Epoch 76/300, Loss: 0.0679 | 0.0429
Epoch 77/300, Loss: 0.0679 | 0.0429
Epoch 78/300, Loss: 0.0679 | 0.0429
Epoch 79/300, Loss: 0.0679 | 0.0429
Epoch 80/300, Loss: 0.0679 | 0.0428
Epoch 81/300, Loss: 0.0679 | 0.0428
Epoch 82/300, Loss: 0.0679 | 0.0428
Epoch 83/300, Loss: 0.0679 | 0.0428
Epoch 84/300, Loss: 0.0678 | 0.0428
Epoch 85/300, Loss: 0.0678 | 0.0428
Epoch 86/300, Loss: 0.0678 | 0.0428
Epoch 87/300, Loss: 0.0678 | 0.0428
Epoch 88/300, Loss: 0.0678 | 0.0428
Epoch 89/300, Loss: 0.0678 | 0.0428
Epoch 90/300, Loss: 0.0678 | 0.0428
Epoch 91/300, Loss: 0.0678 | 0.0428
Epoch 92/300, Loss: 0.0678 | 0.0428
Epoch 93/300, Loss: 0.0678 | 0.0428
Epoch 94/300, Loss: 0.0678 | 0.0428
Epoch 95/300, Loss: 0.0678 | 0.0428
Epoch 96/300, Loss: 0.0678 | 0.0428
Epoch 97/300, Loss: 0.0678 | 0.0428
Epoch 98/300, Loss: 0.0678 | 0.0428
Epoch 99/300, Loss: 0.0678 | 0.0428
Epoch 100/300, Loss: 0.0678 | 0.0428
Epoch 101/300, Loss: 0.0678 | 0.0428
Epoch 102/300, Loss: 0.0678 | 0.0428
Epoch 103/300, Loss: 0.0678 | 0.0428
Epoch 104/300, Loss: 0.0678 | 0.0428
Epoch 105/300, Loss: 0.0678 | 0.0428
Epoch 106/300, Loss: 0.0678 | 0.0428
Epoch 107/300, Loss: 0.0678 | 0.0428
Epoch 108/300, Loss: 0.0678 | 0.0428
Epoch 109/300, Loss: 0.0678 | 0.0428
Epoch 110/300, Loss: 0.0678 | 0.0428
Epoch 111/300, Loss: 0.0678 | 0.0428
Epoch 112/300, Loss: 0.0678 | 0.0428
Epoch 113/300, Loss: 0.0678 | 0.0428
Epoch 114/300, Loss: 0.0678 | 0.0428
Epoch 115/300, Loss: 0.0678 | 0.0428
Epoch 116/300, Loss: 0.0678 | 0.0428
Epoch 117/300, Loss: 0.0678 | 0.0428
Epoch 118/300, Loss: 0.0678 | 0.0428
Epoch 119/300, Loss: 0.0678 | 0.0428
Epoch 120/300, Loss: 0.0678 | 0.0428
Epoch 121/300, Loss: 0.0678 | 0.0428
Epoch 122/300, Loss: 0.0678 | 0.0428
Epoch 123/300, Loss: 0.0678 | 0.0428
Epoch 124/300, Loss: 0.0678 | 0.0428
Epoch 125/300, Loss: 0.0678 | 0.0428
Epoch 126/300, Loss: 0.0678 | 0.0428
Epoch 127/300, Loss: 0.0678 | 0.0428
Epoch 128/300, Loss: 0.0678 | 0.0428
Epoch 129/300, Loss: 0.0678 | 0.0428
Epoch 130/300, Loss: 0.0678 | 0.0428
Epoch 131/300, Loss: 0.0678 | 0.0428
Epoch 132/300, Loss: 0.0678 | 0.0428
Epoch 133/300, Loss: 0.0678 | 0.0428
Epoch 134/300, Loss: 0.0678 | 0.0428
Epoch 135/300, Loss: 0.0678 | 0.0428
Epoch 136/300, Loss: 0.0678 | 0.0428
Epoch 137/300, Loss: 0.0678 | 0.0428
Epoch 138/300, Loss: 0.0678 | 0.0428
Epoch 139/300, Loss: 0.0678 | 0.0428
Epoch 140/300, Loss: 0.0678 | 0.0428
Epoch 141/300, Loss: 0.0678 | 0.0428
Epoch 142/300, Loss: 0.0678 | 0.0428
Epoch 143/300, Loss: 0.0678 | 0.0428
Epoch 144/300, Loss: 0.0678 | 0.0428
Epoch 145/300, Loss: 0.0678 | 0.0428
Epoch 146/300, Loss: 0.0678 | 0.0428
Epoch 147/300, Loss: 0.0678 | 0.0428
Epoch 148/300, Loss: 0.0678 | 0.0428
Epoch 149/300, Loss: 0.0678 | 0.0428
Epoch 150/300, Loss: 0.0678 | 0.0428
Epoch 151/300, Loss: 0.0678 | 0.0428
Epoch 152/300, Loss: 0.0678 | 0.0428
Epoch 153/300, Loss: 0.0678 | 0.0428
Epoch 154/300, Loss: 0.0678 | 0.0428
Epoch 155/300, Loss: 0.0678 | 0.0428
Epoch 156/300, Loss: 0.0678 | 0.0428
Epoch 157/300, Loss: 0.0678 | 0.0428
Epoch 158/300, Loss: 0.0678 | 0.0428
Epoch 159/300, Loss: 0.0678 | 0.0428
Epoch 160/300, Loss: 0.0678 | 0.0428
Early stopping
Runtime (seconds): 575.0692646503448
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)
MSE: 9.659864321351051
RMSE: 3.1080322265625
MAE: 3.1080322265625
R-squared: nan
[194.01196]
