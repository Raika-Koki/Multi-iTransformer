[32m[I 2025-02-04 19:06:33,046][0m A new study created in memory with name: no-name-7dedf6d2-1205-4f46-aba0-1f063fda8337[0m
[32m[I 2025-02-04 19:07:08,389][0m Trial 0 finished with value: 0.47586050629615784 and parameters: {'observation_period_num': 110, 'train_rates': 0.9612782150511132, 'learning_rate': 9.764804091613675e-06, 'batch_size': 179, 'step_size': 13, 'gamma': 0.899021841090433}. Best is trial 0 with value: 0.47586050629615784.[0m
[32m[I 2025-02-04 19:07:51,916][0m Trial 1 finished with value: 0.1463676035570081 and parameters: {'observation_period_num': 145, 'train_rates': 0.8082154222947421, 'learning_rate': 0.00032078214750039984, 'batch_size': 122, 'step_size': 15, 'gamma': 0.8563941245077652}. Best is trial 1 with value: 0.1463676035570081.[0m
[32m[I 2025-02-04 19:11:06,664][0m Trial 2 finished with value: 0.20364843458937318 and parameters: {'observation_period_num': 211, 'train_rates': 0.9456412693667396, 'learning_rate': 0.0002239731922004577, 'batch_size': 28, 'step_size': 8, 'gamma': 0.8780859880300332}. Best is trial 1 with value: 0.1463676035570081.[0m
[32m[I 2025-02-04 19:11:35,735][0m Trial 3 finished with value: 0.8570578993398013 and parameters: {'observation_period_num': 28, 'train_rates': 0.7035291503958785, 'learning_rate': 1.328191683692686e-06, 'batch_size': 180, 'step_size': 6, 'gamma': 0.8560176917659796}. Best is trial 1 with value: 0.1463676035570081.[0m
[32m[I 2025-02-04 19:12:00,804][0m Trial 4 finished with value: 0.25724935064306564 and parameters: {'observation_period_num': 202, 'train_rates': 0.6714688046732363, 'learning_rate': 0.0002680289117895391, 'batch_size': 185, 'step_size': 4, 'gamma': 0.9390640198661395}. Best is trial 1 with value: 0.1463676035570081.[0m
[32m[I 2025-02-04 19:12:41,331][0m Trial 5 finished with value: 0.6064974794439336 and parameters: {'observation_period_num': 47, 'train_rates': 0.7133445428310354, 'learning_rate': 1.1577082254998734e-05, 'batch_size': 122, 'step_size': 3, 'gamma': 0.8457506914154354}. Best is trial 1 with value: 0.1463676035570081.[0m
[32m[I 2025-02-04 19:14:13,737][0m Trial 6 finished with value: 0.19708009030331264 and parameters: {'observation_period_num': 112, 'train_rates': 0.9692159658850097, 'learning_rate': 1.73003154768153e-05, 'batch_size': 63, 'step_size': 14, 'gamma': 0.9618310820387286}. Best is trial 1 with value: 0.1463676035570081.[0m
[32m[I 2025-02-04 19:16:43,598][0m Trial 7 finished with value: 0.23592817268389113 and parameters: {'observation_period_num': 172, 'train_rates': 0.8777483631433539, 'learning_rate': 0.0008226003704046296, 'batch_size': 35, 'step_size': 2, 'gamma': 0.9745847539122618}. Best is trial 1 with value: 0.1463676035570081.[0m
[32m[I 2025-02-04 19:17:19,006][0m Trial 8 finished with value: 0.6836916557346208 and parameters: {'observation_period_num': 190, 'train_rates': 0.8184018120366734, 'learning_rate': 1.3691227393308625e-06, 'batch_size': 154, 'step_size': 10, 'gamma': 0.8773949648068818}. Best is trial 1 with value: 0.1463676035570081.[0m
[32m[I 2025-02-04 19:18:54,718][0m Trial 9 finished with value: 0.3677773832134545 and parameters: {'observation_period_num': 223, 'train_rates': 0.7177420830423803, 'learning_rate': 3.3527993998563756e-05, 'batch_size': 47, 'step_size': 3, 'gamma': 0.9013963644157665}. Best is trial 1 with value: 0.1463676035570081.[0m
[32m[I 2025-02-04 19:19:14,586][0m Trial 10 finished with value: 0.3034643513657326 and parameters: {'observation_period_num': 148, 'train_rates': 0.6166226379999564, 'learning_rate': 8.113217729353945e-05, 'batch_size': 248, 'step_size': 11, 'gamma': 0.7632039041914284}. Best is trial 1 with value: 0.1463676035570081.[0m
[32m[I 2025-02-04 19:20:14,274][0m Trial 11 finished with value: 0.23521187174435398 and parameters: {'observation_period_num': 85, 'train_rates': 0.8559452307625813, 'learning_rate': 9.504712985044623e-06, 'batch_size': 94, 'step_size': 15, 'gamma': 0.8063396520754823}. Best is trial 1 with value: 0.1463676035570081.[0m
[32m[I 2025-02-04 19:21:21,930][0m Trial 12 finished with value: 0.3844339435556495 and parameters: {'observation_period_num': 113, 'train_rates': 0.9118243950723443, 'learning_rate': 4.578629607473056e-05, 'batch_size': 86, 'step_size': 15, 'gamma': 0.9649653024677015}. Best is trial 1 with value: 0.1463676035570081.[0m
[32m[I 2025-02-04 19:22:32,140][0m Trial 13 finished with value: 0.19882975474876516 and parameters: {'observation_period_num': 80, 'train_rates': 0.7810528532566358, 'learning_rate': 0.00012435032980939368, 'batch_size': 74, 'step_size': 12, 'gamma': 0.8278372072977817}. Best is trial 1 with value: 0.1463676035570081.[0m
[32m[I 2025-02-04 19:23:14,410][0m Trial 14 finished with value: 0.26042812818299427 and parameters: {'observation_period_num': 250, 'train_rates': 0.7925140903271373, 'learning_rate': 0.0007884305054781222, 'batch_size': 122, 'step_size': 14, 'gamma': 0.9239463807018888}. Best is trial 1 with value: 0.1463676035570081.[0m
[32m[I 2025-02-04 19:24:33,100][0m Trial 15 finished with value: 0.5682078003883362 and parameters: {'observation_period_num': 153, 'train_rates': 0.9875376209786769, 'learning_rate': 4.03255129400702e-06, 'batch_size': 75, 'step_size': 9, 'gamma': 0.79248911310438}. Best is trial 1 with value: 0.1463676035570081.[0m
[32m[I 2025-02-04 19:25:14,008][0m Trial 16 finished with value: 0.2442940249265684 and parameters: {'observation_period_num': 136, 'train_rates': 0.8975813959913307, 'learning_rate': 1.588575588698754e-05, 'batch_size': 141, 'step_size': 13, 'gamma': 0.9440428464377502}. Best is trial 1 with value: 0.1463676035570081.[0m
[32m[I 2025-02-04 19:26:06,948][0m Trial 17 finished with value: 0.12428514094243193 and parameters: {'observation_period_num': 66, 'train_rates': 0.8381477319653542, 'learning_rate': 0.00034488384026621076, 'batch_size': 107, 'step_size': 7, 'gamma': 0.9890230451041908}. Best is trial 17 with value: 0.12428514094243193.[0m
[32m[I 2025-02-04 19:26:35,069][0m Trial 18 finished with value: 0.04366989450733608 and parameters: {'observation_period_num': 5, 'train_rates': 0.8361691036021526, 'learning_rate': 0.0003114733217016507, 'batch_size': 223, 'step_size': 6, 'gamma': 0.9886379439056633}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:26:57,458][0m Trial 19 finished with value: 0.1638349933552374 and parameters: {'observation_period_num': 5, 'train_rates': 0.7583167845530592, 'learning_rate': 0.00045253415224422074, 'batch_size': 251, 'step_size': 6, 'gamma': 0.9818870732790049}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:27:23,575][0m Trial 20 finished with value: 0.10838177221586802 and parameters: {'observation_period_num': 59, 'train_rates': 0.8408239069581493, 'learning_rate': 0.00010592840654184037, 'batch_size': 230, 'step_size': 6, 'gamma': 0.9894422893165977}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:27:51,168][0m Trial 21 finished with value: 0.09418386595995248 and parameters: {'observation_period_num': 55, 'train_rates': 0.8481176874913041, 'learning_rate': 0.00010526218566888783, 'batch_size': 222, 'step_size': 6, 'gamma': 0.9891565992181176}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:28:21,894][0m Trial 22 finished with value: 0.059277030086377636 and parameters: {'observation_period_num': 6, 'train_rates': 0.913232796397619, 'learning_rate': 9.193674259455483e-05, 'batch_size': 221, 'step_size': 5, 'gamma': 0.9493144044609617}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:28:52,435][0m Trial 23 finished with value: 0.06285083274892037 and parameters: {'observation_period_num': 6, 'train_rates': 0.9203112308686433, 'learning_rate': 6.737671285120848e-05, 'batch_size': 216, 'step_size': 4, 'gamma': 0.9412501536717511}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:29:23,828][0m Trial 24 finished with value: 0.10988649725914001 and parameters: {'observation_period_num': 6, 'train_rates': 0.9314865926912886, 'learning_rate': 5.218858390188054e-05, 'batch_size': 204, 'step_size': 1, 'gamma': 0.9453299438124904}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:29:53,923][0m Trial 25 finished with value: 0.04941221354225269 and parameters: {'observation_period_num': 28, 'train_rates': 0.8849525663306798, 'learning_rate': 0.00017706080072260144, 'batch_size': 203, 'step_size': 4, 'gamma': 0.9220955933276568}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:30:26,034][0m Trial 26 finished with value: 0.05491212525817214 and parameters: {'observation_period_num': 31, 'train_rates': 0.8958218380148202, 'learning_rate': 0.0001668593191436795, 'batch_size': 199, 'step_size': 4, 'gamma': 0.9590157388959344}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:31:03,529][0m Trial 27 finished with value: 0.12632662396351715 and parameters: {'observation_period_num': 36, 'train_rates': 0.876490592309503, 'learning_rate': 0.00014917017644663875, 'batch_size': 161, 'step_size': 1, 'gamma': 0.9126043116914574}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:31:33,530][0m Trial 28 finished with value: 0.05138495179303622 and parameters: {'observation_period_num': 30, 'train_rates': 0.8790658392145253, 'learning_rate': 0.000541150978965239, 'batch_size': 201, 'step_size': 4, 'gamma': 0.9605568346684796}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:32:06,698][0m Trial 29 finished with value: 0.23375416136142652 and parameters: {'observation_period_num': 87, 'train_rates': 0.7595293877842967, 'learning_rate': 0.0006198355871304338, 'batch_size': 165, 'step_size': 8, 'gamma': 0.921204686860609}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:32:38,472][0m Trial 30 finished with value: 0.047633398623987175 and parameters: {'observation_period_num': 27, 'train_rates': 0.8813150204997604, 'learning_rate': 0.0004879310978725038, 'batch_size': 196, 'step_size': 5, 'gamma': 0.8959123060108735}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:33:10,696][0m Trial 31 finished with value: 0.046035920417579056 and parameters: {'observation_period_num': 25, 'train_rates': 0.8645564198375194, 'learning_rate': 0.0005509547627713362, 'batch_size': 192, 'step_size': 5, 'gamma': 0.9041402826537679}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:33:37,336][0m Trial 32 finished with value: 0.05013453747348592 and parameters: {'observation_period_num': 21, 'train_rates': 0.8152406337544367, 'learning_rate': 0.0004205770587110537, 'batch_size': 237, 'step_size': 5, 'gamma': 0.8923426131151707}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:34:09,873][0m Trial 33 finished with value: 0.0631038120319677 and parameters: {'observation_period_num': 46, 'train_rates': 0.8669794382627408, 'learning_rate': 0.0002497480765948862, 'batch_size': 186, 'step_size': 7, 'gamma': 0.8972034057322348}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:34:39,315][0m Trial 34 finished with value: 0.07905120402574539 and parameters: {'observation_period_num': 72, 'train_rates': 0.9447423737669118, 'learning_rate': 0.0009496372340972305, 'batch_size': 210, 'step_size': 3, 'gamma': 0.8662137929245332}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:35:14,641][0m Trial 35 finished with value: 0.054460305692130374 and parameters: {'observation_period_num': 20, 'train_rates': 0.8213743984136461, 'learning_rate': 0.0001960528760754065, 'batch_size': 169, 'step_size': 5, 'gamma': 0.928043585951187}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:35:46,841][0m Trial 36 finished with value: 0.12343622058235257 and parameters: {'observation_period_num': 98, 'train_rates': 0.8941984431637617, 'learning_rate': 0.00032035703428826744, 'batch_size': 191, 'step_size': 8, 'gamma': 0.8873667694710722}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:36:13,194][0m Trial 37 finished with value: 0.05536344475937958 and parameters: {'observation_period_num': 45, 'train_rates': 0.8311916847493827, 'learning_rate': 0.0005358460929230194, 'batch_size': 236, 'step_size': 7, 'gamma': 0.8449569141771791}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:36:49,373][0m Trial 38 finished with value: 0.07932578772306442 and parameters: {'observation_period_num': 21, 'train_rates': 0.9597612338802288, 'learning_rate': 0.00023760806979704612, 'batch_size': 176, 'step_size': 2, 'gamma': 0.9082695150656768}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:37:27,107][0m Trial 39 finished with value: 0.19374237225933388 and parameters: {'observation_period_num': 43, 'train_rates': 0.78106697063017, 'learning_rate': 0.0009998258853954015, 'batch_size': 142, 'step_size': 5, 'gamma': 0.8687386757252288}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:37:59,264][0m Trial 40 finished with value: 0.06889509138225311 and parameters: {'observation_period_num': 57, 'train_rates': 0.8627297504852981, 'learning_rate': 0.0003527901901872134, 'batch_size': 190, 'step_size': 3, 'gamma': 0.8865741957223007}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:38:23,646][0m Trial 41 finished with value: 0.18257403506764344 and parameters: {'observation_period_num': 18, 'train_rates': 0.7903602717490444, 'learning_rate': 0.0003856148402776688, 'batch_size': 236, 'step_size': 5, 'gamma': 0.8906140475299346}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:38:47,882][0m Trial 42 finished with value: 0.04368203944630093 and parameters: {'observation_period_num': 21, 'train_rates': 0.8158128216103776, 'learning_rate': 0.0006230661621099064, 'batch_size': 254, 'step_size': 5, 'gamma': 0.9112296792377458}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:39:12,034][0m Trial 43 finished with value: 0.20144034741273106 and parameters: {'observation_period_num': 34, 'train_rates': 0.7643554094943128, 'learning_rate': 0.000647164053409664, 'batch_size': 247, 'step_size': 6, 'gamma': 0.9316666675615822}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:39:40,416][0m Trial 44 finished with value: 0.07265691894670608 and parameters: {'observation_period_num': 25, 'train_rates': 0.8062803408798925, 'learning_rate': 0.00019739333124696947, 'batch_size': 211, 'step_size': 2, 'gamma': 0.9101090177941591}. Best is trial 18 with value: 0.04366989450733608.[0m
[32m[I 2025-02-04 19:40:08,170][0m Trial 45 finished with value: 0.042287941609119986 and parameters: {'observation_period_num': 17, 'train_rates': 0.8527349635526406, 'learning_rate': 0.0006965061663794121, 'batch_size': 223, 'step_size': 4, 'gamma': 0.8750392003187452}. Best is trial 45 with value: 0.042287941609119986.[0m
[32m[I 2025-02-04 19:40:30,821][0m Trial 46 finished with value: 0.15974301441381109 and parameters: {'observation_period_num': 15, 'train_rates': 0.733603670794167, 'learning_rate': 0.0006749751429506248, 'batch_size': 256, 'step_size': 7, 'gamma': 0.8524862054442945}. Best is trial 45 with value: 0.042287941609119986.[0m
[32m[I 2025-02-04 19:40:54,227][0m Trial 47 finished with value: 0.15795157513184868 and parameters: {'observation_period_num': 41, 'train_rates': 0.6723492030744292, 'learning_rate': 0.00028297022857022477, 'batch_size': 226, 'step_size': 8, 'gamma': 0.8761913779633936}. Best is trial 45 with value: 0.042287941609119986.[0m
[32m[I 2025-02-04 19:41:17,877][0m Trial 48 finished with value: 0.07084856987480194 and parameters: {'observation_period_num': 68, 'train_rates': 0.8495921009246294, 'learning_rate': 0.0007705615436188257, 'batch_size': 245, 'step_size': 4, 'gamma': 0.8277078382427966}. Best is trial 45 with value: 0.042287941609119986.[0m
[32m[I 2025-02-04 19:41:48,540][0m Trial 49 finished with value: 0.1281711635413074 and parameters: {'observation_period_num': 166, 'train_rates': 0.8037254644683527, 'learning_rate': 0.000510525747398132, 'batch_size': 178, 'step_size': 3, 'gamma': 0.8606862521432754}. Best is trial 45 with value: 0.042287941609119986.[0m
最適ハイパーパラメータが見つかりました
最適なハイパーパラメータが best_hyperparameters_GOOG_iTransformer_noMSTL.json に保存されました
Epoch 1/300, Loss: 0.5056 | 0.2600
Epoch 2/300, Loss: 0.2716 | 0.2383
Epoch 3/300, Loss: 0.2849 | 0.5308
Epoch 4/300, Loss: 0.2684 | 0.2565
Epoch 5/300, Loss: 0.2148 | 0.2531
Epoch 6/300, Loss: 0.1762 | 0.1808
Epoch 7/300, Loss: 0.1496 | 0.1411
Epoch 8/300, Loss: 0.1572 | 0.1745
Epoch 9/300, Loss: 0.1639 | 0.1992
Epoch 10/300, Loss: 0.1738 | 0.1415
Epoch 11/300, Loss: 0.1701 | 0.1844
Epoch 12/300, Loss: 0.1640 | 0.1396
Epoch 13/300, Loss: 0.1429 | 0.1954
Epoch 14/300, Loss: 0.1353 | 0.1060
Epoch 15/300, Loss: 0.1240 | 0.1760
Epoch 16/300, Loss: 0.1152 | 0.0999
Epoch 17/300, Loss: 0.1120 | 0.1131
Epoch 18/300, Loss: 0.1082 | 0.0906
Epoch 19/300, Loss: 0.1074 | 0.0920
Epoch 20/300, Loss: 0.1045 | 0.0808
Epoch 21/300, Loss: 0.1035 | 0.0833
Epoch 22/300, Loss: 0.1021 | 0.0752
Epoch 23/300, Loss: 0.1020 | 0.0794
Epoch 24/300, Loss: 0.1004 | 0.0718
Epoch 25/300, Loss: 0.1018 | 0.0810
Epoch 26/300, Loss: 0.0996 | 0.0697
Epoch 27/300, Loss: 0.1013 | 0.0849
Epoch 28/300, Loss: 0.0982 | 0.0683
Epoch 29/300, Loss: 0.0990 | 0.0792
Epoch 30/300, Loss: 0.0965 | 0.0669
Epoch 31/300, Loss: 0.0967 | 0.0706
Epoch 32/300, Loss: 0.0953 | 0.0660
Epoch 33/300, Loss: 0.0953 | 0.0664
Epoch 34/300, Loss: 0.0946 | 0.0656
Epoch 35/300, Loss: 0.0943 | 0.0647
Epoch 36/300, Loss: 0.0940 | 0.0650
Epoch 37/300, Loss: 0.0936 | 0.0640
Epoch 38/300, Loss: 0.0934 | 0.0642
Epoch 39/300, Loss: 0.0931 | 0.0635
Epoch 40/300, Loss: 0.0928 | 0.0635
Epoch 41/300, Loss: 0.0926 | 0.0631
Epoch 42/300, Loss: 0.0924 | 0.0630
Epoch 43/300, Loss: 0.0922 | 0.0627
Epoch 44/300, Loss: 0.0920 | 0.0626
Epoch 45/300, Loss: 0.0918 | 0.0624
Epoch 46/300, Loss: 0.0916 | 0.0622
Epoch 47/300, Loss: 0.0915 | 0.0620
Epoch 48/300, Loss: 0.0913 | 0.0619
Epoch 49/300, Loss: 0.0912 | 0.0618
Epoch 50/300, Loss: 0.0910 | 0.0616
Epoch 51/300, Loss: 0.0909 | 0.0615
Epoch 52/300, Loss: 0.0908 | 0.0614
Epoch 53/300, Loss: 0.0907 | 0.0613
Epoch 54/300, Loss: 0.0906 | 0.0612
Epoch 55/300, Loss: 0.0905 | 0.0611
Epoch 56/300, Loss: 0.0904 | 0.0610
Epoch 57/300, Loss: 0.0903 | 0.0609
Epoch 58/300, Loss: 0.0902 | 0.0609
Epoch 59/300, Loss: 0.0902 | 0.0608
Epoch 60/300, Loss: 0.0901 | 0.0607
Epoch 61/300, Loss: 0.0900 | 0.0606
Epoch 62/300, Loss: 0.0900 | 0.0606
Epoch 63/300, Loss: 0.0899 | 0.0605
Epoch 64/300, Loss: 0.0899 | 0.0605
Epoch 65/300, Loss: 0.0898 | 0.0604
Epoch 66/300, Loss: 0.0898 | 0.0604
Epoch 67/300, Loss: 0.0897 | 0.0603
Epoch 68/300, Loss: 0.0897 | 0.0603
Epoch 69/300, Loss: 0.0896 | 0.0602
Epoch 70/300, Loss: 0.0896 | 0.0602
Epoch 71/300, Loss: 0.0896 | 0.0602
Epoch 72/300, Loss: 0.0895 | 0.0601
Epoch 73/300, Loss: 0.0895 | 0.0601
Epoch 74/300, Loss: 0.0895 | 0.0601
Epoch 75/300, Loss: 0.0894 | 0.0601
Epoch 76/300, Loss: 0.0894 | 0.0600
Epoch 77/300, Loss: 0.0894 | 0.0600
Epoch 78/300, Loss: 0.0894 | 0.0600
Epoch 79/300, Loss: 0.0893 | 0.0600
Epoch 80/300, Loss: 0.0893 | 0.0599
Epoch 81/300, Loss: 0.0893 | 0.0599
Epoch 82/300, Loss: 0.0893 | 0.0599
Epoch 83/300, Loss: 0.0893 | 0.0599
Epoch 84/300, Loss: 0.0892 | 0.0599
Epoch 85/300, Loss: 0.0892 | 0.0599
Epoch 86/300, Loss: 0.0892 | 0.0598
Epoch 87/300, Loss: 0.0892 | 0.0598
Epoch 88/300, Loss: 0.0892 | 0.0598
Epoch 89/300, Loss: 0.0892 | 0.0598
Epoch 90/300, Loss: 0.0892 | 0.0598
Epoch 91/300, Loss: 0.0892 | 0.0598
Epoch 92/300, Loss: 0.0892 | 0.0598
Epoch 93/300, Loss: 0.0891 | 0.0598
Epoch 94/300, Loss: 0.0891 | 0.0598
Epoch 95/300, Loss: 0.0891 | 0.0597
Epoch 96/300, Loss: 0.0891 | 0.0597
Epoch 97/300, Loss: 0.0891 | 0.0597
Epoch 98/300, Loss: 0.0891 | 0.0597
Epoch 99/300, Loss: 0.0891 | 0.0597
Epoch 100/300, Loss: 0.0891 | 0.0597
Epoch 101/300, Loss: 0.0891 | 0.0597
Epoch 102/300, Loss: 0.0891 | 0.0597
Epoch 103/300, Loss: 0.0891 | 0.0597
Epoch 104/300, Loss: 0.0891 | 0.0597
Epoch 105/300, Loss: 0.0891 | 0.0597
Epoch 106/300, Loss: 0.0891 | 0.0597
Epoch 107/300, Loss: 0.0891 | 0.0597
Epoch 108/300, Loss: 0.0891 | 0.0597
Epoch 109/300, Loss: 0.0891 | 0.0597
Epoch 110/300, Loss: 0.0890 | 0.0597
Epoch 111/300, Loss: 0.0890 | 0.0597
Epoch 112/300, Loss: 0.0890 | 0.0597
Epoch 113/300, Loss: 0.0890 | 0.0597
Epoch 114/300, Loss: 0.0890 | 0.0597
Epoch 115/300, Loss: 0.0890 | 0.0597
Epoch 116/300, Loss: 0.0890 | 0.0597
Epoch 117/300, Loss: 0.0890 | 0.0596
Epoch 118/300, Loss: 0.0890 | 0.0596
Epoch 119/300, Loss: 0.0890 | 0.0596
Epoch 120/300, Loss: 0.0890 | 0.0596
Epoch 121/300, Loss: 0.0890 | 0.0596
Epoch 122/300, Loss: 0.0890 | 0.0596
Epoch 123/300, Loss: 0.0890 | 0.0596
Epoch 124/300, Loss: 0.0890 | 0.0596
Epoch 125/300, Loss: 0.0890 | 0.0596
Epoch 126/300, Loss: 0.0890 | 0.0596
Epoch 127/300, Loss: 0.0890 | 0.0596
Epoch 128/300, Loss: 0.0890 | 0.0596
Epoch 129/300, Loss: 0.0890 | 0.0596
Epoch 130/300, Loss: 0.0890 | 0.0596
Epoch 131/300, Loss: 0.0890 | 0.0596
Epoch 132/300, Loss: 0.0890 | 0.0596
Epoch 133/300, Loss: 0.0890 | 0.0596
Epoch 134/300, Loss: 0.0890 | 0.0596
Epoch 135/300, Loss: 0.0890 | 0.0596
Epoch 136/300, Loss: 0.0890 | 0.0596
Epoch 137/300, Loss: 0.0890 | 0.0596
Epoch 138/300, Loss: 0.0890 | 0.0596
Epoch 139/300, Loss: 0.0890 | 0.0596
Epoch 140/300, Loss: 0.0890 | 0.0596
Epoch 141/300, Loss: 0.0890 | 0.0596
Epoch 142/300, Loss: 0.0890 | 0.0596
Epoch 143/300, Loss: 0.0890 | 0.0596
Epoch 144/300, Loss: 0.0890 | 0.0596
Epoch 145/300, Loss: 0.0890 | 0.0596
Epoch 146/300, Loss: 0.0890 | 0.0596
Epoch 147/300, Loss: 0.0890 | 0.0596
Epoch 148/300, Loss: 0.0890 | 0.0596
Epoch 149/300, Loss: 0.0890 | 0.0596
Epoch 150/300, Loss: 0.0890 | 0.0596
Epoch 151/300, Loss: 0.0890 | 0.0596
Epoch 152/300, Loss: 0.0890 | 0.0596
Epoch 153/300, Loss: 0.0890 | 0.0596
Epoch 154/300, Loss: 0.0890 | 0.0596
Epoch 155/300, Loss: 0.0890 | 0.0596
Epoch 156/300, Loss: 0.0890 | 0.0596
Epoch 157/300, Loss: 0.0890 | 0.0596
Epoch 158/300, Loss: 0.0890 | 0.0596
Epoch 159/300, Loss: 0.0890 | 0.0596
Epoch 160/300, Loss: 0.0890 | 0.0596
Epoch 161/300, Loss: 0.0890 | 0.0596
Epoch 162/300, Loss: 0.0890 | 0.0596
Epoch 163/300, Loss: 0.0890 | 0.0596
Epoch 164/300, Loss: 0.0890 | 0.0596
Epoch 165/300, Loss: 0.0890 | 0.0596
Epoch 166/300, Loss: 0.0890 | 0.0596
Epoch 167/300, Loss: 0.0890 | 0.0596
Epoch 168/300, Loss: 0.0890 | 0.0596
Epoch 169/300, Loss: 0.0890 | 0.0596
Epoch 170/300, Loss: 0.0890 | 0.0596
Epoch 171/300, Loss: 0.0890 | 0.0596
Epoch 172/300, Loss: 0.0890 | 0.0596
Epoch 173/300, Loss: 0.0890 | 0.0596
Epoch 174/300, Loss: 0.0890 | 0.0596
Epoch 175/300, Loss: 0.0890 | 0.0596
Epoch 176/300, Loss: 0.0890 | 0.0596
Epoch 177/300, Loss: 0.0890 | 0.0596
Epoch 178/300, Loss: 0.0890 | 0.0596
Epoch 179/300, Loss: 0.0890 | 0.0596
Epoch 180/300, Loss: 0.0890 | 0.0596
Epoch 181/300, Loss: 0.0890 | 0.0596
Epoch 182/300, Loss: 0.0890 | 0.0596
Epoch 183/300, Loss: 0.0890 | 0.0596
Epoch 184/300, Loss: 0.0890 | 0.0596
Epoch 185/300, Loss: 0.0890 | 0.0596
Epoch 186/300, Loss: 0.0890 | 0.0596
Epoch 187/300, Loss: 0.0890 | 0.0596
Epoch 188/300, Loss: 0.0890 | 0.0596
Epoch 189/300, Loss: 0.0890 | 0.0596
Epoch 190/300, Loss: 0.0890 | 0.0596
Epoch 191/300, Loss: 0.0890 | 0.0596
Epoch 192/300, Loss: 0.0890 | 0.0596
Early stopping
Runtime (seconds): 54.54306602478027
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)
MSE: 64.32634269096889
RMSE: 8.020370483398438
MAE: 8.020370483398438
R-squared: nan
[162.40628]
