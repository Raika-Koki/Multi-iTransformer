[32m[I 2025-02-06 14:19:11,195][0m A new study created in memory with name: no-name-706379c6-e73a-440d-b360-a74c256703ad[0m
[32m[I 2025-02-06 14:19:49,509][0m Trial 0 finished with value: 0.22385229607871915 and parameters: {'observation_period_num': 169, 'train_rates': 0.8274554122851937, 'learning_rate': 0.00046044565366138254, 'batch_size': 142, 'step_size': 15, 'gamma': 0.9668745030989031}. Best is trial 0 with value: 0.22385229607871915.[0m
[32m[I 2025-02-06 14:21:20,682][0m Trial 1 finished with value: 0.21778871157230476 and parameters: {'observation_period_num': 213, 'train_rates': 0.8318189407652573, 'learning_rate': 5.187690088737119e-05, 'batch_size': 56, 'step_size': 8, 'gamma': 0.9616571363863581}. Best is trial 1 with value: 0.21778871157230476.[0m
[32m[I 2025-02-06 14:21:49,242][0m Trial 2 finished with value: 0.14466976417125296 and parameters: {'observation_period_num': 114, 'train_rates': 0.8183149560379936, 'learning_rate': 7.833532944086256e-05, 'batch_size': 211, 'step_size': 15, 'gamma': 0.9018670128944044}. Best is trial 2 with value: 0.14466976417125296.[0m
[32m[I 2025-02-06 14:24:00,995][0m Trial 3 finished with value: 0.12539273939249707 and parameters: {'observation_period_num': 96, 'train_rates': 0.9437161941886092, 'learning_rate': 0.0001383067679462686, 'batch_size': 44, 'step_size': 11, 'gamma': 0.979727083988132}. Best is trial 3 with value: 0.12539273939249707.[0m
[32m[I 2025-02-06 14:25:05,280][0m Trial 4 finished with value: 0.4885490265759555 and parameters: {'observation_period_num': 243, 'train_rates': 0.9159091642775271, 'learning_rate': 1.243867174738328e-05, 'batch_size': 84, 'step_size': 8, 'gamma': 0.7905545506135842}. Best is trial 3 with value: 0.12539273939249707.[0m
[32m[I 2025-02-06 14:25:30,115][0m Trial 5 finished with value: 0.40942326885854413 and parameters: {'observation_period_num': 91, 'train_rates': 0.7121740324916541, 'learning_rate': 1.3714154374377613e-05, 'batch_size': 223, 'step_size': 11, 'gamma': 0.8989098060079223}. Best is trial 3 with value: 0.12539273939249707.[0m
[32m[I 2025-02-06 14:26:45,141][0m Trial 6 finished with value: 0.19246504550115973 and parameters: {'observation_period_num': 185, 'train_rates': 0.8312779580679195, 'learning_rate': 2.208593461797643e-05, 'batch_size': 70, 'step_size': 7, 'gamma': 0.8810140946005232}. Best is trial 3 with value: 0.12539273939249707.[0m
[32m[I 2025-02-06 14:27:08,714][0m Trial 7 finished with value: 0.3330494211164343 and parameters: {'observation_period_num': 172, 'train_rates': 0.6544779247505733, 'learning_rate': 0.00010912487574416663, 'batch_size': 219, 'step_size': 8, 'gamma': 0.7790149060638654}. Best is trial 3 with value: 0.12539273939249707.[0m
[32m[I 2025-02-06 14:30:21,905][0m Trial 8 finished with value: 0.26875179419069156 and parameters: {'observation_period_num': 140, 'train_rates': 0.7241366060079204, 'learning_rate': 1.1517557255368035e-05, 'batch_size': 24, 'step_size': 13, 'gamma': 0.8263785712167785}. Best is trial 3 with value: 0.12539273939249707.[0m
[32m[I 2025-02-06 14:32:26,105][0m Trial 9 finished with value: 0.15584548817066377 and parameters: {'observation_period_num': 117, 'train_rates': 0.9419837012082075, 'learning_rate': 4.3940879084965496e-05, 'batch_size': 46, 'step_size': 8, 'gamma': 0.7551095678445028}. Best is trial 3 with value: 0.12539273939249707.[0m
[32m[I 2025-02-06 14:33:14,918][0m Trial 10 finished with value: 1.5632688999176025 and parameters: {'observation_period_num': 23, 'train_rates': 0.9893038500371296, 'learning_rate': 1.4416394299102507e-06, 'batch_size': 129, 'step_size': 1, 'gamma': 0.93821046766189}. Best is trial 3 with value: 0.12539273939249707.[0m
[32m[I 2025-02-06 14:33:48,694][0m Trial 11 finished with value: 0.11031229509956463 and parameters: {'observation_period_num': 62, 'train_rates': 0.8979240544875917, 'learning_rate': 0.0003011073392112724, 'batch_size': 181, 'step_size': 12, 'gamma': 0.9187076748982451}. Best is trial 11 with value: 0.11031229509956463.[0m
[32m[I 2025-02-06 14:34:26,831][0m Trial 12 finished with value: 0.11565069427777981 and parameters: {'observation_period_num': 44, 'train_rates': 0.9018222940181964, 'learning_rate': 0.0008321288398854739, 'batch_size': 162, 'step_size': 11, 'gamma': 0.9301211525785184}. Best is trial 11 with value: 0.11031229509956463.[0m
[32m[I 2025-02-06 14:35:00,944][0m Trial 13 finished with value: 0.08577788003047558 and parameters: {'observation_period_num': 35, 'train_rates': 0.8929151970360483, 'learning_rate': 0.000942242230637305, 'batch_size': 183, 'step_size': 11, 'gamma': 0.9288469197443172}. Best is trial 13 with value: 0.08577788003047558.[0m
[32m[I 2025-02-06 14:35:31,990][0m Trial 14 finished with value: 0.07199336222313732 and parameters: {'observation_period_num': 61, 'train_rates': 0.8819248650111072, 'learning_rate': 0.0002970820143305713, 'batch_size': 185, 'step_size': 5, 'gamma': 0.8695538236696323}. Best is trial 14 with value: 0.07199336222313732.[0m
[32m[I 2025-02-06 14:35:53,687][0m Trial 15 finished with value: 0.1686030737220907 and parameters: {'observation_period_num': 5, 'train_rates': 0.7610127765471598, 'learning_rate': 0.0007659879931291241, 'batch_size': 254, 'step_size': 4, 'gamma': 0.8455606766179513}. Best is trial 14 with value: 0.07199336222313732.[0m
[32m[I 2025-02-06 14:36:48,253][0m Trial 16 finished with value: 0.06067968710609104 and parameters: {'observation_period_num': 62, 'train_rates': 0.8746085791971888, 'learning_rate': 0.00024392591356239436, 'batch_size': 104, 'step_size': 5, 'gamma': 0.8503589169461409}. Best is trial 16 with value: 0.06067968710609104.[0m
[32m[I 2025-02-06 14:37:40,714][0m Trial 17 finished with value: 0.05945719564022319 and parameters: {'observation_period_num': 67, 'train_rates': 0.8671867633947121, 'learning_rate': 0.00024551725375814953, 'batch_size': 106, 'step_size': 5, 'gamma': 0.8470482081644402}. Best is trial 17 with value: 0.05945719564022319.[0m
[32m[I 2025-02-06 14:38:31,057][0m Trial 18 finished with value: 0.24210889028303278 and parameters: {'observation_period_num': 70, 'train_rates': 0.7824667564148922, 'learning_rate': 0.0001913978820132907, 'batch_size': 104, 'step_size': 2, 'gamma': 0.8267416569896489}. Best is trial 17 with value: 0.05945719564022319.[0m
[32m[I 2025-02-06 14:39:13,561][0m Trial 19 finished with value: 0.9767601869859532 and parameters: {'observation_period_num': 141, 'train_rates': 0.6102637297787226, 'learning_rate': 3.808153625193642e-06, 'batch_size': 105, 'step_size': 4, 'gamma': 0.854921498409571}. Best is trial 17 with value: 0.05945719564022319.[0m
[32m[I 2025-02-06 14:40:07,955][0m Trial 20 finished with value: 0.0658061846697645 and parameters: {'observation_period_num': 81, 'train_rates': 0.8566745298821942, 'learning_rate': 0.00023521217178645157, 'batch_size': 107, 'step_size': 6, 'gamma': 0.8085391488441164}. Best is trial 17 with value: 0.05945719564022319.[0m
[32m[I 2025-02-06 14:40:58,893][0m Trial 21 finished with value: 0.07648271458349964 and parameters: {'observation_period_num': 86, 'train_rates': 0.8532003368854452, 'learning_rate': 0.0002336103719689395, 'batch_size': 110, 'step_size': 6, 'gamma': 0.8109523049613762}. Best is trial 17 with value: 0.05945719564022319.[0m
[32m[I 2025-02-06 14:42:04,543][0m Trial 22 finished with value: 0.06275534917887185 and parameters: {'observation_period_num': 44, 'train_rates': 0.8580326760627458, 'learning_rate': 0.0004362366388035577, 'batch_size': 86, 'step_size': 3, 'gamma': 0.805985662034027}. Best is trial 17 with value: 0.05945719564022319.[0m
[32m[I 2025-02-06 14:43:12,656][0m Trial 23 finished with value: 0.05987015981728982 and parameters: {'observation_period_num': 48, 'train_rates': 0.7855873933044225, 'learning_rate': 0.0004263990125887271, 'batch_size': 78, 'step_size': 3, 'gamma': 0.8377192220555515}. Best is trial 17 with value: 0.05945719564022319.[0m
[32m[I 2025-02-06 14:43:52,756][0m Trial 24 finished with value: 0.18672408627432438 and parameters: {'observation_period_num': 6, 'train_rates': 0.7542986886455672, 'learning_rate': 9.166021134545806e-05, 'batch_size': 134, 'step_size': 3, 'gamma': 0.8476712476990251}. Best is trial 17 with value: 0.05945719564022319.[0m
[32m[I 2025-02-06 14:44:58,852][0m Trial 25 finished with value: 0.08315984102395865 and parameters: {'observation_period_num': 58, 'train_rates': 0.7874902490510012, 'learning_rate': 0.0004927701279083047, 'batch_size': 80, 'step_size': 1, 'gamma': 0.8722791396628093}. Best is trial 17 with value: 0.05945719564022319.[0m
[32m[I 2025-02-06 14:48:11,866][0m Trial 26 finished with value: 0.14641350467627387 and parameters: {'observation_period_num': 23, 'train_rates': 0.7012684444309172, 'learning_rate': 0.00016708759108716184, 'batch_size': 25, 'step_size': 5, 'gamma': 0.8390693589147334}. Best is trial 17 with value: 0.05945719564022319.[0m
[32m[I 2025-02-06 14:48:55,572][0m Trial 27 finished with value: 0.20593139851310602 and parameters: {'observation_period_num': 105, 'train_rates': 0.8005521244663052, 'learning_rate': 6.508053856877121e-05, 'batch_size': 123, 'step_size': 3, 'gamma': 0.8610051185189086}. Best is trial 17 with value: 0.05945719564022319.[0m
[32m[I 2025-02-06 14:49:37,954][0m Trial 28 finished with value: 0.13360287249088287 and parameters: {'observation_period_num': 74, 'train_rates': 0.978227882087246, 'learning_rate': 0.0005170620844184211, 'batch_size': 151, 'step_size': 6, 'gamma': 0.8859873784808874}. Best is trial 17 with value: 0.05945719564022319.[0m
[32m[I 2025-02-06 14:51:06,772][0m Trial 29 finished with value: 0.2607973102066252 and parameters: {'observation_period_num': 140, 'train_rates': 0.9369617620125111, 'learning_rate': 3.483351115492597e-05, 'batch_size': 65, 'step_size': 4, 'gamma': 0.8314814847048922}. Best is trial 17 with value: 0.05945719564022319.[0m
[32m[I 2025-02-06 14:52:02,178][0m Trial 30 finished with value: 0.20701993540834984 and parameters: {'observation_period_num': 48, 'train_rates': 0.7539696053751459, 'learning_rate': 0.00048690941881299876, 'batch_size': 95, 'step_size': 2, 'gamma': 0.7718909332628728}. Best is trial 17 with value: 0.05945719564022319.[0m
[32m[I 2025-02-06 14:53:08,932][0m Trial 31 finished with value: 0.05433203178629167 and parameters: {'observation_period_num': 29, 'train_rates': 0.8659854197819113, 'learning_rate': 0.000329492496653607, 'batch_size': 84, 'step_size': 3, 'gamma': 0.8086343036481624}. Best is trial 31 with value: 0.05433203178629167.[0m
[32m[I 2025-02-06 14:53:57,367][0m Trial 32 finished with value: 0.04802614520361394 and parameters: {'observation_period_num': 30, 'train_rates': 0.8633562971596813, 'learning_rate': 0.00034076768811651734, 'batch_size': 118, 'step_size': 5, 'gamma': 0.7964080419998827}. Best is trial 32 with value: 0.04802614520361394.[0m
[32m[I 2025-02-06 14:54:44,756][0m Trial 33 finished with value: 0.07415207908562725 and parameters: {'observation_period_num': 25, 'train_rates': 0.8302217962644836, 'learning_rate': 0.00037423027380361815, 'batch_size': 122, 'step_size': 2, 'gamma': 0.7967128402444325}. Best is trial 32 with value: 0.04802614520361394.[0m
[32m[I 2025-02-06 14:56:39,257][0m Trial 34 finished with value: 0.04668499955644943 and parameters: {'observation_period_num': 33, 'train_rates': 0.8489744778985855, 'learning_rate': 0.0001220894041315993, 'batch_size': 48, 'step_size': 9, 'gamma': 0.7574304224186967}. Best is trial 34 with value: 0.04668499955644943.[0m
[32m[I 2025-02-06 14:58:24,881][0m Trial 35 finished with value: 0.03644203103913812 and parameters: {'observation_period_num': 16, 'train_rates': 0.8178439570475772, 'learning_rate': 0.00014103748300563774, 'batch_size': 51, 'step_size': 10, 'gamma': 0.7538071677243262}. Best is trial 35 with value: 0.03644203103913812.[0m
[32m[I 2025-02-06 15:00:26,970][0m Trial 36 finished with value: 0.03705710166455858 and parameters: {'observation_period_num': 14, 'train_rates': 0.8183815973309144, 'learning_rate': 0.0001140498949073788, 'batch_size': 45, 'step_size': 10, 'gamma': 0.7566800577299889}. Best is trial 35 with value: 0.03644203103913812.[0m
[32m[I 2025-02-06 15:02:50,743][0m Trial 37 finished with value: 0.03327092845682745 and parameters: {'observation_period_num': 14, 'train_rates': 0.8186567386028416, 'learning_rate': 0.00012763796322148274, 'batch_size': 37, 'step_size': 9, 'gamma': 0.7502368328060333}. Best is trial 37 with value: 0.03327092845682745.[0m
[32m[I 2025-02-06 15:05:09,041][0m Trial 38 finished with value: 0.0341426485846209 and parameters: {'observation_period_num': 8, 'train_rates': 0.8128435981388998, 'learning_rate': 0.0001163635933517403, 'batch_size': 39, 'step_size': 9, 'gamma': 0.7510983353468176}. Best is trial 37 with value: 0.03327092845682745.[0m
[32m[I 2025-02-06 15:07:43,803][0m Trial 39 finished with value: 0.03596700341685822 and parameters: {'observation_period_num': 10, 'train_rates': 0.8089353595117574, 'learning_rate': 6.741203932005043e-05, 'batch_size': 34, 'step_size': 9, 'gamma': 0.7721192409222761}. Best is trial 37 with value: 0.03327092845682745.[0m
[32m[I 2025-02-06 15:12:29,812][0m Trial 40 finished with value: 0.17755109095014632 and parameters: {'observation_period_num': 227, 'train_rates': 0.8033943976020496, 'learning_rate': 2.102819797474467e-05, 'batch_size': 17, 'step_size': 9, 'gamma': 0.7725302249975297}. Best is trial 37 with value: 0.03327092845682745.[0m
[32m[I 2025-02-06 15:14:54,527][0m Trial 41 finished with value: 0.046057671681046485 and parameters: {'observation_period_num': 13, 'train_rates': 0.8136648690661608, 'learning_rate': 5.392981889802926e-05, 'batch_size': 37, 'step_size': 10, 'gamma': 0.7504033756515106}. Best is trial 37 with value: 0.03327092845682745.[0m
[32m[I 2025-02-06 15:16:28,352][0m Trial 42 finished with value: 0.047774754783236666 and parameters: {'observation_period_num': 16, 'train_rates': 0.8211171805868326, 'learning_rate': 7.637767073060711e-05, 'batch_size': 59, 'step_size': 9, 'gamma': 0.7642128708276735}. Best is trial 37 with value: 0.03327092845682745.[0m
[32m[I 2025-02-06 15:18:46,136][0m Trial 43 finished with value: 0.15743639092838418 and parameters: {'observation_period_num': 14, 'train_rates': 0.7682847945345728, 'learning_rate': 0.00015385658060811555, 'batch_size': 37, 'step_size': 10, 'gamma': 0.7834533549457661}. Best is trial 37 with value: 0.03327092845682745.[0m
[32m[I 2025-02-06 15:20:28,552][0m Trial 44 finished with value: 0.033587997695490944 and parameters: {'observation_period_num': 7, 'train_rates': 0.8435411790796687, 'learning_rate': 0.00010333418178344299, 'batch_size': 54, 'step_size': 14, 'gamma': 0.7635948570845724}. Best is trial 37 with value: 0.03327092845682745.[0m
[32m[I 2025-02-06 15:23:00,949][0m Trial 45 finished with value: 0.25652983100801113 and parameters: {'observation_period_num': 193, 'train_rates': 0.7303303343477255, 'learning_rate': 4.126727250797832e-05, 'batch_size': 31, 'step_size': 13, 'gamma': 0.7695852455905083}. Best is trial 37 with value: 0.03327092845682745.[0m
[32m[I 2025-02-06 15:24:39,674][0m Trial 46 finished with value: 0.0694540903690726 and parameters: {'observation_period_num': 39, 'train_rates': 0.838637828737915, 'learning_rate': 2.5768094104363585e-05, 'batch_size': 56, 'step_size': 15, 'gamma': 0.7840432690543323}. Best is trial 37 with value: 0.03327092845682745.[0m
[32m[I 2025-02-06 15:29:55,196][0m Trial 47 finished with value: 0.04518030468790122 and parameters: {'observation_period_num': 21, 'train_rates': 0.8372472645813963, 'learning_rate': 6.0481646107850306e-05, 'batch_size': 17, 'step_size': 14, 'gamma': 0.7637278005551048}. Best is trial 37 with value: 0.03327092845682745.[0m
[32m[I 2025-02-06 15:31:22,284][0m Trial 48 finished with value: 0.05043436990429958 and parameters: {'observation_period_num': 7, 'train_rates': 0.9158424785815429, 'learning_rate': 8.350920648139655e-05, 'batch_size': 67, 'step_size': 7, 'gamma': 0.7502351703380603}. Best is trial 37 with value: 0.03327092845682745.[0m
[32m[I 2025-02-06 15:33:05,689][0m Trial 49 finished with value: 0.05604957066038076 and parameters: {'observation_period_num': 37, 'train_rates': 0.8045790541295004, 'learning_rate': 0.00013264739985113412, 'batch_size': 51, 'step_size': 12, 'gamma': 0.7778839146107229}. Best is trial 37 with value: 0.03327092845682745.[0m
ÊúÄÈÅ©„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åó„Åü
ÊúÄÈÅ©„Å™„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„Åå best_hyperparameters_GOOG_iTransformer_noMSTL.json „Å´‰øùÂ≠ò„Åï„Çå„Åæ„Åó„Åü
Epoch 1/300, Loss: 0.2979 | 0.2188
Epoch 2/300, Loss: 0.1447 | 0.1576
Epoch 3/300, Loss: 0.1267 | 0.1222
Epoch 4/300, Loss: 0.1182 | 0.1018
Epoch 5/300, Loss: 0.1118 | 0.0860
Epoch 6/300, Loss: 0.1081 | 0.0784
Epoch 7/300, Loss: 0.1061 | 0.0776
Epoch 8/300, Loss: 0.1098 | 0.0787
Epoch 9/300, Loss: 0.1109 | 0.0754
Epoch 10/300, Loss: 0.1078 | 0.0696
Epoch 11/300, Loss: 0.1064 | 0.0765
Epoch 12/300, Loss: 0.1021 | 0.0806
Epoch 13/300, Loss: 0.0998 | 0.0829
Epoch 14/300, Loss: 0.0981 | 0.0845
Epoch 15/300, Loss: 0.0961 | 0.0732
Epoch 16/300, Loss: 0.0941 | 0.0704
Epoch 17/300, Loss: 0.0917 | 0.0669
Epoch 18/300, Loss: 0.0900 | 0.0615
Epoch 19/300, Loss: 0.0893 | 0.0557
Epoch 20/300, Loss: 0.0894 | 0.0556
Epoch 21/300, Loss: 0.0893 | 0.0541
Epoch 22/300, Loss: 0.0884 | 0.0527
Epoch 23/300, Loss: 0.0868 | 0.0513
Epoch 24/300, Loss: 0.0850 | 0.0503
Epoch 25/300, Loss: 0.0838 | 0.0499
Epoch 26/300, Loss: 0.0829 | 0.0497
Epoch 27/300, Loss: 0.0824 | 0.0496
Epoch 28/300, Loss: 0.0821 | 0.0533
Epoch 29/300, Loss: 0.0819 | 0.0528
Epoch 30/300, Loss: 0.0819 | 0.0522
Epoch 31/300, Loss: 0.0818 | 0.0512
Epoch 32/300, Loss: 0.0815 | 0.0500
Epoch 33/300, Loss: 0.0813 | 0.0476
Epoch 34/300, Loss: 0.0812 | 0.0464
Epoch 35/300, Loss: 0.0811 | 0.0455
Epoch 36/300, Loss: 0.0807 | 0.0448
Epoch 37/300, Loss: 0.0803 | 0.0444
Epoch 38/300, Loss: 0.0798 | 0.0441
Epoch 39/300, Loss: 0.0790 | 0.0439
Epoch 40/300, Loss: 0.0785 | 0.0437
Epoch 41/300, Loss: 0.0781 | 0.0437
Epoch 42/300, Loss: 0.0778 | 0.0439
Epoch 43/300, Loss: 0.0776 | 0.0440
Epoch 44/300, Loss: 0.0775 | 0.0440
Epoch 45/300, Loss: 0.0774 | 0.0440
Epoch 46/300, Loss: 0.0772 | 0.0439
Epoch 47/300, Loss: 0.0771 | 0.0437
Epoch 48/300, Loss: 0.0771 | 0.0436
Epoch 49/300, Loss: 0.0770 | 0.0435
Epoch 50/300, Loss: 0.0769 | 0.0434
Epoch 51/300, Loss: 0.0768 | 0.0433
Epoch 52/300, Loss: 0.0767 | 0.0432
Epoch 53/300, Loss: 0.0766 | 0.0432
Epoch 54/300, Loss: 0.0766 | 0.0431
Epoch 55/300, Loss: 0.0765 | 0.0430
Epoch 56/300, Loss: 0.0764 | 0.0429
Epoch 57/300, Loss: 0.0764 | 0.0429
Epoch 58/300, Loss: 0.0763 | 0.0428
Epoch 59/300, Loss: 0.0762 | 0.0428
Epoch 60/300, Loss: 0.0762 | 0.0427
Epoch 61/300, Loss: 0.0761 | 0.0427
Epoch 62/300, Loss: 0.0761 | 0.0427
Epoch 63/300, Loss: 0.0760 | 0.0426
Epoch 64/300, Loss: 0.0760 | 0.0426
Epoch 65/300, Loss: 0.0760 | 0.0426
Epoch 66/300, Loss: 0.0759 | 0.0425
Epoch 67/300, Loss: 0.0759 | 0.0425
Epoch 68/300, Loss: 0.0758 | 0.0425
Epoch 69/300, Loss: 0.0758 | 0.0425
Epoch 70/300, Loss: 0.0758 | 0.0424
Epoch 71/300, Loss: 0.0757 | 0.0424
Epoch 72/300, Loss: 0.0757 | 0.0424
Epoch 73/300, Loss: 0.0757 | 0.0424
Epoch 74/300, Loss: 0.0756 | 0.0424
Epoch 75/300, Loss: 0.0756 | 0.0424
Epoch 76/300, Loss: 0.0756 | 0.0424
Epoch 77/300, Loss: 0.0756 | 0.0424
Epoch 78/300, Loss: 0.0755 | 0.0423
Epoch 79/300, Loss: 0.0755 | 0.0424
Epoch 80/300, Loss: 0.0755 | 0.0423
Epoch 81/300, Loss: 0.0755 | 0.0423
Epoch 82/300, Loss: 0.0755 | 0.0423
Epoch 83/300, Loss: 0.0755 | 0.0423
Epoch 84/300, Loss: 0.0754 | 0.0423
Epoch 85/300, Loss: 0.0754 | 0.0423
Epoch 86/300, Loss: 0.0754 | 0.0423
Epoch 87/300, Loss: 0.0754 | 0.0423
Epoch 88/300, Loss: 0.0754 | 0.0423
Epoch 89/300, Loss: 0.0754 | 0.0423
Epoch 90/300, Loss: 0.0754 | 0.0423
Epoch 91/300, Loss: 0.0754 | 0.0423
Epoch 92/300, Loss: 0.0754 | 0.0423
Epoch 93/300, Loss: 0.0753 | 0.0422
Epoch 94/300, Loss: 0.0753 | 0.0422
Epoch 95/300, Loss: 0.0753 | 0.0422
Epoch 96/300, Loss: 0.0753 | 0.0422
Epoch 97/300, Loss: 0.0753 | 0.0422
Epoch 98/300, Loss: 0.0753 | 0.0422
Epoch 99/300, Loss: 0.0753 | 0.0422
Epoch 100/300, Loss: 0.0753 | 0.0422
Epoch 101/300, Loss: 0.0753 | 0.0422
Epoch 102/300, Loss: 0.0753 | 0.0422
Epoch 103/300, Loss: 0.0753 | 0.0422
Epoch 104/300, Loss: 0.0753 | 0.0422
Epoch 105/300, Loss: 0.0753 | 0.0422
Epoch 106/300, Loss: 0.0753 | 0.0422
Epoch 107/300, Loss: 0.0753 | 0.0422
Epoch 108/300, Loss: 0.0753 | 0.0422
Epoch 109/300, Loss: 0.0753 | 0.0422
Epoch 110/300, Loss: 0.0753 | 0.0422
Epoch 111/300, Loss: 0.0753 | 0.0422
Epoch 112/300, Loss: 0.0753 | 0.0422
Epoch 113/300, Loss: 0.0753 | 0.0422
Epoch 114/300, Loss: 0.0753 | 0.0422
Epoch 115/300, Loss: 0.0753 | 0.0422
Epoch 116/300, Loss: 0.0753 | 0.0422
Epoch 117/300, Loss: 0.0752 | 0.0422
Epoch 118/300, Loss: 0.0752 | 0.0422
Epoch 119/300, Loss: 0.0752 | 0.0422
Epoch 120/300, Loss: 0.0752 | 0.0422
Epoch 121/300, Loss: 0.0752 | 0.0422
Epoch 122/300, Loss: 0.0752 | 0.0422
Epoch 123/300, Loss: 0.0752 | 0.0422
Epoch 124/300, Loss: 0.0752 | 0.0422
Epoch 125/300, Loss: 0.0752 | 0.0422
Epoch 126/300, Loss: 0.0752 | 0.0422
Epoch 127/300, Loss: 0.0752 | 0.0421
Epoch 128/300, Loss: 0.0752 | 0.0421
Epoch 129/300, Loss: 0.0752 | 0.0421
Epoch 130/300, Loss: 0.0752 | 0.0421
Epoch 131/300, Loss: 0.0752 | 0.0421
Epoch 132/300, Loss: 0.0752 | 0.0421
Epoch 133/300, Loss: 0.0752 | 0.0421
Epoch 134/300, Loss: 0.0752 | 0.0421
Epoch 135/300, Loss: 0.0752 | 0.0421
Epoch 136/300, Loss: 0.0752 | 0.0421
Epoch 137/300, Loss: 0.0752 | 0.0421
Epoch 138/300, Loss: 0.0752 | 0.0421
Epoch 139/300, Loss: 0.0752 | 0.0421
Epoch 140/300, Loss: 0.0752 | 0.0421
Epoch 141/300, Loss: 0.0752 | 0.0421
Epoch 142/300, Loss: 0.0752 | 0.0421
Epoch 143/300, Loss: 0.0752 | 0.0421
Epoch 144/300, Loss: 0.0752 | 0.0421
Epoch 145/300, Loss: 0.0752 | 0.0421
Epoch 146/300, Loss: 0.0752 | 0.0421
Epoch 147/300, Loss: 0.0752 | 0.0421
Epoch 148/300, Loss: 0.0752 | 0.0421
Epoch 149/300, Loss: 0.0752 | 0.0421
Epoch 150/300, Loss: 0.0752 | 0.0421
Epoch 151/300, Loss: 0.0752 | 0.0421
Epoch 152/300, Loss: 0.0752 | 0.0421
Epoch 153/300, Loss: 0.0752 | 0.0421
Epoch 154/300, Loss: 0.0752 | 0.0421
Epoch 155/300, Loss: 0.0752 | 0.0421
Epoch 156/300, Loss: 0.0752 | 0.0421
Epoch 157/300, Loss: 0.0752 | 0.0421
Epoch 158/300, Loss: 0.0752 | 0.0421
Epoch 159/300, Loss: 0.0752 | 0.0421
Epoch 160/300, Loss: 0.0752 | 0.0421
Epoch 161/300, Loss: 0.0752 | 0.0421
Epoch 162/300, Loss: 0.0752 | 0.0421
Epoch 163/300, Loss: 0.0752 | 0.0421
Epoch 164/300, Loss: 0.0752 | 0.0421
Epoch 165/300, Loss: 0.0752 | 0.0421
Epoch 166/300, Loss: 0.0752 | 0.0421
Epoch 167/300, Loss: 0.0752 | 0.0421
Epoch 168/300, Loss: 0.0752 | 0.0421
Epoch 169/300, Loss: 0.0752 | 0.0421
Epoch 170/300, Loss: 0.0752 | 0.0421
Epoch 171/300, Loss: 0.0752 | 0.0421
Epoch 172/300, Loss: 0.0752 | 0.0421
Epoch 173/300, Loss: 0.0752 | 0.0421
Epoch 174/300, Loss: 0.0752 | 0.0421
Epoch 175/300, Loss: 0.0752 | 0.0421
Epoch 176/300, Loss: 0.0752 | 0.0421
Epoch 177/300, Loss: 0.0752 | 0.0421
Epoch 178/300, Loss: 0.0752 | 0.0421
Epoch 179/300, Loss: 0.0752 | 0.0421
Epoch 180/300, Loss: 0.0752 | 0.0421
Epoch 181/300, Loss: 0.0752 | 0.0421
Epoch 182/300, Loss: 0.0752 | 0.0421
Epoch 183/300, Loss: 0.0752 | 0.0421
Epoch 184/300, Loss: 0.0752 | 0.0421
Epoch 185/300, Loss: 0.0752 | 0.0421
Epoch 186/300, Loss: 0.0752 | 0.0421
Epoch 187/300, Loss: 0.0752 | 0.0421
Epoch 188/300, Loss: 0.0752 | 0.0421
Epoch 189/300, Loss: 0.0752 | 0.0421
Epoch 190/300, Loss: 0.0752 | 0.0421
Epoch 191/300, Loss: 0.0752 | 0.0421
Epoch 192/300, Loss: 0.0752 | 0.0421
Epoch 193/300, Loss: 0.0752 | 0.0421
Epoch 194/300, Loss: 0.0752 | 0.0421
Epoch 195/300, Loss: 0.0752 | 0.0421
Epoch 196/300, Loss: 0.0752 | 0.0421
Epoch 197/300, Loss: 0.0752 | 0.0421
Epoch 198/300, Loss: 0.0752 | 0.0421
Epoch 199/300, Loss: 0.0752 | 0.0421
Epoch 200/300, Loss: 0.0752 | 0.0421
Epoch 201/300, Loss: 0.0752 | 0.0421
Epoch 202/300, Loss: 0.0752 | 0.0421
Epoch 203/300, Loss: 0.0752 | 0.0421
Epoch 204/300, Loss: 0.0752 | 0.0421
Epoch 205/300, Loss: 0.0752 | 0.0421
Epoch 206/300, Loss: 0.0752 | 0.0421
Epoch 207/300, Loss: 0.0752 | 0.0421
Epoch 208/300, Loss: 0.0752 | 0.0421
Epoch 209/300, Loss: 0.0752 | 0.0421
Epoch 210/300, Loss: 0.0752 | 0.0421
Epoch 211/300, Loss: 0.0752 | 0.0421
Epoch 212/300, Loss: 0.0752 | 0.0421
Epoch 213/300, Loss: 0.0752 | 0.0421
Epoch 214/300, Loss: 0.0752 | 0.0421
Epoch 215/300, Loss: 0.0752 | 0.0421
Epoch 216/300, Loss: 0.0752 | 0.0421
Epoch 217/300, Loss: 0.0752 | 0.0421
Epoch 218/300, Loss: 0.0752 | 0.0421
Epoch 219/300, Loss: 0.0752 | 0.0421
Epoch 220/300, Loss: 0.0752 | 0.0421
Epoch 221/300, Loss: 0.0752 | 0.0421
Epoch 222/300, Loss: 0.0752 | 0.0421
Epoch 223/300, Loss: 0.0752 | 0.0421
Epoch 224/300, Loss: 0.0752 | 0.0421
Epoch 225/300, Loss: 0.0752 | 0.0421
Epoch 226/300, Loss: 0.0752 | 0.0421
Epoch 227/300, Loss: 0.0752 | 0.0421
Epoch 228/300, Loss: 0.0752 | 0.0421
Early stopping
Runtime (seconds): 326.8117609024048
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)
MSE: 7.971902714110911
RMSE: 2.823455810546875
MAE: 2.823455810546875
R-squared: nan
[204.72345]
