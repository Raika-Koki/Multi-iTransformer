ÊúÄÈÅ©ÂåñÂØæË±°: trend
[32m[I 2025-01-30 17:50:41,071][0m A new study created in memory with name: no-name-0515d784-c750-4d6b-88da-02baec2c5b7c[0m
[32m[I 2025-01-30 17:51:21,514][0m Trial 0 finished with value: 0.5963976979255676 and parameters: {'observation_period_num': 35, 'train_rates': 0.9837198129193718, 'learning_rate': 3.625429971672038e-06, 'batch_size': 178, 'step_size': 9, 'gamma': 0.7852878789261015}. Best is trial 0 with value: 0.5963976979255676.[0m
Early stopping at epoch 68
[32m[I 2025-01-30 17:52:30,710][0m Trial 1 finished with value: 1.357587984496256 and parameters: {'observation_period_num': 151, 'train_rates': 0.6136855214952356, 'learning_rate': 1.4141821852842106e-05, 'batch_size': 175, 'step_size': 1, 'gamma': 0.8404182475822386}. Best is trial 0 with value: 0.5963976979255676.[0m
[32m[I 2025-01-30 17:55:17,154][0m Trial 2 finished with value: 1.1292516615047645 and parameters: {'observation_period_num': 215, 'train_rates': 0.7056001180226675, 'learning_rate': 5.643804232499591e-06, 'batch_size': 165, 'step_size': 11, 'gamma': 0.8396212276475447}. Best is trial 0 with value: 0.5963976979255676.[0m
Early stopping at epoch 39
[32m[I 2025-01-30 17:56:37,049][0m Trial 3 finished with value: 2.4700940813337056 and parameters: {'observation_period_num': 214, 'train_rates': 0.9105052581803476, 'learning_rate': 1.0808195537776863e-06, 'batch_size': 138, 'step_size': 1, 'gamma': 0.7767592820405709}. Best is trial 0 with value: 0.5963976979255676.[0m
[32m[I 2025-01-30 17:58:10,352][0m Trial 4 finished with value: 0.3589404878657978 and parameters: {'observation_period_num': 112, 'train_rates': 0.9194714172217078, 'learning_rate': 2.7872014633656025e-05, 'batch_size': 150, 'step_size': 9, 'gamma': 0.7614888284534153}. Best is trial 4 with value: 0.3589404878657978.[0m
[32m[I 2025-01-30 17:58:53,278][0m Trial 5 finished with value: 1.0226606955399384 and parameters: {'observation_period_num': 12, 'train_rates': 0.8112013202015227, 'learning_rate': 4.870480586373324e-06, 'batch_size': 138, 'step_size': 3, 'gamma': 0.9064957205054712}. Best is trial 4 with value: 0.3589404878657978.[0m
[32m[I 2025-01-30 18:02:25,436][0m Trial 6 finished with value: 0.5011500120162964 and parameters: {'observation_period_num': 224, 'train_rates': 0.9648402751486318, 'learning_rate': 2.0590142715063957e-05, 'batch_size': 242, 'step_size': 14, 'gamma': 0.9449523672169946}. Best is trial 4 with value: 0.3589404878657978.[0m
[32m[I 2025-01-30 18:05:25,451][0m Trial 7 finished with value: 0.4788430131950966 and parameters: {'observation_period_num': 225, 'train_rates': 0.7382187754338942, 'learning_rate': 0.00023959737212674297, 'batch_size': 164, 'step_size': 6, 'gamma': 0.8873981105874641}. Best is trial 4 with value: 0.3589404878657978.[0m
[32m[I 2025-01-30 18:06:10,422][0m Trial 8 finished with value: 0.6283983862020944 and parameters: {'observation_period_num': 63, 'train_rates': 0.7059742263523431, 'learning_rate': 7.737178279869175e-05, 'batch_size': 164, 'step_size': 14, 'gamma': 0.8680958752733303}. Best is trial 4 with value: 0.3589404878657978.[0m
[32m[I 2025-01-30 18:06:52,557][0m Trial 9 finished with value: 0.6447052089955474 and parameters: {'observation_period_num': 58, 'train_rates': 0.6626852703213864, 'learning_rate': 4.241250391764738e-05, 'batch_size': 159, 'step_size': 12, 'gamma': 0.8931016827642277}. Best is trial 4 with value: 0.3589404878657978.[0m
[32m[I 2025-01-30 18:08:51,278][0m Trial 10 finished with value: 0.5456303674362454 and parameters: {'observation_period_num': 122, 'train_rates': 0.8558428035557415, 'learning_rate': 0.000714625075723349, 'batch_size': 47, 'step_size': 6, 'gamma': 0.7502849692803941}. Best is trial 4 with value: 0.3589404878657978.[0m
[32m[I 2025-01-30 18:10:44,001][0m Trial 11 finished with value: 0.8496005546284168 and parameters: {'observation_period_num': 141, 'train_rates': 0.7721467787845618, 'learning_rate': 0.00020695198575781487, 'batch_size': 82, 'step_size': 6, 'gamma': 0.9783632418074593}. Best is trial 4 with value: 0.3589404878657978.[0m
[32m[I 2025-01-30 18:11:59,570][0m Trial 12 finished with value: 0.48811185077913927 and parameters: {'observation_period_num': 104, 'train_rates': 0.7773113857236301, 'learning_rate': 0.00015280513641930356, 'batch_size': 224, 'step_size': 8, 'gamma': 0.8114953831915569}. Best is trial 4 with value: 0.3589404878657978.[0m
[32m[I 2025-01-30 18:14:37,065][0m Trial 13 finished with value: 0.3926707012990935 and parameters: {'observation_period_num': 178, 'train_rates': 0.8778845333006428, 'learning_rate': 0.0006434263601249902, 'batch_size': 99, 'step_size': 5, 'gamma': 0.9241229978130274}. Best is trial 4 with value: 0.3589404878657978.[0m
[32m[I 2025-01-30 18:17:06,867][0m Trial 14 finished with value: 1.1210051397359149 and parameters: {'observation_period_num': 169, 'train_rates': 0.8842921165529534, 'learning_rate': 0.0008489051683910488, 'batch_size': 104, 'step_size': 4, 'gamma': 0.9572313595390467}. Best is trial 4 with value: 0.3589404878657978.[0m
[32m[I 2025-01-30 18:21:46,194][0m Trial 15 finished with value: 0.2531312114550072 and parameters: {'observation_period_num': 179, 'train_rates': 0.9257561374949682, 'learning_rate': 6.619545041535459e-05, 'batch_size': 20, 'step_size': 9, 'gamma': 0.9259501004757461}. Best is trial 15 with value: 0.2531312114550072.[0m
[32m[I 2025-01-30 18:26:34,066][0m Trial 16 finished with value: 0.2635068285304147 and parameters: {'observation_period_num': 98, 'train_rates': 0.9351712383200979, 'learning_rate': 5.8953009224883155e-05, 'batch_size': 20, 'step_size': 9, 'gamma': 0.8568946872019051}. Best is trial 15 with value: 0.2531312114550072.[0m
[32m[I 2025-01-30 18:31:28,743][0m Trial 17 finished with value: 0.3098314971458621 and parameters: {'observation_period_num': 82, 'train_rates': 0.9430473526838583, 'learning_rate': 8.15387887407941e-05, 'batch_size': 20, 'step_size': 10, 'gamma': 0.8586656693506182}. Best is trial 15 with value: 0.2531312114550072.[0m
[32m[I 2025-01-30 18:35:35,619][0m Trial 18 finished with value: 0.2658323562958024 and parameters: {'observation_period_num': 198, 'train_rates': 0.8403575655730655, 'learning_rate': 6.213688460751726e-05, 'batch_size': 21, 'step_size': 13, 'gamma': 0.9287660623520192}. Best is trial 15 with value: 0.2531312114550072.[0m
[32m[I 2025-01-30 18:38:20,633][0m Trial 19 finished with value: 0.31775400842108376 and parameters: {'observation_period_num': 174, 'train_rates': 0.9412517710360411, 'learning_rate': 0.00013603569096645688, 'batch_size': 60, 'step_size': 8, 'gamma': 0.8157972396282105}. Best is trial 15 with value: 0.2531312114550072.[0m
[32m[I 2025-01-30 18:42:09,062][0m Trial 20 finished with value: 0.41240079230226023 and parameters: {'observation_period_num': 249, 'train_rates': 0.8162291083221405, 'learning_rate': 1.1725097925220103e-05, 'batch_size': 48, 'step_size': 11, 'gamma': 0.9722628593134537}. Best is trial 15 with value: 0.2531312114550072.[0m
[32m[I 2025-01-30 18:46:52,382][0m Trial 21 finished with value: 0.2687596296247799 and parameters: {'observation_period_num': 193, 'train_rates': 0.8426764478955198, 'learning_rate': 5.382173620633518e-05, 'batch_size': 18, 'step_size': 15, 'gamma': 0.9315442456841077}. Best is trial 15 with value: 0.2531312114550072.[0m
[32m[I 2025-01-30 18:50:02,216][0m Trial 22 finished with value: 1.9781801789493885 and parameters: {'observation_period_num': 145, 'train_rates': 0.8949130262918291, 'learning_rate': 0.00040981634248452064, 'batch_size': 29, 'step_size': 13, 'gamma': 0.9115509801261462}. Best is trial 15 with value: 0.2531312114550072.[0m
[32m[I 2025-01-30 18:52:58,391][0m Trial 23 finished with value: 0.2527896170458286 and parameters: {'observation_period_num': 196, 'train_rates': 0.8533258247720344, 'learning_rate': 7.54897558855021e-05, 'batch_size': 61, 'step_size': 12, 'gamma': 0.9546104021972166}. Best is trial 23 with value: 0.2527896170458286.[0m
[32m[I 2025-01-30 18:54:24,725][0m Trial 24 finished with value: 0.2840217105163041 and parameters: {'observation_period_num': 82, 'train_rates': 0.9354354271673716, 'learning_rate': 9.838082972472894e-05, 'batch_size': 71, 'step_size': 10, 'gamma': 0.9552441531670183}. Best is trial 23 with value: 0.2527896170458286.[0m
[32m[I 2025-01-30 18:58:35,840][0m Trial 25 finished with value: 0.14641398191452026 and parameters: {'observation_period_num': 249, 'train_rates': 0.9836176988711162, 'learning_rate': 3.2349579987690136e-05, 'batch_size': 103, 'step_size': 7, 'gamma': 0.8860926096351137}. Best is trial 25 with value: 0.14641398191452026.[0m
[32m[I 2025-01-30 19:02:48,927][0m Trial 26 finished with value: 0.15463073551654816 and parameters: {'observation_period_num': 250, 'train_rates': 0.9785544303095259, 'learning_rate': 3.314872343361491e-05, 'batch_size': 110, 'step_size': 7, 'gamma': 0.8901929809051846}. Best is trial 25 with value: 0.14641398191452026.[0m
[32m[I 2025-01-30 19:07:01,461][0m Trial 27 finished with value: 0.14390617609024048 and parameters: {'observation_period_num': 250, 'train_rates': 0.9846319772796169, 'learning_rate': 2.910064371823792e-05, 'batch_size': 115, 'step_size': 7, 'gamma': 0.8839836196991642}. Best is trial 27 with value: 0.14390617609024048.[0m
[32m[I 2025-01-30 19:11:12,707][0m Trial 28 finished with value: 0.7107769846916199 and parameters: {'observation_period_num': 251, 'train_rates': 0.9725378265461341, 'learning_rate': 8.972116034531913e-06, 'batch_size': 113, 'step_size': 7, 'gamma': 0.8895405787496583}. Best is trial 27 with value: 0.14390617609024048.[0m
[32m[I 2025-01-30 19:15:05,381][0m Trial 29 finished with value: 0.22448228299617767 and parameters: {'observation_period_num': 233, 'train_rates': 0.9799795332107428, 'learning_rate': 2.615306714471728e-05, 'batch_size': 119, 'step_size': 4, 'gamma': 0.8774373939126897}. Best is trial 27 with value: 0.14390617609024048.[0m
[32m[I 2025-01-30 19:19:07,031][0m Trial 30 finished with value: 0.6346973776817322 and parameters: {'observation_period_num': 241, 'train_rates': 0.9857812232309432, 'learning_rate': 2.020193952369483e-06, 'batch_size': 88, 'step_size': 7, 'gamma': 0.8390316384255965}. Best is trial 27 with value: 0.14390617609024048.[0m
[32m[I 2025-01-30 19:22:57,717][0m Trial 31 finished with value: 0.26930996775627136 and parameters: {'observation_period_num': 232, 'train_rates': 0.9786068460793111, 'learning_rate': 2.6862640583005736e-05, 'batch_size': 115, 'step_size': 3, 'gamma': 0.8765356961096636}. Best is trial 27 with value: 0.14390617609024048.[0m
[32m[I 2025-01-30 19:26:52,906][0m Trial 32 finished with value: 0.24930210411548615 and parameters: {'observation_period_num': 237, 'train_rates': 0.9893068944629938, 'learning_rate': 1.9106100825497826e-05, 'batch_size': 197, 'step_size': 4, 'gamma': 0.901273453397446}. Best is trial 27 with value: 0.14390617609024048.[0m
[32m[I 2025-01-30 19:30:21,640][0m Trial 33 finished with value: 0.575756311416626 and parameters: {'observation_period_num': 215, 'train_rates': 0.9587253908623072, 'learning_rate': 9.134763467255767e-06, 'batch_size': 123, 'step_size': 7, 'gamma': 0.8749677409388954}. Best is trial 27 with value: 0.14390617609024048.[0m
[32m[I 2025-01-30 19:33:43,669][0m Trial 34 finished with value: 0.5600752234458923 and parameters: {'observation_period_num': 210, 'train_rates': 0.959473163384983, 'learning_rate': 4.030303593543611e-05, 'batch_size': 126, 'step_size': 2, 'gamma': 0.8520981509060545}. Best is trial 27 with value: 0.14390617609024048.[0m
[32m[I 2025-01-30 19:37:39,000][0m Trial 35 finished with value: 0.5175378478091696 and parameters: {'observation_period_num': 252, 'train_rates': 0.9063038375301982, 'learning_rate': 1.6040771642622448e-05, 'batch_size': 187, 'step_size': 5, 'gamma': 0.8325616353808166}. Best is trial 27 with value: 0.14390617609024048.[0m
[32m[I 2025-01-30 19:40:23,988][0m Trial 36 finished with value: 0.9160819200182578 and parameters: {'observation_period_num': 235, 'train_rates': 0.6016276792876591, 'learning_rate': 2.8296403920803687e-05, 'batch_size': 146, 'step_size': 5, 'gamma': 0.8819960246756313}. Best is trial 27 with value: 0.14390617609024048.[0m
[32m[I 2025-01-30 19:43:46,938][0m Trial 37 finished with value: 0.54560408153032 and parameters: {'observation_period_num': 210, 'train_rates': 0.9514793037406558, 'learning_rate': 5.349387891909651e-06, 'batch_size': 91, 'step_size': 7, 'gamma': 0.9140414135858257}. Best is trial 27 with value: 0.14390617609024048.[0m
[32m[I 2025-01-30 19:47:13,303][0m Trial 38 finished with value: 0.4373548190926881 and parameters: {'observation_period_num': 223, 'train_rates': 0.9160280183446592, 'learning_rate': 3.5342905344969764e-05, 'batch_size': 133, 'step_size': 2, 'gamma': 0.8960594835234285}. Best is trial 27 with value: 0.14390617609024048.[0m
[32m[I 2025-01-30 19:51:09,572][0m Trial 39 finished with value: 0.3121049106121063 and parameters: {'observation_period_num': 236, 'train_rates': 0.9892521655314395, 'learning_rate': 1.0533974579213776e-05, 'batch_size': 109, 'step_size': 4, 'gamma': 0.8233196402506009}. Best is trial 27 with value: 0.14390617609024048.[0m
[32m[I 2025-01-30 19:53:53,208][0m Trial 40 finished with value: 1.028459025301047 and parameters: {'observation_period_num': 222, 'train_rates': 0.6529324381245276, 'learning_rate': 1.8711043020919337e-05, 'batch_size': 147, 'step_size': 8, 'gamma': 0.8574915937570071}. Best is trial 27 with value: 0.14390617609024048.[0m
[32m[I 2025-01-30 19:57:44,813][0m Trial 41 finished with value: 0.5816736221313477 and parameters: {'observation_period_num': 238, 'train_rates': 0.9670688538214293, 'learning_rate': 2.2358570352105956e-05, 'batch_size': 193, 'step_size': 4, 'gamma': 0.9003064208335253}. Best is trial 27 with value: 0.14390617609024048.[0m
[32m[I 2025-01-30 20:01:55,479][0m Trial 42 finished with value: 0.2556077837944031 and parameters: {'observation_period_num': 252, 'train_rates': 0.9891899464433621, 'learning_rate': 1.4368582232716343e-05, 'batch_size': 214, 'step_size': 6, 'gamma': 0.8677857885187947}. Best is trial 27 with value: 0.14390617609024048.[0m
[32m[I 2025-01-30 20:05:14,955][0m Trial 43 finished with value: 1.6759318113327026 and parameters: {'observation_period_num': 209, 'train_rates': 0.9660014187839416, 'learning_rate': 3.090932080954157e-06, 'batch_size': 122, 'step_size': 1, 'gamma': 0.9048447132680464}. Best is trial 27 with value: 0.14390617609024048.[0m
[32m[I 2025-01-30 20:08:56,189][0m Trial 44 finished with value: 0.8843703269958496 and parameters: {'observation_period_num': 232, 'train_rates': 0.949621430929422, 'learning_rate': 6.741909599001848e-06, 'batch_size': 178, 'step_size': 3, 'gamma': 0.8855298793980136}. Best is trial 27 with value: 0.14390617609024048.[0m
[33m[W 2025-01-30 20:08:58,039][0m Trial 45 failed with parameters: {'observation_period_num': 242, 'train_rates': 0.9181246046467585, 'learning_rate': 4.498208039210172e-05, 'batch_size': 245, 'step_size': 5, 'gamma': 0.8684895352786677} because of the following error: OutOfMemoryError('CUDA out of memory. Tried to allocate 464.00 MiB (GPU 0; 10.76 GiB total capacity; 9.26 GiB already allocated; 387.44 MiB free; 9.51 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF').[0m
Traceback (most recent call last):
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/Transformer.py", line 575, in <lambda>
    study.optimize(lambda trial: objective(trial, component, depth, dim), n_trials=50) #check
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/Transformer.py", line 110, in objective
    model, _, valid_loss = train(
                           ^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/src/train.py", line 40, in train
    loss.backward()  # ÈÄÜ‰ºùÊí≠
    ^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 464.00 MiB (GPU 0; 10.76 GiB total capacity; 9.26 GiB already allocated; 387.44 MiB free; 9.51 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[33m[W 2025-01-30 20:08:58,235][0m Trial 45 failed with value None.[0m
Traceback (most recent call last):
  File "/data/student/k2110261/Multi-iTransformer/Transformer.py", line 575, in <module>
    study.optimize(lambda trial: objective(trial, component, depth, dim), n_trials=50) #check
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/study.py", line 475, in optimize
    _optimize(
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 63, in _optimize
    _optimize_sequential(
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 160, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 248, in _run_trial
    raise func_err
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/Transformer.py", line 575, in <lambda>
    study.optimize(lambda trial: objective(trial, component, depth, dim), n_trials=50) #check
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/Transformer.py", line 110, in objective
    model, _, valid_loss = train(
                           ^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/src/train.py", line 40, in train
    loss.backward()  # ÈÄÜ‰ºùÊí≠
    ^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 464.00 MiB (GPU 0; 10.76 GiB total capacity; 9.26 GiB already allocated; 387.44 MiB free; 9.51 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
