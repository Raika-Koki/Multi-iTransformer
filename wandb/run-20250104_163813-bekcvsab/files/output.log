[32m[I 2025-01-04 16:38:14,357][0m A new study created in memory with name: no-name-59aa648c-94b1-4f18-ab59-80d519554847[0m
Non-A100 GPU detected, using math or mem efficient attention if input tensor is on cuda
[32m[I 2025-01-04 16:40:35,464][0m Trial 0 finished with value: 0.3412502176697972 and parameters: {'observation_period_num': 183, 'train_rates': 0.6278895637117459, 'learning_rate': 2.320780941467555e-05, 'batch_size': 22, 'step_size': 14, 'gamma': 0.9631961078870515}. Best is trial 0 with value: 0.3412502176697972.[0m
[32m[I 2025-01-04 16:41:21,123][0m Trial 1 finished with value: 0.2909955940842031 and parameters: {'observation_period_num': 141, 'train_rates': 0.644951625379202, 'learning_rate': 1.5217027743442118e-05, 'batch_size': 77, 'step_size': 7, 'gamma': 0.9553264662648143}. Best is trial 1 with value: 0.2909955940842031.[0m
[32m[I 2025-01-04 16:42:04,557][0m Trial 2 finished with value: 1.5398834039425027 and parameters: {'observation_period_num': 122, 'train_rates': 0.907827574349019, 'learning_rate': 1.3045228103514527e-06, 'batch_size': 128, 'step_size': 3, 'gamma': 0.8852616505907241}. Best is trial 1 with value: 0.2909955940842031.[0m
[32m[I 2025-01-04 16:43:01,855][0m Trial 3 finished with value: 0.16768325535821266 and parameters: {'observation_period_num': 86, 'train_rates': 0.897607116419437, 'learning_rate': 3.936546372853009e-06, 'batch_size': 79, 'step_size': 9, 'gamma': 0.9829348626190232}. Best is trial 3 with value: 0.16768325535821266.[0m
[32m[I 2025-01-04 16:43:40,354][0m Trial 4 finished with value: 0.19617470173375384 and parameters: {'observation_period_num': 105, 'train_rates': 0.6389033241288139, 'learning_rate': 0.000294782321088577, 'batch_size': 101, 'step_size': 14, 'gamma': 0.8445515099272164}. Best is trial 3 with value: 0.16768325535821266.[0m
[32m[I 2025-01-04 16:44:15,780][0m Trial 5 finished with value: 0.8907500363758633 and parameters: {'observation_period_num': 31, 'train_rates': 0.7004835905229732, 'learning_rate': 2.5567100176032868e-06, 'batch_size': 214, 'step_size': 4, 'gamma': 0.8304813369214056}. Best is trial 3 with value: 0.16768325535821266.[0m
[32m[I 2025-01-04 16:44:48,905][0m Trial 6 finished with value: 0.3139784452289886 and parameters: {'observation_period_num': 233, 'train_rates': 0.7377682676793286, 'learning_rate': 0.0005176225139146007, 'batch_size': 210, 'step_size': 9, 'gamma': 0.9773557732450113}. Best is trial 3 with value: 0.16768325535821266.[0m
Early stopping at epoch 66
[32m[I 2025-01-04 16:45:14,948][0m Trial 7 finished with value: 0.2611374599472532 and parameters: {'observation_period_num': 226, 'train_rates': 0.8057545889707325, 'learning_rate': 0.00039366641824338045, 'batch_size': 137, 'step_size': 1, 'gamma': 0.8195705944364144}. Best is trial 3 with value: 0.16768325535821266.[0m
[32m[I 2025-01-04 16:45:49,843][0m Trial 8 finished with value: 0.6397104377464918 and parameters: {'observation_period_num': 72, 'train_rates': 0.7088340855600509, 'learning_rate': 1.3556698593648211e-05, 'batch_size': 173, 'step_size': 1, 'gamma': 0.9195454238051417}. Best is trial 3 with value: 0.16768325535821266.[0m
[32m[I 2025-01-04 16:46:34,969][0m Trial 9 finished with value: 0.03759854659438133 and parameters: {'observation_period_num': 5, 'train_rates': 0.9787009663859193, 'learning_rate': 0.0002426304416681072, 'batch_size': 179, 'step_size': 15, 'gamma': 0.831168475724422}. Best is trial 9 with value: 0.03759854659438133.[0m
[32m[I 2025-01-04 16:47:26,030][0m Trial 10 finished with value: 0.06224709004163742 and parameters: {'observation_period_num': 14, 'train_rates': 0.9618812337600747, 'learning_rate': 0.00011008213662137903, 'batch_size': 246, 'step_size': 12, 'gamma': 0.7605501238340125}. Best is trial 9 with value: 0.03759854659438133.[0m
[32m[I 2025-01-04 16:48:23,205][0m Trial 11 finished with value: 0.062163978815078735 and parameters: {'observation_period_num': 11, 'train_rates': 0.9712340911313057, 'learning_rate': 0.0001015244485702667, 'batch_size': 243, 'step_size': 12, 'gamma': 0.7545656552050131}. Best is trial 9 with value: 0.03759854659438133.[0m
[32m[I 2025-01-04 16:49:21,754][0m Trial 12 finished with value: 0.0676729828119278 and parameters: {'observation_period_num': 43, 'train_rates': 0.9829489098053426, 'learning_rate': 9.156746309338327e-05, 'batch_size': 241, 'step_size': 12, 'gamma': 0.7501051331466879}. Best is trial 9 with value: 0.03759854659438133.[0m
[32m[I 2025-01-04 16:50:12,853][0m Trial 13 finished with value: 0.062120216636403096 and parameters: {'observation_period_num': 57, 'train_rates': 0.8577035004761987, 'learning_rate': 9.429706944748786e-05, 'batch_size': 184, 'step_size': 11, 'gamma': 0.7937056812497905}. Best is trial 9 with value: 0.03759854659438133.[0m
[32m[I 2025-01-04 16:50:51,148][0m Trial 14 finished with value: 0.07413765102374978 and parameters: {'observation_period_num': 58, 'train_rates': 0.8350945582387397, 'learning_rate': 0.0008912067737163034, 'batch_size': 170, 'step_size': 15, 'gamma': 0.7924834854019835}. Best is trial 9 with value: 0.03759854659438133.[0m
[32m[I 2025-01-04 16:51:31,366][0m Trial 15 finished with value: 0.07135820449204058 and parameters: {'observation_period_num': 52, 'train_rates': 0.8726286078019074, 'learning_rate': 6.017960675708494e-05, 'batch_size': 179, 'step_size': 11, 'gamma': 0.7952893010605324}. Best is trial 9 with value: 0.03759854659438133.[0m
[32m[I 2025-01-04 16:52:12,485][0m Trial 16 finished with value: 0.07197639154536384 and parameters: {'observation_period_num': 160, 'train_rates': 0.9250716748727923, 'learning_rate': 0.00019229966975902065, 'batch_size': 198, 'step_size': 7, 'gamma': 0.864801357477385}. Best is trial 9 with value: 0.03759854659438133.[0m
[32m[I 2025-01-04 16:52:53,197][0m Trial 17 finished with value: 0.08159273614486058 and parameters: {'observation_period_num': 85, 'train_rates': 0.8516479385860206, 'learning_rate': 4.439748821580954e-05, 'batch_size': 142, 'step_size': 15, 'gamma': 0.7882937141273656}. Best is trial 9 with value: 0.03759854659438133.[0m
[32m[I 2025-01-04 16:53:31,934][0m Trial 18 finished with value: 0.044628122276984726 and parameters: {'observation_period_num': 28, 'train_rates': 0.7998122297586961, 'learning_rate': 0.00019130931313450034, 'batch_size': 151, 'step_size': 10, 'gamma': 0.877933438830933}. Best is trial 9 with value: 0.03759854659438133.[0m
[32m[I 2025-01-04 16:54:10,406][0m Trial 19 finished with value: 0.17772136427771112 and parameters: {'observation_period_num': 16, 'train_rates': 0.7783027508549611, 'learning_rate': 0.00020857093890336138, 'batch_size': 149, 'step_size': 5, 'gamma': 0.8968298431653273}. Best is trial 9 with value: 0.03759854659438133.[0m
[32m[I 2025-01-04 16:54:59,139][0m Trial 20 finished with value: 0.16859438489537593 and parameters: {'observation_period_num': 199, 'train_rates': 0.7804365396280032, 'learning_rate': 0.0008339608186553378, 'batch_size': 103, 'step_size': 9, 'gamma': 0.9224070030000755}. Best is trial 9 with value: 0.03759854659438133.[0m
[32m[I 2025-01-04 16:55:55,172][0m Trial 21 finished with value: 0.04601610040497503 and parameters: {'observation_period_num': 33, 'train_rates': 0.8230865143679572, 'learning_rate': 0.00017491305815665827, 'batch_size': 192, 'step_size': 11, 'gamma': 0.8401323523263726}. Best is trial 9 with value: 0.03759854659438133.[0m
[32m[I 2025-01-04 16:56:37,300][0m Trial 22 finished with value: 0.03393089624701953 and parameters: {'observation_period_num': 5, 'train_rates': 0.8136113098613854, 'learning_rate': 0.00022887728545489458, 'batch_size': 159, 'step_size': 10, 'gamma': 0.8604829191058007}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 16:57:17,638][0m Trial 23 finished with value: 0.1587719779720817 and parameters: {'observation_period_num': 16, 'train_rates': 0.7501908461266864, 'learning_rate': 0.0004955031452081965, 'batch_size': 154, 'step_size': 7, 'gamma': 0.8614481149087359}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 16:58:11,564][0m Trial 24 finished with value: 0.054370490301932604 and parameters: {'observation_period_num': 5, 'train_rates': 0.9383916012677449, 'learning_rate': 3.163597237434167e-05, 'batch_size': 117, 'step_size': 13, 'gamma': 0.8901664855677142}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 16:59:02,226][0m Trial 25 finished with value: 0.1581379098769946 and parameters: {'observation_period_num': 36, 'train_rates': 0.6923157522296637, 'learning_rate': 0.0002989165305840552, 'batch_size': 161, 'step_size': 10, 'gamma': 0.82073790028915}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 16:59:57,355][0m Trial 26 finished with value: 0.20829079130631006 and parameters: {'observation_period_num': 77, 'train_rates': 0.883914765233444, 'learning_rate': 0.00016106981926753642, 'batch_size': 217, 'step_size': 6, 'gamma': 0.9168504791943921}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 17:01:02,431][0m Trial 27 finished with value: 0.1921696654624409 and parameters: {'observation_period_num': 28, 'train_rates': 0.7536563009387593, 'learning_rate': 5.486530621357898e-05, 'batch_size': 116, 'step_size': 8, 'gamma': 0.8537475262833538}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 17:03:42,493][0m Trial 28 finished with value: 0.22466427044466483 and parameters: {'observation_period_num': 103, 'train_rates': 0.6678996191372559, 'learning_rate': 0.0006823034852568132, 'batch_size': 22, 'step_size': 10, 'gamma': 0.8772207766354394}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 17:04:52,679][0m Trial 29 finished with value: 0.05767628855602193 and parameters: {'observation_period_num': 5, 'train_rates': 0.7920264283896368, 'learning_rate': 1.6239712996331082e-05, 'batch_size': 77, 'step_size': 14, 'gamma': 0.9509781236750501}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 17:05:38,715][0m Trial 30 finished with value: 0.06991623167920372 and parameters: {'observation_period_num': 66, 'train_rates': 0.8089288463024991, 'learning_rate': 0.0003069447974211725, 'batch_size': 226, 'step_size': 13, 'gamma': 0.9035601694783698}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 17:06:39,259][0m Trial 31 finished with value: 0.04509505725725264 and parameters: {'observation_period_num': 28, 'train_rates': 0.8330160600207501, 'learning_rate': 0.00015387964536894838, 'batch_size': 194, 'step_size': 10, 'gamma': 0.8403019370585363}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 17:07:37,517][0m Trial 32 finished with value: 0.0506813113493372 and parameters: {'observation_period_num': 43, 'train_rates': 0.844270512469835, 'learning_rate': 0.0001415542289143639, 'batch_size': 164, 'step_size': 10, 'gamma': 0.8142924721523305}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 17:08:34,762][0m Trial 33 finished with value: 0.17642643488943577 and parameters: {'observation_period_num': 22, 'train_rates': 0.7665969311457015, 'learning_rate': 0.00022634881936126942, 'batch_size': 186, 'step_size': 8, 'gamma': 0.8707008789912976}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 17:09:26,531][0m Trial 34 finished with value: 0.28224052480909206 and parameters: {'observation_period_num': 140, 'train_rates': 0.7313671550936963, 'learning_rate': 6.897215742062271e-05, 'batch_size': 203, 'step_size': 13, 'gamma': 0.8476374700062123}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 17:10:20,237][0m Trial 35 finished with value: 0.3404824679179397 and parameters: {'observation_period_num': 44, 'train_rates': 0.6083368700416271, 'learning_rate': 8.069391764462754e-06, 'batch_size': 123, 'step_size': 9, 'gamma': 0.87746570590783}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 17:11:23,004][0m Trial 36 finished with value: 0.11576004880871482 and parameters: {'observation_period_num': 111, 'train_rates': 0.9079134958281797, 'learning_rate': 3.0399720692506278e-05, 'batch_size': 149, 'step_size': 10, 'gamma': 0.8352627297315863}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 17:12:24,771][0m Trial 37 finished with value: 0.041598925356230984 and parameters: {'observation_period_num': 27, 'train_rates': 0.8225090862996793, 'learning_rate': 0.0004705074833358104, 'batch_size': 135, 'step_size': 6, 'gamma': 0.810690755059489}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 17:13:51,989][0m Trial 38 finished with value: 0.08069251284941092 and parameters: {'observation_period_num': 252, 'train_rates': 0.9471160447544091, 'learning_rate': 0.0004790690567909313, 'batch_size': 98, 'step_size': 5, 'gamma': 0.7743040459260289}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 17:14:44,265][0m Trial 39 finished with value: 0.1088782248529927 and parameters: {'observation_period_num': 176, 'train_rates': 0.8172583953985636, 'learning_rate': 0.000315492649519714, 'batch_size': 134, 'step_size': 3, 'gamma': 0.8079019519743496}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 17:16:10,052][0m Trial 40 finished with value: 0.06637060583942132 and parameters: {'observation_period_num': 26, 'train_rates': 0.8713074560589649, 'learning_rate': 0.000684233664320101, 'batch_size': 54, 'step_size': 6, 'gamma': 0.8282852028914063}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 17:16:49,308][0m Trial 41 finished with value: 0.045729685171354444 and parameters: {'observation_period_num': 28, 'train_rates': 0.7978107128111054, 'learning_rate': 0.0003982004166649074, 'batch_size': 161, 'step_size': 8, 'gamma': 0.852733614463653}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 17:17:28,532][0m Trial 42 finished with value: 1.300553694603935 and parameters: {'observation_period_num': 50, 'train_rates': 0.8262993456360667, 'learning_rate': 1.1270158463933416e-06, 'batch_size': 176, 'step_size': 4, 'gamma': 0.8278062244661274}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 17:18:16,790][0m Trial 43 finished with value: 0.04331805874215494 and parameters: {'observation_period_num': 6, 'train_rates': 0.8973508725255736, 'learning_rate': 0.00012786310366197511, 'batch_size': 132, 'step_size': 9, 'gamma': 0.8113858817084982}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 17:19:08,125][0m Trial 44 finished with value: 0.03806739553374096 and parameters: {'observation_period_num': 6, 'train_rates': 0.9072122810607102, 'learning_rate': 0.00023944921616633283, 'batch_size': 138, 'step_size': 6, 'gamma': 0.8052944612905132}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 17:20:14,463][0m Trial 45 finished with value: 0.034525669017038144 and parameters: {'observation_period_num': 14, 'train_rates': 0.902749750921716, 'learning_rate': 0.00038548312971591785, 'batch_size': 108, 'step_size': 6, 'gamma': 0.8026866330963484}. Best is trial 22 with value: 0.03393089624701953.[0m
[32m[I 2025-01-04 17:21:53,910][0m Trial 46 finished with value: 0.02907581441104412 and parameters: {'observation_period_num': 16, 'train_rates': 0.9885533687340229, 'learning_rate': 0.0006103901088211146, 'batch_size': 91, 'step_size': 6, 'gamma': 0.7767102362625873}. Best is trial 46 with value: 0.02907581441104412.[0m
[32m[I 2025-01-04 17:23:33,825][0m Trial 47 finished with value: 0.03855987638235092 and parameters: {'observation_period_num': 15, 'train_rates': 0.989498183267158, 'learning_rate': 0.0009952342200148716, 'batch_size': 89, 'step_size': 7, 'gamma': 0.7680362848914943}. Best is trial 46 with value: 0.02907581441104412.[0m
[32m[I 2025-01-04 17:24:35,506][0m Trial 48 finished with value: 0.05287228384270118 and parameters: {'observation_period_num': 39, 'train_rates': 0.9554432391084476, 'learning_rate': 0.0006682239034191242, 'batch_size': 107, 'step_size': 5, 'gamma': 0.7762406627899451}. Best is trial 46 with value: 0.02907581441104412.[0m
[32m[I 2025-01-04 17:25:43,413][0m Trial 49 finished with value: 0.06101884635595175 and parameters: {'observation_period_num': 61, 'train_rates': 0.9192780969569481, 'learning_rate': 0.0002338766236723919, 'batch_size': 64, 'step_size': 3, 'gamma': 0.8018096982129561}. Best is trial 46 with value: 0.02907581441104412.[0m
最適ハイパーパラメータが見つかりました
最適なハイパーパラメータが best_hyperparameters_AMZN_iTransformer_noMSTL.json に保存されました
Epoch 1/300, Loss: 0.2486 | 0.1214
Epoch 2/300, Loss: 0.1484 | 0.0853
Epoch 3/300, Loss: 0.1285 | 0.0758
Epoch 4/300, Loss: 0.1112 | 0.0669
Epoch 5/300, Loss: 0.1140 | 0.0810
Epoch 6/300, Loss: 0.1158 | 0.1017
Epoch 7/300, Loss: 0.1110 | 0.0620
Epoch 8/300, Loss: 0.1017 | 0.0598
Epoch 9/300, Loss: 0.0965 | 0.0574
Epoch 10/300, Loss: 0.0954 | 0.0649
Epoch 11/300, Loss: 0.0916 | 0.0653
Epoch 12/300, Loss: 0.0893 | 0.0575
Epoch 13/300, Loss: 0.0876 | 0.0638
Epoch 14/300, Loss: 0.0851 | 0.0626
Epoch 15/300, Loss: 0.0837 | 0.0593
Epoch 16/300, Loss: 0.0825 | 0.0605
Epoch 17/300, Loss: 0.0850 | 0.0562
Epoch 18/300, Loss: 0.0912 | 0.0639
Epoch 19/300, Loss: 0.0961 | 0.0618
Epoch 20/300, Loss: 0.1051 | 0.0862
Epoch 21/300, Loss: 0.1039 | 0.1112
Epoch 22/300, Loss: 0.0955 | 0.1008
Epoch 23/300, Loss: 0.0882 | 0.0641
Epoch 24/300, Loss: 0.0830 | 0.0550
Epoch 25/300, Loss: 0.0827 | 0.0473
Epoch 26/300, Loss: 0.0797 | 0.0457
Epoch 27/300, Loss: 0.0769 | 0.0444
Epoch 28/300, Loss: 0.0763 | 0.0469
Epoch 29/300, Loss: 0.0752 | 0.0453
Epoch 30/300, Loss: 0.0744 | 0.0435
Epoch 31/300, Loss: 0.0745 | 0.0432
Epoch 32/300, Loss: 0.0737 | 0.0429
Epoch 33/300, Loss: 0.0728 | 0.0425
Epoch 34/300, Loss: 0.0724 | 0.0417
Epoch 35/300, Loss: 0.0718 | 0.0412
Epoch 36/300, Loss: 0.0715 | 0.0410
Epoch 37/300, Loss: 0.0712 | 0.0413
Epoch 38/300, Loss: 0.0709 | 0.0412
Epoch 39/300, Loss: 0.0706 | 0.0414
Epoch 40/300, Loss: 0.0706 | 0.0420
Epoch 41/300, Loss: 0.0705 | 0.0419
Epoch 42/300, Loss: 0.0701 | 0.0416
Epoch 43/300, Loss: 0.0698 | 0.0410
Epoch 44/300, Loss: 0.0695 | 0.0408
Epoch 45/300, Loss: 0.0693 | 0.0408
Epoch 46/300, Loss: 0.0692 | 0.0406
Epoch 47/300, Loss: 0.0691 | 0.0405
Epoch 48/300, Loss: 0.0690 | 0.0405
Epoch 49/300, Loss: 0.0689 | 0.0404
Epoch 50/300, Loss: 0.0688 | 0.0404
Epoch 51/300, Loss: 0.0688 | 0.0403
Epoch 52/300, Loss: 0.0687 | 0.0403
Epoch 53/300, Loss: 0.0687 | 0.0403
Epoch 54/300, Loss: 0.0686 | 0.0402
Epoch 55/300, Loss: 0.0686 | 0.0402
Epoch 56/300, Loss: 0.0685 | 0.0402
Epoch 57/300, Loss: 0.0685 | 0.0401
Epoch 58/300, Loss: 0.0685 | 0.0401
Epoch 59/300, Loss: 0.0684 | 0.0401
Epoch 60/300, Loss: 0.0684 | 0.0401
Epoch 61/300, Loss: 0.0684 | 0.0401
Epoch 62/300, Loss: 0.0683 | 0.0400
Epoch 63/300, Loss: 0.0683 | 0.0400
Epoch 64/300, Loss: 0.0683 | 0.0400
Epoch 65/300, Loss: 0.0683 | 0.0400
Epoch 66/300, Loss: 0.0683 | 0.0400
Epoch 67/300, Loss: 0.0682 | 0.0400
Epoch 68/300, Loss: 0.0682 | 0.0399
Epoch 69/300, Loss: 0.0682 | 0.0399
Epoch 70/300, Loss: 0.0682 | 0.0399
Epoch 71/300, Loss: 0.0682 | 0.0399
Epoch 72/300, Loss: 0.0682 | 0.0399
Epoch 73/300, Loss: 0.0681 | 0.0399
Epoch 74/300, Loss: 0.0681 | 0.0399
Epoch 75/300, Loss: 0.0681 | 0.0399
Epoch 76/300, Loss: 0.0681 | 0.0399
Epoch 77/300, Loss: 0.0681 | 0.0399
Epoch 78/300, Loss: 0.0681 | 0.0399
Epoch 79/300, Loss: 0.0681 | 0.0399
Epoch 80/300, Loss: 0.0681 | 0.0399
Epoch 81/300, Loss: 0.0681 | 0.0399
Epoch 82/300, Loss: 0.0681 | 0.0399
Epoch 83/300, Loss: 0.0681 | 0.0398
Epoch 84/300, Loss: 0.0681 | 0.0398
Epoch 85/300, Loss: 0.0681 | 0.0398
Epoch 86/300, Loss: 0.0681 | 0.0398
Epoch 87/300, Loss: 0.0681 | 0.0398
Epoch 88/300, Loss: 0.0681 | 0.0398
Epoch 89/300, Loss: 0.0680 | 0.0398
Epoch 90/300, Loss: 0.0680 | 0.0398
Epoch 91/300, Loss: 0.0680 | 0.0398
Epoch 92/300, Loss: 0.0680 | 0.0398
Epoch 93/300, Loss: 0.0680 | 0.0398
Epoch 94/300, Loss: 0.0680 | 0.0398
Epoch 95/300, Loss: 0.0680 | 0.0398
Epoch 96/300, Loss: 0.0680 | 0.0398
Epoch 97/300, Loss: 0.0680 | 0.0398
Epoch 98/300, Loss: 0.0680 | 0.0398
Epoch 99/300, Loss: 0.0680 | 0.0398
Epoch 100/300, Loss: 0.0680 | 0.0398
Epoch 101/300, Loss: 0.0680 | 0.0398
Epoch 102/300, Loss: 0.0680 | 0.0398
Epoch 103/300, Loss: 0.0680 | 0.0398
Epoch 104/300, Loss: 0.0680 | 0.0398
Epoch 105/300, Loss: 0.0680 | 0.0398
Epoch 106/300, Loss: 0.0680 | 0.0398
Epoch 107/300, Loss: 0.0680 | 0.0398
Epoch 108/300, Loss: 0.0680 | 0.0398
Epoch 109/300, Loss: 0.0680 | 0.0398
Epoch 110/300, Loss: 0.0680 | 0.0398
Epoch 111/300, Loss: 0.0680 | 0.0398
Epoch 112/300, Loss: 0.0680 | 0.0398
Epoch 113/300, Loss: 0.0680 | 0.0398
Epoch 114/300, Loss: 0.0680 | 0.0398
Epoch 115/300, Loss: 0.0680 | 0.0398
Epoch 116/300, Loss: 0.0680 | 0.0398
Epoch 117/300, Loss: 0.0680 | 0.0398
Epoch 118/300, Loss: 0.0680 | 0.0398
Epoch 119/300, Loss: 0.0680 | 0.0398
Epoch 120/300, Loss: 0.0680 | 0.0398
Epoch 121/300, Loss: 0.0680 | 0.0398
Epoch 122/300, Loss: 0.0680 | 0.0398
Epoch 123/300, Loss: 0.0680 | 0.0398
Epoch 124/300, Loss: 0.0680 | 0.0398
Epoch 125/300, Loss: 0.0680 | 0.0398
Epoch 126/300, Loss: 0.0680 | 0.0398
Epoch 127/300, Loss: 0.0680 | 0.0398
Epoch 128/300, Loss: 0.0680 | 0.0398
Epoch 129/300, Loss: 0.0680 | 0.0398
Epoch 130/300, Loss: 0.0680 | 0.0398
Epoch 131/300, Loss: 0.0680 | 0.0398
Epoch 132/300, Loss: 0.0680 | 0.0398
Epoch 133/300, Loss: 0.0680 | 0.0398
Epoch 134/300, Loss: 0.0680 | 0.0398
Epoch 135/300, Loss: 0.0680 | 0.0398
Epoch 136/300, Loss: 0.0680 | 0.0398
Epoch 137/300, Loss: 0.0680 | 0.0398
Epoch 138/300, Loss: 0.0680 | 0.0398
Epoch 139/300, Loss: 0.0680 | 0.0398
Epoch 140/300, Loss: 0.0680 | 0.0398
Epoch 141/300, Loss: 0.0680 | 0.0398
Epoch 142/300, Loss: 0.0680 | 0.0398
Epoch 143/300, Loss: 0.0680 | 0.0398
Epoch 144/300, Loss: 0.0680 | 0.0398
Epoch 145/300, Loss: 0.0680 | 0.0398
Early stopping
Runtime (seconds): 81.96119213104248
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)
MSE: 3.6887370890472084
RMSE: 1.9206085205078125
MAE: 1.9206085205078125
R-squared: nan
[199.0406]
