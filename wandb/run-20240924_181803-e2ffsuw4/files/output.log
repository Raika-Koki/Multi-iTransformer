[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
/home/raikakoki/.local/lib/python3.10/site-packages/torch/backends/cuda/__init__.py:342: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
Dataset created successfully.
Epoch 1/100, Training Loss: 0.4223, Validation Loss: 0.2063
Epoch 2/100, Training Loss: 0.2240, Validation Loss: 0.1704
Epoch 3/100, Training Loss: 0.1340, Validation Loss: 0.2117
Epoch 4/100, Training Loss: 0.1095, Validation Loss: 0.1375
Epoch 5/100, Training Loss: 0.0880, Validation Loss: 0.0990
Epoch 6/100, Training Loss: 0.0611, Validation Loss: 0.0902
Epoch 7/100, Training Loss: 0.0541, Validation Loss: 0.0865
Epoch 8/100, Training Loss: 0.0519, Validation Loss: 0.0793
Epoch 9/100, Training Loss: 0.0412, Validation Loss: 0.0639
Epoch 10/100, Training Loss: 0.0361, Validation Loss: 0.0510
Epoch 11/100, Training Loss: 0.0423, Validation Loss: 0.0586
Epoch 12/100, Training Loss: 0.0468, Validation Loss: 0.0730
Epoch 13/100, Training Loss: 0.0340, Validation Loss: 0.0450
Epoch 14/100, Training Loss: 0.0480, Validation Loss: 0.0561
Epoch 15/100, Training Loss: 0.0330, Validation Loss: 0.0939
Epoch 16/100, Training Loss: 0.0854, Validation Loss: 0.0484
Epoch 17/100, Training Loss: 0.0526, Validation Loss: 0.1118
Epoch 18/100, Training Loss: 0.0589, Validation Loss: 0.0573
Epoch 19/100, Training Loss: 0.0506, Validation Loss: 0.1466
Epoch 20/100, Training Loss: 0.0770, Validation Loss: 0.0907
Epoch 21/100, Training Loss: 0.0624, Validation Loss: 0.1591
Epoch 22/100, Training Loss: 0.0642, Validation Loss: 0.0659
Epoch 23/100, Training Loss: 0.0479, Validation Loss: 0.0941
Epoch 24/100, Training Loss: 0.0389, Validation Loss: 0.0465
Epoch 25/100, Training Loss: 0.0330, Validation Loss: 0.0645
Epoch 26/100, Training Loss: 0.0284, Validation Loss: 0.0378
Epoch 27/100, Training Loss: 0.0271, Validation Loss: 0.0529
Epoch 28/100, Training Loss: 0.0248, Validation Loss: 0.0344
Epoch 29/100, Training Loss: 0.0245, Validation Loss: 0.0471
Epoch 30/100, Training Loss: 0.0231, Validation Loss: 0.0316
Epoch 31/100, Training Loss: 0.0231, Validation Loss: 0.0447
Epoch 32/100, Training Loss: 0.0221, Validation Loss: 0.0294
Epoch 33/100, Training Loss: 0.0223, Validation Loss: 0.0434
Epoch 34/100, Training Loss: 0.0215, Validation Loss: 0.0277
Epoch 35/100, Training Loss: 0.0218, Validation Loss: 0.0425
Epoch 36/100, Training Loss: 0.0211, Validation Loss: 0.0265
Epoch 37/100, Training Loss: 0.0214, Validation Loss: 0.0413
Epoch 38/100, Training Loss: 0.0207, Validation Loss: 0.0258
Epoch 39/100, Training Loss: 0.0209, Validation Loss: 0.0390
Epoch 40/100, Training Loss: 0.0202, Validation Loss: 0.0256
Epoch 41/100, Training Loss: 0.0203, Validation Loss: 0.0361
Epoch 42/100, Training Loss: 0.0200, Validation Loss: 0.0262
Epoch 43/100, Training Loss: 0.0204, Validation Loss: 0.0334
Epoch 44/100, Training Loss: 0.0214, Validation Loss: 0.0281
Epoch 45/100, Training Loss: 0.0230, Validation Loss: 0.0321
Epoch 46/100, Training Loss: 0.0276, Validation Loss: 0.0315
Epoch 47/100, Training Loss: 0.0318, Validation Loss: 0.0313
Epoch 48/100, Training Loss: 0.0399, Validation Loss: 0.0325
Epoch 49/100, Training Loss: 0.0363, Validation Loss: 0.0280
Epoch 50/100, Training Loss: 0.0318, Validation Loss: 0.0301
Epoch 51/100, Training Loss: 0.0231, Validation Loss: 0.0275
Epoch 52/100, Training Loss: 0.0199, Validation Loss: 0.0283
Epoch 53/100, Training Loss: 0.0181, Validation Loss: 0.0273
Epoch 54/100, Training Loss: 0.0176, Validation Loss: 0.0272
Epoch 55/100, Training Loss: 0.0173, Validation Loss: 0.0267
Epoch 56/100, Training Loss: 0.0172, Validation Loss: 0.0264
Epoch 57/100, Training Loss: 0.0170, Validation Loss: 0.0262
Epoch 58/100, Training Loss: 0.0169, Validation Loss: 0.0259
Epoch 59/100, Training Loss: 0.0168, Validation Loss: 0.0257
Epoch 60/100, Training Loss: 0.0168, Validation Loss: 0.0255
Epoch 61/100, Training Loss: 0.0167, Validation Loss: 0.0253
Epoch 62/100, Training Loss: 0.0166, Validation Loss: 0.0252
Epoch 63/100, Training Loss: 0.0165, Validation Loss: 0.0250
Epoch 64/100, Training Loss: 0.0165, Validation Loss: 0.0249
Epoch 65/100, Training Loss: 0.0164, Validation Loss: 0.0248
Epoch 66/100, Training Loss: 0.0164, Validation Loss: 0.0246
Epoch 67/100, Training Loss: 0.0163, Validation Loss: 0.0245
Epoch 68/100, Training Loss: 0.0163, Validation Loss: 0.0244
Epoch 69/100, Training Loss: 0.0162, Validation Loss: 0.0243
Epoch 70/100, Training Loss: 0.0162, Validation Loss: 0.0243
Epoch 71/100, Training Loss: 0.0161, Validation Loss: 0.0242
Epoch 72/100, Training Loss: 0.0161, Validation Loss: 0.0241
Epoch 73/100, Training Loss: 0.0161, Validation Loss: 0.0240
Epoch 74/100, Training Loss: 0.0160, Validation Loss: 0.0240
Epoch 75/100, Training Loss: 0.0160, Validation Loss: 0.0239
Epoch 76/100, Training Loss: 0.0160, Validation Loss: 0.0238
Epoch 77/100, Training Loss: 0.0159, Validation Loss: 0.0238
Epoch 78/100, Training Loss: 0.0159, Validation Loss: 0.0237
Epoch 79/100, Training Loss: 0.0159, Validation Loss: 0.0237
Epoch 80/100, Training Loss: 0.0159, Validation Loss: 0.0236
Epoch 81/100, Training Loss: 0.0158, Validation Loss: 0.0236
Epoch 82/100, Training Loss: 0.0158, Validation Loss: 0.0235
Epoch 83/100, Training Loss: 0.0158, Validation Loss: 0.0235
Epoch 84/100, Training Loss: 0.0158, Validation Loss: 0.0235
Epoch 85/100, Training Loss: 0.0157, Validation Loss: 0.0234
Epoch 86/100, Training Loss: 0.0157, Validation Loss: 0.0234
Epoch 87/100, Training Loss: 0.0157, Validation Loss: 0.0234
Epoch 88/100, Training Loss: 0.0157, Validation Loss: 0.0233
Epoch 89/100, Training Loss: 0.0157, Validation Loss: 0.0233
Epoch 90/100, Training Loss: 0.0157, Validation Loss: 0.0233
Epoch 91/100, Training Loss: 0.0156, Validation Loss: 0.0232
Epoch 92/100, Training Loss: 0.0156, Validation Loss: 0.0232
Epoch 93/100, Training Loss: 0.0156, Validation Loss: 0.0232
Epoch 94/100, Training Loss: 0.0156, Validation Loss: 0.0232
Epoch 95/100, Training Loss: 0.0156, Validation Loss: 0.0231
Epoch 96/100, Training Loss: 0.0156, Validation Loss: 0.0231
Epoch 97/100, Training Loss: 0.0156, Validation Loss: 0.0231
/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/demo.py:123: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  predicted_stock_price = predicted_stock_price.cpu().numpy().flatten() * std_list[-1] + mean_list[-1]
Traceback (most recent call last):
  File "/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/demo.py", line 141, in <module>
    plt.plot(predicted_dates, add_predicted_stock_price, linestyle='dotted', color='red', label='Predicted Price')
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/pyplot.py", line 3708, in plot
    return gca().plot(
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/axes/_axes.py", line 1779, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/axes/_base.py", line 296, in __call__
    yield from self._plot_args(
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/axes/_base.py", line 486, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "
ValueError: x and y must have same first dimension, but have shapes (10,) and (14,)
Traceback (most recent call last):
  File "/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/demo.py", line 141, in <module>
    plt.plot(predicted_dates, add_predicted_stock_price, linestyle='dotted', color='red', label='Predicted Price')
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/pyplot.py", line 3708, in plot
    return gca().plot(
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/axes/_axes.py", line 1779, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/axes/_base.py", line 296, in __call__
    yield from self._plot_args(
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/axes/_base.py", line 486, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "
ValueError: x and y must have same first dimension, but have shapes (10,) and (14,)
Epoch 98/100, Training Loss: 0.0156, Validation Loss: 0.0231
Epoch 99/100, Training Loss: 0.0156, Validation Loss: 0.0231
Epoch 100/100, Training Loss: 0.0155, Validation Loss: 0.0230
['2023-05-17', '2023-05-18', '2023-05-19', '2023-05-22', '2023-05-23', '2023-05-24', '2023-05-25', '2023-05-26', '2023-05-30', '2023-05-31']
[279.428   306.73807 257.60022 213.06706 313.5214 ]
[171.57914734 173.9239502  174.03323364 173.079422   170.45640564
 170.73458862 171.87721252 174.30149841 176.15948486 279.42800903
 306.73806763 257.60021973 213.06706238 313.52139282]
[171.57914734 173.9239502  174.03323364 173.079422   170.45640564
 170.73458862 171.87721252 174.30149841 176.15948486 176.10980225]