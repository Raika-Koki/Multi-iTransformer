[32m[I 2025-02-06 02:55:36,430][0m A new study created in memory with name: no-name-fa1d808b-7969-4a20-a9ee-6756a048a605[0m
[32m[I 2025-02-06 02:56:00,466][0m Trial 0 finished with value: 0.1594105035823146 and parameters: {'observation_period_num': 27, 'train_rates': 0.6267537687598091, 'learning_rate': 7.762328995310246e-05, 'batch_size': 218, 'step_size': 14, 'gamma': 0.9151389481719414}. Best is trial 0 with value: 0.1594105035823146.[0m
[32m[I 2025-02-06 02:57:20,853][0m Trial 1 finished with value: 0.585965049709698 and parameters: {'observation_period_num': 227, 'train_rates': 0.7655613897681303, 'learning_rate': 2.5491511569889473e-06, 'batch_size': 60, 'step_size': 12, 'gamma': 0.9473769014729245}. Best is trial 0 with value: 0.1594105035823146.[0m
Early stopping at epoch 82
[32m[I 2025-02-06 02:58:01,237][0m Trial 2 finished with value: 0.32571478826659067 and parameters: {'observation_period_num': 181, 'train_rates': 0.7376521434337275, 'learning_rate': 0.0007632779427290076, 'batch_size': 102, 'step_size': 1, 'gamma': 0.8400518081162296}. Best is trial 0 with value: 0.1594105035823146.[0m
[32m[I 2025-02-06 02:58:27,818][0m Trial 3 finished with value: 0.7867435649546614 and parameters: {'observation_period_num': 18, 'train_rates': 0.7730349703990007, 'learning_rate': 3.1216320219364965e-06, 'batch_size': 213, 'step_size': 15, 'gamma': 0.8314007439962352}. Best is trial 0 with value: 0.1594105035823146.[0m
[32m[I 2025-02-06 02:59:01,701][0m Trial 4 finished with value: 0.34493155924149743 and parameters: {'observation_period_num': 187, 'train_rates': 0.8619892649044942, 'learning_rate': 4.952716626529257e-05, 'batch_size': 164, 'step_size': 1, 'gamma': 0.9512694636722979}. Best is trial 0 with value: 0.1594105035823146.[0m
[32m[I 2025-02-06 03:04:12,859][0m Trial 5 finished with value: 0.041517425252646775 and parameters: {'observation_period_num': 10, 'train_rates': 0.8223744842730503, 'learning_rate': 8.63821408934901e-06, 'batch_size': 17, 'step_size': 15, 'gamma': 0.9213326020681794}. Best is trial 5 with value: 0.041517425252646775.[0m
[32m[I 2025-02-06 03:05:25,429][0m Trial 6 finished with value: 0.17171647060906703 and parameters: {'observation_period_num': 29, 'train_rates': 0.7572917972298436, 'learning_rate': 0.000336851702611771, 'batch_size': 71, 'step_size': 12, 'gamma': 0.9610976241196266}. Best is trial 5 with value: 0.041517425252646775.[0m
[32m[I 2025-02-06 03:06:20,464][0m Trial 7 finished with value: 0.060019106507660396 and parameters: {'observation_period_num': 29, 'train_rates': 0.8594891082150685, 'learning_rate': 2.821477216286227e-05, 'batch_size': 102, 'step_size': 9, 'gamma': 0.8897688023528706}. Best is trial 5 with value: 0.041517425252646775.[0m
[32m[I 2025-02-06 03:07:07,987][0m Trial 8 finished with value: 0.23180432071741744 and parameters: {'observation_period_num': 146, 'train_rates': 0.7293698231500997, 'learning_rate': 0.0003046761730583428, 'batch_size': 107, 'step_size': 3, 'gamma': 0.8654324763367138}. Best is trial 5 with value: 0.041517425252646775.[0m
[32m[I 2025-02-06 03:07:56,540][0m Trial 9 finished with value: 0.7255619861822589 and parameters: {'observation_period_num': 104, 'train_rates': 0.9064945367512285, 'learning_rate': 2.2978577643720776e-06, 'batch_size': 120, 'step_size': 9, 'gamma': 0.8577735599029532}. Best is trial 5 with value: 0.041517425252646775.[0m
[32m[I 2025-02-06 03:11:34,678][0m Trial 10 finished with value: 0.26464097743684595 and parameters: {'observation_period_num': 87, 'train_rates': 0.9394467623515027, 'learning_rate': 1.0146956692527965e-05, 'batch_size': 26, 'step_size': 6, 'gamma': 0.7554138524598986}. Best is trial 5 with value: 0.041517425252646775.[0m
[32m[I 2025-02-06 03:14:03,820][0m Trial 11 finished with value: 0.07847802848752199 and parameters: {'observation_period_num': 67, 'train_rates': 0.8460129506929958, 'learning_rate': 1.351273371256008e-05, 'batch_size': 36, 'step_size': 8, 'gamma': 0.9071857980425339}. Best is trial 5 with value: 0.041517425252646775.[0m
[32m[I 2025-02-06 03:14:42,018][0m Trial 12 finished with value: 0.09501508556076609 and parameters: {'observation_period_num': 5, 'train_rates': 0.8476283060716924, 'learning_rate': 1.4252449379310127e-05, 'batch_size': 155, 'step_size': 10, 'gamma': 0.9023989746342408}. Best is trial 5 with value: 0.041517425252646775.[0m
[32m[I 2025-02-06 03:16:06,359][0m Trial 13 finished with value: 0.08358003944158554 and parameters: {'observation_period_num': 59, 'train_rates': 0.9797299271766812, 'learning_rate': 9.89815525088528e-05, 'batch_size': 73, 'step_size': 7, 'gamma': 0.7988078943581853}. Best is trial 5 with value: 0.041517425252646775.[0m
[32m[I 2025-02-06 03:16:34,363][0m Trial 14 finished with value: 0.8469618324510114 and parameters: {'observation_period_num': 52, 'train_rates': 0.6578914582732946, 'learning_rate': 5.440996461186516e-06, 'batch_size': 188, 'step_size': 4, 'gamma': 0.8918169474042352}. Best is trial 5 with value: 0.041517425252646775.[0m
[32m[I 2025-02-06 03:16:58,078][0m Trial 15 finished with value: 0.864603444305873 and parameters: {'observation_period_num': 130, 'train_rates': 0.8170121201749089, 'learning_rate': 1.0612285759992392e-06, 'batch_size': 254, 'step_size': 12, 'gamma': 0.9842787829010897}. Best is trial 5 with value: 0.041517425252646775.[0m
[32m[I 2025-02-06 03:22:19,687][0m Trial 16 finished with value: 0.07236446658508819 and parameters: {'observation_period_num': 97, 'train_rates': 0.9011920555853628, 'learning_rate': 2.7199591446646292e-05, 'batch_size': 17, 'step_size': 10, 'gamma': 0.9338205879921831}. Best is trial 5 with value: 0.041517425252646775.[0m
[32m[I 2025-02-06 03:23:13,795][0m Trial 17 finished with value: 0.18157394072168495 and parameters: {'observation_period_num': 48, 'train_rates': 0.7012979127618856, 'learning_rate': 3.113451038969115e-05, 'batch_size': 92, 'step_size': 14, 'gamma': 0.8848771046498275}. Best is trial 5 with value: 0.041517425252646775.[0m
[32m[I 2025-02-06 03:24:54,050][0m Trial 18 finished with value: 0.3272179439281806 and parameters: {'observation_period_num': 37, 'train_rates': 0.8012533802755287, 'learning_rate': 6.850833339119679e-06, 'batch_size': 53, 'step_size': 5, 'gamma': 0.7993404524476404}. Best is trial 5 with value: 0.041517425252646775.[0m
[32m[I 2025-02-06 03:25:40,675][0m Trial 19 finished with value: 0.1099574161350512 and parameters: {'observation_period_num': 76, 'train_rates': 0.904690850262393, 'learning_rate': 2.150445590063344e-05, 'batch_size': 128, 'step_size': 11, 'gamma': 0.9830017131285487}. Best is trial 5 with value: 0.041517425252646775.[0m
[32m[I 2025-02-06 03:26:51,743][0m Trial 20 finished with value: 0.05123274773359299 and parameters: {'observation_period_num': 5, 'train_rates': 0.9770690529097746, 'learning_rate': 0.00011101348864248681, 'batch_size': 87, 'step_size': 15, 'gamma': 0.9250351299884019}. Best is trial 5 with value: 0.041517425252646775.[0m
[32m[I 2025-02-06 03:28:06,297][0m Trial 21 finished with value: 0.037381113347438 and parameters: {'observation_period_num': 6, 'train_rates': 0.962775669468684, 'learning_rate': 0.00017345093052117955, 'batch_size': 83, 'step_size': 15, 'gamma': 0.9247967504708147}. Best is trial 21 with value: 0.037381113347438.[0m
[32m[I 2025-02-06 03:29:22,806][0m Trial 22 finished with value: 0.039163004606962204 and parameters: {'observation_period_num': 9, 'train_rates': 0.9783153695607213, 'learning_rate': 0.00016136847574009112, 'batch_size': 79, 'step_size': 15, 'gamma': 0.9267491036346499}. Best is trial 21 with value: 0.037381113347438.[0m
[32m[I 2025-02-06 03:31:33,583][0m Trial 23 finished with value: 0.039911509957164526 and parameters: {'observation_period_num': 7, 'train_rates': 0.9355565477090458, 'learning_rate': 0.00021970769829625416, 'batch_size': 46, 'step_size': 13, 'gamma': 0.9359533268396487}. Best is trial 21 with value: 0.037381113347438.[0m
[32m[I 2025-02-06 03:33:21,210][0m Trial 24 finished with value: 0.1991220619026068 and parameters: {'observation_period_num': 249, 'train_rates': 0.9458313774319406, 'learning_rate': 0.0002773483945195387, 'batch_size': 51, 'step_size': 13, 'gamma': 0.9673649405669713}. Best is trial 21 with value: 0.037381113347438.[0m
[32m[I 2025-02-06 03:35:42,535][0m Trial 25 finished with value: 0.09723816625773907 and parameters: {'observation_period_num': 45, 'train_rates': 0.9442709280005664, 'learning_rate': 0.00017670117740352628, 'batch_size': 41, 'step_size': 13, 'gamma': 0.9398324114863136}. Best is trial 21 with value: 0.037381113347438.[0m
[32m[I 2025-02-06 03:36:58,259][0m Trial 26 finished with value: 0.38258546590805054 and parameters: {'observation_period_num': 112, 'train_rates': 0.9843902534636262, 'learning_rate': 0.00018612325687840167, 'batch_size': 79, 'step_size': 14, 'gamma': 0.9694861070150071}. Best is trial 21 with value: 0.037381113347438.[0m
[32m[I 2025-02-06 03:37:41,885][0m Trial 27 finished with value: 0.156067000427827 and parameters: {'observation_period_num': 63, 'train_rates': 0.9326717250968576, 'learning_rate': 0.0009566263205888602, 'batch_size': 140, 'step_size': 13, 'gamma': 0.8753991190664226}. Best is trial 21 with value: 0.037381113347438.[0m
[32m[I 2025-02-06 03:39:09,104][0m Trial 28 finished with value: 0.10476502477243586 and parameters: {'observation_period_num': 24, 'train_rates': 0.8855699591063895, 'learning_rate': 0.00048633703607297836, 'batch_size': 64, 'step_size': 15, 'gamma': 0.9052624601487956}. Best is trial 21 with value: 0.037381113347438.[0m
[32m[I 2025-02-06 03:40:02,577][0m Trial 29 finished with value: 0.06955398619174957 and parameters: {'observation_period_num': 32, 'train_rates': 0.9640670677013662, 'learning_rate': 4.640676883640313e-05, 'batch_size': 114, 'step_size': 14, 'gamma': 0.9256155036727758}. Best is trial 21 with value: 0.037381113347438.[0m
[32m[I 2025-02-06 03:42:07,235][0m Trial 30 finished with value: 0.17378079537151095 and parameters: {'observation_period_num': 77, 'train_rates': 0.6181992683057725, 'learning_rate': 7.22495056627393e-05, 'batch_size': 35, 'step_size': 11, 'gamma': 0.9460031436735978}. Best is trial 21 with value: 0.037381113347438.[0m
[32m[I 2025-02-06 03:48:03,684][0m Trial 31 finished with value: 0.038802567960285556 and parameters: {'observation_period_num': 10, 'train_rates': 0.9174516353348207, 'learning_rate': 0.00016127151129821063, 'batch_size': 16, 'step_size': 15, 'gamma': 0.9184353255802025}. Best is trial 21 with value: 0.037381113347438.[0m
[32m[I 2025-02-06 03:50:02,072][0m Trial 32 finished with value: 0.04170826768417576 and parameters: {'observation_period_num': 18, 'train_rates': 0.9187737107071945, 'learning_rate': 0.00014064585575459377, 'batch_size': 49, 'step_size': 13, 'gamma': 0.9145759757014519}. Best is trial 21 with value: 0.037381113347438.[0m
[32m[I 2025-02-06 03:51:34,883][0m Trial 33 finished with value: 0.11502524854784663 and parameters: {'observation_period_num': 45, 'train_rates': 0.9550466920390891, 'learning_rate': 0.0006071972080173592, 'batch_size': 65, 'step_size': 15, 'gamma': 0.9551512652531544}. Best is trial 21 with value: 0.037381113347438.[0m
[32m[I 2025-02-06 03:54:28,003][0m Trial 34 finished with value: 0.05365187911824747 and parameters: {'observation_period_num': 17, 'train_rates': 0.881523858780883, 'learning_rate': 0.00024028135473408655, 'batch_size': 32, 'step_size': 14, 'gamma': 0.9338903655464934}. Best is trial 21 with value: 0.037381113347438.[0m
[32m[I 2025-02-06 03:55:31,840][0m Trial 35 finished with value: 0.3293437957763672 and parameters: {'observation_period_num': 187, 'train_rates': 0.9880863379319594, 'learning_rate': 6.78751388557174e-05, 'batch_size': 93, 'step_size': 15, 'gamma': 0.8510108546245911}. Best is trial 21 with value: 0.037381113347438.[0m
[32m[I 2025-02-06 03:57:38,764][0m Trial 36 finished with value: 0.03602354694967685 and parameters: {'observation_period_num': 5, 'train_rates': 0.9615231205903134, 'learning_rate': 0.0003968880518147226, 'batch_size': 48, 'step_size': 12, 'gamma': 0.9162210527196504}. Best is trial 36 with value: 0.03602354694967685.[0m
[32m[I 2025-02-06 03:58:52,618][0m Trial 37 finished with value: 0.08869752140328435 and parameters: {'observation_period_num': 34, 'train_rates': 0.9659439451175115, 'learning_rate': 0.000432152971673174, 'batch_size': 82, 'step_size': 12, 'gamma': 0.9150110126525524}. Best is trial 36 with value: 0.03602354694967685.[0m
[32m[I 2025-02-06 04:03:24,057][0m Trial 38 finished with value: 0.3102574284713177 and parameters: {'observation_period_num': 209, 'train_rates': 0.8777664745441276, 'learning_rate': 0.00013050657684405209, 'batch_size': 19, 'step_size': 11, 'gamma': 0.8764046529136938}. Best is trial 36 with value: 0.03602354694967685.[0m
[32m[I 2025-02-06 04:05:01,516][0m Trial 39 finished with value: 0.05282766351828704 and parameters: {'observation_period_num': 20, 'train_rates': 0.9250071662973813, 'learning_rate': 4.735336946993754e-05, 'batch_size': 60, 'step_size': 14, 'gamma': 0.8990408090399289}. Best is trial 36 with value: 0.03602354694967685.[0m
[32m[I 2025-02-06 04:05:46,969][0m Trial 40 finished with value: 0.1017700657248497 and parameters: {'observation_period_num': 38, 'train_rates': 0.9603369451166177, 'learning_rate': 0.0004252467142153487, 'batch_size': 139, 'step_size': 15, 'gamma': 0.9505089861727892}. Best is trial 36 with value: 0.03602354694967685.[0m
[32m[I 2025-02-06 04:08:16,369][0m Trial 41 finished with value: 0.047179520751039185 and parameters: {'observation_period_num': 8, 'train_rates': 0.9212744866246915, 'learning_rate': 0.00022699455458833698, 'batch_size': 39, 'step_size': 13, 'gamma': 0.9308793040258602}. Best is trial 36 with value: 0.03602354694967685.[0m
[32m[I 2025-02-06 04:10:11,801][0m Trial 42 finished with value: 0.08484802395105362 and parameters: {'observation_period_num': 18, 'train_rates': 0.9896778798833658, 'learning_rate': 0.0007939698864285332, 'batch_size': 54, 'step_size': 12, 'gamma': 0.9430305841167534}. Best is trial 36 with value: 0.03602354694967685.[0m
[32m[I 2025-02-06 04:13:37,212][0m Trial 43 finished with value: 0.18951722350902855 and parameters: {'observation_period_num': 159, 'train_rates': 0.9435664432305717, 'learning_rate': 0.0001621243110034678, 'batch_size': 27, 'step_size': 14, 'gamma': 0.9203566829024203}. Best is trial 36 with value: 0.03602354694967685.[0m
[32m[I 2025-02-06 04:15:02,848][0m Trial 44 finished with value: 0.053453575679153764 and parameters: {'observation_period_num': 25, 'train_rates': 0.964455110130027, 'learning_rate': 0.00037336959791843457, 'batch_size': 71, 'step_size': 15, 'gamma': 0.9617102511858241}. Best is trial 36 with value: 0.03602354694967685.[0m
[32m[I 2025-02-06 04:16:00,647][0m Trial 45 finished with value: 0.040134583265627716 and parameters: {'observation_period_num': 8, 'train_rates': 0.9035518100905, 'learning_rate': 8.399392954546173e-05, 'batch_size': 101, 'step_size': 14, 'gamma': 0.8935374908409242}. Best is trial 36 with value: 0.03602354694967685.[0m
[32m[I 2025-02-06 04:18:16,450][0m Trial 46 finished with value: 0.028875645797399548 and parameters: {'observation_period_num': 5, 'train_rates': 0.9292358923105408, 'learning_rate': 0.0006062042892277756, 'batch_size': 43, 'step_size': 2, 'gamma': 0.9111655372509643}. Best is trial 46 with value: 0.028875645797399548.[0m
[32m[I 2025-02-06 04:22:01,312][0m Trial 47 finished with value: 0.04595181492775896 and parameters: {'observation_period_num': 28, 'train_rates': 0.8609849392404211, 'learning_rate': 0.0006933998422368432, 'batch_size': 24, 'step_size': 2, 'gamma': 0.9092248649490501}. Best is trial 46 with value: 0.028875645797399548.[0m
[32m[I 2025-02-06 04:23:20,323][0m Trial 48 finished with value: 0.07436365306594268 and parameters: {'observation_period_num': 16, 'train_rates': 0.8377590994512084, 'learning_rate': 0.0005311813885319895, 'batch_size': 70, 'step_size': 7, 'gamma': 0.8843797007770718}. Best is trial 46 with value: 0.028875645797399548.[0m
[32m[I 2025-02-06 04:29:01,249][0m Trial 49 finished with value: 0.13808764204098162 and parameters: {'observation_period_num': 58, 'train_rates': 0.8926681610666904, 'learning_rate': 0.0003202862973346139, 'batch_size': 16, 'step_size': 9, 'gamma': 0.8648061789280085}. Best is trial 46 with value: 0.028875645797399548.[0m
最適ハイパーパラメータが見つかりました
最適なハイパーパラメータが best_hyperparameters_GOOG_iTransformer_noMSTL.json に保存されました
Epoch 1/300, Loss: 0.2066 | 0.1215
Epoch 2/300, Loss: 0.1152 | 0.0892
Epoch 3/300, Loss: 0.1038 | 0.0751
Epoch 4/300, Loss: 0.0973 | 0.0658
Epoch 5/300, Loss: 0.0905 | 0.0569
Epoch 6/300, Loss: 0.0865 | 0.0549
Epoch 7/300, Loss: 0.0869 | 0.0569
Epoch 8/300, Loss: 0.0872 | 0.0553
Epoch 9/300, Loss: 0.0843 | 0.0494
Epoch 10/300, Loss: 0.0790 | 0.0472
Epoch 11/300, Loss: 0.0761 | 0.0436
Epoch 12/300, Loss: 0.0746 | 0.0412
Epoch 13/300, Loss: 0.0735 | 0.0400
Epoch 14/300, Loss: 0.0722 | 0.0382
Epoch 15/300, Loss: 0.0709 | 0.0374
Epoch 16/300, Loss: 0.0698 | 0.0367
Epoch 17/300, Loss: 0.0691 | 0.0362
Epoch 18/300, Loss: 0.0685 | 0.0358
Epoch 19/300, Loss: 0.0680 | 0.0356
Epoch 20/300, Loss: 0.0676 | 0.0355
Epoch 21/300, Loss: 0.0672 | 0.0355
Epoch 22/300, Loss: 0.0668 | 0.0355
Epoch 23/300, Loss: 0.0665 | 0.0354
Epoch 24/300, Loss: 0.0662 | 0.0353
Epoch 25/300, Loss: 0.0659 | 0.0350
Epoch 26/300, Loss: 0.0657 | 0.0346
Epoch 27/300, Loss: 0.0655 | 0.0344
Epoch 28/300, Loss: 0.0654 | 0.0347
Epoch 29/300, Loss: 0.0652 | 0.0351
Epoch 30/300, Loss: 0.0649 | 0.0351
Epoch 31/300, Loss: 0.0646 | 0.0346
Epoch 32/300, Loss: 0.0643 | 0.0341
Epoch 33/300, Loss: 0.0640 | 0.0337
Epoch 34/300, Loss: 0.0638 | 0.0336
Epoch 35/300, Loss: 0.0637 | 0.0335
Epoch 36/300, Loss: 0.0635 | 0.0335
Epoch 37/300, Loss: 0.0634 | 0.0335
Epoch 38/300, Loss: 0.0633 | 0.0335
Epoch 39/300, Loss: 0.0631 | 0.0335
Epoch 40/300, Loss: 0.0630 | 0.0335
Epoch 41/300, Loss: 0.0629 | 0.0336
Epoch 42/300, Loss: 0.0628 | 0.0336
Epoch 43/300, Loss: 0.0627 | 0.0335
Epoch 44/300, Loss: 0.0627 | 0.0334
Epoch 45/300, Loss: 0.0626 | 0.0332
Epoch 46/300, Loss: 0.0626 | 0.0331
Epoch 47/300, Loss: 0.0626 | 0.0330
Epoch 48/300, Loss: 0.0626 | 0.0329
Epoch 49/300, Loss: 0.0626 | 0.0328
Epoch 50/300, Loss: 0.0625 | 0.0328
Epoch 51/300, Loss: 0.0624 | 0.0330
Epoch 52/300, Loss: 0.0623 | 0.0331
Epoch 53/300, Loss: 0.0622 | 0.0332
Epoch 54/300, Loss: 0.0621 | 0.0332
Epoch 55/300, Loss: 0.0621 | 0.0333
Epoch 56/300, Loss: 0.0620 | 0.0332
Epoch 57/300, Loss: 0.0620 | 0.0332
Epoch 58/300, Loss: 0.0619 | 0.0332
Epoch 59/300, Loss: 0.0619 | 0.0331
Epoch 60/300, Loss: 0.0619 | 0.0331
Epoch 61/300, Loss: 0.0619 | 0.0330
Epoch 62/300, Loss: 0.0618 | 0.0330
Epoch 63/300, Loss: 0.0618 | 0.0330
Epoch 64/300, Loss: 0.0618 | 0.0329
Epoch 65/300, Loss: 0.0618 | 0.0329
Epoch 66/300, Loss: 0.0618 | 0.0329
Epoch 67/300, Loss: 0.0617 | 0.0329
Epoch 68/300, Loss: 0.0617 | 0.0329
Epoch 69/300, Loss: 0.0617 | 0.0329
Epoch 70/300, Loss: 0.0617 | 0.0329
Epoch 71/300, Loss: 0.0617 | 0.0329
Epoch 72/300, Loss: 0.0616 | 0.0329
Epoch 73/300, Loss: 0.0616 | 0.0329
Epoch 74/300, Loss: 0.0616 | 0.0329
Epoch 75/300, Loss: 0.0616 | 0.0329
Epoch 76/300, Loss: 0.0616 | 0.0329
Epoch 77/300, Loss: 0.0616 | 0.0329
Epoch 78/300, Loss: 0.0616 | 0.0329
Epoch 79/300, Loss: 0.0616 | 0.0329
Epoch 80/300, Loss: 0.0616 | 0.0329
Epoch 81/300, Loss: 0.0615 | 0.0329
Epoch 82/300, Loss: 0.0615 | 0.0329
Epoch 83/300, Loss: 0.0615 | 0.0329
Epoch 84/300, Loss: 0.0615 | 0.0329
Epoch 85/300, Loss: 0.0615 | 0.0329
Epoch 86/300, Loss: 0.0615 | 0.0329
Epoch 87/300, Loss: 0.0615 | 0.0329
Epoch 88/300, Loss: 0.0615 | 0.0329
Epoch 89/300, Loss: 0.0615 | 0.0329
Epoch 90/300, Loss: 0.0615 | 0.0329
Epoch 91/300, Loss: 0.0615 | 0.0329
Epoch 92/300, Loss: 0.0615 | 0.0329
Epoch 93/300, Loss: 0.0615 | 0.0329
Epoch 94/300, Loss: 0.0615 | 0.0329
Epoch 95/300, Loss: 0.0615 | 0.0329
Epoch 96/300, Loss: 0.0615 | 0.0329
Epoch 97/300, Loss: 0.0615 | 0.0329
Epoch 98/300, Loss: 0.0615 | 0.0329
Epoch 99/300, Loss: 0.0615 | 0.0329
Epoch 100/300, Loss: 0.0615 | 0.0329
Epoch 101/300, Loss: 0.0615 | 0.0329
Epoch 102/300, Loss: 0.0615 | 0.0329
Epoch 103/300, Loss: 0.0615 | 0.0329
Epoch 104/300, Loss: 0.0615 | 0.0329
Epoch 105/300, Loss: 0.0615 | 0.0329
Epoch 106/300, Loss: 0.0615 | 0.0329
Epoch 107/300, Loss: 0.0615 | 0.0329
Epoch 108/300, Loss: 0.0615 | 0.0329
Epoch 109/300, Loss: 0.0615 | 0.0329
Epoch 110/300, Loss: 0.0615 | 0.0329
Epoch 111/300, Loss: 0.0615 | 0.0329
Epoch 112/300, Loss: 0.0615 | 0.0329
Epoch 113/300, Loss: 0.0615 | 0.0329
Epoch 114/300, Loss: 0.0615 | 0.0329
Epoch 115/300, Loss: 0.0615 | 0.0329
Epoch 116/300, Loss: 0.0615 | 0.0329
Epoch 117/300, Loss: 0.0615 | 0.0329
Epoch 118/300, Loss: 0.0615 | 0.0329
Epoch 119/300, Loss: 0.0615 | 0.0329
Epoch 120/300, Loss: 0.0615 | 0.0329
Epoch 121/300, Loss: 0.0615 | 0.0329
Epoch 122/300, Loss: 0.0615 | 0.0329
Epoch 123/300, Loss: 0.0615 | 0.0329
Epoch 124/300, Loss: 0.0615 | 0.0329
Epoch 125/300, Loss: 0.0615 | 0.0329
Epoch 126/300, Loss: 0.0615 | 0.0329
Epoch 127/300, Loss: 0.0615 | 0.0329
Epoch 128/300, Loss: 0.0615 | 0.0329
Epoch 129/300, Loss: 0.0615 | 0.0329
Epoch 130/300, Loss: 0.0615 | 0.0329
Epoch 131/300, Loss: 0.0615 | 0.0329
Epoch 132/300, Loss: 0.0615 | 0.0329
Epoch 133/300, Loss: 0.0615 | 0.0329
Epoch 134/300, Loss: 0.0615 | 0.0329
Epoch 135/300, Loss: 0.0615 | 0.0329
Epoch 136/300, Loss: 0.0615 | 0.0329
Epoch 137/300, Loss: 0.0615 | 0.0329
Epoch 138/300, Loss: 0.0615 | 0.0329
Epoch 139/300, Loss: 0.0615 | 0.0329
Epoch 140/300, Loss: 0.0615 | 0.0329
Epoch 141/300, Loss: 0.0615 | 0.0329
Epoch 142/300, Loss: 0.0615 | 0.0329
Epoch 143/300, Loss: 0.0615 | 0.0329
Epoch 144/300, Loss: 0.0615 | 0.0329
Epoch 145/300, Loss: 0.0615 | 0.0329
Epoch 146/300, Loss: 0.0615 | 0.0329
Epoch 147/300, Loss: 0.0615 | 0.0329
Epoch 148/300, Loss: 0.0615 | 0.0329
Epoch 149/300, Loss: 0.0615 | 0.0329
Epoch 150/300, Loss: 0.0615 | 0.0329
Epoch 151/300, Loss: 0.0615 | 0.0329
Epoch 152/300, Loss: 0.0615 | 0.0329
Epoch 153/300, Loss: 0.0615 | 0.0329
Epoch 154/300, Loss: 0.0615 | 0.0329
Epoch 155/300, Loss: 0.0615 | 0.0329
Epoch 156/300, Loss: 0.0615 | 0.0329
Epoch 157/300, Loss: 0.0615 | 0.0329
Epoch 158/300, Loss: 0.0615 | 0.0329
Epoch 159/300, Loss: 0.0615 | 0.0329
Epoch 160/300, Loss: 0.0615 | 0.0329
Epoch 161/300, Loss: 0.0615 | 0.0329
Epoch 162/300, Loss: 0.0615 | 0.0329
Epoch 163/300, Loss: 0.0615 | 0.0329
Epoch 164/300, Loss: 0.0615 | 0.0329
Epoch 165/300, Loss: 0.0615 | 0.0329
Early stopping
Runtime (seconds): 225.82163763046265
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)
MSE: 62.44872487732209
RMSE: 7.9024505615234375
MAE: 7.9024505615234375
R-squared: nan
[187.48755]
