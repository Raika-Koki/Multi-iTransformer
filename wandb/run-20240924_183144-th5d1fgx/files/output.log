[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
/home/raikakoki/.local/lib/python3.10/site-packages/torch/backends/cuda/__init__.py:342: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
Dataset created successfully.
Epoch 1/100, Training Loss: 1.1800, Validation Loss: 0.6286
Epoch 2/100, Training Loss: 0.2986, Validation Loss: 0.2701
Epoch 3/100, Training Loss: 0.1989, Validation Loss: 0.1935
Epoch 4/100, Training Loss: 0.1326, Validation Loss: 0.2033
Epoch 5/100, Training Loss: 0.1147, Validation Loss: 0.1603
Epoch 6/100, Training Loss: 0.0889, Validation Loss: 0.1454
Epoch 7/100, Training Loss: 0.0730, Validation Loss: 0.1299
Epoch 8/100, Training Loss: 0.0635, Validation Loss: 0.1081
Epoch 9/100, Training Loss: 0.0626, Validation Loss: 0.0932
Epoch 10/100, Training Loss: 0.0795, Validation Loss: 0.0919
Epoch 11/100, Training Loss: 0.0714, Validation Loss: 0.0862
Epoch 12/100, Training Loss: 0.0637, Validation Loss: 0.0996
Epoch 13/100, Training Loss: 0.0528, Validation Loss: 0.0864
Epoch 14/100, Training Loss: 0.0542, Validation Loss: 0.0596
Epoch 15/100, Training Loss: 0.0416, Validation Loss: 0.0554
Epoch 16/100, Training Loss: 0.0387, Validation Loss: 0.0619
Epoch 17/100, Training Loss: 0.0347, Validation Loss: 0.0443
Epoch 18/100, Training Loss: 0.0316, Validation Loss: 0.0443
Epoch 19/100, Training Loss: 0.0316, Validation Loss: 0.0424
Epoch 20/100, Training Loss: 0.0286, Validation Loss: 0.0411
Epoch 21/100, Training Loss: 0.0279, Validation Loss: 0.0376
Epoch 22/100, Training Loss: 0.0264, Validation Loss: 0.0345
Epoch 23/100, Training Loss: 0.0257, Validation Loss: 0.0368
Epoch 24/100, Training Loss: 0.0248, Validation Loss: 0.0329
Epoch 25/100, Training Loss: 0.0237, Validation Loss: 0.0325
Epoch 26/100, Training Loss: 0.0234, Validation Loss: 0.0312
Epoch 27/100, Training Loss: 0.0224, Validation Loss: 0.0308
Epoch 28/100, Training Loss: 0.0219, Validation Loss: 0.0300
Epoch 29/100, Training Loss: 0.0213, Validation Loss: 0.0284
Epoch 30/100, Training Loss: 0.0209, Validation Loss: 0.0294
Epoch 31/100, Training Loss: 0.0205, Validation Loss: 0.0271
Epoch 32/100, Training Loss: 0.0200, Validation Loss: 0.0285
Epoch 33/100, Training Loss: 0.0198, Validation Loss: 0.0257
Epoch 34/100, Training Loss: 0.0196, Validation Loss: 0.0294
Epoch 35/100, Training Loss: 0.0197, Validation Loss: 0.0239
Epoch 36/100, Training Loss: 0.0204, Validation Loss: 0.0379
Epoch 37/100, Training Loss: 0.0236, Validation Loss: 0.0292
Epoch 38/100, Training Loss: 0.0330, Validation Loss: 0.1056
Epoch 39/100, Training Loss: 0.0648, Validation Loss: 0.0893
Epoch 40/100, Training Loss: 0.0787, Validation Loss: 0.1353
Epoch 41/100, Training Loss: 0.0931, Validation Loss: 0.0375
Epoch 42/100, Training Loss: 0.0633, Validation Loss: 0.0443
Epoch 43/100, Training Loss: 0.0572, Validation Loss: 0.0404
Epoch 44/100, Training Loss: 0.0344, Validation Loss: 0.0344
Epoch 45/100, Training Loss: 0.0273, Validation Loss: 0.0369
Epoch 46/100, Training Loss: 0.0230, Validation Loss: 0.0338
Epoch 47/100, Training Loss: 0.0218, Validation Loss: 0.0335
Epoch 48/100, Training Loss: 0.0209, Validation Loss: 0.0322
Epoch 49/100, Training Loss: 0.0204, Validation Loss: 0.0314
Epoch 50/100, Training Loss: 0.0200, Validation Loss: 0.0305
Epoch 51/100, Training Loss: 0.0196, Validation Loss: 0.0299
Epoch 52/100, Training Loss: 0.0194, Validation Loss: 0.0293
Epoch 53/100, Training Loss: 0.0191, Validation Loss: 0.0288
Epoch 54/100, Training Loss: 0.0189, Validation Loss: 0.0283
Epoch 55/100, Training Loss: 0.0188, Validation Loss: 0.0279
Epoch 56/100, Training Loss: 0.0186, Validation Loss: 0.0275
Epoch 57/100, Training Loss: 0.0185, Validation Loss: 0.0272
Epoch 58/100, Training Loss: 0.0184, Validation Loss: 0.0269
Epoch 59/100, Training Loss: 0.0183, Validation Loss: 0.0267
Epoch 60/100, Training Loss: 0.0182, Validation Loss: 0.0264
Epoch 61/100, Training Loss: 0.0181, Validation Loss: 0.0262
Epoch 62/100, Training Loss: 0.0180, Validation Loss: 0.0260
Epoch 63/100, Training Loss: 0.0179, Validation Loss: 0.0259
Epoch 64/100, Training Loss: 0.0178, Validation Loss: 0.0257
Epoch 65/100, Training Loss: 0.0178, Validation Loss: 0.0256
Epoch 66/100, Training Loss: 0.0177, Validation Loss: 0.0254
Epoch 67/100, Training Loss: 0.0176, Validation Loss: 0.0253
Epoch 68/100, Training Loss: 0.0176, Validation Loss: 0.0252
Epoch 69/100, Training Loss: 0.0175, Validation Loss: 0.0251
Epoch 70/100, Training Loss: 0.0175, Validation Loss: 0.0250
Epoch 71/100, Training Loss: 0.0174, Validation Loss: 0.0249
Epoch 72/100, Training Loss: 0.0174, Validation Loss: 0.0248
Epoch 73/100, Training Loss: 0.0174, Validation Loss: 0.0247
Epoch 74/100, Training Loss: 0.0173, Validation Loss: 0.0247
Epoch 75/100, Training Loss: 0.0173, Validation Loss: 0.0246
Epoch 76/100, Training Loss: 0.0172, Validation Loss: 0.0245
Epoch 77/100, Training Loss: 0.0172, Validation Loss: 0.0245
Epoch 78/100, Training Loss: 0.0172, Validation Loss: 0.0244
Epoch 79/100, Training Loss: 0.0171, Validation Loss: 0.0243
Epoch 80/100, Training Loss: 0.0171, Validation Loss: 0.0243
Epoch 81/100, Training Loss: 0.0171, Validation Loss: 0.0242
Epoch 82/100, Training Loss: 0.0171, Validation Loss: 0.0242
Epoch 83/100, Training Loss: 0.0170, Validation Loss: 0.0241
Epoch 84/100, Training Loss: 0.0170, Validation Loss: 0.0241
Epoch 85/100, Training Loss: 0.0170, Validation Loss: 0.0241
Epoch 86/100, Training Loss: 0.0170, Validation Loss: 0.0240
Epoch 87/100, Training Loss: 0.0169, Validation Loss: 0.0240
Epoch 88/100, Training Loss: 0.0169, Validation Loss: 0.0240
Epoch 89/100, Training Loss: 0.0169, Validation Loss: 0.0239
Epoch 90/100, Training Loss: 0.0169, Validation Loss: 0.0239
Epoch 91/100, Training Loss: 0.0169, Validation Loss: 0.0239
Epoch 92/100, Training Loss: 0.0169, Validation Loss: 0.0238
Epoch 93/100, Training Loss: 0.0168, Validation Loss: 0.0238
Epoch 94/100, Training Loss: 0.0168, Validation Loss: 0.0238
Epoch 95/100, Training Loss: 0.0168, Validation Loss: 0.0238
Epoch 96/100, Training Loss: 0.0168, Validation Loss: 0.0237
Epoch 97/100, Training Loss: 0.0168, Validation Loss: 0.0237
Epoch 98/100, Training Loss: 0.0168, Validation Loss: 0.0237
Epoch 99/100, Training Loss: 0.0168, Validation Loss: 0.0237
Traceback (most recent call last):
  File "/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/demo.py", line 113, in <module>
    predicted_stock_price = predicted_stock_prices[:, 1].cpu().numpy().flatten() * std_list[1] + mean_list[1]
IndexError: index 1 is out of bounds for dimension 1 with size 1
Traceback (most recent call last):
  File "/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/demo.py", line 113, in <module>
    predicted_stock_price = predicted_stock_prices[:, 1].cpu().numpy().flatten() * std_list[1] + mean_list[1]
IndexError: index 1 is out of bounds for dimension 1 with size 1
Epoch 100/100, Training Loss: 0.0168, Validation Loss: 0.0237