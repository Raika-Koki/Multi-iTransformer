[32m[I 2025-02-08 12:10:58,484][0m A new study created in memory with name: no-name-5fff4103-ecb0-4054-8829-283c508cfb6c[0m
[32m[I 2025-02-08 12:11:32,656][0m Trial 0 finished with value: 0.3681611716747284 and parameters: {'observation_period_num': 74, 'train_rates': 0.9685925937470368, 'learning_rate': 1.2550310873223031e-05, 'batch_size': 197, 'step_size': 13, 'gamma': 0.8104185265424716}. Best is trial 0 with value: 0.3681611716747284.[0m
Early stopping at epoch 60
[32m[I 2025-02-08 12:11:55,059][0m Trial 1 finished with value: 0.43480543898684637 and parameters: {'observation_period_num': 135, 'train_rates': 0.7704053713860844, 'learning_rate': 0.000900214576423534, 'batch_size': 155, 'step_size': 1, 'gamma': 0.7783512442851043}. Best is trial 0 with value: 0.3681611716747284.[0m
[32m[I 2025-02-08 12:12:18,029][0m Trial 2 finished with value: 0.985008709024243 and parameters: {'observation_period_num': 200, 'train_rates': 0.656449257662045, 'learning_rate': 3.055194763843164e-06, 'batch_size': 207, 'step_size': 6, 'gamma': 0.8335116223054897}. Best is trial 0 with value: 0.3681611716747284.[0m
[32m[I 2025-02-08 12:13:11,123][0m Trial 3 finished with value: 0.6574657132349363 and parameters: {'observation_period_num': 45, 'train_rates': 0.7780556647176972, 'learning_rate': 1.9528277319260366e-06, 'batch_size': 102, 'step_size': 7, 'gamma': 0.832492754689383}. Best is trial 0 with value: 0.3681611716747284.[0m
[32m[I 2025-02-08 12:13:58,386][0m Trial 4 finished with value: 0.17035369245747056 and parameters: {'observation_period_num': 172, 'train_rates': 0.8112662633510759, 'learning_rate': 4.7134274175826777e-05, 'batch_size': 110, 'step_size': 5, 'gamma': 0.9885326590402085}. Best is trial 4 with value: 0.17035369245747056.[0m
Early stopping at epoch 80
[32m[I 2025-02-08 12:14:22,233][0m Trial 5 finished with value: 0.4369242498132049 and parameters: {'observation_period_num': 15, 'train_rates': 0.7957647082694534, 'learning_rate': 2.062334815091411e-05, 'batch_size': 198, 'step_size': 1, 'gamma': 0.8575122721709371}. Best is trial 4 with value: 0.17035369245747056.[0m
[32m[I 2025-02-08 12:15:02,786][0m Trial 6 finished with value: 0.3239528311174468 and parameters: {'observation_period_num': 144, 'train_rates': 0.7522732874301972, 'learning_rate': 4.0132488613546285e-05, 'batch_size': 136, 'step_size': 12, 'gamma': 0.8718387920433449}. Best is trial 4 with value: 0.17035369245747056.[0m
[32m[I 2025-02-08 12:15:31,536][0m Trial 7 finished with value: 0.8143938616183007 and parameters: {'observation_period_num': 223, 'train_rates': 0.61506676895396, 'learning_rate': 3.1853660678132065e-06, 'batch_size': 161, 'step_size': 14, 'gamma': 0.8205450203880178}. Best is trial 4 with value: 0.17035369245747056.[0m
[32m[I 2025-02-08 12:16:26,429][0m Trial 8 finished with value: 0.17980220522199358 and parameters: {'observation_period_num': 188, 'train_rates': 0.8135009253353622, 'learning_rate': 3.2925149954698555e-05, 'batch_size': 96, 'step_size': 14, 'gamma': 0.9745440020017045}. Best is trial 4 with value: 0.17035369245747056.[0m
[32m[I 2025-02-08 12:17:02,656][0m Trial 9 finished with value: 0.248243141044454 and parameters: {'observation_period_num': 13, 'train_rates': 0.7735440226591926, 'learning_rate': 3.164898201251201e-05, 'batch_size': 155, 'step_size': 6, 'gamma': 0.8545126949670683}. Best is trial 4 with value: 0.17035369245747056.[0m
[32m[I 2025-02-08 12:21:05,413][0m Trial 10 finished with value: 0.1951976787313191 and parameters: {'observation_period_num': 248, 'train_rates': 0.9052290809781244, 'learning_rate': 0.00026704643484639354, 'batch_size': 22, 'step_size': 10, 'gamma': 0.9897581618587833}. Best is trial 4 with value: 0.17035369245747056.[0m
[32m[I 2025-02-08 12:22:17,828][0m Trial 11 finished with value: 0.19932483564051548 and parameters: {'observation_period_num': 174, 'train_rates': 0.8634092928375283, 'learning_rate': 9.7672189605337e-05, 'batch_size': 75, 'step_size': 4, 'gamma': 0.9899917662327543}. Best is trial 4 with value: 0.17035369245747056.[0m
[32m[I 2025-02-08 12:23:43,369][0m Trial 12 finished with value: 0.22837834725625641 and parameters: {'observation_period_num': 177, 'train_rates': 0.8609711233069766, 'learning_rate': 9.58006633054676e-06, 'batch_size': 65, 'step_size': 9, 'gamma': 0.9324064751621333}. Best is trial 4 with value: 0.17035369245747056.[0m
[32m[I 2025-02-08 12:24:31,666][0m Trial 13 finished with value: 0.19159064216669217 and parameters: {'observation_period_num': 89, 'train_rates': 0.6899907228424618, 'learning_rate': 8.995585061179064e-05, 'batch_size': 102, 'step_size': 15, 'gamma': 0.9427134780633436}. Best is trial 4 with value: 0.17035369245747056.[0m
[32m[I 2025-02-08 12:24:55,694][0m Trial 14 finished with value: 0.1945390267569515 and parameters: {'observation_period_num': 164, 'train_rates': 0.8382225670498851, 'learning_rate': 0.000148652856241417, 'batch_size': 244, 'step_size': 11, 'gamma': 0.9463266015166617}. Best is trial 4 with value: 0.17035369245747056.[0m
[32m[I 2025-02-08 12:27:07,727][0m Trial 15 finished with value: 0.40096485277256333 and parameters: {'observation_period_num': 103, 'train_rates': 0.7138132298978886, 'learning_rate': 6.618523410345444e-06, 'batch_size': 36, 'step_size': 4, 'gamma': 0.9062932631798784}. Best is trial 4 with value: 0.17035369245747056.[0m
[32m[I 2025-02-08 12:28:00,895][0m Trial 16 finished with value: 0.21318270443980372 and parameters: {'observation_period_num': 208, 'train_rates': 0.9282717487953753, 'learning_rate': 4.794935891966889e-05, 'batch_size': 104, 'step_size': 4, 'gamma': 0.9627152617593058}. Best is trial 4 with value: 0.17035369245747056.[0m
[32m[I 2025-02-08 12:29:29,646][0m Trial 17 finished with value: 0.1421323445387733 and parameters: {'observation_period_num': 116, 'train_rates': 0.8401372253167401, 'learning_rate': 0.0003524130483405491, 'batch_size': 61, 'step_size': 8, 'gamma': 0.8967672755061977}. Best is trial 17 with value: 0.1421323445387733.[0m
[32m[I 2025-02-08 12:30:50,185][0m Trial 18 finished with value: 0.19782134336538804 and parameters: {'observation_period_num': 111, 'train_rates': 0.9058417305287008, 'learning_rate': 0.0006787591890367319, 'batch_size': 71, 'step_size': 8, 'gamma': 0.9097883047104505}. Best is trial 17 with value: 0.1421323445387733.[0m
[32m[I 2025-02-08 12:32:36,203][0m Trial 19 finished with value: 0.19259564064865567 and parameters: {'observation_period_num': 68, 'train_rates': 0.7354386570647997, 'learning_rate': 0.00025647623066839503, 'batch_size': 46, 'step_size': 3, 'gamma': 0.8997858229409367}. Best is trial 17 with value: 0.1421323445387733.[0m
[32m[I 2025-02-08 12:33:24,757][0m Trial 20 finished with value: 0.1168920573585763 and parameters: {'observation_period_num': 152, 'train_rates': 0.8373292932993754, 'learning_rate': 0.0004098821218654029, 'batch_size': 117, 'step_size': 6, 'gamma': 0.7706417072134131}. Best is trial 20 with value: 0.1168920573585763.[0m
[32m[I 2025-02-08 12:34:08,832][0m Trial 21 finished with value: 0.10346567291285723 and parameters: {'observation_period_num': 152, 'train_rates': 0.8259877928408995, 'learning_rate': 0.0004223460427127343, 'batch_size': 126, 'step_size': 6, 'gamma': 0.7694641624895778}. Best is trial 21 with value: 0.10346567291285723.[0m
[32m[I 2025-02-08 12:34:52,486][0m Trial 22 finished with value: 0.1089346236616805 and parameters: {'observation_period_num': 153, 'train_rates': 0.8546174652027189, 'learning_rate': 0.00045321802054707253, 'batch_size': 129, 'step_size': 8, 'gamma': 0.7511142289982687}. Best is trial 21 with value: 0.10346567291285723.[0m
[32m[I 2025-02-08 12:35:38,849][0m Trial 23 finished with value: 0.12224107441956523 and parameters: {'observation_period_num': 147, 'train_rates': 0.8927226412904841, 'learning_rate': 0.00046643142533563163, 'batch_size': 126, 'step_size': 7, 'gamma': 0.7505784856364097}. Best is trial 21 with value: 0.10346567291285723.[0m
[32m[I 2025-02-08 12:36:24,541][0m Trial 24 finished with value: 0.2451695203781128 and parameters: {'observation_period_num': 152, 'train_rates': 0.9649992791180413, 'learning_rate': 0.0001783071879276492, 'batch_size': 131, 'step_size': 9, 'gamma': 0.7541030843986442}. Best is trial 21 with value: 0.10346567291285723.[0m
[32m[I 2025-02-08 12:36:58,859][0m Trial 25 finished with value: 0.11971027194783929 and parameters: {'observation_period_num': 127, 'train_rates': 0.8762989154360484, 'learning_rate': 0.0005403358665235792, 'batch_size': 176, 'step_size': 6, 'gamma': 0.7762975050240282}. Best is trial 21 with value: 0.10346567291285723.[0m
[32m[I 2025-02-08 12:37:42,684][0m Trial 26 finished with value: 0.20142950462858852 and parameters: {'observation_period_num': 223, 'train_rates': 0.8228814083519338, 'learning_rate': 0.0008860352747326256, 'batch_size': 126, 'step_size': 10, 'gamma': 0.7874931231123308}. Best is trial 21 with value: 0.10346567291285723.[0m
[32m[I 2025-02-08 12:38:54,737][0m Trial 27 finished with value: 0.27026729480851264 and parameters: {'observation_period_num': 155, 'train_rates': 0.9411613878157151, 'learning_rate': 0.00010863000593225986, 'batch_size': 82, 'step_size': 3, 'gamma': 0.7900808020083179}. Best is trial 21 with value: 0.10346567291285723.[0m
[32m[I 2025-02-08 12:39:27,097][0m Trial 28 finished with value: 0.11576157955310805 and parameters: {'observation_period_num': 126, 'train_rates': 0.8449949071443112, 'learning_rate': 0.00033151564230270717, 'batch_size': 178, 'step_size': 7, 'gamma': 0.7663269839219768}. Best is trial 21 with value: 0.10346567291285723.[0m
[32m[I 2025-02-08 12:39:55,393][0m Trial 29 finished with value: 0.135998215397199 and parameters: {'observation_period_num': 85, 'train_rates': 0.8714353686426559, 'learning_rate': 0.00020823459014985402, 'batch_size': 221, 'step_size': 9, 'gamma': 0.8087290625690998}. Best is trial 21 with value: 0.10346567291285723.[0m
[32m[I 2025-02-08 12:40:32,667][0m Trial 30 finished with value: 0.16512639820575714 and parameters: {'observation_period_num': 126, 'train_rates': 0.9681796285461878, 'learning_rate': 0.00029577392676155074, 'batch_size': 170, 'step_size': 7, 'gamma': 0.8024226698814577}. Best is trial 21 with value: 0.10346567291285723.[0m
[32m[I 2025-02-08 12:41:11,433][0m Trial 31 finished with value: 0.11359441395728818 and parameters: {'observation_period_num': 135, 'train_rates': 0.8380061120642287, 'learning_rate': 0.00046018628490546615, 'batch_size': 144, 'step_size': 5, 'gamma': 0.7673457852026643}. Best is trial 21 with value: 0.10346567291285723.[0m
[32m[I 2025-02-08 12:41:50,722][0m Trial 32 finished with value: 0.10526817687626543 and parameters: {'observation_period_num': 137, 'train_rates': 0.8480825483721666, 'learning_rate': 0.0006609217047596838, 'batch_size': 144, 'step_size': 7, 'gamma': 0.765192698394955}. Best is trial 21 with value: 0.10346567291285723.[0m
[32m[I 2025-02-08 12:42:28,113][0m Trial 33 finished with value: 0.10340283058483053 and parameters: {'observation_period_num': 98, 'train_rates': 0.7960675523348572, 'learning_rate': 0.0008980358609616529, 'batch_size': 151, 'step_size': 5, 'gamma': 0.7637044976531498}. Best is trial 33 with value: 0.10340283058483053.[0m
[32m[I 2025-02-08 12:43:06,248][0m Trial 34 finished with value: 0.07145103196477055 and parameters: {'observation_period_num': 64, 'train_rates': 0.7861701458738383, 'learning_rate': 0.000997742772116902, 'batch_size': 145, 'step_size': 8, 'gamma': 0.7925844415872256}. Best is trial 34 with value: 0.07145103196477055.[0m
[32m[I 2025-02-08 12:43:44,002][0m Trial 35 finished with value: 0.07254965608351982 and parameters: {'observation_period_num': 66, 'train_rates': 0.7970608692368133, 'learning_rate': 0.0008068823656817595, 'batch_size': 152, 'step_size': 5, 'gamma': 0.7966327956001175}. Best is trial 34 with value: 0.07145103196477055.[0m
[32m[I 2025-02-08 12:44:12,533][0m Trial 36 finished with value: 0.2171974287839736 and parameters: {'observation_period_num': 53, 'train_rates': 0.751417629134042, 'learning_rate': 0.000973319607225291, 'batch_size': 192, 'step_size': 2, 'gamma': 0.7943848115078033}. Best is trial 34 with value: 0.07145103196477055.[0m
[32m[I 2025-02-08 12:44:53,187][0m Trial 37 finished with value: 0.050911441778603454 and parameters: {'observation_period_num': 27, 'train_rates': 0.7895356876304575, 'learning_rate': 0.0009313528047057394, 'batch_size': 146, 'step_size': 5, 'gamma': 0.8244327728253861}. Best is trial 37 with value: 0.050911441778603454.[0m
[32m[I 2025-02-08 12:45:30,371][0m Trial 38 finished with value: 0.04507394157265808 and parameters: {'observation_period_num': 31, 'train_rates': 0.7915330891964313, 'learning_rate': 0.0009455078248753565, 'batch_size': 156, 'step_size': 5, 'gamma': 0.8162416359313674}. Best is trial 38 with value: 0.04507394157265808.[0m
[32m[I 2025-02-08 12:46:02,570][0m Trial 39 finished with value: 0.07179626712698174 and parameters: {'observation_period_num': 31, 'train_rates': 0.7853281592280736, 'learning_rate': 0.000678164456364998, 'batch_size': 188, 'step_size': 2, 'gamma': 0.8253369856462961}. Best is trial 38 with value: 0.04507394157265808.[0m
Early stopping at epoch 71
[32m[I 2025-02-08 12:46:24,419][0m Trial 40 finished with value: 0.44833892190428537 and parameters: {'observation_period_num': 28, 'train_rates': 0.7121283065818892, 'learning_rate': 6.612258138214904e-05, 'batch_size': 190, 'step_size': 1, 'gamma': 0.8337583019382829}. Best is trial 38 with value: 0.04507394157265808.[0m
[32m[I 2025-02-08 12:46:57,325][0m Trial 41 finished with value: 0.22157832403855257 and parameters: {'observation_period_num': 34, 'train_rates': 0.7812379717232059, 'learning_rate': 0.0006730506573820796, 'batch_size': 168, 'step_size': 2, 'gamma': 0.8224179654598456}. Best is trial 38 with value: 0.04507394157265808.[0m
[32m[I 2025-02-08 12:47:23,577][0m Trial 42 finished with value: 0.0759852641446519 and parameters: {'observation_period_num': 57, 'train_rates': 0.7959404648213906, 'learning_rate': 0.0006786553406330468, 'batch_size': 219, 'step_size': 3, 'gamma': 0.8456332702108628}. Best is trial 38 with value: 0.04507394157265808.[0m
[32m[I 2025-02-08 12:47:50,163][0m Trial 43 finished with value: 0.6662108153714652 and parameters: {'observation_period_num': 26, 'train_rates': 0.7538666270929769, 'learning_rate': 1.0726357103588869e-06, 'batch_size': 205, 'step_size': 5, 'gamma': 0.8181386767863114}. Best is trial 38 with value: 0.04507394157265808.[0m
[32m[I 2025-02-08 12:48:21,822][0m Trial 44 finished with value: 0.31350053083605883 and parameters: {'observation_period_num': 5, 'train_rates': 0.7675254349874916, 'learning_rate': 1.831247445960681e-05, 'batch_size': 184, 'step_size': 2, 'gamma': 0.868234317076162}. Best is trial 38 with value: 0.04507394157265808.[0m
[32m[I 2025-02-08 12:48:58,380][0m Trial 45 finished with value: 0.05389355772345419 and parameters: {'observation_period_num': 41, 'train_rates': 0.8083796426595663, 'learning_rate': 0.0009491594105482513, 'batch_size': 157, 'step_size': 4, 'gamma': 0.8368126089012996}. Best is trial 38 with value: 0.04507394157265808.[0m
[32m[I 2025-02-08 12:49:33,410][0m Trial 46 finished with value: 0.056242923380113115 and parameters: {'observation_period_num': 35, 'train_rates': 0.8108082365788198, 'learning_rate': 0.0009882782719894266, 'batch_size': 164, 'step_size': 4, 'gamma': 0.8403030108118866}. Best is trial 38 with value: 0.04507394157265808.[0m
[32m[I 2025-02-08 12:50:08,851][0m Trial 47 finished with value: 0.0610234714369579 and parameters: {'observation_period_num': 43, 'train_rates': 0.8097366299375997, 'learning_rate': 0.000973055304710803, 'batch_size': 165, 'step_size': 4, 'gamma': 0.8370614908666432}. Best is trial 38 with value: 0.04507394157265808.[0m
[32m[I 2025-02-08 12:50:46,031][0m Trial 48 finished with value: 0.05605929477317543 and parameters: {'observation_period_num': 44, 'train_rates': 0.8119011463392815, 'learning_rate': 0.0005883671613857642, 'batch_size': 156, 'step_size': 4, 'gamma': 0.8395977914218914}. Best is trial 38 with value: 0.04507394157265808.[0m
[32m[I 2025-02-08 12:51:22,900][0m Trial 49 finished with value: 0.048361949568445035 and parameters: {'observation_period_num': 17, 'train_rates': 0.8158458983935323, 'learning_rate': 0.0005536459108888359, 'batch_size': 161, 'step_size': 3, 'gamma': 0.8565960950828942}. Best is trial 38 with value: 0.04507394157265808.[0m
最適ハイパーパラメータが見つかりました
最適なハイパーパラメータが best_hyperparameters_GOOG_iTransformer_noMSTL.json に保存されました
Epoch 1/300, Loss: 0.5857 | 0.3155
Epoch 2/300, Loss: 0.2008 | 0.3482
Epoch 3/300, Loss: 0.1813 | 0.2193
Epoch 4/300, Loss: 0.1694 | 0.2383
Epoch 5/300, Loss: 0.2062 | 0.2755
Epoch 6/300, Loss: 0.2272 | 0.1740
Epoch 7/300, Loss: 0.1991 | 0.2199
Epoch 8/300, Loss: 0.1935 | 0.2869
Epoch 9/300, Loss: 0.1627 | 0.1414
Epoch 10/300, Loss: 0.1398 | 0.1194
Epoch 11/300, Loss: 0.1315 | 0.1013
Epoch 12/300, Loss: 0.1187 | 0.1640
Epoch 13/300, Loss: 0.1225 | 0.0965
Epoch 14/300, Loss: 0.1216 | 0.1550
Epoch 15/300, Loss: 0.1332 | 0.1194
Epoch 16/300, Loss: 0.1194 | 0.1101
Epoch 17/300, Loss: 0.1332 | 0.1785
Epoch 18/300, Loss: 0.1388 | 0.1147
Epoch 19/300, Loss: 0.1379 | 0.1818
Epoch 20/300, Loss: 0.1226 | 0.1022
Epoch 21/300, Loss: 0.1162 | 0.1153
Epoch 22/300, Loss: 0.1117 | 0.0947
Epoch 23/300, Loss: 0.1129 | 0.1000
Epoch 24/300, Loss: 0.1067 | 0.0819
Epoch 25/300, Loss: 0.1043 | 0.1110
Epoch 26/300, Loss: 0.0986 | 0.0760
Epoch 27/300, Loss: 0.0979 | 0.0918
Epoch 28/300, Loss: 0.0945 | 0.0733
Epoch 29/300, Loss: 0.0938 | 0.0799
Epoch 30/300, Loss: 0.0913 | 0.0697
Epoch 31/300, Loss: 0.0907 | 0.0732
Epoch 32/300, Loss: 0.0894 | 0.0679
Epoch 33/300, Loss: 0.0890 | 0.0693
Epoch 34/300, Loss: 0.0884 | 0.0671
Epoch 35/300, Loss: 0.0881 | 0.0679
Epoch 36/300, Loss: 0.0878 | 0.0665
Epoch 37/300, Loss: 0.0875 | 0.0668
Epoch 38/300, Loss: 0.0873 | 0.0660
Epoch 39/300, Loss: 0.0870 | 0.0660
Epoch 40/300, Loss: 0.0868 | 0.0656
Epoch 41/300, Loss: 0.0866 | 0.0654
Epoch 42/300, Loss: 0.0865 | 0.0652
Epoch 43/300, Loss: 0.0863 | 0.0650
Epoch 44/300, Loss: 0.0862 | 0.0648
Epoch 45/300, Loss: 0.0860 | 0.0647
Epoch 46/300, Loss: 0.0859 | 0.0645
Epoch 47/300, Loss: 0.0858 | 0.0644
Epoch 48/300, Loss: 0.0857 | 0.0642
Epoch 49/300, Loss: 0.0856 | 0.0641
Epoch 50/300, Loss: 0.0855 | 0.0640
Epoch 51/300, Loss: 0.0854 | 0.0639
Epoch 52/300, Loss: 0.0853 | 0.0638
Epoch 53/300, Loss: 0.0853 | 0.0637
Epoch 54/300, Loss: 0.0852 | 0.0637
Epoch 55/300, Loss: 0.0851 | 0.0636
Epoch 56/300, Loss: 0.0851 | 0.0635
Epoch 57/300, Loss: 0.0850 | 0.0635
Epoch 58/300, Loss: 0.0850 | 0.0634
Epoch 59/300, Loss: 0.0849 | 0.0633
Epoch 60/300, Loss: 0.0849 | 0.0633
Epoch 61/300, Loss: 0.0848 | 0.0632
Epoch 62/300, Loss: 0.0848 | 0.0632
Epoch 63/300, Loss: 0.0848 | 0.0632
Epoch 64/300, Loss: 0.0847 | 0.0631
Epoch 65/300, Loss: 0.0847 | 0.0631
Epoch 66/300, Loss: 0.0847 | 0.0631
Epoch 67/300, Loss: 0.0847 | 0.0630
Epoch 68/300, Loss: 0.0846 | 0.0630
Epoch 69/300, Loss: 0.0846 | 0.0630
Epoch 70/300, Loss: 0.0846 | 0.0630
Epoch 71/300, Loss: 0.0846 | 0.0629
Epoch 72/300, Loss: 0.0846 | 0.0629
Epoch 73/300, Loss: 0.0845 | 0.0629
Epoch 74/300, Loss: 0.0845 | 0.0629
Epoch 75/300, Loss: 0.0845 | 0.0629
Epoch 76/300, Loss: 0.0845 | 0.0628
Epoch 77/300, Loss: 0.0845 | 0.0628
Epoch 78/300, Loss: 0.0845 | 0.0628
Epoch 79/300, Loss: 0.0845 | 0.0628
Epoch 80/300, Loss: 0.0845 | 0.0628
Epoch 81/300, Loss: 0.0844 | 0.0628
Epoch 82/300, Loss: 0.0844 | 0.0628
Epoch 83/300, Loss: 0.0844 | 0.0628
Epoch 84/300, Loss: 0.0844 | 0.0628
Epoch 85/300, Loss: 0.0844 | 0.0627
Epoch 86/300, Loss: 0.0844 | 0.0627
Epoch 87/300, Loss: 0.0844 | 0.0627
Epoch 88/300, Loss: 0.0844 | 0.0627
Epoch 89/300, Loss: 0.0844 | 0.0627
Epoch 90/300, Loss: 0.0844 | 0.0627
Epoch 91/300, Loss: 0.0844 | 0.0627
Epoch 92/300, Loss: 0.0844 | 0.0627
Epoch 93/300, Loss: 0.0844 | 0.0627
Epoch 94/300, Loss: 0.0844 | 0.0627
Epoch 95/300, Loss: 0.0844 | 0.0627
Epoch 96/300, Loss: 0.0844 | 0.0627
Epoch 97/300, Loss: 0.0844 | 0.0627
Epoch 98/300, Loss: 0.0844 | 0.0627
Epoch 99/300, Loss: 0.0844 | 0.0627
Epoch 100/300, Loss: 0.0844 | 0.0627
Epoch 101/300, Loss: 0.0844 | 0.0627
Epoch 102/300, Loss: 0.0844 | 0.0627
Epoch 103/300, Loss: 0.0843 | 0.0627
Epoch 104/300, Loss: 0.0843 | 0.0627
Epoch 105/300, Loss: 0.0843 | 0.0627
Epoch 106/300, Loss: 0.0843 | 0.0627
Epoch 107/300, Loss: 0.0843 | 0.0627
Epoch 108/300, Loss: 0.0843 | 0.0627
Epoch 109/300, Loss: 0.0843 | 0.0627
Epoch 110/300, Loss: 0.0843 | 0.0627
Epoch 111/300, Loss: 0.0843 | 0.0627
Epoch 112/300, Loss: 0.0843 | 0.0627
Epoch 113/300, Loss: 0.0843 | 0.0627
Epoch 114/300, Loss: 0.0843 | 0.0627
Epoch 115/300, Loss: 0.0843 | 0.0627
Epoch 116/300, Loss: 0.0843 | 0.0627
Epoch 117/300, Loss: 0.0843 | 0.0627
Epoch 118/300, Loss: 0.0843 | 0.0626
Epoch 119/300, Loss: 0.0843 | 0.0626
Epoch 120/300, Loss: 0.0843 | 0.0626
Epoch 121/300, Loss: 0.0843 | 0.0626
Epoch 122/300, Loss: 0.0843 | 0.0626
Epoch 123/300, Loss: 0.0843 | 0.0626
Epoch 124/300, Loss: 0.0843 | 0.0626
Epoch 125/300, Loss: 0.0843 | 0.0626
Epoch 126/300, Loss: 0.0843 | 0.0626
Epoch 127/300, Loss: 0.0843 | 0.0626
Epoch 128/300, Loss: 0.0843 | 0.0626
Epoch 129/300, Loss: 0.0843 | 0.0626
Epoch 130/300, Loss: 0.0843 | 0.0626
Epoch 131/300, Loss: 0.0843 | 0.0626
Epoch 132/300, Loss: 0.0843 | 0.0626
Epoch 133/300, Loss: 0.0843 | 0.0626
Epoch 134/300, Loss: 0.0843 | 0.0626
Epoch 135/300, Loss: 0.0843 | 0.0626
Epoch 136/300, Loss: 0.0843 | 0.0626
Epoch 137/300, Loss: 0.0843 | 0.0626
Epoch 138/300, Loss: 0.0843 | 0.0626
Epoch 139/300, Loss: 0.0843 | 0.0626
Epoch 140/300, Loss: 0.0843 | 0.0626
Epoch 141/300, Loss: 0.0843 | 0.0626
Epoch 142/300, Loss: 0.0843 | 0.0626
Epoch 143/300, Loss: 0.0843 | 0.0626
Epoch 144/300, Loss: 0.0843 | 0.0626
Epoch 145/300, Loss: 0.0843 | 0.0626
Epoch 146/300, Loss: 0.0843 | 0.0626
Epoch 147/300, Loss: 0.0843 | 0.0626
Epoch 148/300, Loss: 0.0843 | 0.0626
Epoch 149/300, Loss: 0.0843 | 0.0626
Epoch 150/300, Loss: 0.0843 | 0.0626
Epoch 151/300, Loss: 0.0843 | 0.0626
Epoch 152/300, Loss: 0.0843 | 0.0626
Epoch 153/300, Loss: 0.0843 | 0.0626
Epoch 154/300, Loss: 0.0843 | 0.0626
Epoch 155/300, Loss: 0.0843 | 0.0626
Epoch 156/300, Loss: 0.0843 | 0.0626
Epoch 157/300, Loss: 0.0843 | 0.0626
Epoch 158/300, Loss: 0.0843 | 0.0626
Epoch 159/300, Loss: 0.0843 | 0.0626
Epoch 160/300, Loss: 0.0843 | 0.0626
Epoch 161/300, Loss: 0.0843 | 0.0626
Epoch 162/300, Loss: 0.0843 | 0.0626
Epoch 163/300, Loss: 0.0843 | 0.0626
Epoch 164/300, Loss: 0.0843 | 0.0626
Epoch 165/300, Loss: 0.0843 | 0.0626
Epoch 166/300, Loss: 0.0843 | 0.0626
Epoch 167/300, Loss: 0.0843 | 0.0626
Epoch 168/300, Loss: 0.0843 | 0.0626
Epoch 169/300, Loss: 0.0843 | 0.0626
Epoch 170/300, Loss: 0.0843 | 0.0626
Early stopping
Runtime (seconds): 63.52145981788635
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)
MSE: 279.9713886438403
RMSE: 16.732345581054688
MAE: 16.732345581054688
R-squared: nan
[203.87234]
