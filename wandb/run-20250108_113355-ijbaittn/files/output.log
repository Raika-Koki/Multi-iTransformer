[32m[I 2025-01-08 11:33:56,033][0m A new study created in memory with name: no-name-506dabb9-d0b3-4089-9d33-86e0b3e13e45[0m
[32m[I 2025-01-08 11:38:13,135][0m Trial 0 finished with value: 0.5178016281853883 and parameters: {'observation_period_num': 194, 'train_rates': 0.7754373920759202, 'learning_rate': 0.00043590785765098606, 'batch_size': 166, 'step_size': 7, 'gamma': 0.7696068666522915}. Best is trial 0 with value: 0.5178016281853883.[0m
[32m[I 2025-01-08 11:43:06,786][0m Trial 1 finished with value: 0.8528610734927903 and parameters: {'observation_period_num': 232, 'train_rates': 0.7018600258987476, 'learning_rate': 6.093316812137358e-05, 'batch_size': 246, 'step_size': 11, 'gamma': 0.9493663551472267}. Best is trial 0 with value: 0.5178016281853883.[0m
Early stopping at epoch 41
[32m[I 2025-01-08 11:44:40,676][0m Trial 2 finished with value: 1.7465843247140156 and parameters: {'observation_period_num': 195, 'train_rates': 0.6085125872285629, 'learning_rate': 8.100548417736918e-06, 'batch_size': 156, 'step_size': 1, 'gamma': 0.757936931376641}. Best is trial 0 with value: 0.5178016281853883.[0m
[32m[I 2025-01-08 11:46:00,143][0m Trial 3 finished with value: 1.0344054831131813 and parameters: {'observation_period_num': 73, 'train_rates': 0.6578732893567402, 'learning_rate': 0.0006493446461374151, 'batch_size': 184, 'step_size': 7, 'gamma': 0.9135280650424429}. Best is trial 0 with value: 0.5178016281853883.[0m
[32m[I 2025-01-08 11:51:16,584][0m Trial 4 finished with value: 0.5588779440149665 and parameters: {'observation_period_num': 226, 'train_rates': 0.8254882956785177, 'learning_rate': 5.696962879732105e-06, 'batch_size': 130, 'step_size': 15, 'gamma': 0.9893472003700523}. Best is trial 0 with value: 0.5178016281853883.[0m
[32m[I 2025-01-08 11:52:18,106][0m Trial 5 finished with value: 0.16057628122243015 and parameters: {'observation_period_num': 38, 'train_rates': 0.9476724700658339, 'learning_rate': 2.2406804629381307e-05, 'batch_size': 84, 'step_size': 7, 'gamma': 0.9262309071038651}. Best is trial 5 with value: 0.16057628122243015.[0m
[32m[I 2025-01-08 11:58:09,860][0m Trial 6 finished with value: 0.9320833868926324 and parameters: {'observation_period_num': 249, 'train_rates': 0.8057944940917617, 'learning_rate': 4.725268031841578e-06, 'batch_size': 209, 'step_size': 13, 'gamma': 0.8186133183550054}. Best is trial 5 with value: 0.16057628122243015.[0m
[32m[I 2025-01-08 12:01:44,711][0m Trial 7 finished with value: 2.0815332699829425 and parameters: {'observation_period_num': 147, 'train_rates': 0.8996259719816564, 'learning_rate': 0.0005607710601630228, 'batch_size': 42, 'step_size': 10, 'gamma': 0.9447573416127902}. Best is trial 5 with value: 0.16057628122243015.[0m
[32m[I 2025-01-08 12:06:05,444][0m Trial 8 finished with value: 0.23959853500127792 and parameters: {'observation_period_num': 184, 'train_rates': 0.9142633689794794, 'learning_rate': 2.3462826840761593e-05, 'batch_size': 165, 'step_size': 4, 'gamma': 0.9576345729623414}. Best is trial 5 with value: 0.16057628122243015.[0m
[32m[I 2025-01-08 12:09:12,351][0m Trial 9 finished with value: 0.2661143523342204 and parameters: {'observation_period_num': 132, 'train_rates': 0.9069511322275196, 'learning_rate': 0.0003245158187856792, 'batch_size': 83, 'step_size': 15, 'gamma': 0.9418555330843716}. Best is trial 5 with value: 0.16057628122243015.[0m
[32m[I 2025-01-08 12:14:08,941][0m Trial 10 finished with value: 0.10377341972457038 and parameters: {'observation_period_num': 14, 'train_rates': 0.9849692509869473, 'learning_rate': 6.19698108376848e-05, 'batch_size': 16, 'step_size': 4, 'gamma': 0.8754881179198238}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:18:38,251][0m Trial 11 finished with value: 0.6423027347295712 and parameters: {'observation_period_num': 5, 'train_rates': 0.9869864294304292, 'learning_rate': 1.1394914155977492e-06, 'batch_size': 17, 'step_size': 4, 'gamma': 0.8712938862553353}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:19:42,514][0m Trial 12 finished with value: 0.13992741703987122 and parameters: {'observation_period_num': 14, 'train_rates': 0.9744023185267615, 'learning_rate': 8.09394785526765e-05, 'batch_size': 82, 'step_size': 4, 'gamma': 0.8783511183978638}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:21:35,165][0m Trial 13 finished with value: 0.18173524737358093 and parameters: {'observation_period_num': 78, 'train_rates': 0.9784145309400569, 'learning_rate': 0.00012613425706979947, 'batch_size': 73, 'step_size': 3, 'gamma': 0.8706403261095255}. Best is trial 10 with value: 0.10377341972457038.[0m
Early stopping at epoch 70
[32m[I 2025-01-08 12:22:06,624][0m Trial 14 finished with value: 0.46710808614841676 and parameters: {'observation_period_num': 7, 'train_rates': 0.8607568919212838, 'learning_rate': 0.00013620842109151286, 'batch_size': 108, 'step_size': 1, 'gamma': 0.8323001890640932}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:25:55,124][0m Trial 15 finished with value: 0.6590566124456624 and parameters: {'observation_period_num': 76, 'train_rates': 0.7349661244482877, 'learning_rate': 5.6369237248621955e-05, 'batch_size': 16, 'step_size': 4, 'gamma': 0.8921425628844383}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:27:08,297][0m Trial 16 finished with value: 0.26367259786712177 and parameters: {'observation_period_num': 47, 'train_rates': 0.8576868660305101, 'learning_rate': 0.00010802813652027595, 'batch_size': 54, 'step_size': 5, 'gamma': 0.8319857939449355}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:29:27,925][0m Trial 17 finished with value: 0.3094856802906309 and parameters: {'observation_period_num': 104, 'train_rates': 0.9441053804428199, 'learning_rate': 1.2594258659137208e-05, 'batch_size': 117, 'step_size': 9, 'gamma': 0.8049124841279099}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:31:04,956][0m Trial 18 finished with value: 0.250061604125268 and parameters: {'observation_period_num': 41, 'train_rates': 0.8667588569791695, 'learning_rate': 0.0002373092969092175, 'batch_size': 47, 'step_size': 2, 'gamma': 0.8944764630047685}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:32:18,405][0m Trial 19 finished with value: 0.13945309765689023 and parameters: {'observation_period_num': 30, 'train_rates': 0.9517145234988797, 'learning_rate': 5.269622756800025e-05, 'batch_size': 68, 'step_size': 6, 'gamma': 0.8553474636077066}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:34:53,148][0m Trial 20 finished with value: 0.15167823577309675 and parameters: {'observation_period_num': 98, 'train_rates': 0.9352390515634021, 'learning_rate': 3.724020605444394e-05, 'batch_size': 32, 'step_size': 6, 'gamma': 0.8422358490176877}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:36:00,451][0m Trial 21 finished with value: 0.1612364790505833 and parameters: {'observation_period_num': 22, 'train_rates': 0.9725669271452112, 'learning_rate': 7.243864262277285e-05, 'batch_size': 67, 'step_size': 5, 'gamma': 0.8564178680031126}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:37:13,436][0m Trial 22 finished with value: 0.18387895822525024 and parameters: {'observation_period_num': 50, 'train_rates': 0.9873820353965832, 'learning_rate': 0.00020094530979374953, 'batch_size': 95, 'step_size': 3, 'gamma': 0.8918822743114325}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:38:30,835][0m Trial 23 finished with value: 0.1692659564657149 and parameters: {'observation_period_num': 26, 'train_rates': 0.948158053220376, 'learning_rate': 3.887498118260848e-05, 'batch_size': 58, 'step_size': 6, 'gamma': 0.7933769978174253}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:39:48,791][0m Trial 24 finished with value: 0.4399182748004615 and parameters: {'observation_period_num': 61, 'train_rates': 0.8861821287000163, 'learning_rate': 1.564888726870305e-05, 'batch_size': 105, 'step_size': 3, 'gamma': 0.8526868098311265}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:42:04,156][0m Trial 25 finished with value: 0.140641987323761 and parameters: {'observation_period_num': 18, 'train_rates': 0.9215591995276357, 'learning_rate': 6.501992257439585e-05, 'batch_size': 29, 'step_size': 8, 'gamma': 0.9086160020558294}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:44:19,556][0m Trial 26 finished with value: 0.16304679214954376 and parameters: {'observation_period_num': 98, 'train_rates': 0.9656150784035304, 'learning_rate': 9.708242785599719e-05, 'batch_size': 125, 'step_size': 5, 'gamma': 0.8792141595300237}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:45:18,491][0m Trial 27 finished with value: 2.138472260430802 and parameters: {'observation_period_num': 21, 'train_rates': 0.8836361643805324, 'learning_rate': 0.0009999970792166379, 'batch_size': 72, 'step_size': 6, 'gamma': 0.8545508609931706}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:46:36,244][0m Trial 28 finished with value: 0.3003557681492189 and parameters: {'observation_period_num': 64, 'train_rates': 0.831114403283713, 'learning_rate': 0.00020319853357353692, 'batch_size': 93, 'step_size': 2, 'gamma': 0.9117139618505625}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:48:27,538][0m Trial 29 finished with value: 1.126904707433831 and parameters: {'observation_period_num': 35, 'train_rates': 0.7611414727463878, 'learning_rate': 2.171408509960107e-06, 'batch_size': 35, 'step_size': 8, 'gamma': 0.7814753512056692}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:48:59,102][0m Trial 30 finished with value: 0.38913729786872864 and parameters: {'observation_period_num': 5, 'train_rates': 0.9590975638053691, 'learning_rate': 3.915108210097756e-05, 'batch_size': 141, 'step_size': 2, 'gamma': 0.8184795740873667}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:51:10,653][0m Trial 31 finished with value: 0.14049789107782873 and parameters: {'observation_period_num': 20, 'train_rates': 0.922642157356795, 'learning_rate': 5.367673165583407e-05, 'batch_size': 30, 'step_size': 8, 'gamma': 0.8844924982996922}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:52:32,555][0m Trial 32 finished with value: 0.164821351153983 and parameters: {'observation_period_num': 54, 'train_rates': 0.9321594241380191, 'learning_rate': 2.6021189621637406e-05, 'batch_size': 55, 'step_size': 9, 'gamma': 0.882581985303568}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:55:13,733][0m Trial 33 finished with value: 0.10743779118094489 and parameters: {'observation_period_num': 29, 'train_rates': 0.9637076213933631, 'learning_rate': 4.7636178136611875e-05, 'batch_size': 25, 'step_size': 7, 'gamma': 0.8627909378654993}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:56:19,482][0m Trial 34 finished with value: 0.32791316509246826 and parameters: {'observation_period_num': 32, 'train_rates': 0.9897131362006256, 'learning_rate': 1.2698836069478672e-05, 'batch_size': 64, 'step_size': 6, 'gamma': 0.8513385585644252}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 12:59:42,091][0m Trial 35 finished with value: 0.7711949373994554 and parameters: {'observation_period_num': 84, 'train_rates': 0.684917641439026, 'learning_rate': 7.01540857304433e-05, 'batch_size': 16, 'step_size': 7, 'gamma': 0.8653379248007539}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 13:02:36,576][0m Trial 36 finished with value: 0.9169574656274884 and parameters: {'observation_period_num': 161, 'train_rates': 0.6236078226149715, 'learning_rate': 0.00015401781612445865, 'batch_size': 254, 'step_size': 11, 'gamma': 0.7521696882248953}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 13:03:58,585][0m Trial 37 finished with value: 0.3881102204322815 and parameters: {'observation_period_num': 62, 'train_rates': 0.9600787154979874, 'learning_rate': 1.827297687485558e-05, 'batch_size': 198, 'step_size': 5, 'gamma': 0.836792954594874}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 13:05:30,266][0m Trial 38 finished with value: 0.3831310628390894 and parameters: {'observation_period_num': 42, 'train_rates': 0.9582968811073889, 'learning_rate': 0.00036450756111100686, 'batch_size': 45, 'step_size': 7, 'gamma': 0.9066373861832967}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 13:08:06,441][0m Trial 39 finished with value: 0.819183465681578 and parameters: {'observation_period_num': 120, 'train_rates': 0.893420099571258, 'learning_rate': 6.780340927760352e-06, 'batch_size': 146, 'step_size': 4, 'gamma': 0.8198897776534335}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 13:12:50,376][0m Trial 40 finished with value: 0.3788095515412398 and parameters: {'observation_period_num': 203, 'train_rates': 0.8311273843385016, 'learning_rate': 9.43515229607352e-05, 'batch_size': 85, 'step_size': 10, 'gamma': 0.9222626436530847}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 13:15:14,511][0m Trial 41 finished with value: 0.11498900903104174 and parameters: {'observation_period_num': 16, 'train_rates': 0.922580599384632, 'learning_rate': 4.856547752693843e-05, 'batch_size': 28, 'step_size': 9, 'gamma': 0.881816165273648}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 13:17:05,177][0m Trial 42 finished with value: 0.12797677644330602 and parameters: {'observation_period_num': 32, 'train_rates': 0.9345411605853688, 'learning_rate': 4.3212179444647644e-05, 'batch_size': 39, 'step_size': 13, 'gamma': 0.8687112949156703}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 13:19:49,551][0m Trial 43 finished with value: 0.13358048338621745 and parameters: {'observation_period_num': 32, 'train_rates': 0.9081006896401652, 'learning_rate': 2.8050045671622917e-05, 'batch_size': 25, 'step_size': 13, 'gamma': 0.8640796630441407}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 13:22:22,100][0m Trial 44 finished with value: 0.15359506543559306 and parameters: {'observation_period_num': 35, 'train_rates': 0.9010387950259957, 'learning_rate': 2.8678438441255326e-05, 'batch_size': 25, 'step_size': 13, 'gamma': 0.8646107204935938}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 13:24:10,779][0m Trial 45 finished with value: 0.16358758967656356 and parameters: {'observation_period_num': 13, 'train_rates': 0.9168122830272214, 'learning_rate': 9.686298198669962e-06, 'batch_size': 38, 'step_size': 13, 'gamma': 0.8941935864554259}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 13:25:42,354][0m Trial 46 finished with value: 0.22674192843559957 and parameters: {'observation_period_num': 54, 'train_rates': 0.8736782180784712, 'learning_rate': 2.0709934109559937e-05, 'batch_size': 46, 'step_size': 14, 'gamma': 0.9285295308209143}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 13:27:10,967][0m Trial 47 finished with value: 0.3792293273350772 and parameters: {'observation_period_num': 71, 'train_rates': 0.8476676637530152, 'learning_rate': 4.3586399137422365e-05, 'batch_size': 222, 'step_size': 12, 'gamma': 0.8685061037466842}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 13:29:39,210][0m Trial 48 finished with value: 0.4522401177650922 and parameters: {'observation_period_num': 88, 'train_rates': 0.7864167027465837, 'learning_rate': 2.9842162718989653e-05, 'batch_size': 24, 'step_size': 12, 'gamma': 0.9799511314582303}. Best is trial 10 with value: 0.10377341972457038.[0m
[32m[I 2025-01-08 13:31:33,189][0m Trial 49 finished with value: 0.1366254487277373 and parameters: {'observation_period_num': 44, 'train_rates': 0.9372781117424945, 'learning_rate': 5.025596648191761e-05, 'batch_size': 38, 'step_size': 15, 'gamma': 0.8736842669015671}. Best is trial 10 with value: 0.10377341972457038.[0m
最適ハイパーパラメータが見つかりました
最適ハイパーパラメータが best_hyperparameters_AMZN_Transformer(nomstl).json に保存されました
Epoch 1/300, Loss: 0.4274 | 0.5125
Epoch 2/300, Loss: 0.3173 | 0.4233
Epoch 3/300, Loss: 0.2714 | 0.3989
Epoch 4/300, Loss: 0.2280 | 0.3506
Epoch 5/300, Loss: 0.2056 | 0.3093
Epoch 6/300, Loss: 0.1976 | 0.2740
Epoch 7/300, Loss: 0.1842 | 0.2630
Epoch 8/300, Loss: 0.1733 | 0.2856
Epoch 9/300, Loss: 0.1668 | 0.2678
Epoch 10/300, Loss: 0.1548 | 0.2423
Epoch 11/300, Loss: 0.1509 | 0.2237
Epoch 12/300, Loss: 0.1451 | 0.2297
Epoch 13/300, Loss: 0.1399 | 0.2205
Epoch 14/300, Loss: 0.1348 | 0.2046
Epoch 15/300, Loss: 0.1316 | 0.2000
Epoch 16/300, Loss: 0.1286 | 0.1924
Epoch 17/300, Loss: 0.1268 | 0.1972
Epoch 18/300, Loss: 0.1226 | 0.1879
Epoch 19/300, Loss: 0.1203 | 0.1808
Epoch 20/300, Loss: 0.1185 | 0.1809
Epoch 21/300, Loss: 0.1154 | 0.1834
Epoch 22/300, Loss: 0.1135 | 0.1764
Epoch 23/300, Loss: 0.1113 | 0.1707
Epoch 24/300, Loss: 0.1091 | 0.1675
Epoch 25/300, Loss: 0.1073 | 0.1654
Epoch 26/300, Loss: 0.1055 | 0.1641
Epoch 27/300, Loss: 0.1045 | 0.1609
Epoch 28/300, Loss: 0.1039 | 0.1589
Epoch 29/300, Loss: 0.1028 | 0.1543
Epoch 30/300, Loss: 0.1024 | 0.1537
Epoch 31/300, Loss: 0.1008 | 0.1542
Epoch 32/300, Loss: 0.1000 | 0.1557
Epoch 33/300, Loss: 0.0992 | 0.1525
Epoch 34/300, Loss: 0.0989 | 0.1482
Epoch 35/300, Loss: 0.0976 | 0.1479
Epoch 36/300, Loss: 0.0972 | 0.1489
Epoch 37/300, Loss: 0.0966 | 0.1466
Epoch 38/300, Loss: 0.0967 | 0.1452
Epoch 39/300, Loss: 0.0959 | 0.1458
Epoch 40/300, Loss: 0.0948 | 0.1458
Epoch 41/300, Loss: 0.0946 | 0.1447
Epoch 42/300, Loss: 0.0941 | 0.1436
Epoch 43/300, Loss: 0.0939 | 0.1422
Epoch 44/300, Loss: 0.0937 | 0.1422
Epoch 45/300, Loss: 0.0934 | 0.1407
Epoch 46/300, Loss: 0.0932 | 0.1402
Epoch 47/300, Loss: 0.0926 | 0.1405
Epoch 48/300, Loss: 0.0923 | 0.1398
Epoch 49/300, Loss: 0.0920 | 0.1391
Epoch 50/300, Loss: 0.0923 | 0.1386
Epoch 51/300, Loss: 0.0917 | 0.1382
Epoch 52/300, Loss: 0.0916 | 0.1385
Epoch 53/300, Loss: 0.0914 | 0.1384
Epoch 54/300, Loss: 0.0917 | 0.1384
Epoch 55/300, Loss: 0.0911 | 0.1378
Epoch 56/300, Loss: 0.0915 | 0.1383
Epoch 57/300, Loss: 0.0910 | 0.1369
Epoch 58/300, Loss: 0.0908 | 0.1378
Epoch 59/300, Loss: 0.0906 | 0.1376
Epoch 60/300, Loss: 0.0906 | 0.1366
Epoch 61/300, Loss: 0.0903 | 0.1366
Epoch 62/300, Loss: 0.0907 | 0.1367
Epoch 63/300, Loss: 0.0904 | 0.1365
Epoch 64/300, Loss: 0.0900 | 0.1364
Epoch 65/300, Loss: 0.0903 | 0.1360
Epoch 66/300, Loss: 0.0896 | 0.1361
Epoch 67/300, Loss: 0.0901 | 0.1365
Epoch 68/300, Loss: 0.0897 | 0.1359
Epoch 69/300, Loss: 0.0893 | 0.1361
Epoch 70/300, Loss: 0.0901 | 0.1358
Epoch 71/300, Loss: 0.0897 | 0.1356
Epoch 72/300, Loss: 0.0897 | 0.1358
Epoch 73/300, Loss: 0.0896 | 0.1355
Epoch 74/300, Loss: 0.0899 | 0.1358
Epoch 75/300, Loss: 0.0895 | 0.1357
Epoch 76/300, Loss: 0.0896 | 0.1356
Epoch 77/300, Loss: 0.0899 | 0.1354
Epoch 78/300, Loss: 0.0897 | 0.1356
Epoch 79/300, Loss: 0.0891 | 0.1356
Epoch 80/300, Loss: 0.0894 | 0.1354
Epoch 81/300, Loss: 0.0896 | 0.1354
Epoch 82/300, Loss: 0.0894 | 0.1357
Epoch 83/300, Loss: 0.0893 | 0.1357
Epoch 84/300, Loss: 0.0897 | 0.1356
Epoch 85/300, Loss: 0.0895 | 0.1356
Epoch 86/300, Loss: 0.0894 | 0.1357
Epoch 87/300, Loss: 0.0890 | 0.1356
Epoch 88/300, Loss: 0.0892 | 0.1354
Epoch 89/300, Loss: 0.0894 | 0.1354
Epoch 90/300, Loss: 0.0887 | 0.1354
Epoch 91/300, Loss: 0.0885 | 0.1353
Epoch 92/300, Loss: 0.0897 | 0.1353
Epoch 93/300, Loss: 0.0887 | 0.1354
Epoch 94/300, Loss: 0.0892 | 0.1354
Epoch 95/300, Loss: 0.0888 | 0.1355
Epoch 96/300, Loss: 0.0893 | 0.1354
Epoch 97/300, Loss: 0.0894 | 0.1355
Epoch 98/300, Loss: 0.0892 | 0.1355
Epoch 99/300, Loss: 0.0889 | 0.1355
Epoch 100/300, Loss: 0.0891 | 0.1354
Epoch 101/300, Loss: 0.0890 | 0.1353
Epoch 102/300, Loss: 0.0892 | 0.1353
Epoch 103/300, Loss: 0.0893 | 0.1353
Epoch 104/300, Loss: 0.0893 | 0.1352
Epoch 105/300, Loss: 0.0885 | 0.1353
Epoch 106/300, Loss: 0.0887 | 0.1354
Epoch 107/300, Loss: 0.0889 | 0.1354
Epoch 108/300, Loss: 0.0892 | 0.1354
Epoch 109/300, Loss: 0.0889 | 0.1354
Epoch 110/300, Loss: 0.0897 | 0.1355
Epoch 111/300, Loss: 0.0892 | 0.1354
Epoch 112/300, Loss: 0.0889 | 0.1354
Epoch 113/300, Loss: 0.0893 | 0.1354
Epoch 114/300, Loss: 0.0897 | 0.1354
Epoch 115/300, Loss: 0.0888 | 0.1354
Epoch 116/300, Loss: 0.0891 | 0.1354
Epoch 117/300, Loss: 0.0890 | 0.1354
Epoch 118/300, Loss: 0.0892 | 0.1354
Epoch 119/300, Loss: 0.0887 | 0.1354
Epoch 120/300, Loss: 0.0889 | 0.1354
Epoch 121/300, Loss: 0.0891 | 0.1354
Epoch 122/300, Loss: 0.0883 | 0.1354
Epoch 123/300, Loss: 0.0897 | 0.1354
Epoch 124/300, Loss: 0.0897 | 0.1354
Epoch 125/300, Loss: 0.0898 | 0.1354
Epoch 126/300, Loss: 0.0892 | 0.1354
Epoch 127/300, Loss: 0.0894 | 0.1354
Epoch 128/300, Loss: 0.0884 | 0.1354
Epoch 129/300, Loss: 0.0894 | 0.1354
Epoch 130/300, Loss: 0.0897 | 0.1354
Epoch 131/300, Loss: 0.0895 | 0.1354
Epoch 132/300, Loss: 0.0891 | 0.1354
Epoch 133/300, Loss: 0.0893 | 0.1354
Epoch 134/300, Loss: 0.0892 | 0.1354
Epoch 135/300, Loss: 0.0885 | 0.1354
Epoch 136/300, Loss: 0.0887 | 0.1354
Epoch 137/300, Loss: 0.0895 | 0.1354
Epoch 138/300, Loss: 0.0888 | 0.1354
Epoch 139/300, Loss: 0.0890 | 0.1354
Epoch 140/300, Loss: 0.0887 | 0.1354
Epoch 141/300, Loss: 0.0891 | 0.1354
Epoch 142/300, Loss: 0.0888 | 0.1354
Epoch 143/300, Loss: 0.0889 | 0.1354
Epoch 144/300, Loss: 0.0888 | 0.1354
Epoch 145/300, Loss: 0.0894 | 0.1354
Epoch 146/300, Loss: 0.0896 | 0.1354
Epoch 147/300, Loss: 0.0894 | 0.1354
Epoch 148/300, Loss: 0.0892 | 0.1354
Epoch 149/300, Loss: 0.0891 | 0.1354
Epoch 150/300, Loss: 0.0892 | 0.1354
Epoch 151/300, Loss: 0.0895 | 0.1354
Epoch 152/300, Loss: 0.0887 | 0.1354
Epoch 153/300, Loss: 0.0895 | 0.1354
Epoch 154/300, Loss: 0.0887 | 0.1354
Epoch 155/300, Loss: 0.0893 | 0.1354
Epoch 156/300, Loss: 0.0890 | 0.1354
Epoch 157/300, Loss: 0.0890 | 0.1354
Epoch 158/300, Loss: 0.0894 | 0.1354
Epoch 159/300, Loss: 0.0887 | 0.1354
Epoch 160/300, Loss: 0.0889 | 0.1354
Epoch 161/300, Loss: 0.0893 | 0.1354
Epoch 162/300, Loss: 0.0899 | 0.1354
Epoch 163/300, Loss: 0.0888 | 0.1354
Epoch 164/300, Loss: 0.0889 | 0.1354
Epoch 165/300, Loss: 0.0891 | 0.1354
Epoch 166/300, Loss: 0.0895 | 0.1354
Epoch 167/300, Loss: 0.0891 | 0.1354
Epoch 168/300, Loss: 0.0892 | 0.1354
Epoch 169/300, Loss: 0.0895 | 0.1354
Epoch 170/300, Loss: 0.0893 | 0.1354
Epoch 171/300, Loss: 0.0891 | 0.1354
Epoch 172/300, Loss: 0.0887 | 0.1354
Epoch 173/300, Loss: 0.0891 | 0.1354
Epoch 174/300, Loss: 0.0890 | 0.1354
Epoch 175/300, Loss: 0.0888 | 0.1354
Epoch 176/300, Loss: 0.0892 | 0.1354
Epoch 177/300, Loss: 0.0891 | 0.1354
Epoch 178/300, Loss: 0.0894 | 0.1354
Epoch 179/300, Loss: 0.0890 | 0.1354
Epoch 180/300, Loss: 0.0885 | 0.1354
Epoch 181/300, Loss: 0.0889 | 0.1354
Epoch 182/300, Loss: 0.0890 | 0.1354
Epoch 183/300, Loss: 0.0886 | 0.1354
Epoch 184/300, Loss: 0.0890 | 0.1354
Epoch 185/300, Loss: 0.0892 | 0.1354
Epoch 186/300, Loss: 0.0893 | 0.1354
Epoch 187/300, Loss: 0.0888 | 0.1354
Epoch 188/300, Loss: 0.0893 | 0.1354
Epoch 189/300, Loss: 0.0893 | 0.1354
Epoch 190/300, Loss: 0.0891 | 0.1354
Epoch 191/300, Loss: 0.0886 | 0.1354
Epoch 192/300, Loss: 0.0890 | 0.1354
Epoch 193/300, Loss: 0.0890 | 0.1354
Epoch 194/300, Loss: 0.0888 | 0.1354
Epoch 195/300, Loss: 0.0889 | 0.1354
Epoch 196/300, Loss: 0.0891 | 0.1354
Epoch 197/300, Loss: 0.0893 | 0.1354
Epoch 198/300, Loss: 0.0888 | 0.1354
Epoch 199/300, Loss: 0.0889 | 0.1354
Epoch 200/300, Loss: 0.0888 | 0.1354
Epoch 201/300, Loss: 0.0893 | 0.1354
Epoch 202/300, Loss: 0.0888 | 0.1354
Epoch 203/300, Loss: 0.0890 | 0.1354
Epoch 204/300, Loss: 0.0891 | 0.1354
Epoch 205/300, Loss: 0.0894 | 0.1354
Epoch 206/300, Loss: 0.0893 | 0.1354
Epoch 207/300, Loss: 0.0892 | 0.1354
Epoch 208/300, Loss: 0.0888 | 0.1354
Epoch 209/300, Loss: 0.0893 | 0.1354
Early stopping
Runtime (seconds): 542.536511182785
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)
MSE: 635.1259819141123
RMSE: 25.201705932617188
MAE: 25.201705932617188
R-squared: nan
[201.8483]
