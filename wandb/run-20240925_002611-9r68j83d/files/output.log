[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
/home/raikakoki/.local/lib/python3.10/site-packages/torch/backends/cuda/__init__.py:342: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
Dataset created successfully.
Epoch 1/100, Training Loss: 0.7291, Validation Loss: 0.3263
Epoch 2/100, Training Loss: 0.1913, Validation Loss: 0.3066
Epoch 3/100, Training Loss: 0.1651, Validation Loss: 0.2508
Epoch 4/100, Training Loss: 0.1412, Validation Loss: 0.1861
Epoch 5/100, Training Loss: 0.1072, Validation Loss: 0.1868
Epoch 6/100, Training Loss: 0.0916, Validation Loss: 0.1362
Epoch 7/100, Training Loss: 0.0756, Validation Loss: 0.1287
Epoch 8/100, Training Loss: 0.0642, Validation Loss: 0.1138
Epoch 9/100, Training Loss: 0.0600, Validation Loss: 0.0956
Epoch 10/100, Training Loss: 0.0501, Validation Loss: 0.0815
Epoch 11/100, Training Loss: 0.0463, Validation Loss: 0.0806
Epoch 12/100, Training Loss: 0.0461, Validation Loss: 0.0759
Epoch 13/100, Training Loss: 0.0378, Validation Loss: 0.0574
Epoch 14/100, Training Loss: 0.0350, Validation Loss: 0.0611
Epoch 15/100, Training Loss: 0.0392, Validation Loss: 0.0676
Epoch 16/100, Training Loss: 0.0308, Validation Loss: 0.0431
Epoch 17/100, Training Loss: 0.0318, Validation Loss: 0.0557
Epoch 18/100, Training Loss: 0.0427, Validation Loss: 0.0693
Epoch 19/100, Training Loss: 0.0284, Validation Loss: 0.0415
Epoch 20/100, Training Loss: 0.0394, Validation Loss: 0.1280
Epoch 21/100, Training Loss: 0.0972, Validation Loss: 0.0772
Epoch 22/100, Training Loss: 0.0736, Validation Loss: 0.1986
Epoch 23/100, Training Loss: 0.0777, Validation Loss: 0.0897
Epoch 24/100, Training Loss: 0.0613, Validation Loss: 0.1265
Epoch 25/100, Training Loss: 0.0437, Validation Loss: 0.0581
Epoch 26/100, Training Loss: 0.0381, Validation Loss: 0.0813
Epoch 27/100, Training Loss: 0.0309, Validation Loss: 0.0526
Epoch 28/100, Training Loss: 0.0297, Validation Loss: 0.0623
Epoch 29/100, Training Loss: 0.0271, Validation Loss: 0.0467
Epoch 30/100, Training Loss: 0.0267, Validation Loss: 0.0549
Epoch 31/100, Training Loss: 0.0249, Validation Loss: 0.0437
Epoch 32/100, Training Loss: 0.0245, Validation Loss: 0.0488
Epoch 33/100, Training Loss: 0.0235, Validation Loss: 0.0403
Epoch 34/100, Training Loss: 0.0233, Validation Loss: 0.0460
Epoch 35/100, Training Loss: 0.0225, Validation Loss: 0.0381
Epoch 36/100, Training Loss: 0.0222, Validation Loss: 0.0428
Epoch 37/100, Training Loss: 0.0216, Validation Loss: 0.0366
Epoch 38/100, Training Loss: 0.0214, Validation Loss: 0.0408
Epoch 39/100, Training Loss: 0.0210, Validation Loss: 0.0351
Epoch 40/100, Training Loss: 0.0207, Validation Loss: 0.0389
Epoch 41/100, Training Loss: 0.0204, Validation Loss: 0.0343
Epoch 42/100, Training Loss: 0.0202, Validation Loss: 0.0371
Epoch 43/100, Training Loss: 0.0199, Validation Loss: 0.0337
Epoch 44/100, Training Loss: 0.0197, Validation Loss: 0.0355
Epoch 45/100, Training Loss: 0.0195, Validation Loss: 0.0334
Epoch 46/100, Training Loss: 0.0192, Validation Loss: 0.0341
Epoch 47/100, Training Loss: 0.0191, Validation Loss: 0.0331
Epoch 48/100, Training Loss: 0.0189, Validation Loss: 0.0329
Epoch 49/100, Training Loss: 0.0189, Validation Loss: 0.0328
Epoch 50/100, Training Loss: 0.0186, Validation Loss: 0.0321
Epoch 51/100, Training Loss: 0.0186, Validation Loss: 0.0325
Epoch 52/100, Training Loss: 0.0184, Validation Loss: 0.0315
Epoch 53/100, Training Loss: 0.0185, Validation Loss: 0.0321
Epoch 54/100, Training Loss: 0.0183, Validation Loss: 0.0311
Epoch 55/100, Training Loss: 0.0187, Validation Loss: 0.0319
Epoch 56/100, Training Loss: 0.0186, Validation Loss: 0.0309
Epoch 57/100, Training Loss: 0.0196, Validation Loss: 0.0321
Epoch 58/100, Training Loss: 0.0202, Validation Loss: 0.0311
Epoch 59/100, Training Loss: 0.0230, Validation Loss: 0.0326
Epoch 60/100, Training Loss: 0.0247, Validation Loss: 0.0310
Epoch 61/100, Training Loss: 0.0289, Validation Loss: 0.0322
Epoch 62/100, Training Loss: 0.0262, Validation Loss: 0.0299
Epoch 63/100, Training Loss: 0.0247, Validation Loss: 0.0310
Epoch 64/100, Training Loss: 0.0202, Validation Loss: 0.0301
Epoch 65/100, Training Loss: 0.0187, Validation Loss: 0.0304
Epoch 66/100, Training Loss: 0.0177, Validation Loss: 0.0301
Epoch 67/100, Training Loss: 0.0175, Validation Loss: 0.0300
Epoch 68/100, Training Loss: 0.0174, Validation Loss: 0.0298
Epoch 69/100, Training Loss: 0.0173, Validation Loss: 0.0297
Epoch 70/100, Training Loss: 0.0173, Validation Loss: 0.0296
Epoch 71/100, Training Loss: 0.0173, Validation Loss: 0.0295
Epoch 72/100, Training Loss: 0.0172, Validation Loss: 0.0294
Epoch 73/100, Training Loss: 0.0172, Validation Loss: 0.0293
Epoch 74/100, Training Loss: 0.0171, Validation Loss: 0.0292
Epoch 75/100, Training Loss: 0.0171, Validation Loss: 0.0291
Epoch 76/100, Training Loss: 0.0171, Validation Loss: 0.0290
Epoch 77/100, Training Loss: 0.0170, Validation Loss: 0.0290
Epoch 78/100, Training Loss: 0.0170, Validation Loss: 0.0289
Epoch 79/100, Training Loss: 0.0170, Validation Loss: 0.0288
Epoch 80/100, Training Loss: 0.0170, Validation Loss: 0.0288
Epoch 81/100, Training Loss: 0.0169, Validation Loss: 0.0287
Epoch 82/100, Training Loss: 0.0169, Validation Loss: 0.0287
Epoch 83/100, Training Loss: 0.0169, Validation Loss: 0.0286
Epoch 84/100, Training Loss: 0.0169, Validation Loss: 0.0286
Epoch 85/100, Training Loss: 0.0168, Validation Loss: 0.0285
Epoch 86/100, Training Loss: 0.0168, Validation Loss: 0.0285
Epoch 87/100, Training Loss: 0.0168, Validation Loss: 0.0284
Epoch 88/100, Training Loss: 0.0168, Validation Loss: 0.0284
Epoch 89/100, Training Loss: 0.0168, Validation Loss: 0.0284
Epoch 90/100, Training Loss: 0.0168, Validation Loss: 0.0283
Epoch 91/100, Training Loss: 0.0167, Validation Loss: 0.0283
Epoch 92/100, Training Loss: 0.0167, Validation Loss: 0.0283
Epoch 93/100, Training Loss: 0.0167, Validation Loss: 0.0282
Epoch 94/100, Training Loss: 0.0167, Validation Loss: 0.0282
Epoch 95/100, Training Loss: 0.0167, Validation Loss: 0.0282
Epoch 96/100, Training Loss: 0.0167, Validation Loss: 0.0281
Epoch 97/100, Training Loss: 0.0167, Validation Loss: 0.0281
/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/demo.py:115: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  predicted_selected_stock_price = predicted_selected_stock_price.cpu().numpy().flatten() * std_list[0] + mean_list[0]  # Using AAPL normalization factors
Epoch 98/100, Training Loss: 0.0166, Validation Loss: 0.0281
Epoch 99/100, Training Loss: 0.0166, Validation Loss: 0.0281
Epoch 100/100, Training Loss: 0.0166, Validation Loss: 0.0280
['2023-05-17', '2023-05-18', '2023-05-19', '2023-05-22', '2023-05-23', '2023-05-24', '2023-05-25', '2023-05-26', '2023-05-30', '2023-05-31']
tensor([[[ 1.1857,  0.7295,  0.1377, -0.7420,  1.4366]]])
[171.57913208 173.92396545 174.0332489  173.079422   170.45639038
 170.73460388 171.87721252 174.30149841 176.1594696  167.19815063]
[171.57913208 173.92396545 174.0332489  173.079422   170.45639038
 170.73460388 171.87721252 174.30149841 176.1594696  176.10980225]
/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/demo.py:147: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown
  plt.show()