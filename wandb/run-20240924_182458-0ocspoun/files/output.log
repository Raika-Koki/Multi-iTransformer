[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
/home/raikakoki/.local/lib/python3.10/site-packages/torch/backends/cuda/__init__.py:342: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
Dataset created successfully.
Epoch 1/100, Training Loss: 0.2851, Validation Loss: 0.2066
Epoch 2/100, Training Loss: 0.1242, Validation Loss: 0.1682
Epoch 3/100, Training Loss: 0.1141, Validation Loss: 0.1325
Epoch 4/100, Training Loss: 0.0903, Validation Loss: 0.1187
Epoch 5/100, Training Loss: 0.0645, Validation Loss: 0.0971
Epoch 6/100, Training Loss: 0.0550, Validation Loss: 0.0843
Epoch 7/100, Training Loss: 0.0577, Validation Loss: 0.0843
Epoch 8/100, Training Loss: 0.0486, Validation Loss: 0.0824
Epoch 9/100, Training Loss: 0.0388, Validation Loss: 0.0616
Epoch 10/100, Training Loss: 0.0468, Validation Loss: 0.0691
Epoch 11/100, Training Loss: 0.0426, Validation Loss: 0.0595
Epoch 12/100, Training Loss: 0.0295, Validation Loss: 0.0415
Epoch 13/100, Training Loss: 0.0302, Validation Loss: 0.0550
Epoch 14/100, Training Loss: 0.0268, Validation Loss: 0.0563
Epoch 15/100, Training Loss: 0.0321, Validation Loss: 0.0535
Epoch 16/100, Training Loss: 0.0273, Validation Loss: 0.0364
Epoch 17/100, Training Loss: 0.0221, Validation Loss: 0.0406
Epoch 18/100, Training Loss: 0.0241, Validation Loss: 0.0541
Epoch 19/100, Training Loss: 0.0220, Validation Loss: 0.0329
Epoch 20/100, Training Loss: 0.0240, Validation Loss: 0.0401
Epoch 21/100, Training Loss: 0.0296, Validation Loss: 0.0608
Epoch 22/100, Training Loss: 0.0220, Validation Loss: 0.0297
Epoch 23/100, Training Loss: 0.0320, Validation Loss: 0.1267
Epoch 24/100, Training Loss: 0.0985, Validation Loss: 0.0601
Epoch 25/100, Training Loss: 0.0551, Validation Loss: 0.1737
Epoch 26/100, Training Loss: 0.0746, Validation Loss: 0.0660
Epoch 27/100, Training Loss: 0.0445, Validation Loss: 0.0942
Epoch 28/100, Training Loss: 0.0331, Validation Loss: 0.0432
Epoch 29/100, Training Loss: 0.0274, Validation Loss: 0.0653
Epoch 30/100, Training Loss: 0.0244, Validation Loss: 0.0392
Epoch 31/100, Training Loss: 0.0221, Validation Loss: 0.0497
Epoch 32/100, Training Loss: 0.0206, Validation Loss: 0.0391
Epoch 33/100, Training Loss: 0.0200, Validation Loss: 0.0428
Epoch 34/100, Training Loss: 0.0191, Validation Loss: 0.0371
Epoch 35/100, Training Loss: 0.0188, Validation Loss: 0.0394
Epoch 36/100, Training Loss: 0.0183, Validation Loss: 0.0356
Epoch 37/100, Training Loss: 0.0179, Validation Loss: 0.0368
Epoch 38/100, Training Loss: 0.0176, Validation Loss: 0.0346
Epoch 39/100, Training Loss: 0.0173, Validation Loss: 0.0350
Epoch 40/100, Training Loss: 0.0170, Validation Loss: 0.0338
Epoch 41/100, Training Loss: 0.0167, Validation Loss: 0.0336
Epoch 42/100, Training Loss: 0.0166, Validation Loss: 0.0330
Epoch 43/100, Training Loss: 0.0163, Validation Loss: 0.0326
Epoch 44/100, Training Loss: 0.0162, Validation Loss: 0.0324
Epoch 45/100, Training Loss: 0.0160, Validation Loss: 0.0318
Epoch 46/100, Training Loss: 0.0159, Validation Loss: 0.0318
Epoch 47/100, Training Loss: 0.0157, Validation Loss: 0.0311
Epoch 48/100, Training Loss: 0.0156, Validation Loss: 0.0313
Epoch 49/100, Training Loss: 0.0154, Validation Loss: 0.0306
Epoch 50/100, Training Loss: 0.0155, Validation Loss: 0.0309
Epoch 51/100, Training Loss: 0.0153, Validation Loss: 0.0301
Epoch 52/100, Training Loss: 0.0155, Validation Loss: 0.0307
Epoch 53/100, Training Loss: 0.0153, Validation Loss: 0.0298
Epoch 54/100, Training Loss: 0.0161, Validation Loss: 0.0309
Epoch 55/100, Training Loss: 0.0165, Validation Loss: 0.0298
Epoch 56/100, Training Loss: 0.0190, Validation Loss: 0.0320
Epoch 57/100, Training Loss: 0.0206, Validation Loss: 0.0300
Epoch 58/100, Training Loss: 0.0262, Validation Loss: 0.0326
Epoch 59/100, Training Loss: 0.0249, Validation Loss: 0.0290
Epoch 60/100, Training Loss: 0.0255, Validation Loss: 0.0310
Epoch 61/100, Training Loss: 0.0190, Validation Loss: 0.0291
Epoch 62/100, Training Loss: 0.0169, Validation Loss: 0.0296
Epoch 63/100, Training Loss: 0.0151, Validation Loss: 0.0291
Epoch 64/100, Training Loss: 0.0147, Validation Loss: 0.0291
Epoch 65/100, Training Loss: 0.0145, Validation Loss: 0.0289
Epoch 66/100, Training Loss: 0.0144, Validation Loss: 0.0288
Epoch 67/100, Training Loss: 0.0144, Validation Loss: 0.0287
Epoch 68/100, Training Loss: 0.0143, Validation Loss: 0.0285
Epoch 69/100, Training Loss: 0.0143, Validation Loss: 0.0284
Epoch 70/100, Training Loss: 0.0143, Validation Loss: 0.0283
Epoch 71/100, Training Loss: 0.0142, Validation Loss: 0.0282
Epoch 72/100, Training Loss: 0.0142, Validation Loss: 0.0281
Epoch 73/100, Training Loss: 0.0142, Validation Loss: 0.0281
Epoch 74/100, Training Loss: 0.0142, Validation Loss: 0.0280
Epoch 75/100, Training Loss: 0.0141, Validation Loss: 0.0279
Epoch 76/100, Training Loss: 0.0141, Validation Loss: 0.0278
Epoch 77/100, Training Loss: 0.0141, Validation Loss: 0.0278
Epoch 78/100, Training Loss: 0.0141, Validation Loss: 0.0277
Epoch 79/100, Training Loss: 0.0140, Validation Loss: 0.0276
Epoch 80/100, Training Loss: 0.0140, Validation Loss: 0.0276
Epoch 81/100, Training Loss: 0.0140, Validation Loss: 0.0275
Epoch 82/100, Training Loss: 0.0140, Validation Loss: 0.0275
Epoch 83/100, Training Loss: 0.0140, Validation Loss: 0.0274
Epoch 84/100, Training Loss: 0.0139, Validation Loss: 0.0274
Epoch 85/100, Training Loss: 0.0139, Validation Loss: 0.0273
Epoch 86/100, Training Loss: 0.0139, Validation Loss: 0.0273
Epoch 87/100, Training Loss: 0.0139, Validation Loss: 0.0273
Epoch 88/100, Training Loss: 0.0139, Validation Loss: 0.0272
Epoch 89/100, Training Loss: 0.0139, Validation Loss: 0.0272
Epoch 90/100, Training Loss: 0.0139, Validation Loss: 0.0272
Epoch 91/100, Training Loss: 0.0138, Validation Loss: 0.0271
Epoch 92/100, Training Loss: 0.0138, Validation Loss: 0.0271
Epoch 93/100, Training Loss: 0.0138, Validation Loss: 0.0271
Epoch 94/100, Training Loss: 0.0138, Validation Loss: 0.0270
Epoch 95/100, Training Loss: 0.0138, Validation Loss: 0.0270
Epoch 96/100, Training Loss: 0.0138, Validation Loss: 0.0270
Epoch 97/100, Training Loss: 0.0138, Validation Loss: 0.0270
Epoch 98/100, Training Loss: 0.0138, Validation Loss: 0.0269
Epoch 99/100, Training Loss: 0.0138, Validation Loss: 0.0269
Traceback (most recent call last):
  File "/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/demo.py", line 107, in <module>
    predicted_stock_price = predicted_stock_prices[:, 1].cpu().numpy().flatten() * std_list[1] + mean_list[1]
IndexError: index 1 is out of bounds for dimension 1 with size 1
Traceback (most recent call last):
  File "/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/demo.py", line 107, in <module>
    predicted_stock_price = predicted_stock_prices[:, 1].cpu().numpy().flatten() * std_list[1] + mean_list[1]
IndexError: index 1 is out of bounds for dimension 1 with size 1
Epoch 100/100, Training Loss: 0.0138, Validation Loss: 0.0269