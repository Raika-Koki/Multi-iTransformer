ÊúÄÈÅ©ÂåñÂØæË±°: trend
[32m[I 2025-01-30 17:36:48,425][0m A new study created in memory with name: no-name-3da76566-8f39-4315-8f4b-fa5a30b8b0ce[0m
Non-A100 GPU detected, using math or mem efficient attention if input tensor is on cuda
[32m[I 2025-01-30 17:38:25,205][0m Trial 0 finished with value: 0.11776838068276038 and parameters: {'observation_period_num': 93, 'train_rates': 0.6386145908691019, 'learning_rate': 0.0007681868867414466, 'batch_size': 45, 'step_size': 3, 'gamma': 0.952372299225832}. Best is trial 0 with value: 0.11776838068276038.[0m
[32m[I 2025-01-30 17:38:46,493][0m Trial 1 finished with value: 1.5734783952190228 and parameters: {'observation_period_num': 10, 'train_rates': 0.682470352843313, 'learning_rate': 1.879612955662108e-06, 'batch_size': 235, 'step_size': 4, 'gamma': 0.7670879141067575}. Best is trial 0 with value: 0.11776838068276038.[0m
[32m[I 2025-01-30 17:39:22,231][0m Trial 2 finished with value: 0.14664232987936665 and parameters: {'observation_period_num': 51, 'train_rates': 0.6562918780190518, 'learning_rate': 3.9551671486777736e-05, 'batch_size': 132, 'step_size': 5, 'gamma': 0.9896931182139941}. Best is trial 0 with value: 0.11776838068276038.[0m
[33m[W 2025-01-30 17:39:25,804][0m Trial 3 failed with parameters: {'observation_period_num': 242, 'train_rates': 0.8663975986520707, 'learning_rate': 0.00028505195301261883, 'batch_size': 61, 'step_size': 7, 'gamma': 0.9829836019835577} because of the following error: KeyboardInterrupt().[0m
Traceback (most recent call last):
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/roop_optuna.py", line 551, in <lambda>
    study.optimize(lambda trial: objective(trial, component, depth, dim), n_trials=50) #check
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/roop_optuna.py", line 113, in objective
    model, _, valid_loss = train(
                           ^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/src/train.py", line 32, in train
    output = model(data)
             ^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<@beartype(src.model.iTransformer.forward) at 0x7f398f6400e0>", line 66, in forward
  File "/data/student/k2110261/Multi-iTransformer/src/model.py", line 188, in forward
    x = attn(x) + x
        ^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/src/model.py", line 67, in forward
    out = self.attend(q, k, v)
          ^^^^^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/attend.py", line 123, in forward
    return self.flash_attn(q, k, v)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/attend.py", line 97, in flash_attn
    with torch.backends.cuda.sdp_kernel(**config._asdict()):
                                          ^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/collections/__init__.py", line 467, in _asdict
    return _dict(_zip(self._fields, self))
                 ^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
[33m[W 2025-01-30 17:39:25,891][0m Trial 3 failed with value None.[0m
Traceback (most recent call last):
  File "/data/student/k2110261/Multi-iTransformer/roop_optuna.py", line 551, in <module>
    study.optimize(lambda trial: objective(trial, component, depth, dim), n_trials=50) #check
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/study.py", line 475, in optimize
    _optimize(
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 63, in _optimize
    _optimize_sequential(
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 160, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 248, in _run_trial
    raise func_err
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/roop_optuna.py", line 551, in <lambda>
    study.optimize(lambda trial: objective(trial, component, depth, dim), n_trials=50) #check
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/roop_optuna.py", line 113, in objective
    model, _, valid_loss = train(
                           ^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/src/train.py", line 32, in train
    output = model(data)
             ^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<@beartype(src.model.iTransformer.forward) at 0x7f398f6400e0>", line 66, in forward
  File "/data/student/k2110261/Multi-iTransformer/src/model.py", line 188, in forward
    x = attn(x) + x
        ^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/src/model.py", line 67, in forward
    out = self.attend(q, k, v)
          ^^^^^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/attend.py", line 123, in forward
    return self.flash_attn(q, k, v)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/attend.py", line 97, in flash_attn
    with torch.backends.cuda.sdp_kernel(**config._asdict()):
                                          ^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/collections/__init__.py", line 467, in _asdict
    return _dict(_zip(self._fields, self))
                 ^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
