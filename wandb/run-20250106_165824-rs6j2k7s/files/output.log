[32m[I 2025-01-06 16:58:30,220][0m A new study created in memory with name: no-name-cde66ef9-b711-4063-91c6-3429ee865300[0m
[32m[I 2025-01-06 17:00:45,745][0m Trial 0 finished with value: 1.2881277799606323 and parameters: {'observation_period_num': 100, 'train_rates': 0.9530128594637537, 'learning_rate': 2.0747106532460917e-06, 'batch_size': 224, 'step_size': 14, 'gamma': 0.794480171190338}. Best is trial 0 with value: 1.2881277799606323.[0m
[32m[I 2025-01-06 17:02:17,154][0m Trial 1 finished with value: 0.9100068377629491 and parameters: {'observation_period_num': 85, 'train_rates': 0.6351186421635764, 'learning_rate': 4.452220840796955e-05, 'batch_size': 104, 'step_size': 6, 'gamma': 0.7591468008818746}. Best is trial 1 with value: 0.9100068377629491.[0m
[32m[I 2025-01-06 17:05:47,438][0m Trial 2 finished with value: 0.6199563839326897 and parameters: {'observation_period_num': 168, 'train_rates': 0.7485917829660462, 'learning_rate': 0.0005115851071167949, 'batch_size': 233, 'step_size': 13, 'gamma': 0.9410829682884349}. Best is trial 2 with value: 0.6199563839326897.[0m
[32m[I 2025-01-06 17:10:49,536][0m Trial 3 finished with value: 0.3800238370895386 and parameters: {'observation_period_num': 198, 'train_rates': 0.9633236534332332, 'learning_rate': 1.377943122033949e-05, 'batch_size': 112, 'step_size': 1, 'gamma': 0.97646660736742}. Best is trial 3 with value: 0.3800238370895386.[0m
[32m[I 2025-01-06 17:17:13,961][0m Trial 4 finished with value: 0.19255519000136798 and parameters: {'observation_period_num': 250, 'train_rates': 0.9178179524820061, 'learning_rate': 0.00011591069677270909, 'batch_size': 82, 'step_size': 7, 'gamma': 0.9875449157415698}. Best is trial 4 with value: 0.19255519000136798.[0m
[32m[I 2025-01-06 17:20:37,530][0m Trial 5 finished with value: 1.6155239961178978 and parameters: {'observation_period_num': 184, 'train_rates': 0.6200853693472796, 'learning_rate': 3.0315588865642667e-06, 'batch_size': 212, 'step_size': 2, 'gamma': 0.8700039714186838}. Best is trial 4 with value: 0.19255519000136798.[0m
[32m[I 2025-01-06 17:25:41,936][0m Trial 6 finished with value: 0.4027856977417311 and parameters: {'observation_period_num': 224, 'train_rates': 0.8121254317354463, 'learning_rate': 2.7385447081867654e-05, 'batch_size': 154, 'step_size': 15, 'gamma': 0.9560649085254415}. Best is trial 4 with value: 0.19255519000136798.[0m
[32m[I 2025-01-06 17:27:43,145][0m Trial 7 finished with value: 2.0842105571378085 and parameters: {'observation_period_num': 106, 'train_rates': 0.6162974318806574, 'learning_rate': 0.0007502606535720022, 'batch_size': 43, 'step_size': 8, 'gamma': 0.8696031177462316}. Best is trial 4 with value: 0.19255519000136798.[0m
[32m[I 2025-01-06 17:29:02,587][0m Trial 8 finished with value: 0.6798822222923746 and parameters: {'observation_period_num': 65, 'train_rates': 0.7291649456213737, 'learning_rate': 0.00019737272740778588, 'batch_size': 120, 'step_size': 8, 'gamma': 0.9815057486727286}. Best is trial 4 with value: 0.19255519000136798.[0m
[32m[I 2025-01-06 17:31:50,470][0m Trial 9 finished with value: 1.8837041513116202 and parameters: {'observation_period_num': 145, 'train_rates': 0.6826535552266119, 'learning_rate': 3.076833522304995e-06, 'batch_size': 255, 'step_size': 3, 'gamma': 0.8273535889741678}. Best is trial 4 with value: 0.19255519000136798.[0m
[32m[I 2025-01-06 17:34:54,461][0m Trial 10 finished with value: 0.15359139221055168 and parameters: {'observation_period_num': 30, 'train_rates': 0.8804314930235534, 'learning_rate': 9.80156329005354e-05, 'batch_size': 24, 'step_size': 11, 'gamma': 0.907781474194389}. Best is trial 10 with value: 0.15359139221055168.[0m
[32m[I 2025-01-06 17:38:17,535][0m Trial 11 finished with value: 0.19070425062764995 and parameters: {'observation_period_num': 10, 'train_rates': 0.8668077449101256, 'learning_rate': 0.00012315369495858545, 'batch_size': 22, 'step_size': 11, 'gamma': 0.9161283659626058}. Best is trial 10 with value: 0.15359139221055168.[0m
[32m[I 2025-01-06 17:42:17,663][0m Trial 12 finished with value: 0.23869713248783037 and parameters: {'observation_period_num': 7, 'train_rates': 0.8455939971022159, 'learning_rate': 0.0001244342618419826, 'batch_size': 18, 'step_size': 11, 'gamma': 0.9131855893802989}. Best is trial 10 with value: 0.15359139221055168.[0m
[32m[I 2025-01-06 17:43:39,247][0m Trial 13 finished with value: 0.13690560189007367 and parameters: {'observation_period_num': 7, 'train_rates': 0.8802175850432087, 'learning_rate': 5.861007826135776e-05, 'batch_size': 56, 'step_size': 11, 'gamma': 0.9029086745181379}. Best is trial 13 with value: 0.13690560189007367.[0m
[32m[I 2025-01-06 17:44:55,759][0m Trial 14 finished with value: 0.2796252720926437 and parameters: {'observation_period_num': 53, 'train_rates': 0.8878963101006362, 'learning_rate': 1.0411822177259504e-05, 'batch_size': 66, 'step_size': 11, 'gamma': 0.8806260699455344}. Best is trial 13 with value: 0.13690560189007367.[0m
[32m[I 2025-01-06 17:45:44,290][0m Trial 15 finished with value: 0.33959649543723336 and parameters: {'observation_period_num': 39, 'train_rates': 0.8108992050447797, 'learning_rate': 4.4018854216703365e-05, 'batch_size': 163, 'step_size': 10, 'gamma': 0.9083094273962958}. Best is trial 13 with value: 0.13690560189007367.[0m
[32m[I 2025-01-06 17:47:01,177][0m Trial 16 finished with value: 0.15191328078508376 and parameters: {'observation_period_num': 33, 'train_rates': 0.9079619751632308, 'learning_rate': 0.00027993334979267736, 'batch_size': 54, 'step_size': 5, 'gamma': 0.8424780460446829}. Best is trial 13 with value: 0.13690560189007367.[0m
[32m[I 2025-01-06 17:48:45,538][0m Trial 17 finished with value: 0.09831278026103973 and parameters: {'observation_period_num': 70, 'train_rates': 0.9880089781055434, 'learning_rate': 0.0002680640439447129, 'batch_size': 67, 'step_size': 5, 'gamma': 0.8439944062968266}. Best is trial 17 with value: 0.09831278026103973.[0m
[32m[I 2025-01-06 17:51:52,705][0m Trial 18 finished with value: 0.21128263975892747 and parameters: {'observation_period_num': 130, 'train_rates': 0.9383324915283, 'learning_rate': 0.0003437632035140481, 'batch_size': 88, 'step_size': 4, 'gamma': 0.8277069713759161}. Best is trial 17 with value: 0.09831278026103973.[0m
[32m[I 2025-01-06 17:53:37,460][0m Trial 19 finished with value: 0.5195221304893494 and parameters: {'observation_period_num': 74, 'train_rates': 0.9815449771582159, 'learning_rate': 8.487788333736955e-06, 'batch_size': 145, 'step_size': 9, 'gamma': 0.7947299342371025}. Best is trial 17 with value: 0.09831278026103973.[0m
[32m[I 2025-01-06 17:55:50,282][0m Trial 20 finished with value: 1.0582460423092266 and parameters: {'observation_period_num': 102, 'train_rates': 0.8406543095401573, 'learning_rate': 0.0009366408255137316, 'batch_size': 73, 'step_size': 13, 'gamma': 0.84997756187188}. Best is trial 17 with value: 0.09831278026103973.[0m
[32m[I 2025-01-06 17:57:12,087][0m Trial 21 finished with value: 0.14449928931057685 and parameters: {'observation_period_num': 27, 'train_rates': 0.9117537472336255, 'learning_rate': 0.0002784963029053552, 'batch_size': 48, 'step_size': 5, 'gamma': 0.837449530284632}. Best is trial 17 with value: 0.09831278026103973.[0m
[32m[I 2025-01-06 17:58:38,573][0m Trial 22 finished with value: 0.07546427845954895 and parameters: {'observation_period_num': 7, 'train_rates': 0.978342995590486, 'learning_rate': 7.527005783224374e-05, 'batch_size': 48, 'step_size': 5, 'gamma': 0.8084561335440368}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 17:59:49,513][0m Trial 23 finished with value: 0.23533128201961517 and parameters: {'observation_period_num': 53, 'train_rates': 0.9704815139900391, 'learning_rate': 6.352547502888474e-05, 'batch_size': 181, 'step_size': 6, 'gamma': 0.7995500255560299}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:00:35,446][0m Trial 24 finished with value: 0.4370286166667938 and parameters: {'observation_period_num': 23, 'train_rates': 0.987893804630273, 'learning_rate': 2.3343086207314965e-05, 'batch_size': 95, 'step_size': 3, 'gamma': 0.7505128662362707}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:02:21,330][0m Trial 25 finished with value: 0.10814598792543013 and parameters: {'observation_period_num': 6, 'train_rates': 0.9349524952134656, 'learning_rate': 8.721768107721242e-05, 'batch_size': 37, 'step_size': 7, 'gamma': 0.809897411539979}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:04:10,856][0m Trial 26 finished with value: 0.15132764503359794 and parameters: {'observation_period_num': 52, 'train_rates': 0.9383283358294398, 'learning_rate': 0.00018668607513657603, 'batch_size': 36, 'step_size': 6, 'gamma': 0.7752507412001037}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:06:00,919][0m Trial 27 finished with value: 0.2135816514492035 and parameters: {'observation_period_num': 80, 'train_rates': 0.9885107582977777, 'learning_rate': 7.869208751806055e-05, 'batch_size': 125, 'step_size': 4, 'gamma': 0.8170539261302716}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:07:10,464][0m Trial 28 finished with value: 0.21288412903484547 and parameters: {'observation_period_num': 47, 'train_rates': 0.9348093236039368, 'learning_rate': 0.0004684681774135887, 'batch_size': 68, 'step_size': 7, 'gamma': 0.7703931815831873}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:10:10,026][0m Trial 29 finished with value: 0.17356734065448537 and parameters: {'observation_period_num': 118, 'train_rates': 0.9522184747032372, 'learning_rate': 0.0001867821998103219, 'batch_size': 35, 'step_size': 4, 'gamma': 0.8084084895338197}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:11:56,196][0m Trial 30 finished with value: 0.4887436775552542 and parameters: {'observation_period_num': 87, 'train_rates': 0.7693797933402344, 'learning_rate': 4.354665177761616e-05, 'batch_size': 75, 'step_size': 7, 'gamma': 0.7808361370128657}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:13:04,648][0m Trial 31 finished with value: 0.12230044515044601 and parameters: {'observation_period_num': 8, 'train_rates': 0.9543055787506658, 'learning_rate': 7.173466644643977e-05, 'batch_size': 59, 'step_size': 9, 'gamma': 0.85384232138338}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:13:46,356][0m Trial 32 finished with value: 0.2992825624015596 and parameters: {'observation_period_num': 17, 'train_rates': 0.9511979638694468, 'learning_rate': 1.8682962053296993e-05, 'batch_size': 100, 'step_size': 9, 'gamma': 0.8502326011404493}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:14:54,454][0m Trial 33 finished with value: 0.2298640248910436 and parameters: {'observation_period_num': 37, 'train_rates': 0.9639449090618522, 'learning_rate': 3.3704865306924944e-05, 'batch_size': 60, 'step_size': 5, 'gamma': 0.8559826535168737}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:16:44,428][0m Trial 34 finished with value: 0.10600452863762522 and parameters: {'observation_period_num': 18, 'train_rates': 0.9204081640799254, 'learning_rate': 8.02463120815169e-05, 'batch_size': 35, 'step_size': 9, 'gamma': 0.8160202090278248}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:18:32,541][0m Trial 35 finished with value: 0.8874026629831884 and parameters: {'observation_period_num': 62, 'train_rates': 0.9203572712696755, 'learning_rate': 1.2680418300623188e-06, 'batch_size': 36, 'step_size': 7, 'gamma': 0.8158250256200028}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:20:55,363][0m Trial 36 finished with value: 0.13353534865946998 and parameters: {'observation_period_num': 22, 'train_rates': 0.8927355125224409, 'learning_rate': 0.00015934141359394264, 'batch_size': 29, 'step_size': 6, 'gamma': 0.7860764302543211}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:24:32,771][0m Trial 37 finished with value: 0.5662252240710788 and parameters: {'observation_period_num': 155, 'train_rates': 0.852602102380639, 'learning_rate': 0.0005355367965036437, 'batch_size': 46, 'step_size': 3, 'gamma': 0.8053864506052053}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:25:28,389][0m Trial 38 finished with value: 0.2916263408604122 and parameters: {'observation_period_num': 37, 'train_rates': 0.9282053177190633, 'learning_rate': 8.462365621983537e-05, 'batch_size': 89, 'step_size': 2, 'gamma': 0.8285568602008396}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:27:37,960][0m Trial 39 finished with value: 0.19563797658140009 and parameters: {'observation_period_num': 92, 'train_rates': 0.9693891265520578, 'learning_rate': 3.437047297106424e-05, 'batch_size': 80, 'step_size': 8, 'gamma': 0.8785097642503796}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:28:47,162][0m Trial 40 finished with value: 0.606613185865996 and parameters: {'observation_period_num': 63, 'train_rates': 0.704227041445737, 'learning_rate': 0.00026265990341884564, 'batch_size': 110, 'step_size': 5, 'gamma': 0.7670692919582128}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:32:40,237][0m Trial 41 finished with value: 0.11760981881270444 and parameters: {'observation_period_num': 6, 'train_rates': 0.953783044190892, 'learning_rate': 7.69800215908778e-05, 'batch_size': 17, 'step_size': 9, 'gamma': 0.8633858313200615}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:34:18,905][0m Trial 42 finished with value: 0.140465565419323 and parameters: {'observation_period_num': 17, 'train_rates': 0.90373988931353, 'learning_rate': 5.06371219307408e-05, 'batch_size': 39, 'step_size': 10, 'gamma': 0.8685773188267435}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:37:49,808][0m Trial 43 finished with value: 0.10240470127177399 and parameters: {'observation_period_num': 5, 'train_rates': 0.9499011116581156, 'learning_rate': 0.00010663131559718335, 'batch_size': 19, 'step_size': 8, 'gamma': 0.8193675078157656}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:39:19,650][0m Trial 44 finished with value: 0.07631399482488632 and parameters: {'observation_period_num': 22, 'train_rates': 0.9895932508526339, 'learning_rate': 0.00012504933053363187, 'batch_size': 47, 'step_size': 8, 'gamma': 0.8171554014105143}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:41:10,653][0m Trial 45 finished with value: 0.9661949528381228 and parameters: {'observation_period_num': 42, 'train_rates': 0.6542641093111717, 'learning_rate': 0.00013871817390340627, 'batch_size': 27, 'step_size': 8, 'gamma': 0.8341003003334536}. Best is trial 22 with value: 0.07546427845954895.[0m
Early stopping at epoch 54
[32m[I 2025-01-06 18:41:58,103][0m Trial 46 finished with value: 0.3257727432996035 and parameters: {'observation_period_num': 21, 'train_rates': 0.9729140372989721, 'learning_rate': 0.00012442339239293406, 'batch_size': 49, 'step_size': 1, 'gamma': 0.7894331391943737}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:47:11,731][0m Trial 47 finished with value: 0.1249571000225842 and parameters: {'observation_period_num': 182, 'train_rates': 0.9887261657235927, 'learning_rate': 0.00037476968946645626, 'batch_size': 18, 'step_size': 10, 'gamma': 0.8203004501244234}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:52:45,674][0m Trial 48 finished with value: 0.1277715563774109 and parameters: {'observation_period_num': 215, 'train_rates': 0.9696476046885799, 'learning_rate': 0.0002159364649399139, 'batch_size': 216, 'step_size': 12, 'gamma': 0.841106300666407}. Best is trial 22 with value: 0.07546427845954895.[0m
[32m[I 2025-01-06 18:54:36,145][0m Trial 49 finished with value: 0.18628324858554 and parameters: {'observation_period_num': 74, 'train_rates': 0.9467717615793839, 'learning_rate': 9.812752185917307e-05, 'batch_size': 62, 'step_size': 8, 'gamma': 0.7966773021316685}. Best is trial 22 with value: 0.07546427845954895.[0m
最適ハイパーパラメータが見つかりました
最適ハイパーパラメータが best_hyperparameters_AAPL_Transformer(nomstl).json に保存されました
Epoch 1/300, Loss: 0.6902 | 0.6878
Epoch 2/300, Loss: 0.5222 | 0.5338
Epoch 3/300, Loss: 0.4202 | 0.5499
Epoch 4/300, Loss: 0.3354 | 0.4093
Epoch 5/300, Loss: 0.2853 | 0.3554
Epoch 6/300, Loss: 0.2500 | 0.3411
Epoch 7/300, Loss: 0.2327 | 0.3045
Epoch 8/300, Loss: 0.2116 | 0.2745
Epoch 9/300, Loss: 0.1991 | 0.2578
Epoch 10/300, Loss: 0.1834 | 0.2371
Epoch 11/300, Loss: 0.1768 | 0.2250
Epoch 12/300, Loss: 0.1721 | 0.2156
Epoch 13/300, Loss: 0.1638 | 0.2040
Epoch 14/300, Loss: 0.1611 | 0.1954
Epoch 15/300, Loss: 0.1566 | 0.1900
Epoch 16/300, Loss: 0.1532 | 0.1835
Epoch 17/300, Loss: 0.1510 | 0.1790
Epoch 18/300, Loss: 0.1488 | 0.1750
Epoch 19/300, Loss: 0.1468 | 0.1686
Epoch 20/300, Loss: 0.1444 | 0.1665
Epoch 21/300, Loss: 0.1428 | 0.1621
Epoch 22/300, Loss: 0.1410 | 0.1596
Epoch 23/300, Loss: 0.1401 | 0.1572
Epoch 24/300, Loss: 0.1389 | 0.1539
Epoch 25/300, Loss: 0.1373 | 0.1516
Epoch 26/300, Loss: 0.1362 | 0.1493
Epoch 27/300, Loss: 0.1355 | 0.1481
Epoch 28/300, Loss: 0.1353 | 0.1466
Epoch 29/300, Loss: 0.1337 | 0.1447
Epoch 30/300, Loss: 0.1335 | 0.1433
Epoch 31/300, Loss: 0.1332 | 0.1420
Epoch 32/300, Loss: 0.1322 | 0.1406
Epoch 33/300, Loss: 0.1317 | 0.1394
Epoch 34/300, Loss: 0.1306 | 0.1387
Epoch 35/300, Loss: 0.1304 | 0.1379
Epoch 36/300, Loss: 0.1304 | 0.1372
Epoch 37/300, Loss: 0.1295 | 0.1361
Epoch 38/300, Loss: 0.1295 | 0.1354
Epoch 39/300, Loss: 0.1296 | 0.1344
Epoch 40/300, Loss: 0.1294 | 0.1340
Epoch 41/300, Loss: 0.1284 | 0.1336
Epoch 42/300, Loss: 0.1277 | 0.1329
Epoch 43/300, Loss: 0.1280 | 0.1325
Epoch 44/300, Loss: 0.1275 | 0.1322
Epoch 45/300, Loss: 0.1274 | 0.1316
Epoch 46/300, Loss: 0.1272 | 0.1313
Epoch 47/300, Loss: 0.1275 | 0.1311
Epoch 48/300, Loss: 0.1270 | 0.1307
Epoch 49/300, Loss: 0.1268 | 0.1301
Epoch 50/300, Loss: 0.1268 | 0.1300
Epoch 51/300, Loss: 0.1265 | 0.1297
Epoch 52/300, Loss: 0.1258 | 0.1295
Epoch 53/300, Loss: 0.1268 | 0.1294
Epoch 54/300, Loss: 0.1265 | 0.1290
Epoch 55/300, Loss: 0.1264 | 0.1287
Epoch 56/300, Loss: 0.1257 | 0.1285
Epoch 57/300, Loss: 0.1267 | 0.1284
Epoch 58/300, Loss: 0.1255 | 0.1283
Epoch 59/300, Loss: 0.1263 | 0.1281
Epoch 60/300, Loss: 0.1249 | 0.1280
Epoch 61/300, Loss: 0.1254 | 0.1279
Epoch 62/300, Loss: 0.1253 | 0.1278
Epoch 63/300, Loss: 0.1248 | 0.1276
Epoch 64/300, Loss: 0.1252 | 0.1276
Epoch 65/300, Loss: 0.1253 | 0.1275
Epoch 66/300, Loss: 0.1254 | 0.1274
Epoch 67/300, Loss: 0.1256 | 0.1274
Epoch 68/300, Loss: 0.1255 | 0.1274
Epoch 69/300, Loss: 0.1256 | 0.1274
Epoch 70/300, Loss: 0.1251 | 0.1273
Epoch 71/300, Loss: 0.1261 | 0.1273
Epoch 72/300, Loss: 0.1254 | 0.1273
Epoch 73/300, Loss: 0.1255 | 0.1272
Epoch 74/300, Loss: 0.1250 | 0.1272
Epoch 75/300, Loss: 0.1252 | 0.1271
Epoch 76/300, Loss: 0.1247 | 0.1271
Epoch 77/300, Loss: 0.1251 | 0.1271
Epoch 78/300, Loss: 0.1251 | 0.1270
Epoch 79/300, Loss: 0.1255 | 0.1270
Epoch 80/300, Loss: 0.1254 | 0.1270
Epoch 81/300, Loss: 0.1253 | 0.1270
Epoch 82/300, Loss: 0.1253 | 0.1270
Epoch 83/300, Loss: 0.1252 | 0.1269
Epoch 84/300, Loss: 0.1244 | 0.1269
Epoch 85/300, Loss: 0.1252 | 0.1269
Epoch 86/300, Loss: 0.1251 | 0.1269
Epoch 87/300, Loss: 0.1251 | 0.1268
Epoch 88/300, Loss: 0.1249 | 0.1268
Epoch 89/300, Loss: 0.1251 | 0.1268
Epoch 90/300, Loss: 0.1250 | 0.1268
Epoch 91/300, Loss: 0.1249 | 0.1268
Epoch 92/300, Loss: 0.1249 | 0.1268
Epoch 93/300, Loss: 0.1249 | 0.1268
Epoch 94/300, Loss: 0.1251 | 0.1268
Epoch 95/300, Loss: 0.1256 | 0.1267
Epoch 96/300, Loss: 0.1252 | 0.1267
Epoch 97/300, Loss: 0.1246 | 0.1267
Epoch 98/300, Loss: 0.1240 | 0.1267
Epoch 99/300, Loss: 0.1252 | 0.1267
Epoch 100/300, Loss: 0.1253 | 0.1267
Epoch 101/300, Loss: 0.1248 | 0.1267
Epoch 102/300, Loss: 0.1250 | 0.1267
Epoch 103/300, Loss: 0.1254 | 0.1267
Epoch 104/300, Loss: 0.1248 | 0.1267
Epoch 105/300, Loss: 0.1249 | 0.1267
Epoch 106/300, Loss: 0.1252 | 0.1267
Epoch 107/300, Loss: 0.1249 | 0.1267
Epoch 108/300, Loss: 0.1255 | 0.1267
Epoch 109/300, Loss: 0.1256 | 0.1267
Epoch 110/300, Loss: 0.1244 | 0.1267
Epoch 111/300, Loss: 0.1250 | 0.1267
Epoch 112/300, Loss: 0.1247 | 0.1267
Epoch 113/300, Loss: 0.1254 | 0.1267
Epoch 114/300, Loss: 0.1252 | 0.1267
Epoch 115/300, Loss: 0.1251 | 0.1267
Epoch 116/300, Loss: 0.1253 | 0.1267
Epoch 117/300, Loss: 0.1242 | 0.1267
Epoch 118/300, Loss: 0.1251 | 0.1267
Epoch 119/300, Loss: 0.1252 | 0.1267
Epoch 120/300, Loss: 0.1246 | 0.1267
Epoch 121/300, Loss: 0.1251 | 0.1267
Epoch 122/300, Loss: 0.1255 | 0.1267
Epoch 123/300, Loss: 0.1253 | 0.1267
Epoch 124/300, Loss: 0.1246 | 0.1267
Epoch 125/300, Loss: 0.1256 | 0.1267
Epoch 126/300, Loss: 0.1256 | 0.1267
Epoch 127/300, Loss: 0.1247 | 0.1267
Epoch 128/300, Loss: 0.1251 | 0.1267
Epoch 129/300, Loss: 0.1249 | 0.1267
Epoch 130/300, Loss: 0.1248 | 0.1267
Epoch 131/300, Loss: 0.1250 | 0.1267
Epoch 132/300, Loss: 0.1250 | 0.1267
Epoch 133/300, Loss: 0.1249 | 0.1267
Epoch 134/300, Loss: 0.1251 | 0.1267
Epoch 135/300, Loss: 0.1256 | 0.1267
Epoch 136/300, Loss: 0.1254 | 0.1267
Epoch 137/300, Loss: 0.1252 | 0.1267
Epoch 138/300, Loss: 0.1251 | 0.1267
Epoch 139/300, Loss: 0.1249 | 0.1267
Epoch 140/300, Loss: 0.1251 | 0.1267
Epoch 141/300, Loss: 0.1246 | 0.1267
Epoch 142/300, Loss: 0.1249 | 0.1267
Epoch 143/300, Loss: 0.1253 | 0.1267
Epoch 144/300, Loss: 0.1256 | 0.1267
Epoch 145/300, Loss: 0.1246 | 0.1267
Epoch 146/300, Loss: 0.1252 | 0.1267
Epoch 147/300, Loss: 0.1249 | 0.1267
Early stopping
Runtime (seconds): 126.66805076599121
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)
MSE: 712.6999967927113
RMSE: 26.696441650390625
MAE: 26.696441650390625
R-squared: nan
[216.31355]
