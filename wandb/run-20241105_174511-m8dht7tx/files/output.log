/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)
  return torch._C._cuda_getDeviceCount() > 0
Using device: cpu
[*********************100%***********************]  1 of 1 completed
Ticker                           AAPL
Date
2012-05-18 00:00:00+00:00   15.996176
2012-05-21 00:00:00+00:00   16.928112
2012-05-22 00:00:00+00:00   16.798122
2012-05-23 00:00:00+00:00   17.207989
2012-05-24 00:00:00+00:00   17.049955
...                               ...
2023-05-24 00:00:00+00:00  170.734604
2023-05-25 00:00:00+00:00  171.877197
2023-05-26 00:00:00+00:00  174.301498
2023-05-30 00:00:00+00:00  176.159470
2023-05-31 00:00:00+00:00  176.109787

[2776 rows x 1 columns]
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[32m[I 2024-11-05 17:45:18,769][0m A new study created in memory with name: no-name-01ac94c0-b4ec-4a84-8c1f-1ec92c17eaa6[0m
/data/student/k2110261/Multi-iTransformer/optunademo.py:109: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-3)
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
[32m[I 2024-11-05 17:47:14,434][0m Trial 0 finished with value: 0.05300695502332279 and parameters: {'learning_rate': 7.500198787885075e-06, 'batch_size': 19, 'step_size': 7, 'gamma': 0.8560909698978978, 'depth': 2, 'dim': 70}. Best is trial 0 with value: 0.05300695502332279.[0m
[33m[W 2024-11-05 17:49:45,496][0m Trial 1 failed with parameters: {'learning_rate': 5.9454377631415025e-06, 'batch_size': 71, 'step_size': 8, 'gamma': 0.7977532765795919, 'depth': 5, 'dim': 197} because of the following error: KeyboardInterrupt().[0m
Traceback (most recent call last):
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/optunademo.py", line 152, in <lambda>
    study_trend.optimize(lambda trial: objective(trial, "trend"), n_trials=100)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/optunademo.py", line 140, in objective
    model, train_loss, valid_loss = train(
                                    ^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/src/train.py", line 31, in train
    output = model(data)
             ^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<@beartype(src.model.iTransformer.forward) at 0x7f9206ee1f80>", line 66, in forward
  File "/data/student/k2110261/Multi-iTransformer/src/model.py", line 188, in forward
    x = attn(x) + x
        ^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/src/model.py", line 67, in forward
    out = self.attend(q, k, v)
          ^^^^^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/attend.py", line 123, in forward
    return self.flash_attn(q, k, v)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/attend.py", line 98, in flash_attn
    out = F.scaled_dot_product_attention(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
[33m[W 2024-11-05 17:49:45,505][0m Trial 1 failed with value None.[0m
Traceback (most recent call last):
  File "/data/student/k2110261/Multi-iTransformer/optunademo.py", line 152, in <module>
    study_trend.optimize(lambda trial: objective(trial, "trend"), n_trials=100)
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/study.py", line 475, in optimize
    _optimize(
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 63, in _optimize
    _optimize_sequential(
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 160, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 248, in _run_trial
    raise func_err
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/optunademo.py", line 152, in <lambda>
    study_trend.optimize(lambda trial: objective(trial, "trend"), n_trials=100)
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/optunademo.py", line 140, in objective
    model, train_loss, valid_loss = train(
                                    ^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/src/train.py", line 31, in train
    output = model(data)
             ^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<@beartype(src.model.iTransformer.forward) at 0x7f9206ee1f80>", line 66, in forward
  File "/data/student/k2110261/Multi-iTransformer/src/model.py", line 188, in forward
    x = attn(x) + x
        ^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/src/model.py", line 67, in forward
    out = self.attend(q, k, v)
          ^^^^^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/attend.py", line 123, in forward
    return self.flash_attn(q, k, v)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/attend.py", line 98, in flash_attn
    out = F.scaled_dot_product_attention(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
