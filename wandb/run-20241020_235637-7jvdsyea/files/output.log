[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
['AAPL'] is =  [ 0.00000000e+00  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  1.22464680e-16 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -2.44929360e-16  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  3.67394040e-16 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -4.89858720e-16  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  6.12323400e-16 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -7.34788079e-16  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  8.57252759e-16 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -9.79717439e-16  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  1.10218212e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -1.22464680e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  4.89982516e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -1.46957616e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01 -1.96067284e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -1.71450552e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  5.38968388e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -1.95943488e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01 -1.47081412e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -2.20436424e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  5.87954260e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -2.44929360e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01 -9.80955401e-16 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -9.79965032e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  6.36940132e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -2.93915232e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01 -4.91096681e-16 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
  3.92134568e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  6.85926004e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -3.42901104e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01 -1.23796127e-18 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -1.07793678e-14  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  7.34911876e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -3.91886976e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  4.88620758e-16 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
  2.94162824e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  7.83897748e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -4.40872848e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  9.78479478e-16 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -1.17590852e-14  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  8.32883620e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -4.89858720e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  1.56791929e-14 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
  1.96191080e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  8.81869492e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -1.95993006e-14  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  1.95819692e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -1.27388026e-14  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01 -4.90230108e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -5.87830464e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  1.66589104e-14 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
  9.82193362e-16  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  9.79841235e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
  7.84269136e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  2.93791436e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -1.37185201e-14  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01 -3.92258364e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -6.85802208e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  1.76386278e-14 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
  2.47592255e-18  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  1.07781298e-14 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -2.15587355e-14  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  3.91763180e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -1.46982375e-14  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01 -2.94286620e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -7.83773951e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  1.86183452e-14 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -9.77241517e-16  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  1.17578472e-14 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
  5.88325648e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  4.89734924e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -1.56779550e-14  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01 -1.96314876e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -8.81745695e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  1.95980627e-14 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -1.95695896e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  1.27375647e-14 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -2.35181704e-14  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  5.87706667e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -1.66576724e-14  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01 -9.83431323e-16 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -9.79717439e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  2.05777801e-14 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -3.13583858e-14  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01 -1.47044273e-14 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
  3.92382160e-15  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  6.85678411e-15 -3.09016994e-01
 -5.87785252e-01 -8.09016994e-01 -9.51056516e-01 -1.00000000e+00
 -9.51056516e-01 -8.09016994e-01 -5.87785252e-01 -3.09016994e-01
 -1.76373898e-14  3.09016994e-01  5.87785252e-01  8.09016994e-01
  9.51056516e-01  1.00000000e+00  9.51056516e-01  8.09016994e-01
  5.87785252e-01  3.09016994e-01  2.84179955e-14 -3.09016994e-01
 -5.87785252e-01]
Dataset created successfully.
/home/raikakoki/.local/lib/python3.10/site-packages/torch/backends/cuda/__init__.py:342: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
Epoch 1/100, (Training, Validation) Trend Loss: 0.7319, 0.1096| Seasonal Loss: 0.7306, 0.0771| Residual Loss: 1.4244, 0.4964
Epoch 2/100, (Training, Validation) Trend Loss: 0.0958, 0.0655| Seasonal Loss: 0.0889, 0.0555| Residual Loss: 0.2534, 0.0837
Epoch 3/100, (Training, Validation) Trend Loss: 0.0391, 0.0330| Seasonal Loss: 0.0373, 0.0278| Residual Loss: 0.0919, 0.0857
Epoch 4/100, (Training, Validation) Trend Loss: 0.0211, 0.0095| Seasonal Loss: 0.0158, 0.0127| Residual Loss: 0.0591, 0.0242
Epoch 5/100, (Training, Validation) Trend Loss: 0.0093, 0.0064| Seasonal Loss: 0.0097, 0.0042| Residual Loss: 0.0199, 0.0184
Epoch 6/100, (Training, Validation) Trend Loss: 0.0043, 0.0032| Seasonal Loss: 0.0041, 0.0033| Residual Loss: 0.0162, 0.0107
Epoch 7/100, (Training, Validation) Trend Loss: 0.0030, 0.0011| Seasonal Loss: 0.0023, 0.0012| Residual Loss: 0.0073, 0.0043
Epoch 8/100, (Training, Validation) Trend Loss: 0.0011, 0.0013| Seasonal Loss: 0.0012, 0.0010| Residual Loss: 0.0040, 0.0036
Epoch 9/100, (Training, Validation) Trend Loss: 0.0008, 0.0004| Seasonal Loss: 0.0006, 0.0005| Residual Loss: 0.0028, 0.0014
Epoch 10/100, (Training, Validation) Trend Loss: 0.0004, 0.0003| Seasonal Loss: 0.0004, 0.0003| Residual Loss: 0.0011, 0.0009
Epoch 11/100, (Training, Validation) Trend Loss: 0.0002, 0.0001| Seasonal Loss: 0.0002, 0.0002| Residual Loss: 0.0009, 0.0009
Epoch 12/100, (Training, Validation) Trend Loss: 0.0001, 0.0001| Seasonal Loss: 0.0001, 0.0001| Residual Loss: 0.0006, 0.0004
Epoch 13/100, (Training, Validation) Trend Loss: 0.0001, 0.0001| Seasonal Loss: 0.0001, 0.0001| Residual Loss: 0.0003, 0.0003
Epoch 14/100, (Training, Validation) Trend Loss: 0.0001, 0.0000| Seasonal Loss: 0.0001, 0.0000| Residual Loss: 0.0003, 0.0003
Epoch 15/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0003, 0.0002
Epoch 16/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0002, 0.0002
Epoch 17/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0002, 0.0002
Epoch 18/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0002, 0.0002
Epoch 19/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0002, 0.0002
Epoch 20/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 21/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 22/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 23/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 24/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 25/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 26/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 27/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 28/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 29/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 30/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 31/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 32/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 33/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 34/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 35/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 36/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 37/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 38/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 39/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 40/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 41/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 42/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 43/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 44/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 45/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 46/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 47/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 48/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 49/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 50/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 51/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 52/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 53/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 54/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 55/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 56/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 57/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 58/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 59/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 60/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 61/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 62/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 63/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 64/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 65/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 66/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 67/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 68/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 69/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 70/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 71/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 72/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 73/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 74/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 75/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 76/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 77/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0001, 0.0001
Epoch 78/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0001
Epoch 79/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0001
Epoch 80/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0001
Epoch 81/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0001
Epoch 82/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0000
Epoch 83/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0000
Epoch 84/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0000
Epoch 85/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0000
Epoch 86/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0000
Epoch 87/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0000
Epoch 88/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0000
Epoch 89/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0000
Epoch 90/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0000
Epoch 91/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0000
Epoch 92/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0000
Epoch 93/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0000
Epoch 94/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0000
Epoch 95/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0000
Epoch 96/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0000
Epoch 97/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0000
Epoch 98/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0000
Epoch 99/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0000
Epoch 100/100, (Training, Validation) Trend Loss: 0.0000, 0.0000| Seasonal Loss: 0.0000, 0.0000| Residual Loss: 0.0000, 0.0000
/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/STLdemo.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  predicted_trend_aapl = predicted_trend[1][0, :, 0].cpu().numpy().flatten() * std_list_trend[0] + mean_list_trend[0]
/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/STLdemo.py:247: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  predicted_seasonal_aapl = predicted_seasonal[1][0, :, 0].cpu().numpy().flatten() * std_list_seasonal[0] + mean_list_seasonal[0]
/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/STLdemo.py:248: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  predicted_resid_aapl = predicted_resid[1][0, :, 0].cpu().numpy().flatten() * std_list_resid[0] + mean_list_resid[0]
[0.00044293]
[0.00184369]
[-0.00014026]
[0.00214635]
actual_stock_price: [178.05718994 176.6761322  179.40844727 179.79592896 182.60772705
 182.1308136  182.76670837 184.81344604 183.73045349 183.81985474]
add_predicted_stock_price: [1.78057190e+02 1.76676132e+02 1.79408447e+02 1.79795929e+02
 1.82607727e+02 1.82130814e+02 1.82766708e+02 1.84813446e+02
 1.83730453e+02 2.14635003e-03]
/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/STLdemo.py:294: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown
  plt.show()
