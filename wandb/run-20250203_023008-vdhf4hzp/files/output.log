ÊúÄÈÅ©ÂåñÂØæË±°: trend
[32m[I 2025-02-03 02:30:10,748][0m A new study created in memory with name: no-name-641a1ca2-913f-470e-92f3-51cb7fdfd37a[0m
Non-A100 GPU detected, using math or mem efficient attention if input tensor is on cuda
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
[33m[W 2025-02-03 02:30:12,075][0m Trial 0 failed with parameters: {'observation_period_num': 10, 'train_rates': 0.6583467721983292, 'learning_rate': 0.00032814547802820476, 'batch_size': 204, 'step_size': 10, 'gamma': 0.7965007150994566} because of the following error: ZeroDivisionError('float division by zero').[0m
Traceback (most recent call last):
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/roop_optuna.py", line 554, in <lambda>
    study.optimize(lambda trial: objective(trial, component, depth, dim), n_trials=50) #check
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/roop_optuna.py", line 116, in objective
    model, _, valid_loss = train(
                           ^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/src/train.py", line 49, in train
    total_loss_train = total_loss_train / len(train_data)
                       ~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~
ZeroDivisionError: float division by zero
[33m[W 2025-02-03 02:30:12,078][0m Trial 0 failed with value None.[0m
Traceback (most recent call last):
  File "/data/student/k2110261/Multi-iTransformer/roop_optuna.py", line 554, in <module>
    study.optimize(lambda trial: objective(trial, component, depth, dim), n_trials=50) #check
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/study.py", line 475, in optimize
    _optimize(
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 63, in _optimize
    _optimize_sequential(
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 160, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 248, in _run_trial
    raise func_err
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/roop_optuna.py", line 554, in <lambda>
    study.optimize(lambda trial: objective(trial, component, depth, dim), n_trials=50) #check
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/roop_optuna.py", line 116, in objective
    model, _, valid_loss = train(
                           ^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/src/train.py", line 49, in train
    total_loss_train = total_loss_train / len(train_data)
                       ~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~
ZeroDivisionError: float division by zero
