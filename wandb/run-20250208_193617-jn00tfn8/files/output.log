[32m[I 2025-02-08 19:36:23,227][0m A new study created in memory with name: no-name-5b9ce0e7-2a23-4e19-b35e-71eaffcc9e79[0m
[32m[I 2025-02-08 19:36:48,630][0m Trial 0 finished with value: 0.5276584216510601 and parameters: {'observation_period_num': 232, 'train_rates': 0.6148863875219845, 'learning_rate': 1.6305915159720205e-05, 'batch_size': 186, 'step_size': 6, 'gamma': 0.8612912346130089}. Best is trial 0 with value: 0.5276584216510601.[0m
[32m[I 2025-02-08 19:37:18,116][0m Trial 1 finished with value: 0.18074444122165798 and parameters: {'observation_period_num': 65, 'train_rates': 0.715919701949242, 'learning_rate': 0.0005243230171833504, 'batch_size': 184, 'step_size': 12, 'gamma': 0.754380833587991}. Best is trial 1 with value: 0.18074444122165798.[0m
[32m[I 2025-02-08 19:40:35,379][0m Trial 2 finished with value: 0.059178040789308745 and parameters: {'observation_period_num': 52, 'train_rates': 0.8513301400983164, 'learning_rate': 0.0002059473872448373, 'batch_size': 28, 'step_size': 1, 'gamma': 0.8867487175850619}. Best is trial 2 with value: 0.059178040789308745.[0m
[32m[I 2025-02-08 19:41:00,785][0m Trial 3 finished with value: 0.2506584048837046 and parameters: {'observation_period_num': 247, 'train_rates': 0.8853429498551146, 'learning_rate': 3.9104992632715326e-05, 'batch_size': 226, 'step_size': 10, 'gamma': 0.9791708304574822}. Best is trial 2 with value: 0.059178040789308745.[0m
[32m[I 2025-02-08 19:44:13,676][0m Trial 4 finished with value: 0.19444713383825257 and parameters: {'observation_period_num': 60, 'train_rates': 0.7692985352348527, 'learning_rate': 1.6320136906232403e-05, 'batch_size': 26, 'step_size': 5, 'gamma': 0.9864724779052282}. Best is trial 2 with value: 0.059178040789308745.[0m
[32m[I 2025-02-08 19:44:40,730][0m Trial 5 finished with value: 1.3299109472567776 and parameters: {'observation_period_num': 124, 'train_rates': 0.8270974513855255, 'learning_rate': 2.096285365534131e-06, 'batch_size': 223, 'step_size': 9, 'gamma': 0.7835574603005219}. Best is trial 2 with value: 0.059178040789308745.[0m
[32m[I 2025-02-08 19:45:37,655][0m Trial 6 finished with value: 0.2667635016295375 and parameters: {'observation_period_num': 179, 'train_rates': 0.8785506213515668, 'learning_rate': 2.4391448877165914e-05, 'batch_size': 97, 'step_size': 12, 'gamma': 0.800005123986155}. Best is trial 2 with value: 0.059178040789308745.[0m
[32m[I 2025-02-08 19:46:06,040][0m Trial 7 finished with value: 0.6238108772865321 and parameters: {'observation_period_num': 50, 'train_rates': 0.7971055758646546, 'learning_rate': 2.41888429855768e-06, 'batch_size': 212, 'step_size': 12, 'gamma': 0.8377597055475126}. Best is trial 2 with value: 0.059178040789308745.[0m
[32m[I 2025-02-08 19:46:40,246][0m Trial 8 finished with value: 0.34502900888522464 and parameters: {'observation_period_num': 217, 'train_rates': 0.7930476926417613, 'learning_rate': 0.0005955528652758116, 'batch_size': 150, 'step_size': 8, 'gamma': 0.9727032895385046}. Best is trial 2 with value: 0.059178040789308745.[0m
[32m[I 2025-02-08 19:47:11,215][0m Trial 9 finished with value: 0.9600831598974764 and parameters: {'observation_period_num': 179, 'train_rates': 0.6033094745715677, 'learning_rate': 9.091155299741689e-05, 'batch_size': 147, 'step_size': 8, 'gamma': 0.9294785777063869}. Best is trial 2 with value: 0.059178040789308745.[0m
[32m[I 2025-02-08 19:53:01,146][0m Trial 10 finished with value: 0.0479038998049188 and parameters: {'observation_period_num': 22, 'train_rates': 0.9741546909661172, 'learning_rate': 0.00016394333729774656, 'batch_size': 17, 'step_size': 1, 'gamma': 0.9113727936592517}. Best is trial 10 with value: 0.0479038998049188.[0m
[32m[I 2025-02-08 19:58:39,225][0m Trial 11 finished with value: 0.03800123941994483 and parameters: {'observation_period_num': 10, 'train_rates': 0.9896548161414012, 'learning_rate': 0.0001812158132749674, 'batch_size': 18, 'step_size': 1, 'gamma': 0.9050597100026588}. Best is trial 11 with value: 0.03800123941994483.[0m
[32m[I 2025-02-08 20:00:07,186][0m Trial 12 finished with value: 0.05014524236321449 and parameters: {'observation_period_num': 5, 'train_rates': 0.9882320943917727, 'learning_rate': 0.00015645562786975928, 'batch_size': 72, 'step_size': 1, 'gamma': 0.9089303851243334}. Best is trial 11 with value: 0.03800123941994483.[0m
[32m[I 2025-02-08 20:01:37,025][0m Trial 13 finished with value: 0.03607301414012909 and parameters: {'observation_period_num': 6, 'train_rates': 0.989771327500639, 'learning_rate': 7.036362322261292e-05, 'batch_size': 70, 'step_size': 3, 'gamma': 0.9377310808820095}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:02:58,245][0m Trial 14 finished with value: 0.11171646695584059 and parameters: {'observation_period_num': 96, 'train_rates': 0.9340862370529487, 'learning_rate': 5.578371569695359e-05, 'batch_size': 72, 'step_size': 4, 'gamma': 0.9402321548815219}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:04:36,180][0m Trial 15 finished with value: 0.12994478663928072 and parameters: {'observation_period_num': 5, 'train_rates': 0.9291911055243782, 'learning_rate': 8.073591087425891e-06, 'batch_size': 63, 'step_size': 3, 'gamma': 0.8614392057097287}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:05:30,880][0m Trial 16 finished with value: 0.1680515096946196 and parameters: {'observation_period_num': 107, 'train_rates': 0.9354247903113306, 'learning_rate': 0.0009192565598296219, 'batch_size': 111, 'step_size': 3, 'gamma': 0.9431420335077612}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:07:30,990][0m Trial 17 finished with value: 0.2646087110042572 and parameters: {'observation_period_num': 34, 'train_rates': 0.9876764032863669, 'learning_rate': 6.342528675207626e-06, 'batch_size': 51, 'step_size': 6, 'gamma': 0.8890006846476208}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:08:16,475][0m Trial 18 finished with value: 0.19449439376609065 and parameters: {'observation_period_num': 87, 'train_rates': 0.6888819699366122, 'learning_rate': 0.00034421907327665, 'batch_size': 109, 'step_size': 14, 'gamma': 0.9556180237749892}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:10:46,771][0m Trial 19 finished with value: 0.15219874017441226 and parameters: {'observation_period_num': 151, 'train_rates': 0.9113522027507521, 'learning_rate': 7.811087322155134e-05, 'batch_size': 37, 'step_size': 3, 'gamma': 0.8387606286148126}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:11:13,761][0m Trial 20 finished with value: 0.09284025430679321 and parameters: {'observation_period_num': 30, 'train_rates': 0.9493630438356259, 'learning_rate': 0.00029237630057821055, 'batch_size': 254, 'step_size': 2, 'gamma': 0.9162830099668166}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:16:45,797][0m Trial 21 finished with value: 0.05120694185809597 and parameters: {'observation_period_num': 25, 'train_rates': 0.9691760457521019, 'learning_rate': 0.0001321625328922244, 'batch_size': 18, 'step_size': 1, 'gamma': 0.9053363322175821}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:18:54,283][0m Trial 22 finished with value: 0.055858254808732764 and parameters: {'observation_period_num': 18, 'train_rates': 0.8938862055618256, 'learning_rate': 0.00010439672110884563, 'batch_size': 45, 'step_size': 2, 'gamma': 0.8863957960759034}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:24:58,298][0m Trial 23 finished with value: 0.097913886819567 and parameters: {'observation_period_num': 77, 'train_rates': 0.9618587467189409, 'learning_rate': 5.474436210463655e-05, 'batch_size': 16, 'step_size': 4, 'gamma': 0.9574255131533389}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:26:16,493][0m Trial 24 finished with value: 0.06017601117491722 and parameters: {'observation_period_num': 36, 'train_rates': 0.9844675304331084, 'learning_rate': 0.00019949339056136506, 'batch_size': 81, 'step_size': 6, 'gamma': 0.9262408964370389}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:28:04,202][0m Trial 25 finished with value: 0.04965105054041022 and parameters: {'observation_period_num': 6, 'train_rates': 0.8540176510415278, 'learning_rate': 0.0003257265425695937, 'batch_size': 52, 'step_size': 1, 'gamma': 0.902253981452273}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:29:09,116][0m Trial 26 finished with value: 0.09058390543559346 and parameters: {'observation_period_num': 42, 'train_rates': 0.9202708387291723, 'learning_rate': 3.290531884577813e-05, 'batch_size': 91, 'step_size': 2, 'gamma': 0.9545519725662326}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:29:58,586][0m Trial 27 finished with value: 0.1668234020471573 and parameters: {'observation_period_num': 76, 'train_rates': 0.9586299617024949, 'learning_rate': 6.471266373741991e-05, 'batch_size': 126, 'step_size': 4, 'gamma': 0.872097653243432}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:32:23,544][0m Trial 28 finished with value: 0.036916973117780506 and parameters: {'observation_period_num': 16, 'train_rates': 0.9101250733689716, 'learning_rate': 0.00013337950009589732, 'batch_size': 40, 'step_size': 5, 'gamma': 0.8454074656434025}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:33:44,128][0m Trial 29 finished with value: 0.3525266940308254 and parameters: {'observation_period_num': 107, 'train_rates': 0.6638828484750056, 'learning_rate': 1.936950621504495e-05, 'batch_size': 58, 'step_size': 6, 'gamma': 0.8351898713105729}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:36:05,175][0m Trial 30 finished with value: 0.27614159964852864 and parameters: {'observation_period_num': 138, 'train_rates': 0.9059600217868725, 'learning_rate': 1.0340430984545264e-05, 'batch_size': 39, 'step_size': 7, 'gamma': 0.8183286885270665}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:38:59,043][0m Trial 31 finished with value: 0.04098780999581019 and parameters: {'observation_period_num': 19, 'train_rates': 0.9547915959445005, 'learning_rate': 0.0001406077291466424, 'batch_size': 34, 'step_size': 5, 'gamma': 0.8543700112836232}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:41:37,200][0m Trial 32 finished with value: 0.0418782836812384 and parameters: {'observation_period_num': 18, 'train_rates': 0.9488153906227635, 'learning_rate': 0.0002580763263575582, 'batch_size': 38, 'step_size': 5, 'gamma': 0.8538518441797057}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:43:01,522][0m Trial 33 finished with value: 0.13828045246249096 and parameters: {'observation_period_num': 65, 'train_rates': 0.862716738456544, 'learning_rate': 0.0005297532795467032, 'batch_size': 66, 'step_size': 5, 'gamma': 0.8723536575444789}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:43:39,911][0m Trial 34 finished with value: 0.38293543457984924 and parameters: {'observation_period_num': 46, 'train_rates': 0.9501273956765516, 'learning_rate': 4.433548418247352e-05, 'batch_size': 169, 'step_size': 3, 'gamma': 0.8125211651470937}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:46:20,084][0m Trial 35 finished with value: 0.15769239640861477 and parameters: {'observation_period_num': 19, 'train_rates': 0.7427819756008298, 'learning_rate': 0.00011092893306257254, 'batch_size': 31, 'step_size': 7, 'gamma': 0.8477505134961371}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:47:23,955][0m Trial 36 finished with value: 0.06521241625051687 and parameters: {'observation_period_num': 60, 'train_rates': 0.8283487180348166, 'learning_rate': 0.0003996203204216621, 'batch_size': 85, 'step_size': 4, 'gamma': 0.7584416610009372}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:50:41,950][0m Trial 37 finished with value: 0.0656995434085084 and parameters: {'observation_period_num': 48, 'train_rates': 0.8788651941457555, 'learning_rate': 0.0002162958871046097, 'batch_size': 28, 'step_size': 5, 'gamma': 0.8861097412868555}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:52:35,295][0m Trial 38 finished with value: 0.06810717307962477 and parameters: {'observation_period_num': 36, 'train_rates': 0.8975156441884559, 'learning_rate': 2.929798241648339e-05, 'batch_size': 51, 'step_size': 10, 'gamma': 0.7887711298355944}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:53:33,436][0m Trial 39 finished with value: 0.051548162377194354 and parameters: {'observation_period_num': 13, 'train_rates': 0.9238539873397502, 'learning_rate': 0.0007879089557345954, 'batch_size': 106, 'step_size': 2, 'gamma': 0.8282806806795263}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:56:47,832][0m Trial 40 finished with value: 0.25949767523485684 and parameters: {'observation_period_num': 216, 'train_rates': 0.9673114253481032, 'learning_rate': 7.77600278393753e-05, 'batch_size': 29, 'step_size': 7, 'gamma': 0.8960834922503813}. Best is trial 13 with value: 0.03607301414012909.[0m
[32m[I 2025-02-08 20:59:24,986][0m Trial 41 finished with value: 0.03585138609011968 and parameters: {'observation_period_num': 19, 'train_rates': 0.9500144740042646, 'learning_rate': 0.00022399451274385384, 'batch_size': 38, 'step_size': 5, 'gamma': 0.8515522200594863}. Best is trial 41 with value: 0.03585138609011968.[0m
[32m[I 2025-02-08 21:01:52,305][0m Trial 42 finished with value: 0.03425724431872368 and parameters: {'observation_period_num': 28, 'train_rates': 0.9899834044110151, 'learning_rate': 0.00013983804763647857, 'batch_size': 42, 'step_size': 5, 'gamma': 0.862530132637529}. Best is trial 42 with value: 0.03425724431872368.[0m
[32m[I 2025-02-08 21:03:13,106][0m Trial 43 finished with value: 0.07247207581025103 and parameters: {'observation_period_num': 55, 'train_rates': 0.9377685155987117, 'learning_rate': 0.00018904256866600046, 'batch_size': 74, 'step_size': 9, 'gamma': 0.8743187724376459}. Best is trial 42 with value: 0.03425724431872368.[0m
[32m[I 2025-02-08 21:05:28,107][0m Trial 44 finished with value: 0.061239873078909324 and parameters: {'observation_period_num': 29, 'train_rates': 0.9844459246467498, 'learning_rate': 0.0004422672393072684, 'batch_size': 45, 'step_size': 3, 'gamma': 0.8607401922851107}. Best is trial 42 with value: 0.03425724431872368.[0m
[32m[I 2025-02-08 21:07:09,517][0m Trial 45 finished with value: 0.03848678295034915 and parameters: {'observation_period_num': 9, 'train_rates': 0.9732729357645571, 'learning_rate': 0.00011230477218759918, 'batch_size': 61, 'step_size': 6, 'gamma': 0.9261384575193372}. Best is trial 42 with value: 0.03425724431872368.[0m
[32m[I 2025-02-08 21:12:45,356][0m Trial 46 finished with value: 0.10827036088939464 and parameters: {'observation_period_num': 72, 'train_rates': 0.9394542681895691, 'learning_rate': 0.00024933429994633007, 'batch_size': 17, 'step_size': 4, 'gamma': 0.8173757303591287}. Best is trial 42 with value: 0.03425724431872368.[0m
[32m[I 2025-02-08 21:14:42,802][0m Trial 47 finished with value: 0.7521497828960418 and parameters: {'observation_period_num': 40, 'train_rates': 0.831382229880596, 'learning_rate': 1.0561217683483731e-06, 'batch_size': 46, 'step_size': 2, 'gamma': 0.8445524217225131}. Best is trial 42 with value: 0.03425724431872368.[0m
[32m[I 2025-02-08 21:16:30,601][0m Trial 48 finished with value: 0.08316610008478165 and parameters: {'observation_period_num': 26, 'train_rates': 0.9863843451024417, 'learning_rate': 4.610271686727393e-05, 'batch_size': 57, 'step_size': 5, 'gamma': 0.8639776736203738}. Best is trial 42 with value: 0.03425724431872368.[0m
[32m[I 2025-02-08 21:17:11,683][0m Trial 49 finished with value: 0.265069556998768 and parameters: {'observation_period_num': 169, 'train_rates': 0.7888290628467771, 'learning_rate': 8.031593460616959e-05, 'batch_size': 131, 'step_size': 15, 'gamma': 0.9771611201553788}. Best is trial 42 with value: 0.03425724431872368.[0m
最適ハイパーパラメータが見つかりました
最適なハイパーパラメータが best_hyperparameters_GOOG_iTransformer_noMSTL.json に保存されました
Epoch 1/300, Loss: 0.2193 | 0.1448
Epoch 2/300, Loss: 0.1521 | 0.1366
Epoch 3/300, Loss: 0.1275 | 0.1073
Epoch 4/300, Loss: 0.1158 | 0.0930
Epoch 5/300, Loss: 0.1076 | 0.0748
Epoch 6/300, Loss: 0.1043 | 0.0676
Epoch 7/300, Loss: 0.1024 | 0.0831
Epoch 8/300, Loss: 0.1006 | 0.0606
Epoch 9/300, Loss: 0.0932 | 0.0569
Epoch 10/300, Loss: 0.0907 | 0.0510
Epoch 11/300, Loss: 0.0887 | 0.0527
Epoch 12/300, Loss: 0.0874 | 0.0443
Epoch 13/300, Loss: 0.0848 | 0.0429
Epoch 14/300, Loss: 0.0842 | 0.0406
Epoch 15/300, Loss: 0.0833 | 0.0384
Epoch 16/300, Loss: 0.0824 | 0.0400
Epoch 17/300, Loss: 0.0829 | 0.0405
Epoch 18/300, Loss: 0.0841 | 0.0410
Epoch 19/300, Loss: 0.0863 | 0.0725
Epoch 20/300, Loss: 0.0870 | 0.0692
Epoch 21/300, Loss: 0.0835 | 0.0533
Epoch 22/300, Loss: 0.0816 | 0.0481
Epoch 23/300, Loss: 0.0797 | 0.0450
Epoch 24/300, Loss: 0.0782 | 0.0413
Epoch 25/300, Loss: 0.0770 | 0.0404
Epoch 26/300, Loss: 0.0759 | 0.0399
Epoch 27/300, Loss: 0.0750 | 0.0398
Epoch 28/300, Loss: 0.0741 | 0.0397
Epoch 29/300, Loss: 0.0732 | 0.0397
Epoch 30/300, Loss: 0.0726 | 0.0395
Epoch 31/300, Loss: 0.0720 | 0.0387
Epoch 32/300, Loss: 0.0717 | 0.0384
Epoch 33/300, Loss: 0.0714 | 0.0382
Epoch 34/300, Loss: 0.0712 | 0.0375
Epoch 35/300, Loss: 0.0711 | 0.0372
Epoch 36/300, Loss: 0.0708 | 0.0368
Epoch 37/300, Loss: 0.0707 | 0.0366
Epoch 38/300, Loss: 0.0704 | 0.0364
Epoch 39/300, Loss: 0.0701 | 0.0361
Epoch 40/300, Loss: 0.0698 | 0.0359
Epoch 41/300, Loss: 0.0696 | 0.0357
Epoch 42/300, Loss: 0.0694 | 0.0355
Epoch 43/300, Loss: 0.0692 | 0.0353
Epoch 44/300, Loss: 0.0690 | 0.0353
Epoch 45/300, Loss: 0.0688 | 0.0351
Epoch 46/300, Loss: 0.0687 | 0.0351
Epoch 47/300, Loss: 0.0686 | 0.0350
Epoch 48/300, Loss: 0.0685 | 0.0349
Epoch 49/300, Loss: 0.0683 | 0.0348
Epoch 50/300, Loss: 0.0682 | 0.0348
Epoch 51/300, Loss: 0.0681 | 0.0346
Epoch 52/300, Loss: 0.0680 | 0.0345
Epoch 53/300, Loss: 0.0679 | 0.0345
Epoch 54/300, Loss: 0.0678 | 0.0343
Epoch 55/300, Loss: 0.0677 | 0.0342
Epoch 56/300, Loss: 0.0676 | 0.0341
Epoch 57/300, Loss: 0.0675 | 0.0340
Epoch 58/300, Loss: 0.0674 | 0.0339
Epoch 59/300, Loss: 0.0673 | 0.0338
Epoch 60/300, Loss: 0.0673 | 0.0337
Epoch 61/300, Loss: 0.0672 | 0.0338
Epoch 62/300, Loss: 0.0671 | 0.0337
Epoch 63/300, Loss: 0.0671 | 0.0337
Epoch 64/300, Loss: 0.0670 | 0.0339
Epoch 65/300, Loss: 0.0670 | 0.0339
Epoch 66/300, Loss: 0.0669 | 0.0341
Epoch 67/300, Loss: 0.0669 | 0.0341
Epoch 68/300, Loss: 0.0668 | 0.0340
Epoch 69/300, Loss: 0.0668 | 0.0342
Epoch 70/300, Loss: 0.0668 | 0.0341
Epoch 71/300, Loss: 0.0667 | 0.0342
Epoch 72/300, Loss: 0.0667 | 0.0341
Epoch 73/300, Loss: 0.0667 | 0.0341
Epoch 74/300, Loss: 0.0666 | 0.0341
Epoch 75/300, Loss: 0.0666 | 0.0341
Epoch 76/300, Loss: 0.0666 | 0.0341
Epoch 77/300, Loss: 0.0666 | 0.0341
Epoch 78/300, Loss: 0.0665 | 0.0341
Epoch 79/300, Loss: 0.0665 | 0.0341
Epoch 80/300, Loss: 0.0665 | 0.0341
Epoch 81/300, Loss: 0.0665 | 0.0341
Epoch 82/300, Loss: 0.0664 | 0.0341
Epoch 83/300, Loss: 0.0664 | 0.0341
Epoch 84/300, Loss: 0.0664 | 0.0341
Epoch 85/300, Loss: 0.0664 | 0.0341
Epoch 86/300, Loss: 0.0664 | 0.0341
Epoch 87/300, Loss: 0.0664 | 0.0340
Epoch 88/300, Loss: 0.0664 | 0.0340
Epoch 89/300, Loss: 0.0663 | 0.0340
Epoch 90/300, Loss: 0.0663 | 0.0340
Epoch 91/300, Loss: 0.0663 | 0.0340
Epoch 92/300, Loss: 0.0663 | 0.0340
Epoch 93/300, Loss: 0.0663 | 0.0340
Epoch 94/300, Loss: 0.0663 | 0.0340
Epoch 95/300, Loss: 0.0663 | 0.0340
Epoch 96/300, Loss: 0.0663 | 0.0340
Epoch 97/300, Loss: 0.0663 | 0.0340
Epoch 98/300, Loss: 0.0663 | 0.0340
Epoch 99/300, Loss: 0.0662 | 0.0340
Epoch 100/300, Loss: 0.0662 | 0.0340
Epoch 101/300, Loss: 0.0662 | 0.0340
Epoch 102/300, Loss: 0.0662 | 0.0340
Epoch 103/300, Loss: 0.0662 | 0.0340
Epoch 104/300, Loss: 0.0662 | 0.0340
Epoch 105/300, Loss: 0.0662 | 0.0340
Epoch 106/300, Loss: 0.0662 | 0.0340
Epoch 107/300, Loss: 0.0662 | 0.0340
Epoch 108/300, Loss: 0.0662 | 0.0340
Epoch 109/300, Loss: 0.0662 | 0.0340
Epoch 110/300, Loss: 0.0662 | 0.0340
Epoch 111/300, Loss: 0.0662 | 0.0340
Epoch 112/300, Loss: 0.0662 | 0.0340
Epoch 113/300, Loss: 0.0662 | 0.0340
Epoch 114/300, Loss: 0.0662 | 0.0340
Epoch 115/300, Loss: 0.0662 | 0.0340
Epoch 116/300, Loss: 0.0662 | 0.0340
Epoch 117/300, Loss: 0.0662 | 0.0340
Epoch 118/300, Loss: 0.0662 | 0.0340
Epoch 119/300, Loss: 0.0662 | 0.0340
Epoch 120/300, Loss: 0.0662 | 0.0340
Epoch 121/300, Loss: 0.0662 | 0.0340
Epoch 122/300, Loss: 0.0662 | 0.0340
Epoch 123/300, Loss: 0.0662 | 0.0340
Epoch 124/300, Loss: 0.0661 | 0.0340
Epoch 125/300, Loss: 0.0661 | 0.0340
Epoch 126/300, Loss: 0.0661 | 0.0340
Epoch 127/300, Loss: 0.0661 | 0.0340
Epoch 128/300, Loss: 0.0661 | 0.0340
Epoch 129/300, Loss: 0.0661 | 0.0340
Epoch 130/300, Loss: 0.0661 | 0.0340
Epoch 131/300, Loss: 0.0661 | 0.0340
Epoch 132/300, Loss: 0.0661 | 0.0340
Epoch 133/300, Loss: 0.0661 | 0.0340
Epoch 134/300, Loss: 0.0661 | 0.0340
Epoch 135/300, Loss: 0.0661 | 0.0340
Epoch 136/300, Loss: 0.0661 | 0.0340
Epoch 137/300, Loss: 0.0661 | 0.0340
Epoch 138/300, Loss: 0.0661 | 0.0340
Epoch 139/300, Loss: 0.0661 | 0.0340
Epoch 140/300, Loss: 0.0661 | 0.0340
Epoch 141/300, Loss: 0.0661 | 0.0340
Epoch 142/300, Loss: 0.0661 | 0.0340
Epoch 143/300, Loss: 0.0661 | 0.0340
Epoch 144/300, Loss: 0.0661 | 0.0340
Epoch 145/300, Loss: 0.0661 | 0.0340
Epoch 146/300, Loss: 0.0661 | 0.0340
Epoch 147/300, Loss: 0.0661 | 0.0340
Epoch 148/300, Loss: 0.0661 | 0.0340
Epoch 149/300, Loss: 0.0661 | 0.0340
Epoch 150/300, Loss: 0.0661 | 0.0340
Epoch 151/300, Loss: 0.0661 | 0.0340
Epoch 152/300, Loss: 0.0661 | 0.0340
Epoch 153/300, Loss: 0.0661 | 0.0340
Epoch 154/300, Loss: 0.0661 | 0.0340
Epoch 155/300, Loss: 0.0661 | 0.0340
Epoch 156/300, Loss: 0.0661 | 0.0340
Epoch 157/300, Loss: 0.0661 | 0.0340
Epoch 158/300, Loss: 0.0661 | 0.0340
Epoch 159/300, Loss: 0.0661 | 0.0340
Epoch 160/300, Loss: 0.0661 | 0.0340
Epoch 161/300, Loss: 0.0661 | 0.0340
Epoch 162/300, Loss: 0.0661 | 0.0340
Epoch 163/300, Loss: 0.0661 | 0.0340
Epoch 164/300, Loss: 0.0661 | 0.0340
Epoch 165/300, Loss: 0.0661 | 0.0340
Epoch 166/300, Loss: 0.0661 | 0.0340
Epoch 167/300, Loss: 0.0661 | 0.0340
Epoch 168/300, Loss: 0.0661 | 0.0340
Epoch 169/300, Loss: 0.0661 | 0.0340
Epoch 170/300, Loss: 0.0661 | 0.0340
Epoch 171/300, Loss: 0.0661 | 0.0340
Epoch 172/300, Loss: 0.0661 | 0.0340
Epoch 173/300, Loss: 0.0661 | 0.0340
Epoch 174/300, Loss: 0.0661 | 0.0340
Epoch 175/300, Loss: 0.0661 | 0.0340
Epoch 176/300, Loss: 0.0661 | 0.0340
Epoch 177/300, Loss: 0.0661 | 0.0340
Epoch 178/300, Loss: 0.0661 | 0.0340
Epoch 179/300, Loss: 0.0661 | 0.0340
Epoch 180/300, Loss: 0.0661 | 0.0340
Epoch 181/300, Loss: 0.0661 | 0.0340
Epoch 182/300, Loss: 0.0661 | 0.0340
Epoch 183/300, Loss: 0.0661 | 0.0340
Epoch 184/300, Loss: 0.0661 | 0.0340
Epoch 185/300, Loss: 0.0661 | 0.0340
Epoch 186/300, Loss: 0.0661 | 0.0340
Epoch 187/300, Loss: 0.0661 | 0.0340
Epoch 188/300, Loss: 0.0661 | 0.0340
Epoch 189/300, Loss: 0.0661 | 0.0340
Epoch 190/300, Loss: 0.0661 | 0.0340
Epoch 191/300, Loss: 0.0661 | 0.0340
Epoch 192/300, Loss: 0.0661 | 0.0340
Epoch 193/300, Loss: 0.0661 | 0.0340
Epoch 194/300, Loss: 0.0661 | 0.0340
Epoch 195/300, Loss: 0.0661 | 0.0340
Epoch 196/300, Loss: 0.0661 | 0.0340
Epoch 197/300, Loss: 0.0661 | 0.0340
Epoch 198/300, Loss: 0.0661 | 0.0340
Epoch 199/300, Loss: 0.0661 | 0.0340
Epoch 200/300, Loss: 0.0661 | 0.0340
Epoch 201/300, Loss: 0.0661 | 0.0340
Epoch 202/300, Loss: 0.0661 | 0.0340
Epoch 203/300, Loss: 0.0661 | 0.0340
Epoch 204/300, Loss: 0.0661 | 0.0340
Epoch 205/300, Loss: 0.0661 | 0.0340
Early stopping
Runtime (seconds): 303.3403103351593
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)
MSE: 620.6124332549516
RMSE: 24.912094116210938
MAE: 24.912094116210938
R-squared: nan
[212.0521]
