[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
/home/raikakoki/.local/lib/python3.10/site-packages/torch/backends/cuda/__init__.py:342: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
Dataset created successfully.
Epoch 1/100, Training Loss: 0.5999, Validation Loss: 0.2252
Epoch 2/100, Training Loss: 0.2254, Validation Loss: 0.2344
Epoch 3/100, Training Loss: 0.1677, Validation Loss: 0.2068
Epoch 4/100, Training Loss: 0.1455, Validation Loss: 0.1589
Epoch 5/100, Training Loss: 0.1065, Validation Loss: 0.1570
Epoch 6/100, Training Loss: 0.0933, Validation Loss: 0.1197
Epoch 7/100, Training Loss: 0.0723, Validation Loss: 0.1015
Epoch 8/100, Training Loss: 0.0590, Validation Loss: 0.1050
Epoch 9/100, Training Loss: 0.0608, Validation Loss: 0.0595
Epoch 10/100, Training Loss: 0.0492, Validation Loss: 0.0991
Epoch 11/100, Training Loss: 0.0677, Validation Loss: 0.0536
Epoch 12/100, Training Loss: 0.0514, Validation Loss: 0.1216
Epoch 13/100, Training Loss: 0.0713, Validation Loss: 0.0671
Epoch 14/100, Training Loss: 0.0626, Validation Loss: 0.1711
Epoch 15/100, Training Loss: 0.0815, Validation Loss: 0.0858
Epoch 16/100, Training Loss: 0.0677, Validation Loss: 0.1477
Epoch 17/100, Training Loss: 0.0594, Validation Loss: 0.0606
Epoch 18/100, Training Loss: 0.0493, Validation Loss: 0.0926
Epoch 19/100, Training Loss: 0.0392, Validation Loss: 0.0448
Epoch 20/100, Training Loss: 0.0363, Validation Loss: 0.0666
Epoch 21/100, Training Loss: 0.0318, Validation Loss: 0.0395
Epoch 22/100, Training Loss: 0.0307, Validation Loss: 0.0554
Epoch 23/100, Training Loss: 0.0276, Validation Loss: 0.0361
Epoch 24/100, Training Loss: 0.0267, Validation Loss: 0.0490
Epoch 25/100, Training Loss: 0.0247, Validation Loss: 0.0335
Epoch 26/100, Training Loss: 0.0245, Validation Loss: 0.0460
Epoch 27/100, Training Loss: 0.0233, Validation Loss: 0.0310
Epoch 28/100, Training Loss: 0.0234, Validation Loss: 0.0447
Epoch 29/100, Training Loss: 0.0224, Validation Loss: 0.0290
Epoch 30/100, Training Loss: 0.0224, Validation Loss: 0.0443
Epoch 31/100, Training Loss: 0.0215, Validation Loss: 0.0275
Epoch 32/100, Training Loss: 0.0219, Validation Loss: 0.0443
Epoch 33/100, Training Loss: 0.0212, Validation Loss: 0.0265
Epoch 34/100, Training Loss: 0.0214, Validation Loss: 0.0433
Epoch 35/100, Training Loss: 0.0206, Validation Loss: 0.0260
Epoch 36/100, Training Loss: 0.0206, Validation Loss: 0.0410
Epoch 37/100, Training Loss: 0.0197, Validation Loss: 0.0260
Epoch 38/100, Training Loss: 0.0195, Validation Loss: 0.0376
Epoch 39/100, Training Loss: 0.0187, Validation Loss: 0.0264
Epoch 40/100, Training Loss: 0.0184, Validation Loss: 0.0344
Epoch 41/100, Training Loss: 0.0179, Validation Loss: 0.0271
Epoch 42/100, Training Loss: 0.0176, Validation Loss: 0.0318
Epoch 43/100, Training Loss: 0.0173, Validation Loss: 0.0277
Epoch 44/100, Training Loss: 0.0171, Validation Loss: 0.0300
Epoch 45/100, Training Loss: 0.0169, Validation Loss: 0.0280
Epoch 46/100, Training Loss: 0.0167, Validation Loss: 0.0289
Epoch 47/100, Training Loss: 0.0166, Validation Loss: 0.0280
Epoch 48/100, Training Loss: 0.0164, Validation Loss: 0.0281
Epoch 49/100, Training Loss: 0.0163, Validation Loss: 0.0278
Epoch 50/100, Training Loss: 0.0162, Validation Loss: 0.0277
Epoch 51/100, Training Loss: 0.0161, Validation Loss: 0.0275
Epoch 52/100, Training Loss: 0.0160, Validation Loss: 0.0273
Epoch 53/100, Training Loss: 0.0159, Validation Loss: 0.0272
Epoch 54/100, Training Loss: 0.0158, Validation Loss: 0.0271
Epoch 55/100, Training Loss: 0.0158, Validation Loss: 0.0270
Epoch 56/100, Training Loss: 0.0157, Validation Loss: 0.0268
Epoch 57/100, Training Loss: 0.0156, Validation Loss: 0.0267
Epoch 58/100, Training Loss: 0.0155, Validation Loss: 0.0266
Epoch 59/100, Training Loss: 0.0155, Validation Loss: 0.0265
Epoch 60/100, Training Loss: 0.0154, Validation Loss: 0.0264
Epoch 61/100, Training Loss: 0.0154, Validation Loss: 0.0263
Epoch 62/100, Training Loss: 0.0153, Validation Loss: 0.0262
Epoch 63/100, Training Loss: 0.0154, Validation Loss: 0.0262
Epoch 64/100, Training Loss: 0.0153, Validation Loss: 0.0261
Epoch 65/100, Training Loss: 0.0156, Validation Loss: 0.0261
Epoch 66/100, Training Loss: 0.0156, Validation Loss: 0.0261
Epoch 67/100, Training Loss: 0.0162, Validation Loss: 0.0260
Epoch 68/100, Training Loss: 0.0162, Validation Loss: 0.0260
Epoch 69/100, Training Loss: 0.0168, Validation Loss: 0.0259
Epoch 70/100, Training Loss: 0.0165, Validation Loss: 0.0258
Epoch 71/100, Training Loss: 0.0166, Validation Loss: 0.0257
Epoch 72/100, Training Loss: 0.0159, Validation Loss: 0.0256
Epoch 73/100, Training Loss: 0.0156, Validation Loss: 0.0256
Epoch 74/100, Training Loss: 0.0151, Validation Loss: 0.0255
Epoch 75/100, Training Loss: 0.0150, Validation Loss: 0.0254
Epoch 76/100, Training Loss: 0.0148, Validation Loss: 0.0254
Epoch 77/100, Training Loss: 0.0148, Validation Loss: 0.0253
Epoch 78/100, Training Loss: 0.0147, Validation Loss: 0.0253
Epoch 79/100, Training Loss: 0.0147, Validation Loss: 0.0252
Epoch 80/100, Training Loss: 0.0147, Validation Loss: 0.0252
Epoch 81/100, Training Loss: 0.0147, Validation Loss: 0.0251
Epoch 82/100, Training Loss: 0.0147, Validation Loss: 0.0251
Epoch 83/100, Training Loss: 0.0146, Validation Loss: 0.0251
Epoch 84/100, Training Loss: 0.0146, Validation Loss: 0.0250
Epoch 85/100, Training Loss: 0.0146, Validation Loss: 0.0250
Epoch 86/100, Training Loss: 0.0146, Validation Loss: 0.0250
Epoch 87/100, Training Loss: 0.0146, Validation Loss: 0.0249
Epoch 88/100, Training Loss: 0.0146, Validation Loss: 0.0249
Epoch 89/100, Training Loss: 0.0145, Validation Loss: 0.0249
Epoch 90/100, Training Loss: 0.0145, Validation Loss: 0.0249
Epoch 91/100, Training Loss: 0.0145, Validation Loss: 0.0248
Epoch 92/100, Training Loss: 0.0145, Validation Loss: 0.0248
Epoch 93/100, Training Loss: 0.0145, Validation Loss: 0.0248
Epoch 94/100, Training Loss: 0.0145, Validation Loss: 0.0248
Epoch 95/100, Training Loss: 0.0145, Validation Loss: 0.0248
Epoch 96/100, Training Loss: 0.0145, Validation Loss: 0.0247
Epoch 97/100, Training Loss: 0.0145, Validation Loss: 0.0247
Epoch 98/100, Training Loss: 0.0145, Validation Loss: 0.0247
Epoch 99/100, Training Loss: 0.0144, Validation Loss: 0.0247
Epoch 100/100, Training Loss: 0.0144, Validation Loss: 0.0247
['2023-05-17', '2023-05-18', '2023-05-19', '2023-05-22', '2023-05-23', '2023-05-24', '2023-05-25', '2023-05-26', '2023-05-30', '2023-05-31']
[170.52797]
[171.57913208 173.9239502  174.0332489  173.07940674 170.45640564
 170.73458862 171.87721252 174.30149841 176.15945435 170.52796936]
[171.57913208 173.9239502  174.0332489  173.07940674 170.45640564
 170.73458862 171.87721252 174.30149841 176.15945435 176.10980225]
/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/demo.py:115: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  predicted_selected_stock_price = predicted_selected_stock_price.cpu().numpy().flatten() * std_list[0] + mean_list[0]  # Using AAPL normalization factors
/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/demo.py:147: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown
  plt.show()