[32m[I 2025-02-06 11:31:31,115][0m A new study created in memory with name: no-name-b6be11f5-a9e4-41eb-b0b6-d426416ca50b[0m
[32m[I 2025-02-06 11:32:00,453][0m Trial 0 finished with value: 0.33591943979263306 and parameters: {'observation_period_num': 111, 'train_rates': 0.9482995049718987, 'learning_rate': 0.00020512799496964155, 'batch_size': 216, 'step_size': 2, 'gamma': 0.8588646279783904}. Best is trial 0 with value: 0.33591943979263306.[0m
[32m[I 2025-02-06 11:32:46,251][0m Trial 1 finished with value: 0.670393717295579 and parameters: {'observation_period_num': 115, 'train_rates': 0.6862276789963107, 'learning_rate': 6.2809407488383766e-06, 'batch_size': 111, 'step_size': 2, 'gamma': 0.9411556305143657}. Best is trial 0 with value: 0.33591943979263306.[0m
Early stopping at epoch 86
[32m[I 2025-02-06 11:34:40,732][0m Trial 2 finished with value: 0.21078924986780906 and parameters: {'observation_period_num': 78, 'train_rates': 0.7645540363480477, 'learning_rate': 0.0006158231572145789, 'batch_size': 38, 'step_size': 1, 'gamma': 0.8373447146314995}. Best is trial 2 with value: 0.21078924986780906.[0m
[32m[I 2025-02-06 11:35:04,075][0m Trial 3 finished with value: 0.508042171311705 and parameters: {'observation_period_num': 141, 'train_rates': 0.6154899936424107, 'learning_rate': 0.0001782371636022394, 'batch_size': 216, 'step_size': 10, 'gamma': 0.9275222110975286}. Best is trial 2 with value: 0.21078924986780906.[0m
[32m[I 2025-02-06 11:35:30,262][0m Trial 4 finished with value: 0.8502025329067958 and parameters: {'observation_period_num': 212, 'train_rates': 0.798028329172437, 'learning_rate': 1.8236846845481315e-05, 'batch_size': 203, 'step_size': 2, 'gamma': 0.8086768458544461}. Best is trial 2 with value: 0.21078924986780906.[0m
[32m[I 2025-02-06 11:36:00,749][0m Trial 5 finished with value: 0.25232493498652275 and parameters: {'observation_period_num': 28, 'train_rates': 0.7980065895038458, 'learning_rate': 2.4617076691862264e-05, 'batch_size': 192, 'step_size': 2, 'gamma': 0.8969748065256166}. Best is trial 2 with value: 0.21078924986780906.[0m
[32m[I 2025-02-06 11:37:02,010][0m Trial 6 finished with value: 0.24533797800540924 and parameters: {'observation_period_num': 252, 'train_rates': 0.9846490241262413, 'learning_rate': 0.0003253196020152235, 'batch_size': 95, 'step_size': 15, 'gamma': 0.8021541976640065}. Best is trial 2 with value: 0.21078924986780906.[0m
[32m[I 2025-02-06 11:37:46,903][0m Trial 7 finished with value: 0.3891298470953113 and parameters: {'observation_period_num': 106, 'train_rates': 0.6648278140915237, 'learning_rate': 0.00012918262303001504, 'batch_size': 101, 'step_size': 2, 'gamma': 0.8345762468578241}. Best is trial 2 with value: 0.21078924986780906.[0m
[32m[I 2025-02-06 11:38:10,902][0m Trial 8 finished with value: 0.36231699805931755 and parameters: {'observation_period_num': 219, 'train_rates': 0.784960116860083, 'learning_rate': 1.6368326437504977e-05, 'batch_size': 232, 'step_size': 8, 'gamma': 0.9701485953657315}. Best is trial 2 with value: 0.21078924986780906.[0m
[32m[I 2025-02-06 11:38:34,012][0m Trial 9 finished with value: 0.414130104321336 and parameters: {'observation_period_num': 199, 'train_rates': 0.638827748331912, 'learning_rate': 5.4049603173821955e-05, 'batch_size': 202, 'step_size': 5, 'gamma': 0.9072317970997485}. Best is trial 2 with value: 0.21078924986780906.[0m
[32m[I 2025-02-06 11:43:27,113][0m Trial 10 finished with value: 0.04435883741825819 and parameters: {'observation_period_num': 7, 'train_rates': 0.8849327554308369, 'learning_rate': 0.000903603527496998, 'batch_size': 19, 'step_size': 7, 'gamma': 0.7656550631206827}. Best is trial 10 with value: 0.04435883741825819.[0m
[32m[I 2025-02-06 11:48:35,724][0m Trial 11 finished with value: 0.032991600911956645 and parameters: {'observation_period_num': 8, 'train_rates': 0.8840897675109337, 'learning_rate': 0.0008049193709469731, 'batch_size': 18, 'step_size': 6, 'gamma': 0.7506008831309704}. Best is trial 11 with value: 0.032991600911956645.[0m
[32m[I 2025-02-06 11:53:46,653][0m Trial 12 finished with value: 0.2221585560303468 and parameters: {'observation_period_num': 7, 'train_rates': 0.8910186428158103, 'learning_rate': 1.0794071086187918e-06, 'batch_size': 18, 'step_size': 7, 'gamma': 0.7506827867794438}. Best is trial 11 with value: 0.032991600911956645.[0m
[32m[I 2025-02-06 11:55:25,987][0m Trial 13 finished with value: 0.11874669630612646 and parameters: {'observation_period_num': 32, 'train_rates': 0.8676152813967121, 'learning_rate': 0.000832599747221173, 'batch_size': 56, 'step_size': 10, 'gamma': 0.7617107286501944}. Best is trial 11 with value: 0.032991600911956645.[0m
[32m[I 2025-02-06 11:56:45,556][0m Trial 14 finished with value: 0.10497573827361238 and parameters: {'observation_period_num': 58, 'train_rates': 0.8812768839517676, 'learning_rate': 0.0007972973536918563, 'batch_size': 70, 'step_size': 5, 'gamma': 0.7840602004758469}. Best is trial 11 with value: 0.032991600911956645.[0m
[32m[I 2025-02-06 11:57:24,933][0m Trial 15 finished with value: 0.11175630495534929 and parameters: {'observation_period_num': 66, 'train_rates': 0.9390039622830137, 'learning_rate': 7.238912765455704e-05, 'batch_size': 155, 'step_size': 11, 'gamma': 0.7802572088457421}. Best is trial 11 with value: 0.032991600911956645.[0m
[32m[I 2025-02-06 12:02:22,582][0m Trial 16 finished with value: 0.02853755179204439 and parameters: {'observation_period_num': 7, 'train_rates': 0.8408260708422233, 'learning_rate': 0.00033615400546773994, 'batch_size': 18, 'step_size': 5, 'gamma': 0.7510505704965049}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:03:01,041][0m Trial 17 finished with value: 0.060756018594001863 and parameters: {'observation_period_num': 42, 'train_rates': 0.8395854788289059, 'learning_rate': 0.00030557782046009176, 'batch_size': 148, 'step_size': 5, 'gamma': 0.8134150006281944}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:04:09,343][0m Trial 18 finished with value: 0.23238045315850864 and parameters: {'observation_period_num': 147, 'train_rates': 0.7291464377913945, 'learning_rate': 0.00040366745919242234, 'batch_size': 70, 'step_size': 4, 'gamma': 0.872157534583004}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:06:20,162][0m Trial 19 finished with value: 0.1406044140458107 and parameters: {'observation_period_num': 86, 'train_rates': 0.9283315979962484, 'learning_rate': 8.302809165792205e-05, 'batch_size': 44, 'step_size': 12, 'gamma': 0.9885570387760533}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:06:43,200][0m Trial 20 finished with value: 0.9752378874941717 and parameters: {'observation_period_num': 171, 'train_rates': 0.8317502220506079, 'learning_rate': 2.4718911741705246e-06, 'batch_size': 255, 'step_size': 7, 'gamma': 0.7862058840897793}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:12:37,704][0m Trial 21 finished with value: 0.03980425028412631 and parameters: {'observation_period_num': 8, 'train_rates': 0.9116710503060269, 'learning_rate': 0.0009208338402004081, 'batch_size': 16, 'step_size': 7, 'gamma': 0.7505312436451906}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:15:42,143][0m Trial 22 finished with value: 0.029211925274255323 and parameters: {'observation_period_num': 7, 'train_rates': 0.8356905182874643, 'learning_rate': 0.0004480223799780668, 'batch_size': 29, 'step_size': 4, 'gamma': 0.7518764896990882}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:17:50,015][0m Trial 23 finished with value: 0.059704358163087265 and parameters: {'observation_period_num': 41, 'train_rates': 0.8363088183477351, 'learning_rate': 0.00037721022823173207, 'batch_size': 42, 'step_size': 4, 'gamma': 0.7764446449673741}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:18:57,387][0m Trial 24 finished with value: 0.1773194295377687 and parameters: {'observation_period_num': 25, 'train_rates': 0.7461668154885918, 'learning_rate': 0.00012281935632048164, 'batch_size': 76, 'step_size': 4, 'gamma': 0.8008933742756852}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:19:41,615][0m Trial 25 finished with value: 0.14018370446036843 and parameters: {'observation_period_num': 57, 'train_rates': 0.85512310316229, 'learning_rate': 4.6898481226102116e-05, 'batch_size': 126, 'step_size': 6, 'gamma': 0.8214420003506216}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:21:52,461][0m Trial 26 finished with value: 0.11534526000885084 and parameters: {'observation_period_num': 87, 'train_rates': 0.8067907995961654, 'learning_rate': 0.00043425503096504995, 'batch_size': 39, 'step_size': 9, 'gamma': 0.7686937643972339}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:23:37,819][0m Trial 27 finished with value: 0.06475125900224636 and parameters: {'observation_period_num': 20, 'train_rates': 0.9746474203330359, 'learning_rate': 0.00021090362021525114, 'batch_size': 58, 'step_size': 3, 'gamma': 0.7913358335586482}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:26:33,412][0m Trial 28 finished with value: 0.11778634079227238 and parameters: {'observation_period_num': 46, 'train_rates': 0.8220374858716363, 'learning_rate': 0.0005160974023313694, 'batch_size': 30, 'step_size': 6, 'gamma': 0.7517936286032976}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:28:15,697][0m Trial 29 finished with value: 0.040332818403840065 and parameters: {'observation_period_num': 22, 'train_rates': 0.9103415157512477, 'learning_rate': 0.00021286132486122842, 'batch_size': 57, 'step_size': 6, 'gamma': 0.853196446793619}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:29:25,062][0m Trial 30 finished with value: 0.6468001278963956 and parameters: {'observation_period_num': 74, 'train_rates': 0.9622823732715152, 'learning_rate': 8.837121363807737e-06, 'batch_size': 85, 'step_size': 3, 'gamma': 0.8267847940070376}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:35:22,725][0m Trial 31 finished with value: 0.03761607107513816 and parameters: {'observation_period_num': 8, 'train_rates': 0.9206729047361897, 'learning_rate': 0.000622796160883541, 'batch_size': 16, 'step_size': 8, 'gamma': 0.7529947937979409}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:39:01,055][0m Trial 32 finished with value: 0.03517634697617537 and parameters: {'observation_period_num': 5, 'train_rates': 0.8611747460817745, 'learning_rate': 0.0005721884160742747, 'batch_size': 25, 'step_size': 8, 'gamma': 0.7641647822133125}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:41:49,778][0m Trial 33 finished with value: 0.1687910736452603 and parameters: {'observation_period_num': 45, 'train_rates': 0.856412788250289, 'learning_rate': 0.0002768722717177021, 'batch_size': 32, 'step_size': 9, 'gamma': 0.7697559498133894}. Best is trial 16 with value: 0.02853755179204439.[0m
Early stopping at epoch 87
[32m[I 2025-02-06 12:43:31,052][0m Trial 34 finished with value: 0.07127623767141372 and parameters: {'observation_period_num': 24, 'train_rates': 0.8954936202578809, 'learning_rate': 0.0005558424773822136, 'batch_size': 51, 'step_size': 1, 'gamma': 0.7916852024138696}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:46:06,120][0m Trial 35 finished with value: 0.15946257953270734 and parameters: {'observation_period_num': 6, 'train_rates': 0.7672634033326524, 'learning_rate': 0.00014640137325527396, 'batch_size': 33, 'step_size': 5, 'gamma': 0.7666206968438277}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:46:37,916][0m Trial 36 finished with value: 0.10011812565379015 and parameters: {'observation_period_num': 106, 'train_rates': 0.8183881406769863, 'learning_rate': 0.0005526211598853521, 'batch_size': 173, 'step_size': 3, 'gamma': 0.8697829383981254}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:47:20,163][0m Trial 37 finished with value: 0.14745253038209274 and parameters: {'observation_period_num': 32, 'train_rates': 0.7034922900389108, 'learning_rate': 0.00023677685952314673, 'batch_size': 118, 'step_size': 13, 'gamma': 0.8007862634562487}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:48:27,608][0m Trial 38 finished with value: 0.055904892118026815 and parameters: {'observation_period_num': 56, 'train_rates': 0.8611142568358858, 'learning_rate': 0.00010021987929876756, 'batch_size': 85, 'step_size': 8, 'gamma': 0.847022084496034}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:51:20,344][0m Trial 39 finished with value: 0.10187441446185112 and parameters: {'observation_period_num': 122, 'train_rates': 0.7819775481398754, 'learning_rate': 0.0009991133904873296, 'batch_size': 29, 'step_size': 6, 'gamma': 0.7792409507489149}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:52:19,683][0m Trial 40 finished with value: 0.05866384777155789 and parameters: {'observation_period_num': 37, 'train_rates': 0.9480280790077159, 'learning_rate': 0.00015767725377615458, 'batch_size': 103, 'step_size': 9, 'gamma': 0.9379821378037312}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 12:58:17,742][0m Trial 41 finished with value: 0.04319427127264581 and parameters: {'observation_period_num': 17, 'train_rates': 0.9286781683431351, 'learning_rate': 0.0005812384940063232, 'batch_size': 16, 'step_size': 8, 'gamma': 0.760778670341422}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 13:01:56,169][0m Trial 42 finished with value: 0.040270498015712745 and parameters: {'observation_period_num': 18, 'train_rates': 0.9069268605609847, 'learning_rate': 0.0006839859653079514, 'batch_size': 26, 'step_size': 10, 'gamma': 0.7561626866664461}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 13:03:52,136][0m Trial 43 finished with value: 0.03401935405527372 and parameters: {'observation_period_num': 14, 'train_rates': 0.8703794169054132, 'learning_rate': 0.0003586380166921149, 'batch_size': 48, 'step_size': 7, 'gamma': 0.7698289001159337}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 13:05:51,824][0m Trial 44 finished with value: 0.03769513975320146 and parameters: {'observation_period_num': 5, 'train_rates': 0.8480066795621014, 'learning_rate': 0.0003246077819433224, 'batch_size': 46, 'step_size': 4, 'gamma': 0.7744702353218411}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 13:07:18,669][0m Trial 45 finished with value: 0.04126425279136846 and parameters: {'observation_period_num': 18, 'train_rates': 0.873032646143085, 'learning_rate': 0.00043327152999702375, 'batch_size': 67, 'step_size': 5, 'gamma': 0.7924870960593132}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 13:09:34,509][0m Trial 46 finished with value: 0.048023827841336075 and parameters: {'observation_period_num': 35, 'train_rates': 0.8138117250062099, 'learning_rate': 0.0002016983688086338, 'batch_size': 39, 'step_size': 6, 'gamma': 0.7658588833590636}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 13:12:48,024][0m Trial 47 finished with value: 0.30593139878080466 and parameters: {'observation_period_num': 239, 'train_rates': 0.875234685948359, 'learning_rate': 0.00029831173271886523, 'batch_size': 27, 'step_size': 7, 'gamma': 0.8105558104991641}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 13:14:00,649][0m Trial 48 finished with value: 0.3846905891928831 and parameters: {'observation_period_num': 54, 'train_rates': 0.6003755665575173, 'learning_rate': 2.7729627956699187e-05, 'batch_size': 62, 'step_size': 3, 'gamma': 0.9150233072324271}. Best is trial 16 with value: 0.02853755179204439.[0m
[32m[I 2025-02-06 13:17:23,809][0m Trial 49 finished with value: 0.08984982027213428 and parameters: {'observation_period_num': 69, 'train_rates': 0.791017064546064, 'learning_rate': 1.13189067664234e-05, 'batch_size': 25, 'step_size': 15, 'gamma': 0.7594525196912153}. Best is trial 16 with value: 0.02853755179204439.[0m
最適ハイパーパラメータが見つかりました
最適なハイパーパラメータが best_hyperparameters_GOOG_iTransformer_noMSTL.json に保存されました
Epoch 1/300, Loss: 0.1570 | 0.0850
Epoch 2/300, Loss: 0.1100 | 0.0670
Epoch 3/300, Loss: 0.1037 | 0.0685
Epoch 4/300, Loss: 0.0965 | 0.0615
Epoch 5/300, Loss: 0.0917 | 0.0504
Epoch 6/300, Loss: 0.0849 | 0.0454
Epoch 7/300, Loss: 0.0815 | 0.0429
Epoch 8/300, Loss: 0.0792 | 0.0409
Epoch 9/300, Loss: 0.0764 | 0.0406
Epoch 10/300, Loss: 0.0743 | 0.0381
Epoch 11/300, Loss: 0.0722 | 0.0411
Epoch 12/300, Loss: 0.0711 | 0.0393
Epoch 13/300, Loss: 0.0702 | 0.0373
Epoch 14/300, Loss: 0.0690 | 0.0380
Epoch 15/300, Loss: 0.0684 | 0.0372
Epoch 16/300, Loss: 0.0675 | 0.0362
Epoch 17/300, Loss: 0.0670 | 0.0361
Epoch 18/300, Loss: 0.0665 | 0.0360
Epoch 19/300, Loss: 0.0658 | 0.0362
Epoch 20/300, Loss: 0.0655 | 0.0361
Epoch 21/300, Loss: 0.0650 | 0.0357
Epoch 22/300, Loss: 0.0647 | 0.0361
Epoch 23/300, Loss: 0.0644 | 0.0365
Epoch 24/300, Loss: 0.0640 | 0.0343
Epoch 25/300, Loss: 0.0638 | 0.0345
Epoch 26/300, Loss: 0.0634 | 0.0332
Epoch 27/300, Loss: 0.0632 | 0.0333
Epoch 28/300, Loss: 0.0631 | 0.0333
Epoch 29/300, Loss: 0.0629 | 0.0327
Epoch 30/300, Loss: 0.0627 | 0.0327
Epoch 31/300, Loss: 0.0626 | 0.0324
Epoch 32/300, Loss: 0.0625 | 0.0323
Epoch 33/300, Loss: 0.0624 | 0.0323
Epoch 34/300, Loss: 0.0623 | 0.0318
Epoch 35/300, Loss: 0.0622 | 0.0318
Epoch 36/300, Loss: 0.0622 | 0.0315
Epoch 37/300, Loss: 0.0621 | 0.0315
Epoch 38/300, Loss: 0.0620 | 0.0315
Epoch 39/300, Loss: 0.0620 | 0.0310
Epoch 40/300, Loss: 0.0619 | 0.0310
Epoch 41/300, Loss: 0.0619 | 0.0307
Epoch 42/300, Loss: 0.0619 | 0.0307
Epoch 43/300, Loss: 0.0618 | 0.0306
Epoch 44/300, Loss: 0.0618 | 0.0308
Epoch 45/300, Loss: 0.0618 | 0.0308
Epoch 46/300, Loss: 0.0618 | 0.0311
Epoch 47/300, Loss: 0.0618 | 0.0311
Epoch 48/300, Loss: 0.0617 | 0.0311
Epoch 49/300, Loss: 0.0617 | 0.0315
Epoch 50/300, Loss: 0.0617 | 0.0315
Epoch 51/300, Loss: 0.0617 | 0.0318
Epoch 52/300, Loss: 0.0616 | 0.0318
Epoch 53/300, Loss: 0.0615 | 0.0318
Epoch 54/300, Loss: 0.0615 | 0.0320
Epoch 55/300, Loss: 0.0615 | 0.0320
Epoch 56/300, Loss: 0.0615 | 0.0321
Epoch 57/300, Loss: 0.0614 | 0.0322
Epoch 58/300, Loss: 0.0614 | 0.0322
Epoch 59/300, Loss: 0.0614 | 0.0322
Epoch 60/300, Loss: 0.0613 | 0.0322
Epoch 61/300, Loss: 0.0613 | 0.0322
Epoch 62/300, Loss: 0.0613 | 0.0323
Epoch 63/300, Loss: 0.0613 | 0.0323
Epoch 64/300, Loss: 0.0613 | 0.0323
Epoch 65/300, Loss: 0.0613 | 0.0323
Epoch 66/300, Loss: 0.0613 | 0.0323
Epoch 67/300, Loss: 0.0613 | 0.0323
Epoch 68/300, Loss: 0.0612 | 0.0323
Epoch 69/300, Loss: 0.0612 | 0.0323
Epoch 70/300, Loss: 0.0612 | 0.0323
Epoch 71/300, Loss: 0.0612 | 0.0323
Epoch 72/300, Loss: 0.0612 | 0.0323
Epoch 73/300, Loss: 0.0612 | 0.0323
Epoch 74/300, Loss: 0.0612 | 0.0323
Epoch 75/300, Loss: 0.0612 | 0.0323
Epoch 76/300, Loss: 0.0612 | 0.0323
Epoch 77/300, Loss: 0.0612 | 0.0323
Epoch 78/300, Loss: 0.0612 | 0.0323
Epoch 79/300, Loss: 0.0612 | 0.0323
Epoch 80/300, Loss: 0.0612 | 0.0324
Epoch 81/300, Loss: 0.0612 | 0.0324
Epoch 82/300, Loss: 0.0612 | 0.0324
Epoch 83/300, Loss: 0.0612 | 0.0324
Epoch 84/300, Loss: 0.0612 | 0.0324
Epoch 85/300, Loss: 0.0612 | 0.0324
Epoch 86/300, Loss: 0.0612 | 0.0324
Epoch 87/300, Loss: 0.0612 | 0.0324
Epoch 88/300, Loss: 0.0612 | 0.0324
Epoch 89/300, Loss: 0.0612 | 0.0324
Epoch 90/300, Loss: 0.0612 | 0.0324
Epoch 91/300, Loss: 0.0612 | 0.0324
Epoch 92/300, Loss: 0.0612 | 0.0324
Epoch 93/300, Loss: 0.0612 | 0.0324
Epoch 94/300, Loss: 0.0612 | 0.0324
Epoch 95/300, Loss: 0.0612 | 0.0324
Epoch 96/300, Loss: 0.0612 | 0.0324
Epoch 97/300, Loss: 0.0612 | 0.0323
Epoch 98/300, Loss: 0.0612 | 0.0323
Epoch 99/300, Loss: 0.0612 | 0.0323
Epoch 100/300, Loss: 0.0612 | 0.0323
Epoch 101/300, Loss: 0.0612 | 0.0323
Epoch 102/300, Loss: 0.0612 | 0.0323
Epoch 103/300, Loss: 0.0612 | 0.0323
Epoch 104/300, Loss: 0.0612 | 0.0323
Epoch 105/300, Loss: 0.0612 | 0.0323
Epoch 106/300, Loss: 0.0612 | 0.0323
Epoch 107/300, Loss: 0.0612 | 0.0323
Epoch 108/300, Loss: 0.0612 | 0.0323
Epoch 109/300, Loss: 0.0612 | 0.0323
Epoch 110/300, Loss: 0.0612 | 0.0323
Epoch 111/300, Loss: 0.0612 | 0.0323
Epoch 112/300, Loss: 0.0612 | 0.0323
Epoch 113/300, Loss: 0.0612 | 0.0323
Epoch 114/300, Loss: 0.0612 | 0.0323
Epoch 115/300, Loss: 0.0612 | 0.0323
Epoch 116/300, Loss: 0.0612 | 0.0323
Epoch 117/300, Loss: 0.0612 | 0.0323
Epoch 118/300, Loss: 0.0612 | 0.0323
Epoch 119/300, Loss: 0.0612 | 0.0323
Epoch 120/300, Loss: 0.0612 | 0.0323
Epoch 121/300, Loss: 0.0612 | 0.0323
Epoch 122/300, Loss: 0.0612 | 0.0323
Epoch 123/300, Loss: 0.0612 | 0.0323
Epoch 124/300, Loss: 0.0612 | 0.0323
Epoch 125/300, Loss: 0.0612 | 0.0323
Epoch 126/300, Loss: 0.0612 | 0.0323
Epoch 127/300, Loss: 0.0612 | 0.0323
Epoch 128/300, Loss: 0.0612 | 0.0323
Epoch 129/300, Loss: 0.0612 | 0.0323
Epoch 130/300, Loss: 0.0612 | 0.0323
Epoch 131/300, Loss: 0.0612 | 0.0323
Epoch 132/300, Loss: 0.0612 | 0.0323
Epoch 133/300, Loss: 0.0612 | 0.0323
Epoch 134/300, Loss: 0.0612 | 0.0323
Epoch 135/300, Loss: 0.0612 | 0.0323
Epoch 136/300, Loss: 0.0612 | 0.0323
Epoch 137/300, Loss: 0.0612 | 0.0323
Epoch 138/300, Loss: 0.0612 | 0.0323
Epoch 139/300, Loss: 0.0612 | 0.0323
Epoch 140/300, Loss: 0.0612 | 0.0323
Epoch 141/300, Loss: 0.0612 | 0.0323
Epoch 142/300, Loss: 0.0612 | 0.0323
Epoch 143/300, Loss: 0.0612 | 0.0323
Epoch 144/300, Loss: 0.0612 | 0.0323
Epoch 145/300, Loss: 0.0612 | 0.0323
Epoch 146/300, Loss: 0.0612 | 0.0323
Epoch 147/300, Loss: 0.0612 | 0.0323
Epoch 148/300, Loss: 0.0612 | 0.0323
Epoch 149/300, Loss: 0.0612 | 0.0323
Epoch 150/300, Loss: 0.0612 | 0.0323
Epoch 151/300, Loss: 0.0612 | 0.0323
Epoch 152/300, Loss: 0.0612 | 0.0323
Epoch 153/300, Loss: 0.0612 | 0.0323
Epoch 154/300, Loss: 0.0612 | 0.0323
Epoch 155/300, Loss: 0.0612 | 0.0323
Epoch 156/300, Loss: 0.0612 | 0.0323
Epoch 157/300, Loss: 0.0612 | 0.0323
Epoch 158/300, Loss: 0.0612 | 0.0323
Epoch 159/300, Loss: 0.0612 | 0.0323
Epoch 160/300, Loss: 0.0612 | 0.0323
Epoch 161/300, Loss: 0.0612 | 0.0323
Epoch 162/300, Loss: 0.0612 | 0.0323
Epoch 163/300, Loss: 0.0612 | 0.0323
Epoch 164/300, Loss: 0.0612 | 0.0323
Epoch 165/300, Loss: 0.0612 | 0.0323
Epoch 166/300, Loss: 0.0612 | 0.0323
Epoch 167/300, Loss: 0.0612 | 0.0323
Epoch 168/300, Loss: 0.0612 | 0.0323
Epoch 169/300, Loss: 0.0612 | 0.0323
Epoch 170/300, Loss: 0.0612 | 0.0323
Epoch 171/300, Loss: 0.0612 | 0.0323
Epoch 172/300, Loss: 0.0612 | 0.0323
Epoch 173/300, Loss: 0.0612 | 0.0323
Epoch 174/300, Loss: 0.0612 | 0.0323
Epoch 175/300, Loss: 0.0612 | 0.0323
Epoch 176/300, Loss: 0.0612 | 0.0323
Epoch 177/300, Loss: 0.0612 | 0.0323
Epoch 178/300, Loss: 0.0612 | 0.0323
Early stopping
Runtime (seconds): 534.5476734638214
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)
MSE: 297.4714348858688
RMSE: 17.247360229492188
MAE: 17.247360229492188
R-squared: nan
[182.78264]
