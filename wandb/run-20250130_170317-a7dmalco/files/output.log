ÊúÄÈÅ©ÂåñÂØæË±°: trend
[32m[I 2025-01-30 17:03:19,758][0m A new study created in memory with name: no-name-959bd8ff-f3bf-4e99-a752-bcdbeddf8e99[0m
Non-A100 GPU detected, using math or mem efficient attention if input tensor is on cuda
[33m[W 2025-01-30 17:03:47,921][0m Trial 0 failed with parameters: {'observation_period_num': 197, 'train_rates': 0.9670738533176083, 'learning_rate': 9.340990055876131e-06, 'batch_size': 171, 'step_size': 9, 'gamma': 0.8421911886949633} because of the following error: KeyboardInterrupt().[0m
Traceback (most recent call last):
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/roop_optuna.py", line 551, in <lambda>
    study.optimize(lambda trial: objective(trial, component, depth, dim), n_trials=50) #check
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/roop_optuna.py", line 113, in objective
    model, _, valid_loss = train(
                           ^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/src/train.py", line 40, in train
    loss.backward()  # ÈÄÜ‰ºùÊí≠
    ^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
[33m[W 2025-01-30 17:03:47,954][0m Trial 0 failed with value None.[0m
Traceback (most recent call last):
  File "/data/student/k2110261/Multi-iTransformer/roop_optuna.py", line 551, in <module>
    study.optimize(lambda trial: objective(trial, component, depth, dim), n_trials=50) #check
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/study.py", line 475, in optimize
    _optimize(
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 63, in _optimize
    _optimize_sequential(
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 160, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 248, in _run_trial
    raise func_err
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
                      ^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/roop_optuna.py", line 551, in <lambda>
    study.optimize(lambda trial: objective(trial, component, depth, dim), n_trials=50) #check
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/roop_optuna.py", line 113, in objective
    model, _, valid_loss = train(
                           ^^^^^^
  File "/data/student/k2110261/Multi-iTransformer/src/train.py", line 40, in train
    loss.backward()  # ÈÄÜ‰ºùÊí≠
    ^^^^^^^^^^^^^^^
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
