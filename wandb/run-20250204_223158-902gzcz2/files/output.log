[32m[I 2025-02-04 22:32:02,176][0m A new study created in memory with name: no-name-420be296-baf9-4771-b91b-bff58ac0ba52[0m
[32m[I 2025-02-04 22:32:27,967][0m Trial 0 finished with value: 0.2493679436175174 and parameters: {'observation_period_num': 212, 'train_rates': 0.8409325527245153, 'learning_rate': 5.4387801742529604e-05, 'batch_size': 220, 'step_size': 8, 'gamma': 0.8377957098523322}. Best is trial 0 with value: 0.2493679436175174.[0m
[32m[I 2025-02-04 22:33:48,994][0m Trial 1 finished with value: 0.611749964746389 and parameters: {'observation_period_num': 175, 'train_rates': 0.6620635027486927, 'learning_rate': 1.2673331773103525e-05, 'batch_size': 55, 'step_size': 3, 'gamma': 0.7812882006720825}. Best is trial 0 with value: 0.2493679436175174.[0m
[32m[I 2025-02-04 22:34:21,562][0m Trial 2 finished with value: 0.17097630042326514 and parameters: {'observation_period_num': 14, 'train_rates': 0.6787796808168289, 'learning_rate': 2.9316040408393742e-05, 'batch_size': 155, 'step_size': 8, 'gamma': 0.9856012705089355}. Best is trial 2 with value: 0.17097630042326514.[0m
[32m[I 2025-02-04 22:35:00,188][0m Trial 3 finished with value: 0.344592382777028 and parameters: {'observation_period_num': 107, 'train_rates': 0.8563611852075792, 'learning_rate': 1.058339323701712e-05, 'batch_size': 146, 'step_size': 4, 'gamma': 0.934235312889856}. Best is trial 2 with value: 0.17097630042326514.[0m
[32m[I 2025-02-04 22:35:25,275][0m Trial 4 finished with value: 0.35785153946694626 and parameters: {'observation_period_num': 208, 'train_rates': 0.7331473441531873, 'learning_rate': 7.1209755454031e-05, 'batch_size': 214, 'step_size': 11, 'gamma': 0.8145244725862997}. Best is trial 2 with value: 0.17097630042326514.[0m
[32m[I 2025-02-04 22:36:58,902][0m Trial 5 finished with value: 0.18548267317513759 and parameters: {'observation_period_num': 55, 'train_rates': 0.746110216676975, 'learning_rate': 0.0004944218359431011, 'batch_size': 53, 'step_size': 9, 'gamma': 0.7821187067158235}. Best is trial 2 with value: 0.17097630042326514.[0m
[32m[I 2025-02-04 22:37:31,213][0m Trial 6 finished with value: 0.2472692111814485 and parameters: {'observation_period_num': 73, 'train_rates': 0.6429470762611432, 'learning_rate': 0.0002961755719840139, 'batch_size': 149, 'step_size': 2, 'gamma': 0.8122618620034837}. Best is trial 2 with value: 0.17097630042326514.[0m
[32m[I 2025-02-04 22:38:09,112][0m Trial 7 finished with value: 0.6886418932877352 and parameters: {'observation_period_num': 90, 'train_rates': 0.6172577444021403, 'learning_rate': 3.0465631426316842e-06, 'batch_size': 122, 'step_size': 12, 'gamma': 0.9173740264637715}. Best is trial 2 with value: 0.17097630042326514.[0m
[32m[I 2025-02-04 22:38:43,701][0m Trial 8 finished with value: 0.25453080449785503 and parameters: {'observation_period_num': 146, 'train_rates': 0.8432656735701636, 'learning_rate': 1.7375919837888775e-05, 'batch_size': 164, 'step_size': 2, 'gamma': 0.9735825763176966}. Best is trial 2 with value: 0.17097630042326514.[0m
[32m[I 2025-02-04 22:39:13,293][0m Trial 9 finished with value: 0.5441530313160855 and parameters: {'observation_period_num': 228, 'train_rates': 0.7148119542257745, 'learning_rate': 1.7716943384178933e-05, 'batch_size': 164, 'step_size': 5, 'gamma': 0.8960984589614933}. Best is trial 2 with value: 0.17097630042326514.[0m
[32m[I 2025-02-04 22:40:16,169][0m Trial 10 finished with value: 0.413230299949646 and parameters: {'observation_period_num': 26, 'train_rates': 0.9813865106486942, 'learning_rate': 1.555477192217093e-06, 'batch_size': 101, 'step_size': 14, 'gamma': 0.9871954823302707}. Best is trial 2 with value: 0.17097630042326514.[0m
[32m[I 2025-02-04 22:42:26,094][0m Trial 11 finished with value: 0.15495946080781672 and parameters: {'observation_period_num': 5, 'train_rates': 0.7688548677662557, 'learning_rate': 0.000892413662195117, 'batch_size': 40, 'step_size': 8, 'gamma': 0.764619701928391}. Best is trial 11 with value: 0.15495946080781672.[0m
[32m[I 2025-02-04 22:47:12,673][0m Trial 12 finished with value: 0.16462242873254784 and parameters: {'observation_period_num': 5, 'train_rates': 0.7827597036185031, 'learning_rate': 0.00015758492115317777, 'batch_size': 18, 'step_size': 7, 'gamma': 0.8591616591718201}. Best is trial 11 with value: 0.15495946080781672.[0m
[32m[I 2025-02-04 22:50:35,409][0m Trial 13 finished with value: 0.18357542551759826 and parameters: {'observation_period_num': 5, 'train_rates': 0.7942237736123371, 'learning_rate': 0.0009726414723741818, 'batch_size': 26, 'step_size': 6, 'gamma': 0.8645625634611194}. Best is trial 11 with value: 0.15495946080781672.[0m
[32m[I 2025-02-04 22:54:56,948][0m Trial 14 finished with value: 0.0477562697741103 and parameters: {'observation_period_num': 46, 'train_rates': 0.9391787896305007, 'learning_rate': 0.00017630969761650835, 'batch_size': 22, 'step_size': 7, 'gamma': 0.7638666526291613}. Best is trial 14 with value: 0.0477562697741103.[0m
[32m[I 2025-02-04 22:56:09,930][0m Trial 15 finished with value: 0.0574466941687159 and parameters: {'observation_period_num': 47, 'train_rates': 0.9466548195514954, 'learning_rate': 0.00017272365478408506, 'batch_size': 83, 'step_size': 10, 'gamma': 0.7521810768011833}. Best is trial 14 with value: 0.0477562697741103.[0m
[32m[I 2025-02-04 22:57:15,175][0m Trial 16 finished with value: 0.05948253348469734 and parameters: {'observation_period_num': 50, 'train_rates': 0.9831561714319066, 'learning_rate': 0.00014916255438466886, 'batch_size': 98, 'step_size': 11, 'gamma': 0.7546886161067168}. Best is trial 14 with value: 0.0477562697741103.[0m
[32m[I 2025-02-04 22:58:28,688][0m Trial 17 finished with value: 0.09278858850622392 and parameters: {'observation_period_num': 121, 'train_rates': 0.921659994521146, 'learning_rate': 0.00013512180603675056, 'batch_size': 78, 'step_size': 10, 'gamma': 0.7974274547504661}. Best is trial 14 with value: 0.0477562697741103.[0m
[32m[I 2025-02-04 22:58:54,173][0m Trial 18 finished with value: 0.09567880630493164 and parameters: {'observation_period_num': 43, 'train_rates': 0.9163572105204232, 'learning_rate': 0.0003383618595830767, 'batch_size': 253, 'step_size': 13, 'gamma': 0.8241389396891299}. Best is trial 14 with value: 0.0477562697741103.[0m
[32m[I 2025-02-04 23:00:16,100][0m Trial 19 finished with value: 0.07609073002822697 and parameters: {'observation_period_num': 80, 'train_rates': 0.9222057168308112, 'learning_rate': 7.903310084741569e-05, 'batch_size': 70, 'step_size': 15, 'gamma': 0.7552732538565712}. Best is trial 14 with value: 0.0477562697741103.[0m
[32m[I 2025-02-04 23:01:19,628][0m Trial 20 finished with value: 0.5032413560768654 and parameters: {'observation_period_num': 149, 'train_rates': 0.8865435342865811, 'learning_rate': 5.3091296574980215e-06, 'batch_size': 88, 'step_size': 6, 'gamma': 0.778951007369959}. Best is trial 14 with value: 0.0477562697741103.[0m
[32m[I 2025-02-04 23:02:17,436][0m Trial 21 finished with value: 0.06716305762529373 and parameters: {'observation_period_num': 46, 'train_rates': 0.9886775311687561, 'learning_rate': 0.0001765188805445908, 'batch_size': 113, 'step_size': 10, 'gamma': 0.7522710523963531}. Best is trial 14 with value: 0.0477562697741103.[0m
[32m[I 2025-02-04 23:03:21,226][0m Trial 22 finished with value: 0.07501395304997761 and parameters: {'observation_period_num': 61, 'train_rates': 0.9484341023793386, 'learning_rate': 0.00010310928516091957, 'batch_size': 97, 'step_size': 12, 'gamma': 0.7932006443068028}. Best is trial 14 with value: 0.0477562697741103.[0m
[32m[I 2025-02-04 23:04:58,236][0m Trial 23 finished with value: 0.07242022887352974 and parameters: {'observation_period_num': 34, 'train_rates': 0.9575876032639075, 'learning_rate': 4.807007876473683e-05, 'batch_size': 63, 'step_size': 10, 'gamma': 0.7522031911989391}. Best is trial 14 with value: 0.0477562697741103.[0m
[32m[I 2025-02-04 23:05:47,553][0m Trial 24 finished with value: 0.07764199687149918 and parameters: {'observation_period_num': 84, 'train_rates': 0.8924881613302234, 'learning_rate': 0.00027881250123585325, 'batch_size': 120, 'step_size': 12, 'gamma': 0.8390242938869055}. Best is trial 14 with value: 0.0477562697741103.[0m
[32m[I 2025-02-04 23:09:07,794][0m Trial 25 finished with value: 0.15012278172530627 and parameters: {'observation_period_num': 104, 'train_rates': 0.9601675944259511, 'learning_rate': 0.0005426687236585654, 'batch_size': 29, 'step_size': 9, 'gamma': 0.7665206465827565}. Best is trial 14 with value: 0.0477562697741103.[0m
[32m[I 2025-02-04 23:09:40,760][0m Trial 26 finished with value: 0.14120605933949312 and parameters: {'observation_period_num': 63, 'train_rates': 0.8690087355291428, 'learning_rate': 3.424257620111151e-05, 'batch_size': 184, 'step_size': 11, 'gamma': 0.8001609911383187}. Best is trial 14 with value: 0.0477562697741103.[0m
[32m[I 2025-02-04 23:11:48,466][0m Trial 27 finished with value: 0.045293505980887196 and parameters: {'observation_period_num': 28, 'train_rates': 0.8198559659573625, 'learning_rate': 0.0001854211423145046, 'batch_size': 42, 'step_size': 7, 'gamma': 0.7756402918103541}. Best is trial 27 with value: 0.045293505980887196.[0m
[32m[I 2025-02-04 23:13:58,416][0m Trial 28 finished with value: 0.055510628383484646 and parameters: {'observation_period_num': 37, 'train_rates': 0.8221924344550738, 'learning_rate': 0.00021802769850531975, 'batch_size': 41, 'step_size': 6, 'gamma': 0.7740618314486114}. Best is trial 27 with value: 0.045293505980887196.[0m
[32m[I 2025-02-04 23:16:02,215][0m Trial 29 finished with value: 0.0454548600105548 and parameters: {'observation_period_num': 27, 'train_rates': 0.816578178577699, 'learning_rate': 0.0004956341985012645, 'batch_size': 43, 'step_size': 5, 'gamma': 0.8388372465621904}. Best is trial 27 with value: 0.045293505980887196.[0m
[32m[I 2025-02-04 23:18:21,863][0m Trial 30 finished with value: 0.04465299580522158 and parameters: {'observation_period_num': 31, 'train_rates': 0.8156535469154977, 'learning_rate': 0.0005625795082313339, 'batch_size': 38, 'step_size': 4, 'gamma': 0.8445571672883917}. Best is trial 30 with value: 0.04465299580522158.[0m
[32m[I 2025-02-04 23:20:19,375][0m Trial 31 finished with value: 0.04720263607544071 and parameters: {'observation_period_num': 22, 'train_rates': 0.8216119640653035, 'learning_rate': 0.0005445085434027194, 'batch_size': 46, 'step_size': 4, 'gamma': 0.838462215170425}. Best is trial 30 with value: 0.04465299580522158.[0m
[32m[I 2025-02-04 23:22:16,203][0m Trial 32 finished with value: 0.0536455842813744 and parameters: {'observation_period_num': 24, 'train_rates': 0.8170831187305192, 'learning_rate': 0.0004828616786999512, 'batch_size': 46, 'step_size': 4, 'gamma': 0.8426256144318457}. Best is trial 30 with value: 0.04465299580522158.[0m
[32m[I 2025-02-04 23:23:50,742][0m Trial 33 finished with value: 0.04825201675377257 and parameters: {'observation_period_num': 26, 'train_rates': 0.8125993023108861, 'learning_rate': 0.0007013444223393353, 'batch_size': 58, 'step_size': 1, 'gamma': 0.8814160680411037}. Best is trial 30 with value: 0.04465299580522158.[0m
[32m[I 2025-02-04 23:25:59,365][0m Trial 34 finished with value: 0.1647774321390382 and parameters: {'observation_period_num': 20, 'train_rates': 0.7600069687863912, 'learning_rate': 0.00038875861013905685, 'batch_size': 40, 'step_size': 4, 'gamma': 0.8515515039047958}. Best is trial 30 with value: 0.04465299580522158.[0m
[32m[I 2025-02-04 23:27:12,634][0m Trial 35 finished with value: 0.12756735297920402 and parameters: {'observation_period_num': 190, 'train_rates': 0.834406613860901, 'learning_rate': 0.0007232006736224023, 'batch_size': 71, 'step_size': 3, 'gamma': 0.8795029782076967}. Best is trial 30 with value: 0.04465299580522158.[0m
[32m[I 2025-02-04 23:28:50,986][0m Trial 36 finished with value: 0.11965365746780725 and parameters: {'observation_period_num': 66, 'train_rates': 0.8675169667559419, 'learning_rate': 0.0005705624370841714, 'batch_size': 56, 'step_size': 5, 'gamma': 0.8250345344004085}. Best is trial 30 with value: 0.04465299580522158.[0m
[32m[I 2025-02-04 23:31:30,513][0m Trial 37 finished with value: 0.03496870857737572 and parameters: {'observation_period_num': 15, 'train_rates': 0.8034434960794363, 'learning_rate': 0.00026125872966775054, 'batch_size': 33, 'step_size': 3, 'gamma': 0.8244101962709038}. Best is trial 37 with value: 0.03496870857737572.[0m
[32m[I 2025-02-04 23:34:01,387][0m Trial 38 finished with value: 0.15258015615279685 and parameters: {'observation_period_num': 33, 'train_rates': 0.708480751152204, 'learning_rate': 0.00025541938992424085, 'batch_size': 32, 'step_size': 3, 'gamma': 0.8195748442057935}. Best is trial 37 with value: 0.03496870857737572.[0m
Early stopping at epoch 92
[32m[I 2025-02-04 23:37:57,521][0m Trial 39 finished with value: 0.13357327860521984 and parameters: {'observation_period_num': 92, 'train_rates': 0.7971928699724188, 'learning_rate': 9.031926146353893e-05, 'batch_size': 20, 'step_size': 1, 'gamma': 0.8080378749215262}. Best is trial 37 with value: 0.03496870857737572.[0m
[32m[I 2025-02-04 23:39:12,270][0m Trial 40 finished with value: 0.14686493584801197 and parameters: {'observation_period_num': 14, 'train_rates': 0.7395118882052832, 'learning_rate': 0.0003787013381605457, 'batch_size': 68, 'step_size': 5, 'gamma': 0.8508188380858184}. Best is trial 37 with value: 0.03496870857737572.[0m
[32m[I 2025-02-04 23:41:03,137][0m Trial 41 finished with value: 0.04066223161170344 and parameters: {'observation_period_num': 16, 'train_rates': 0.8426710541632201, 'learning_rate': 0.0004246867355925299, 'batch_size': 50, 'step_size': 2, 'gamma': 0.8337764263468213}. Best is trial 37 with value: 0.03496870857737572.[0m
[32m[I 2025-02-04 23:42:50,592][0m Trial 42 finished with value: 0.046349367713683275 and parameters: {'observation_period_num': 17, 'train_rates': 0.8510608292311244, 'learning_rate': 0.00035124035689225745, 'batch_size': 52, 'step_size': 2, 'gamma': 0.8311392335408114}. Best is trial 37 with value: 0.03496870857737572.[0m
[32m[I 2025-02-04 23:45:24,811][0m Trial 43 finished with value: 0.04928169448253692 and parameters: {'observation_period_num': 32, 'train_rates': 0.7963221765657901, 'learning_rate': 0.0002505920212149145, 'batch_size': 34, 'step_size': 3, 'gamma': 0.8753864664636967}. Best is trial 37 with value: 0.03496870857737572.[0m
[32m[I 2025-02-04 23:50:51,924][0m Trial 44 finished with value: 0.060558112019212254 and parameters: {'observation_period_num': 70, 'train_rates': 0.8363831191507053, 'learning_rate': 5.4145316136815555e-05, 'batch_size': 16, 'step_size': 2, 'gamma': 0.8928688799992581}. Best is trial 37 with value: 0.03496870857737572.[0m
[32m[I 2025-02-04 23:52:26,113][0m Trial 45 finished with value: 0.2795865909395703 and parameters: {'observation_period_num': 239, 'train_rates': 0.7575742201884337, 'learning_rate': 0.00011203577330527339, 'batch_size': 51, 'step_size': 7, 'gamma': 0.7896457070395776}. Best is trial 37 with value: 0.03496870857737572.[0m
[32m[I 2025-02-04 23:54:57,639][0m Trial 46 finished with value: 0.1639317639172077 and parameters: {'observation_period_num': 12, 'train_rates': 0.7811258274798097, 'learning_rate': 0.0007416161190359046, 'batch_size': 34, 'step_size': 3, 'gamma': 0.8122808308334948}. Best is trial 37 with value: 0.03496870857737572.[0m
[32m[I 2025-02-04 23:55:39,460][0m Trial 47 finished with value: 0.0722709199590824 and parameters: {'observation_period_num': 56, 'train_rates': 0.8658352107755309, 'learning_rate': 0.0009780118658952704, 'batch_size': 141, 'step_size': 5, 'gamma': 0.9111583450971821}. Best is trial 37 with value: 0.03496870857737572.[0m
[32m[I 2025-02-04 23:56:07,077][0m Trial 48 finished with value: 0.2595087771032219 and parameters: {'observation_period_num': 166, 'train_rates': 0.7126564513804504, 'learning_rate': 0.00021155967750743869, 'batch_size': 191, 'step_size': 6, 'gamma': 0.8621811277959572}. Best is trial 37 with value: 0.03496870857737572.[0m
Early stopping at epoch 64
[32m[I 2025-02-04 23:56:52,321][0m Trial 49 finished with value: 0.20276124777670876 and parameters: {'observation_period_num': 6, 'train_rates': 0.7765706007876472, 'learning_rate': 0.000369985067541327, 'batch_size': 78, 'step_size': 1, 'gamma': 0.8062338511376441}. Best is trial 37 with value: 0.03496870857737572.[0m
最適ハイパーパラメータが見つかりました
最適なハイパーパラメータが best_hyperparameters_GOOG_iTransformer_noMSTL.json に保存されました
Epoch 1/300, Loss: 0.3367 | 0.1843
Epoch 2/300, Loss: 0.1426 | 0.1531
Epoch 3/300, Loss: 0.1230 | 0.1121
Epoch 4/300, Loss: 0.1129 | 0.0862
Epoch 5/300, Loss: 0.1088 | 0.0784
Epoch 6/300, Loss: 0.1075 | 0.0763
Epoch 7/300, Loss: 0.1056 | 0.0793
Epoch 8/300, Loss: 0.1090 | 0.0649
Epoch 9/300, Loss: 0.1023 | 0.0675
Epoch 10/300, Loss: 0.1020 | 0.0623
Epoch 11/300, Loss: 0.0989 | 0.0626
Epoch 12/300, Loss: 0.0961 | 0.0602
Epoch 13/300, Loss: 0.0936 | 0.0584
Epoch 14/300, Loss: 0.0914 | 0.0565
Epoch 15/300, Loss: 0.0901 | 0.0552
Epoch 16/300, Loss: 0.0897 | 0.0561
Epoch 17/300, Loss: 0.0891 | 0.0556
Epoch 18/300, Loss: 0.0880 | 0.0556
Epoch 19/300, Loss: 0.0870 | 0.0548
Epoch 20/300, Loss: 0.0860 | 0.0539
Epoch 21/300, Loss: 0.0852 | 0.0528
Epoch 22/300, Loss: 0.0849 | 0.0522
Epoch 23/300, Loss: 0.0848 | 0.0515
Epoch 24/300, Loss: 0.0845 | 0.0511
Epoch 25/300, Loss: 0.0842 | 0.0506
Epoch 26/300, Loss: 0.0838 | 0.0500
Epoch 27/300, Loss: 0.0834 | 0.0497
Epoch 28/300, Loss: 0.0831 | 0.0496
Epoch 29/300, Loss: 0.0828 | 0.0493
Epoch 30/300, Loss: 0.0826 | 0.0492
Epoch 31/300, Loss: 0.0825 | 0.0491
Epoch 32/300, Loss: 0.0823 | 0.0489
Epoch 33/300, Loss: 0.0822 | 0.0487
Epoch 34/300, Loss: 0.0820 | 0.0485
Epoch 35/300, Loss: 0.0819 | 0.0484
Epoch 36/300, Loss: 0.0818 | 0.0482
Epoch 37/300, Loss: 0.0817 | 0.0481
Epoch 38/300, Loss: 0.0816 | 0.0480
Epoch 39/300, Loss: 0.0816 | 0.0479
Epoch 40/300, Loss: 0.0815 | 0.0478
Epoch 41/300, Loss: 0.0814 | 0.0478
Epoch 42/300, Loss: 0.0814 | 0.0477
Epoch 43/300, Loss: 0.0813 | 0.0477
Epoch 44/300, Loss: 0.0812 | 0.0477
Epoch 45/300, Loss: 0.0812 | 0.0477
Epoch 46/300, Loss: 0.0811 | 0.0477
Epoch 47/300, Loss: 0.0811 | 0.0476
Epoch 48/300, Loss: 0.0811 | 0.0476
Epoch 49/300, Loss: 0.0810 | 0.0476
Epoch 50/300, Loss: 0.0810 | 0.0476
Epoch 51/300, Loss: 0.0810 | 0.0476
Epoch 52/300, Loss: 0.0810 | 0.0476
Epoch 53/300, Loss: 0.0810 | 0.0476
Epoch 54/300, Loss: 0.0810 | 0.0476
Epoch 55/300, Loss: 0.0809 | 0.0476
Epoch 56/300, Loss: 0.0809 | 0.0476
Epoch 57/300, Loss: 0.0809 | 0.0476
Epoch 58/300, Loss: 0.0809 | 0.0476
Epoch 59/300, Loss: 0.0809 | 0.0476
Epoch 60/300, Loss: 0.0809 | 0.0475
Epoch 61/300, Loss: 0.0809 | 0.0475
Epoch 62/300, Loss: 0.0809 | 0.0475
Epoch 63/300, Loss: 0.0809 | 0.0475
Epoch 64/300, Loss: 0.0809 | 0.0475
Epoch 65/300, Loss: 0.0809 | 0.0475
Epoch 66/300, Loss: 0.0809 | 0.0475
Epoch 67/300, Loss: 0.0809 | 0.0475
Epoch 68/300, Loss: 0.0809 | 0.0475
Epoch 69/300, Loss: 0.0809 | 0.0475
Epoch 70/300, Loss: 0.0809 | 0.0475
Epoch 71/300, Loss: 0.0809 | 0.0475
Epoch 72/300, Loss: 0.0809 | 0.0475
Epoch 73/300, Loss: 0.0809 | 0.0475
Epoch 74/300, Loss: 0.0809 | 0.0475
Epoch 75/300, Loss: 0.0809 | 0.0475
Epoch 76/300, Loss: 0.0809 | 0.0475
Epoch 77/300, Loss: 0.0809 | 0.0475
Epoch 78/300, Loss: 0.0809 | 0.0475
Epoch 79/300, Loss: 0.0809 | 0.0475
Epoch 80/300, Loss: 0.0809 | 0.0475
Epoch 81/300, Loss: 0.0809 | 0.0475
Epoch 82/300, Loss: 0.0809 | 0.0475
Epoch 83/300, Loss: 0.0809 | 0.0475
Epoch 84/300, Loss: 0.0809 | 0.0475
Epoch 85/300, Loss: 0.0809 | 0.0475
Epoch 86/300, Loss: 0.0809 | 0.0475
Epoch 87/300, Loss: 0.0809 | 0.0475
Epoch 88/300, Loss: 0.0809 | 0.0475
Epoch 89/300, Loss: 0.0809 | 0.0475
Epoch 90/300, Loss: 0.0809 | 0.0475
Epoch 91/300, Loss: 0.0809 | 0.0475
Epoch 92/300, Loss: 0.0809 | 0.0475
Epoch 93/300, Loss: 0.0809 | 0.0475
Epoch 94/300, Loss: 0.0809 | 0.0475
Epoch 95/300, Loss: 0.0809 | 0.0475
Epoch 96/300, Loss: 0.0809 | 0.0475
Epoch 97/300, Loss: 0.0809 | 0.0475
Epoch 98/300, Loss: 0.0809 | 0.0475
Epoch 99/300, Loss: 0.0809 | 0.0475
Epoch 100/300, Loss: 0.0809 | 0.0475
Epoch 101/300, Loss: 0.0809 | 0.0475
Epoch 102/300, Loss: 0.0809 | 0.0475
Epoch 103/300, Loss: 0.0809 | 0.0475
Epoch 104/300, Loss: 0.0809 | 0.0475
Epoch 105/300, Loss: 0.0809 | 0.0475
Epoch 106/300, Loss: 0.0809 | 0.0475
Epoch 107/300, Loss: 0.0809 | 0.0475
Epoch 108/300, Loss: 0.0809 | 0.0475
Epoch 109/300, Loss: 0.0809 | 0.0475
Epoch 110/300, Loss: 0.0809 | 0.0475
Epoch 111/300, Loss: 0.0809 | 0.0475
Epoch 112/300, Loss: 0.0809 | 0.0475
Epoch 113/300, Loss: 0.0809 | 0.0475
Epoch 114/300, Loss: 0.0809 | 0.0475
Epoch 115/300, Loss: 0.0809 | 0.0475
Epoch 116/300, Loss: 0.0809 | 0.0475
Epoch 117/300, Loss: 0.0809 | 0.0475
Epoch 118/300, Loss: 0.0809 | 0.0475
Epoch 119/300, Loss: 0.0809 | 0.0475
Epoch 120/300, Loss: 0.0809 | 0.0475
Epoch 121/300, Loss: 0.0809 | 0.0475
Epoch 122/300, Loss: 0.0809 | 0.0475
Epoch 123/300, Loss: 0.0809 | 0.0475
Epoch 124/300, Loss: 0.0809 | 0.0475
Epoch 125/300, Loss: 0.0809 | 0.0475
Epoch 126/300, Loss: 0.0809 | 0.0475
Epoch 127/300, Loss: 0.0809 | 0.0475
Epoch 128/300, Loss: 0.0809 | 0.0475
Epoch 129/300, Loss: 0.0809 | 0.0475
Epoch 130/300, Loss: 0.0809 | 0.0475
Epoch 131/300, Loss: 0.0809 | 0.0475
Epoch 132/300, Loss: 0.0809 | 0.0475
Epoch 133/300, Loss: 0.0809 | 0.0475
Epoch 134/300, Loss: 0.0809 | 0.0475
Epoch 135/300, Loss: 0.0809 | 0.0475
Epoch 136/300, Loss: 0.0809 | 0.0475
Epoch 137/300, Loss: 0.0809 | 0.0475
Epoch 138/300, Loss: 0.0809 | 0.0475
Epoch 139/300, Loss: 0.0809 | 0.0475
Epoch 140/300, Loss: 0.0809 | 0.0475
Epoch 141/300, Loss: 0.0809 | 0.0475
Epoch 142/300, Loss: 0.0809 | 0.0475
Early stopping
Runtime (seconds): 225.9505729675293
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)
MSE: 1.0013126863632351
RMSE: 1.0006561279296875
MAE: 1.0006561279296875
R-squared: nan
[173.78464]
