Using device: cuda
[*********************100%***********************]  1 of 1 completed
Ticker                           AAPL
Date
2012-05-18 00:00:00+00:00   15.996168
2012-05-21 00:00:00+00:00   16.928102
2012-05-22 00:00:00+00:00   16.798124
2012-05-23 00:00:00+00:00   17.207989
2012-05-24 00:00:00+00:00   17.049955
...                               ...
2023-05-24 00:00:00+00:00  170.734604
2023-05-25 00:00:00+00:00  171.877213
2023-05-26 00:00:00+00:00  174.301483
2023-05-30 00:00:00+00:00  176.159470
2023-05-31 00:00:00+00:00  176.109802

[2776 rows x 1 columns]
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[*********************100%***********************]  1 of 1 completed
[32m[I 2024-11-05 21:50:50,884][0m A new study created in memory with name: no-name-52bc3c82-57ca-4a21-ab66-72c14673ceff[0m
/data/student/k2110261/Multi-iTransformer/optunademo.py:117: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-3)
Non-A100 GPU detected, using math or mem efficient attention if input tensor is on cuda
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/contextlib.py:105: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.
  self.gen = func(*args, **kwds)
[32m[I 2024-11-05 21:52:42,782][0m Trial 0 finished with value: 0.12688933312892914 and parameters: {'learning_rate': 3.5726481531036095e-06, 'batch_size': 61, 'step_size': 10, 'gamma': 0.7660901649685558, 'depth': 6, 'dim': 134}. Best is trial 0 with value: 0.12688933312892914.[0m
[32m[I 2024-11-05 21:53:54,597][0m Trial 1 finished with value: 0.21788956224918365 and parameters: {'learning_rate': 2.097308655558091e-06, 'batch_size': 94, 'step_size': 12, 'gamma': 0.7666969881945322, 'depth': 6, 'dim': 188}. Best is trial 0 with value: 0.12688933312892914.[0m
[32m[I 2024-11-05 21:55:37,244][0m Trial 2 finished with value: 0.01000259444117546 and parameters: {'learning_rate': 3.2152670148190094e-05, 'batch_size': 38, 'step_size': 5, 'gamma': 0.8766888207519654, 'depth': 3, 'dim': 121}. Best is trial 2 with value: 0.01000259444117546.[0m
[32m[I 2024-11-05 21:56:01,909][0m Trial 3 finished with value: 0.028360851109027863 and parameters: {'learning_rate': 6.336804671036594e-05, 'batch_size': 253, 'step_size': 7, 'gamma': 0.8664191349252391, 'depth': 5, 'dim': 92}. Best is trial 2 with value: 0.01000259444117546.[0m
[32m[I 2024-11-05 21:56:44,556][0m Trial 4 finished with value: 0.00809408351778984 and parameters: {'learning_rate': 6.535571779501741e-05, 'batch_size': 119, 'step_size': 14, 'gamma': 0.7806174352713355, 'depth': 4, 'dim': 202}. Best is trial 4 with value: 0.00809408351778984.[0m
[32m[I 2024-11-05 21:57:02,958][0m Trial 5 finished with value: 0.010173387825489044 and parameters: {'learning_rate': 0.0006107979562993306, 'batch_size': 237, 'step_size': 15, 'gamma': 0.8102873952115978, 'depth': 3, 'dim': 129}. Best is trial 4 with value: 0.00809408351778984.[0m
[32m[I 2024-11-05 21:57:43,219][0m Trial 6 finished with value: 0.4093327224254608 and parameters: {'learning_rate': 1.8888654659698343e-06, 'batch_size': 174, 'step_size': 1, 'gamma': 0.9482945642532635, 'depth': 6, 'dim': 221}. Best is trial 4 with value: 0.00809408351778984.[0m
[32m[I 2024-11-05 21:57:58,743][0m Trial 7 finished with value: 0.39941900968551636 and parameters: {'learning_rate': 1.0901034235338292e-06, 'batch_size': 198, 'step_size': 8, 'gamma': 0.8824033686766762, 'depth': 2, 'dim': 109}. Best is trial 4 with value: 0.00809408351778984.[0m
[32m[I 2024-11-05 21:59:32,582][0m Trial 8 finished with value: 0.010884508490562439 and parameters: {'learning_rate': 0.0006754152700496496, 'batch_size': 73, 'step_size': 6, 'gamma': 0.7629760191493132, 'depth': 6, 'dim': 194}. Best is trial 4 with value: 0.00809408351778984.[0m
[32m[I 2024-11-05 22:00:44,206][0m Trial 9 finished with value: 0.1263396292924881 and parameters: {'learning_rate': 4.109347594852875e-06, 'batch_size': 96, 'step_size': 13, 'gamma': 0.8980441338290174, 'depth': 6, 'dim': 46}. Best is trial 4 with value: 0.00809408351778984.[0m
[32m[I 2024-11-05 22:01:17,857][0m Trial 10 finished with value: 0.009213242679834366 and parameters: {'learning_rate': 0.0001271099625910615, 'batch_size': 154, 'step_size': 15, 'gamma': 0.8144277133720342, 'depth': 4, 'dim': 236}. Best is trial 4 with value: 0.00809408351778984.[0m
[32m[I 2024-11-05 22:01:58,657][0m Trial 11 finished with value: 0.009749487973749638 and parameters: {'learning_rate': 0.00013539757974664855, 'batch_size': 129, 'step_size': 15, 'gamma': 0.8171213654766187, 'depth': 4, 'dim': 253}. Best is trial 4 with value: 0.00809408351778984.[0m
[32m[I 2024-11-05 22:02:34,368][0m Trial 12 finished with value: 0.008610308170318604 and parameters: {'learning_rate': 0.00016266746138651127, 'batch_size': 148, 'step_size': 12, 'gamma': 0.8185562795141087, 'depth': 4, 'dim': 184}. Best is trial 4 with value: 0.00809408351778984.[0m
[32m[I 2024-11-05 22:03:04,261][0m Trial 13 finished with value: 0.05323703587055206 and parameters: {'learning_rate': 1.772726114909903e-05, 'batch_size': 139, 'step_size': 11, 'gamma': 0.8400990721527569, 'depth': 3, 'dim': 174}. Best is trial 4 with value: 0.00809408351778984.[0m
[32m[I 2024-11-05 22:03:35,337][0m Trial 14 finished with value: 0.007958981208503246 and parameters: {'learning_rate': 0.00023462725135717534, 'batch_size': 205, 'step_size': 10, 'gamma': 0.7923466259510645, 'depth': 5, 'dim': 163}. Best is trial 14 with value: 0.007958981208503246.[0m
[32m[I 2024-11-05 22:04:06,455][0m Trial 15 finished with value: 0.10566208511590958 and parameters: {'learning_rate': 1.231588768716882e-05, 'batch_size': 207, 'step_size': 9, 'gamma': 0.7886214884603769, 'depth': 5, 'dim': 157}. Best is trial 14 with value: 0.007958981208503246.[0m
[32m[I 2024-11-05 22:04:35,471][0m Trial 16 finished with value: 0.009510859847068787 and parameters: {'learning_rate': 0.00020489656849167305, 'batch_size': 216, 'step_size': 3, 'gamma': 0.9390202261150401, 'depth': 5, 'dim': 214}. Best is trial 14 with value: 0.007958981208503246.[0m
[32m[I 2024-11-05 22:05:29,886][0m Trial 17 finished with value: 0.0050771646201610565 and parameters: {'learning_rate': 0.00035032464068416154, 'batch_size': 113, 'step_size': 13, 'gamma': 0.9883674512333436, 'depth': 5, 'dim': 156}. Best is trial 17 with value: 0.0050771646201610565.[0m
[32m[I 2024-11-05 22:06:03,195][0m Trial 18 finished with value: 0.07032809406518936 and parameters: {'learning_rate': 0.00037224735823149175, 'batch_size': 183, 'step_size': 10, 'gamma': 0.9867640426973939, 'depth': 5, 'dim': 63}. Best is trial 17 with value: 0.0050771646201610565.[0m
[32m[I 2024-11-05 22:09:23,063][0m Trial 19 finished with value: 2.3790266513824463 and parameters: {'learning_rate': 0.0008794333450618199, 'batch_size': 29, 'step_size': 13, 'gamma': 0.9199919031230994, 'depth': 5, 'dim': 157}. Best is trial 17 with value: 0.0050771646201610565.[0m
[32m[I 2024-11-05 22:10:19,131][0m Trial 20 finished with value: 0.11130528151988983 and parameters: {'learning_rate': 0.0003569273854963332, 'batch_size': 107, 'step_size': 8, 'gamma': 0.9877321749160326, 'depth': 5, 'dim': 20}. Best is trial 17 with value: 0.0050771646201610565.[0m
[32m[I 2024-11-05 22:11:01,740][0m Trial 21 finished with value: 0.011027870699763298 and parameters: {'learning_rate': 5.799294327428675e-05, 'batch_size': 114, 'step_size': 13, 'gamma': 0.84709274168042, 'depth': 4, 'dim': 148}. Best is trial 17 with value: 0.0050771646201610565.[0m
[32m[I 2024-11-05 22:11:33,572][0m Trial 22 finished with value: 0.01387725304812193 and parameters: {'learning_rate': 6.660576013146193e-05, 'batch_size': 165, 'step_size': 14, 'gamma': 0.7853841826586495, 'depth': 4, 'dim': 212}. Best is trial 17 with value: 0.0050771646201610565.[0m
[32m[I 2024-11-05 22:12:21,962][0m Trial 23 finished with value: 0.008770283311605453 and parameters: {'learning_rate': 0.00027578655412928557, 'batch_size': 124, 'step_size': 11, 'gamma': 0.7935146424121128, 'depth': 5, 'dim': 168}. Best is trial 17 with value: 0.0050771646201610565.[0m
[32m[I 2024-11-05 22:13:11,838][0m Trial 24 finished with value: 0.005880520213395357 and parameters: {'learning_rate': 9.577825374259347e-05, 'batch_size': 80, 'step_size': 12, 'gamma': 0.750098055474121, 'depth': 3, 'dim': 98}. Best is trial 17 with value: 0.0050771646201610565.[0m
[32m[I 2024-11-05 22:13:48,678][0m Trial 25 finished with value: 0.004093529656529427 and parameters: {'learning_rate': 0.0004603331986762368, 'batch_size': 77, 'step_size': 11, 'gamma': 0.7528232363709876, 'depth': 2, 'dim': 86}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:14:27,434][0m Trial 26 finished with value: 0.005920142866671085 and parameters: {'learning_rate': 0.0005305942986888307, 'batch_size': 70, 'step_size': 12, 'gamma': 0.7547091781234522, 'depth': 2, 'dim': 95}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:15:25,682][0m Trial 27 finished with value: 0.01825338415801525 and parameters: {'learning_rate': 0.0001105030132083157, 'batch_size': 49, 'step_size': 11, 'gamma': 0.9501978425215291, 'depth': 2, 'dim': 74}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:16:15,504][0m Trial 28 finished with value: 0.03516324236989021 and parameters: {'learning_rate': 0.0004228745456052549, 'batch_size': 82, 'step_size': 9, 'gamma': 0.9710357090148214, 'depth': 3, 'dim': 105}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:17:05,744][0m Trial 29 finished with value: 0.09577800333499908 and parameters: {'learning_rate': 0.0009882104341301019, 'batch_size': 57, 'step_size': 9, 'gamma': 0.9140491813627822, 'depth': 2, 'dim': 73}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:17:49,745][0m Trial 30 finished with value: 0.01962573453783989 and parameters: {'learning_rate': 3.0142941489010207e-05, 'batch_size': 93, 'step_size': 10, 'gamma': 0.7525858174905687, 'depth': 3, 'dim': 137}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:18:30,919][0m Trial 31 finished with value: 0.006774174980819225 and parameters: {'learning_rate': 0.0006548596500406004, 'batch_size': 71, 'step_size': 12, 'gamma': 0.7513908568658332, 'depth': 2, 'dim': 91}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:21:13,133][0m Trial 32 finished with value: 0.02107035860951458 and parameters: {'learning_rate': 0.00033639631367382095, 'batch_size': 17, 'step_size': 12, 'gamma': 0.7722109687563737, 'depth': 2, 'dim': 55}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:21:47,347][0m Trial 33 finished with value: 0.0098264766857028 and parameters: {'learning_rate': 8.989022469260761e-05, 'batch_size': 83, 'step_size': 14, 'gamma': 0.7651017059600784, 'depth': 2, 'dim': 114}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:23:14,694][0m Trial 34 finished with value: 0.009528320282697678 and parameters: {'learning_rate': 0.0004783137010991694, 'batch_size': 45, 'step_size': 13, 'gamma': 0.8367523220725944, 'depth': 3, 'dim': 93}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:24:21,133][0m Trial 35 finished with value: 0.006232743617147207 and parameters: {'learning_rate': 0.00021123607549280822, 'batch_size': 60, 'step_size': 11, 'gamma': 0.7739099500505225, 'depth': 3, 'dim': 37}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:24:52,011][0m Trial 36 finished with value: 0.010041305795311928 and parameters: {'learning_rate': 0.0005040293368871357, 'batch_size': 96, 'step_size': 12, 'gamma': 0.8025571915544941, 'depth': 2, 'dim': 140}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:25:32,227][0m Trial 37 finished with value: 0.027746573090553284 and parameters: {'learning_rate': 3.510064776452984e-05, 'batch_size': 72, 'step_size': 14, 'gamma': 0.7502294903004003, 'depth': 2, 'dim': 85}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:26:10,595][0m Trial 38 finished with value: 0.011762802489101887 and parameters: {'learning_rate': 0.00017382387669562084, 'batch_size': 107, 'step_size': 7, 'gamma': 0.7636843205574527, 'depth': 3, 'dim': 99}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:28:01,898][0m Trial 39 finished with value: 0.0120059970899352 and parameters: {'learning_rate': 0.00027919057028254353, 'batch_size': 25, 'step_size': 12, 'gamma': 0.8654651405598379, 'depth': 2, 'dim': 122}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:28:48,684][0m Trial 40 finished with value: 0.005494711920619011 and parameters: {'learning_rate': 0.0007674398094032162, 'batch_size': 86, 'step_size': 4, 'gamma': 0.7781701301306965, 'depth': 3, 'dim': 124}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:29:34,182][0m Trial 41 finished with value: 0.015702037140727043 and parameters: {'learning_rate': 0.0008518420420222308, 'batch_size': 88, 'step_size': 2, 'gamma': 0.7779031115881194, 'depth': 3, 'dim': 129}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:30:14,026][0m Trial 42 finished with value: 0.004803563468158245 and parameters: {'learning_rate': 0.0005899542166519694, 'batch_size': 104, 'step_size': 5, 'gamma': 0.7636180057003539, 'depth': 3, 'dim': 113}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:30:52,460][0m Trial 43 finished with value: 0.008260615170001984 and parameters: {'learning_rate': 0.0006796205096290165, 'batch_size': 107, 'step_size': 3, 'gamma': 0.7653180457117635, 'depth': 3, 'dim': 115}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:31:31,605][0m Trial 44 finished with value: 0.00849729124456644 and parameters: {'learning_rate': 0.0006776082085864266, 'batch_size': 135, 'step_size': 4, 'gamma': 0.8030861398764534, 'depth': 4, 'dim': 144}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:32:11,494][0m Trial 45 finished with value: 0.2920399308204651 and parameters: {'learning_rate': 7.374418863175055e-06, 'batch_size': 102, 'step_size': 5, 'gamma': 0.8288942291606763, 'depth': 3, 'dim': 76}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:33:04,537][0m Trial 46 finished with value: 0.007965801283717155 and parameters: {'learning_rate': 0.0002999562854941979, 'batch_size': 120, 'step_size': 6, 'gamma': 0.8557614630119448, 'depth': 6, 'dim': 116}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:34:01,959][0m Trial 47 finished with value: 0.004652049858123064 and parameters: {'learning_rate': 9.543372977444253e-05, 'batch_size': 84, 'step_size': 5, 'gamma': 0.8903278619163311, 'depth': 4, 'dim': 128}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:34:37,328][0m Trial 48 finished with value: 0.01271731685847044 and parameters: {'learning_rate': 0.00042921494087917365, 'batch_size': 144, 'step_size': 5, 'gamma': 0.9235111934999048, 'depth': 4, 'dim': 131}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:35:18,275][0m Trial 49 finished with value: 0.009877887554466724 and parameters: {'learning_rate': 0.00015468267942227482, 'batch_size': 127, 'step_size': 4, 'gamma': 0.8831945432991853, 'depth': 4, 'dim': 183}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:36:55,479][0m Trial 50 finished with value: 2.341010570526123 and parameters: {'learning_rate': 0.0007976975711311123, 'batch_size': 51, 'step_size': 6, 'gamma': 0.968980555778042, 'depth': 4, 'dim': 106}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:37:42,466][0m Trial 51 finished with value: 0.01458310429006815 and parameters: {'learning_rate': 4.919322649602571e-05, 'batch_size': 85, 'step_size': 4, 'gamma': 0.8946477226443293, 'depth': 3, 'dim': 122}. Best is trial 25 with value: 0.004093529656529427.[0m
Early stopping
[32m[I 2024-11-05 22:38:05,465][0m Trial 52 finished with value: 0.13633830845355988 and parameters: {'learning_rate': 8.939857231808314e-05, 'batch_size': 68, 'step_size': 1, 'gamma': 0.7599762272659303, 'depth': 3, 'dim': 152}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:39:07,154][0m Trial 53 finished with value: 0.015511058270931244 and parameters: {'learning_rate': 0.00022098392495069783, 'batch_size': 79, 'step_size': 7, 'gamma': 0.7825888276973206, 'depth': 4, 'dim': 82}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:39:49,775][0m Trial 54 finished with value: 0.10580497235059738 and parameters: {'learning_rate': 3.739405755772129e-05, 'batch_size': 96, 'step_size': 3, 'gamma': 0.7742026839585885, 'depth': 3, 'dim': 104}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:40:49,652][0m Trial 55 finished with value: 0.021077999845147133 and parameters: {'learning_rate': 0.00011071905077892865, 'batch_size': 115, 'step_size': 5, 'gamma': 0.8001739139040633, 'depth': 6, 'dim': 127}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:42:28,080][0m Trial 56 finished with value: 0.1250566691160202 and parameters: {'learning_rate': 2.18209941071709e-05, 'batch_size': 60, 'step_size': 2, 'gamma': 0.9018463677633274, 'depth': 5, 'dim': 60}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:43:07,724][0m Trial 57 finished with value: 0.008772293105721474 and parameters: {'learning_rate': 0.0005372683928093233, 'batch_size': 103, 'step_size': 6, 'gamma': 0.8222666861929581, 'depth': 3, 'dim': 173}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:45:14,063][0m Trial 58 finished with value: 0.004319567698985338 and parameters: {'learning_rate': 7.55260044477883e-05, 'batch_size': 39, 'step_size': 15, 'gamma': 0.7943033102816999, 'depth': 4, 'dim': 161}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:47:57,616][0m Trial 59 finished with value: 0.014286071993410587 and parameters: {'learning_rate': 0.00036433690099110425, 'batch_size': 30, 'step_size': 14, 'gamma': 0.8095089085954776, 'depth': 4, 'dim': 195}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:50:14,812][0m Trial 60 finished with value: 0.012644675560295582 and parameters: {'learning_rate': 7.729398641432624e-05, 'batch_size': 42, 'step_size': 15, 'gamma': 0.7925807650757872, 'depth': 5, 'dim': 160}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:51:20,512][0m Trial 61 finished with value: 0.005356648005545139 and parameters: {'learning_rate': 5.00691425928614e-05, 'batch_size': 77, 'step_size': 13, 'gamma': 0.7611596292923298, 'depth': 4, 'dim': 148}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:52:04,726][0m Trial 62 finished with value: 0.012677337974309921 and parameters: {'learning_rate': 2.7261157749958873e-05, 'batch_size': 115, 'step_size': 15, 'gamma': 0.7830325127038388, 'depth': 4, 'dim': 137}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:54:25,688][0m Trial 63 finished with value: 0.005466418340802193 and parameters: {'learning_rate': 4.530459807575863e-05, 'batch_size': 35, 'step_size': 13, 'gamma': 0.7591988779005098, 'depth': 4, 'dim': 154}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:56:38,383][0m Trial 64 finished with value: 0.0052313366904854774 and parameters: {'learning_rate': 4.53615214379267e-05, 'batch_size': 37, 'step_size': 13, 'gamma': 0.7586045443799548, 'depth': 4, 'dim': 150}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 22:56:59,523][0m Trial 65 finished with value: 0.09324846416711807 and parameters: {'learning_rate': 1.4844886650898468e-05, 'batch_size': 255, 'step_size': 14, 'gamma': 0.7692336807203248, 'depth': 4, 'dim': 166}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 23:01:02,637][0m Trial 66 finished with value: 0.00896121361958129 and parameters: {'learning_rate': 5.9553298617198843e-05, 'batch_size': 20, 'step_size': 13, 'gamma': 0.9356969569756625, 'depth': 4, 'dim': 147}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 23:02:56,268][0m Trial 67 finished with value: 0.008213859051465988 and parameters: {'learning_rate': 4.559380629207596e-05, 'batch_size': 52, 'step_size': 15, 'gamma': 0.7597976644471685, 'depth': 5, 'dim': 178}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 23:04:11,059][0m Trial 68 finished with value: 0.08859432488679886 and parameters: {'learning_rate': 7.353751886176638e-05, 'batch_size': 67, 'step_size': 11, 'gamma': 0.9580822778073054, 'depth': 4, 'dim': 192}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 23:04:33,738][0m Trial 69 finished with value: 0.04373879358172417 and parameters: {'learning_rate': 2.428085423271171e-05, 'batch_size': 242, 'step_size': 14, 'gamma': 0.7890916592813613, 'depth': 4, 'dim': 170}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 23:06:58,680][0m Trial 70 finished with value: 0.004845614079385996 and parameters: {'learning_rate': 0.0001297638270156868, 'batch_size': 40, 'step_size': 7, 'gamma': 0.7686454987284889, 'depth': 5, 'dim': 159}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 23:09:42,292][0m Trial 71 finished with value: 0.005829351954162121 and parameters: {'learning_rate': 0.00013028928870228797, 'batch_size': 35, 'step_size': 7, 'gamma': 0.7686175819684166, 'depth': 5, 'dim': 142}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 23:12:12,015][0m Trial 72 finished with value: 0.018709536641836166 and parameters: {'learning_rate': 0.00017859488882750974, 'batch_size': 39, 'step_size': 9, 'gamma': 0.7571314500625939, 'depth': 5, 'dim': 161}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 23:13:55,503][0m Trial 73 finished with value: 0.005046635866165161 and parameters: {'learning_rate': 5.7573758328554335e-05, 'batch_size': 57, 'step_size': 13, 'gamma': 0.7706453282915264, 'depth': 5, 'dim': 151}. Best is trial 25 with value: 0.004093529656529427.[0m
[32m[I 2024-11-05 23:16:12,257][0m Trial 74 finished with value: 0.0038291425444185734 and parameters: {'learning_rate': 0.00010263483166563465, 'batch_size': 43, 'step_size': 8, 'gamma': 0.7960885354343817, 'depth': 5, 'dim': 135}. Best is trial 74 with value: 0.0038291425444185734.[0m
[32m[I 2024-11-05 23:18:01,520][0m Trial 75 finished with value: 0.004822975490242243 and parameters: {'learning_rate': 0.00011321309682098084, 'batch_size': 54, 'step_size': 7, 'gamma': 0.7956036854166516, 'depth': 5, 'dim': 134}. Best is trial 74 with value: 0.0038291425444185734.[0m
[32m[I 2024-11-05 23:19:59,056][0m Trial 76 finished with value: 0.0043684798292815685 and parameters: {'learning_rate': 0.00010163045090850204, 'batch_size': 50, 'step_size': 8, 'gamma': 0.799430666943282, 'depth': 5, 'dim': 132}. Best is trial 74 with value: 0.0038291425444185734.[0m
[32m[I 2024-11-05 23:22:26,079][0m Trial 77 finished with value: 0.006110911723226309 and parameters: {'learning_rate': 0.0001117935310371496, 'batch_size': 46, 'step_size': 8, 'gamma': 0.81107632370124, 'depth': 6, 'dim': 111}. Best is trial 74 with value: 0.0038291425444185734.[0m
[32m[I 2024-11-05 23:26:09,921][0m Trial 78 finished with value: 0.009900514502078295 and parameters: {'learning_rate': 0.00013802944487299558, 'batch_size': 26, 'step_size': 8, 'gamma': 0.8246508233154541, 'depth': 5, 'dim': 133}. Best is trial 74 with value: 0.0038291425444185734.[0m
[32m[I 2024-11-05 23:27:40,552][0m Trial 79 finished with value: 0.0049867182970047 and parameters: {'learning_rate': 9.310994111096874e-05, 'batch_size': 66, 'step_size': 7, 'gamma': 0.7975190413660554, 'depth': 5, 'dim': 117}. Best is trial 74 with value: 0.0038291425444185734.[0m
[32m[I 2024-11-05 23:29:31,620][0m Trial 80 finished with value: 0.1644069403409958 and parameters: {'learning_rate': 1.0717401275180168e-06, 'batch_size': 53, 'step_size': 8, 'gamma': 0.8788342127792774, 'depth': 5, 'dim': 136}. Best is trial 74 with value: 0.0038291425444185734.[0m
[32m[I 2024-11-05 23:31:02,197][0m Trial 81 finished with value: 0.005119300913065672 and parameters: {'learning_rate': 8.502164216526047e-05, 'batch_size': 65, 'step_size': 7, 'gamma': 0.8003593131924795, 'depth': 5, 'dim': 125}. Best is trial 74 with value: 0.0038291425444185734.[0m
[32m[I 2024-11-05 23:33:14,167][0m Trial 82 finished with value: 0.0074039120227098465 and parameters: {'learning_rate': 0.00010169151154950419, 'batch_size': 44, 'step_size': 9, 'gamma': 0.7962728033498525, 'depth': 5, 'dim': 116}. Best is trial 74 with value: 0.0038291425444185734.[0m
[32m[I 2024-11-05 23:34:34,114][0m Trial 83 finished with value: 0.004230089485645294 and parameters: {'learning_rate': 0.00024564247027666864, 'batch_size': 75, 'step_size': 7, 'gamma': 0.8063364294863127, 'depth': 5, 'dim': 119}. Best is trial 74 with value: 0.0038291425444185734.[0m
[32m[I 2024-11-05 23:35:39,196][0m Trial 84 finished with value: 0.006176714785397053 and parameters: {'learning_rate': 0.00026636548233733063, 'batch_size': 92, 'step_size': 6, 'gamma': 0.8073979203020814, 'depth': 5, 'dim': 102}. Best is trial 74 with value: 0.0038291425444185734.[0m
[32m[I 2024-11-05 23:36:56,927][0m Trial 85 finished with value: 0.004923832602798939 and parameters: {'learning_rate': 0.00019742196622637423, 'batch_size': 77, 'step_size': 8, 'gamma': 0.790167778331061, 'depth': 5, 'dim': 89}. Best is trial 74 with value: 0.0038291425444185734.[0m
[32m[I 2024-11-05 23:38:52,930][0m Trial 86 finished with value: 0.004565061070024967 and parameters: {'learning_rate': 0.0001539156727641991, 'batch_size': 58, 'step_size': 6, 'gamma': 0.8146370651496991, 'depth': 6, 'dim': 142}. Best is trial 74 with value: 0.0038291425444185734.[0m
[32m[I 2024-11-05 23:40:53,264][0m Trial 87 finished with value: 0.003879527561366558 and parameters: {'learning_rate': 0.0001696638158835505, 'batch_size': 56, 'step_size': 10, 'gamma': 0.8133542783599014, 'depth': 6, 'dim': 110}. Best is trial 74 with value: 0.0038291425444185734.[0m
[32m[I 2024-11-05 23:42:27,332][0m Trial 88 finished with value: 0.005125222261995077 and parameters: {'learning_rate': 0.00023486237421316581, 'batch_size': 73, 'step_size': 10, 'gamma': 0.8312432782504839, 'depth': 6, 'dim': 109}. Best is trial 74 with value: 0.0038291425444185734.[0m
[32m[I 2024-11-05 23:44:13,290][0m Trial 89 finished with value: 0.005872882436960936 and parameters: {'learning_rate': 0.00016057872141766734, 'batch_size': 63, 'step_size': 5, 'gamma': 0.8163285773608909, 'depth': 6, 'dim': 97}. Best is trial 74 with value: 0.0038291425444185734.[0m
[32m[I 2024-11-05 23:46:04,938][0m Trial 90 finished with value: 0.011070542968809605 and parameters: {'learning_rate': 0.0003208353233707598, 'batch_size': 58, 'step_size': 6, 'gamma': 0.8470610040051687, 'depth': 6, 'dim': 120}. Best is trial 74 with value: 0.0038291425444185734.[0m
[32m[I 2024-11-05 23:48:10,220][0m Trial 91 finished with value: 0.00464087538421154 and parameters: {'learning_rate': 0.00025335234986734667, 'batch_size': 54, 'step_size': 6, 'gamma': 0.8060549627862968, 'depth': 6, 'dim': 129}. Best is trial 74 with value: 0.0038291425444185734.[0m
[32m[I 2024-11-05 23:50:32,367][0m Trial 92 finished with value: 0.007046893239021301 and parameters: {'learning_rate': 0.00044323398378927104, 'batch_size': 47, 'step_size': 6, 'gamma': 0.8054873350117415, 'depth': 6, 'dim': 142}. Best is trial 74 with value: 0.0038291425444185734.[0m
[32m[I 2024-11-05 23:52:06,425][0m Trial 93 finished with value: 0.004307568073272705 and parameters: {'learning_rate': 0.00025748376927244964, 'batch_size': 73, 'step_size': 10, 'gamma': 0.8230503273021914, 'depth': 6, 'dim': 130}. Best is trial 74 with value: 0.0038291425444185734.[0m
[32m[I 2024-11-05 23:55:37,570][0m Trial 94 finished with value: 0.028241999447345734 and parameters: {'learning_rate': 0.00015438733321619059, 'batch_size': 31, 'step_size': 9, 'gamma': 0.8187444124554064, 'depth': 6, 'dim': 126}. Best is trial 74 with value: 0.0038291425444185734.[0m
[32m[I 2024-11-05 23:57:25,599][0m Trial 95 finished with value: 0.007699951063841581 and parameters: {'learning_rate': 0.00026506714140227586, 'batch_size': 61, 'step_size': 10, 'gamma': 0.8376674972935437, 'depth': 6, 'dim': 132}. Best is trial 74 with value: 0.0038291425444185734.[0m
[32m[I 2024-11-05 23:58:59,394][0m Trial 96 finished with value: 0.00364663265645504 and parameters: {'learning_rate': 0.00019454806514490895, 'batch_size': 73, 'step_size': 9, 'gamma': 0.8130493841839006, 'depth': 6, 'dim': 139}. Best is trial 96 with value: 0.00364663265645504.[0m
[32m[I 2024-11-06 00:00:33,565][0m Trial 97 finished with value: 0.004694799892604351 and parameters: {'learning_rate': 0.00019170377191575177, 'batch_size': 73, 'step_size': 9, 'gamma': 0.8317775270901688, 'depth': 6, 'dim': 138}. Best is trial 96 with value: 0.00364663265645504.[0m
[32m[I 2024-11-06 00:02:49,422][0m Trial 98 finished with value: 0.010022228583693504 and parameters: {'learning_rate': 0.0002548002003935911, 'batch_size': 49, 'step_size': 8, 'gamma': 0.8153579447006714, 'depth': 6, 'dim': 142}. Best is trial 96 with value: 0.00364663265645504.[0m
[32m[I 2024-11-06 00:04:47,802][0m Trial 99 finished with value: 0.21990251541137695 and parameters: {'learning_rate': 1.7619492198221377e-06, 'batch_size': 57, 'step_size': 11, 'gamma': 0.8431769106271091, 'depth': 6, 'dim': 107}. Best is trial 96 with value: 0.00364663265645504.[0m
[32m[I 2024-11-06 00:04:47,803][0m A new study created in memory with name: no-name-6ea8b136-645e-4831-bc35-3c456eb03294[0m
[32m[I 2024-11-06 00:05:19,100][0m Trial 0 finished with value: 0.1501373052597046 and parameters: {'learning_rate': 3.0339437035446866e-05, 'batch_size': 199, 'step_size': 9, 'gamma': 0.9765407552251603, 'depth': 5, 'dim': 67}. Best is trial 0 with value: 0.1501373052597046.[0m
[32m[I 2024-11-06 00:05:42,279][0m Trial 1 finished with value: 0.2608056664466858 and parameters: {'learning_rate': 4.51531610646016e-06, 'batch_size': 245, 'step_size': 12, 'gamma': 0.9767602990525682, 'depth': 4, 'dim': 246}. Best is trial 0 with value: 0.1501373052597046.[0m
[32m[I 2024-11-06 00:06:34,840][0m Trial 2 finished with value: 0.06889446079730988 and parameters: {'learning_rate': 0.0002715608968916371, 'batch_size': 135, 'step_size': 13, 'gamma': 0.8646976042469329, 'depth': 6, 'dim': 54}. Best is trial 2 with value: 0.06889446079730988.[0m
[32m[I 2024-11-06 00:07:03,017][0m Trial 3 finished with value: 1.5308337211608887 and parameters: {'learning_rate': 1.035972876274326e-06, 'batch_size': 251, 'step_size': 2, 'gamma': 0.9594325995914972, 'depth': 6, 'dim': 91}. Best is trial 2 with value: 0.06889446079730988.[0m
[32m[I 2024-11-06 00:07:38,607][0m Trial 4 finished with value: 0.12072721123695374 and parameters: {'learning_rate': 4.143159734847979e-05, 'batch_size': 195, 'step_size': 10, 'gamma': 0.8208393433154854, 'depth': 6, 'dim': 140}. Best is trial 2 with value: 0.06889446079730988.[0m
[32m[I 2024-11-06 00:07:55,681][0m Trial 5 finished with value: 0.06767282634973526 and parameters: {'learning_rate': 0.0003240027369503459, 'batch_size': 248, 'step_size': 2, 'gamma': 0.9477723303008044, 'depth': 3, 'dim': 206}. Best is trial 5 with value: 0.06767282634973526.[0m
[32m[I 2024-11-06 00:10:04,220][0m Trial 6 finished with value: 1.8031102418899536 and parameters: {'learning_rate': 1.6990364495038088e-06, 'batch_size': 38, 'step_size': 3, 'gamma': 0.9001185843823535, 'depth': 4, 'dim': 16}. Best is trial 5 with value: 0.06767282634973526.[0m
[32m[I 2024-11-06 00:10:27,204][0m Trial 7 finished with value: 0.1332252025604248 and parameters: {'learning_rate': 1.2303647188315049e-05, 'batch_size': 232, 'step_size': 12, 'gamma': 0.9720191182066598, 'depth': 4, 'dim': 238}. Best is trial 5 with value: 0.06767282634973526.[0m
[32m[I 2024-11-06 00:11:15,236][0m Trial 8 finished with value: 0.40301448106765747 and parameters: {'learning_rate': 1.2051199213472621e-05, 'batch_size': 124, 'step_size': 8, 'gamma': 0.9666572682454034, 'depth': 5, 'dim': 27}. Best is trial 5 with value: 0.06767282634973526.[0m
[32m[I 2024-11-06 00:11:57,696][0m Trial 9 finished with value: 0.24057549238204956 and parameters: {'learning_rate': 3.7886897582904896e-05, 'batch_size': 120, 'step_size': 6, 'gamma': 0.8518017945919573, 'depth': 4, 'dim': 52}. Best is trial 5 with value: 0.06767282634973526.[0m
[32m[I 2024-11-06 00:12:44,062][0m Trial 10 finished with value: 0.058021191507577896 and parameters: {'learning_rate': 0.0009758879567728226, 'batch_size': 63, 'step_size': 5, 'gamma': 0.7565737692045995, 'depth': 2, 'dim': 186}. Best is trial 10 with value: 0.058021191507577896.[0m
[32m[I 2024-11-06 00:14:03,237][0m Trial 11 finished with value: 0.0357695072889328 and parameters: {'learning_rate': 0.0009061603915578932, 'batch_size': 36, 'step_size': 5, 'gamma': 0.751274622585052, 'depth': 2, 'dim': 181}. Best is trial 11 with value: 0.0357695072889328.[0m
[32m[I 2024-11-06 00:16:48,879][0m Trial 12 finished with value: 0.03183768230623433 and parameters: {'learning_rate': 0.0008924375498165931, 'batch_size': 17, 'step_size': 5, 'gamma': 0.7553328305632248, 'depth': 2, 'dim': 171}. Best is trial 12 with value: 0.03183768230623433.[0m
[32m[I 2024-11-06 00:19:42,273][0m Trial 13 finished with value: 0.02805421528007303 and parameters: {'learning_rate': 0.000813774329398311, 'batch_size': 16, 'step_size': 5, 'gamma': 0.7500871780899685, 'depth': 2, 'dim': 152}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:20:18,369][0m Trial 14 finished with value: 0.0763128399848938 and parameters: {'learning_rate': 0.00017786977274957165, 'batch_size': 82, 'step_size': 7, 'gamma': 0.7969251877989383, 'depth': 2, 'dim': 135}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:24:21,030][0m Trial 15 finished with value: 0.0627917583499636 and parameters: {'learning_rate': 0.0001110353860766158, 'batch_size': 16, 'step_size': 4, 'gamma': 0.7872538369420219, 'depth': 3, 'dim': 141}. Best is trial 13 with value: 0.02805421528007303.[0m
Early stopping
[32m[I 2024-11-06 00:24:48,030][0m Trial 16 finished with value: 0.1454622894525528 and parameters: {'learning_rate': 0.000483989173026322, 'batch_size': 86, 'step_size': 1, 'gamma': 0.7840875382204949, 'depth': 3, 'dim': 166}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:27:22,530][0m Trial 17 finished with value: 0.04748392451022353 and parameters: {'learning_rate': 0.00013769695637734172, 'batch_size': 18, 'step_size': 7, 'gamma': 0.8399309274579896, 'depth': 2, 'dim': 104}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:28:25,279][0m Trial 18 finished with value: 0.06846171617507935 and parameters: {'learning_rate': 0.0005462286389848766, 'batch_size': 64, 'step_size': 15, 'gamma': 0.8955088697642433, 'depth': 3, 'dim': 207}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:28:42,986][0m Trial 19 finished with value: 0.17578522861003876 and parameters: {'learning_rate': 6.821476645647287e-05, 'batch_size': 179, 'step_size': 4, 'gamma': 0.8194911599824236, 'depth': 2, 'dim': 159}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:29:22,789][0m Trial 20 finished with value: 0.07217095047235489 and parameters: {'learning_rate': 0.00048224920643159336, 'batch_size': 103, 'step_size': 10, 'gamma': 0.7708962065297057, 'depth': 3, 'dim': 107}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:30:16,284][0m Trial 21 finished with value: 0.04254624620079994 and parameters: {'learning_rate': 0.000903025054027058, 'batch_size': 53, 'step_size': 6, 'gamma': 0.7505782092935501, 'depth': 2, 'dim': 187}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:31:39,339][0m Trial 22 finished with value: 0.031363971531391144 and parameters: {'learning_rate': 0.0009110358422294964, 'batch_size': 34, 'step_size': 5, 'gamma': 0.8110404280066281, 'depth': 2, 'dim': 215}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:32:53,018][0m Trial 23 finished with value: 0.05327809602022171 and parameters: {'learning_rate': 0.0003219292709466742, 'batch_size': 38, 'step_size': 4, 'gamma': 0.807326201985072, 'depth': 2, 'dim': 208}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:36:54,665][0m Trial 24 finished with value: 0.03431981110147068 and parameters: {'learning_rate': 0.00021030022063751606, 'batch_size': 16, 'step_size': 6, 'gamma': 0.7751393521785429, 'depth': 3, 'dim': 159}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:37:14,403][0m Trial 25 finished with value: 0.08924196660518646 and parameters: {'learning_rate': 0.0005325175286638342, 'batch_size': 159, 'step_size': 3, 'gamma': 0.8270679932836471, 'depth': 2, 'dim': 215}. Best is trial 13 with value: 0.02805421528007303.[0m
Early stopping
[32m[I 2024-11-06 00:38:03,554][0m Trial 26 finished with value: 0.058876678347587585 and parameters: {'learning_rate': 0.0001115018939115548, 'batch_size': 80, 'step_size': 8, 'gamma': 0.7707819397952185, 'depth': 3, 'dim': 232}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:39:03,342][0m Trial 27 finished with value: 0.05339926481246948 and parameters: {'learning_rate': 0.0005893118560823263, 'batch_size': 48, 'step_size': 5, 'gamma': 0.8010678553069639, 'depth': 2, 'dim': 255}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:40:26,060][0m Trial 28 finished with value: 0.08377500623464584 and parameters: {'learning_rate': 0.0003265384079906891, 'batch_size': 34, 'step_size': 1, 'gamma': 0.8931458581302292, 'depth': 2, 'dim': 120}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:41:28,892][0m Trial 29 finished with value: 0.10657544434070587 and parameters: {'learning_rate': 1.57842876183443e-05, 'batch_size': 97, 'step_size': 9, 'gamma': 0.7666851613235152, 'depth': 5, 'dim': 223}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:42:30,198][0m Trial 30 finished with value: 0.11048515141010284 and parameters: {'learning_rate': 6.754716818662643e-05, 'batch_size': 66, 'step_size': 3, 'gamma': 0.7955584434254561, 'depth': 3, 'dim': 172}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:46:32,126][0m Trial 31 finished with value: 0.03975188359618187 and parameters: {'learning_rate': 0.00020966422458524548, 'batch_size': 16, 'step_size': 6, 'gamma': 0.777346499149743, 'depth': 3, 'dim': 151}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:47:58,924][0m Trial 32 finished with value: 0.03438834473490715 and parameters: {'learning_rate': 0.0007152920381436786, 'batch_size': 33, 'step_size': 7, 'gamma': 0.7640789495077915, 'depth': 2, 'dim': 195}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:50:22,803][0m Trial 33 finished with value: 0.038230032460497956 and parameters: {'learning_rate': 0.0003807201155753252, 'batch_size': 27, 'step_size': 5, 'gamma': 0.7809039599812716, 'depth': 3, 'dim': 125}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:51:18,607][0m Trial 34 finished with value: 0.05202480033040047 and parameters: {'learning_rate': 0.00021663782393809545, 'batch_size': 52, 'step_size': 6, 'gamma': 0.8106379604746435, 'depth': 2, 'dim': 174}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:52:37,431][0m Trial 35 finished with value: 0.04570687934756279 and parameters: {'learning_rate': 0.0007185144726063149, 'batch_size': 50, 'step_size': 8, 'gamma': 0.7900456563336701, 'depth': 3, 'dim': 156}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:54:29,266][0m Trial 36 finished with value: 0.09380537484373365 and parameters: {'learning_rate': 7.218088816876028e-05, 'batch_size': 25, 'step_size': 4, 'gamma': 0.7648573891174979, 'depth': 2, 'dim': 78}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:55:02,935][0m Trial 37 finished with value: 0.10399144142866135 and parameters: {'learning_rate': 0.0003805156715075924, 'batch_size': 156, 'step_size': 2, 'gamma': 0.866159497176205, 'depth': 4, 'dim': 149}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:55:59,820][0m Trial 38 finished with value: 0.04125218465924263 and parameters: {'learning_rate': 0.0009947962310637984, 'batch_size': 70, 'step_size': 9, 'gamma': 0.8352249457975192, 'depth': 3, 'dim': 119}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:56:24,595][0m Trial 39 finished with value: 0.28286221623420715 and parameters: {'learning_rate': 5.7595153640567986e-06, 'batch_size': 214, 'step_size': 7, 'gamma': 0.9417822174105979, 'depth': 4, 'dim': 196}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:57:26,178][0m Trial 40 finished with value: 0.06413758546113968 and parameters: {'learning_rate': 0.0002519035647316669, 'batch_size': 45, 'step_size': 5, 'gamma': 0.8139144578713634, 'depth': 2, 'dim': 223}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 00:58:59,808][0m Trial 41 finished with value: 0.028497671708464622 and parameters: {'learning_rate': 0.0007273181508354172, 'batch_size': 30, 'step_size': 7, 'gamma': 0.7637294467611526, 'depth': 2, 'dim': 195}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 01:00:43,671][0m Trial 42 finished with value: 0.03187866889805134 and parameters: {'learning_rate': 0.0006519863707947592, 'batch_size': 27, 'step_size': 6, 'gamma': 0.7603414513528967, 'depth': 2, 'dim': 197}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 01:02:21,327][0m Trial 43 finished with value: 0.054606031626462936 and parameters: {'learning_rate': 0.0006877065392587688, 'batch_size': 29, 'step_size': 3, 'gamma': 0.7566134375562236, 'depth': 2, 'dim': 199}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 01:04:02,644][0m Trial 44 finished with value: 0.03530219569802284 and parameters: {'learning_rate': 0.00043244470101435223, 'batch_size': 58, 'step_size': 10, 'gamma': 0.7592761857980445, 'depth': 5, 'dim': 240}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 01:05:11,860][0m Trial 45 finished with value: 0.0325704850256443 and parameters: {'learning_rate': 0.0007254334915130196, 'batch_size': 41, 'step_size': 8, 'gamma': 0.7511619937022855, 'depth': 2, 'dim': 184}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 01:07:03,831][0m Trial 46 finished with value: 0.3039620114224298 and parameters: {'learning_rate': 2.2148973597740683e-06, 'batch_size': 25, 'step_size': 6, 'gamma': 0.8821546797107329, 'depth': 2, 'dim': 173}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 01:08:15,055][0m Trial 47 finished with value: 0.03128626570105553 and parameters: {'learning_rate': 0.0009847702135925523, 'batch_size': 40, 'step_size': 7, 'gamma': 0.7845859490651393, 'depth': 2, 'dim': 219}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 01:09:46,555][0m Trial 48 finished with value: 0.6812909841537476 and parameters: {'learning_rate': 0.0009581352936256213, 'batch_size': 74, 'step_size': 7, 'gamma': 0.8527908885429005, 'depth': 6, 'dim': 227}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 01:10:18,623][0m Trial 49 finished with value: 0.09518210589885712 and parameters: {'learning_rate': 2.511050234016672e-05, 'batch_size': 92, 'step_size': 11, 'gamma': 0.7873894178264974, 'depth': 2, 'dim': 250}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 01:11:26,183][0m Trial 50 finished with value: 0.06673727184534073 and parameters: {'learning_rate': 0.00014664536714891575, 'batch_size': 42, 'step_size': 4, 'gamma': 0.7789691389587142, 'depth': 2, 'dim': 210}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 01:13:11,548][0m Trial 51 finished with value: 0.03890264539846352 and parameters: {'learning_rate': 0.0006363887936777311, 'batch_size': 27, 'step_size': 5, 'gamma': 0.7619618126244434, 'depth': 2, 'dim': 218}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 01:14:01,296][0m Trial 52 finished with value: 0.04772131145000458 and parameters: {'learning_rate': 0.0002905118535931901, 'batch_size': 59, 'step_size': 7, 'gamma': 0.9254582876779416, 'depth': 2, 'dim': 191}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 01:16:01,769][0m Trial 53 finished with value: 0.02864674013108015 and parameters: {'learning_rate': 0.0007989613372845276, 'batch_size': 23, 'step_size': 6, 'gamma': 0.7987040634253613, 'depth': 2, 'dim': 202}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 01:16:28,777][0m Trial 54 finished with value: 0.06843956559896469 and parameters: {'learning_rate': 0.0004398582627427813, 'batch_size': 110, 'step_size': 9, 'gamma': 0.7986547496535413, 'depth': 2, 'dim': 237}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 01:17:41,602][0m Trial 55 finished with value: 0.030231114476919174 and parameters: {'learning_rate': 0.0008041033443355898, 'batch_size': 39, 'step_size': 5, 'gamma': 0.8255021342394865, 'depth': 2, 'dim': 180}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 01:18:49,949][0m Trial 56 finished with value: 0.12874843180179596 and parameters: {'learning_rate': 0.000997495014478196, 'batch_size': 42, 'step_size': 7, 'gamma': 0.9861789403366173, 'depth': 2, 'dim': 203}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 01:20:42,018][0m Trial 57 finished with value: 0.07135922461748123 and parameters: {'learning_rate': 0.0007774758484947709, 'batch_size': 35, 'step_size': 8, 'gamma': 0.8344414497590008, 'depth': 3, 'dim': 137}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 01:21:35,650][0m Trial 58 finished with value: 0.06468234211206436 and parameters: {'learning_rate': 0.0005208559160220719, 'batch_size': 54, 'step_size': 4, 'gamma': 0.8490676524392111, 'depth': 2, 'dim': 178}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 01:21:49,215][0m Trial 59 finished with value: 0.08109938353300095 and parameters: {'learning_rate': 0.0003496648805132446, 'batch_size': 235, 'step_size': 6, 'gamma': 0.8064317098252838, 'depth': 2, 'dim': 163}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 01:22:20,649][0m Trial 60 finished with value: 0.08695501834154129 and parameters: {'learning_rate': 0.000563808309821788, 'batch_size': 135, 'step_size': 5, 'gamma': 0.8223723146580326, 'depth': 3, 'dim': 214}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 01:24:34,243][0m Trial 61 finished with value: 0.028545440174639225 and parameters: {'learning_rate': 0.0008377301329283031, 'batch_size': 21, 'step_size': 5, 'gamma': 0.7913910697871968, 'depth': 2, 'dim': 186}. Best is trial 13 with value: 0.02805421528007303.[0m
[32m[I 2024-11-06 01:26:35,873][0m Trial 62 finished with value: 0.025036592369100878 and parameters: {'learning_rate': 0.0007608844408913345, 'batch_size': 23, 'step_size': 5, 'gamma': 0.7924614646892125, 'depth': 2, 'dim': 184}. Best is trial 62 with value: 0.025036592369100878.[0m
[32m[I 2024-11-06 01:28:48,728][0m Trial 63 finished with value: 0.025048861280083656 and parameters: {'learning_rate': 0.0007790983613841226, 'batch_size': 21, 'step_size': 14, 'gamma': 0.7896063727349638, 'depth': 2, 'dim': 185}. Best is trial 62 with value: 0.025036592369100878.[0m
[32m[I 2024-11-06 01:31:02,622][0m Trial 64 finished with value: 0.03519754344597459 and parameters: {'learning_rate': 0.0004309429696191607, 'batch_size': 21, 'step_size': 5, 'gamma': 0.7727884511305091, 'depth': 2, 'dim': 184}. Best is trial 62 with value: 0.025036592369100878.[0m
[32m[I 2024-11-06 01:33:22,368][0m Trial 65 finished with value: 0.01510771191013711 and parameters: {'learning_rate': 0.0007615323253877758, 'batch_size': 20, 'step_size': 15, 'gamma': 0.7975246603221708, 'depth': 2, 'dim': 146}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 01:35:41,891][0m Trial 66 finished with value: 0.043337022619588036 and parameters: {'learning_rate': 0.00056033620282062, 'batch_size': 20, 'step_size': 15, 'gamma': 0.7938363759590434, 'depth': 2, 'dim': 147}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 01:38:20,678][0m Trial 67 finished with value: 0.023041709858391966 and parameters: {'learning_rate': 0.00048080205012694205, 'batch_size': 17, 'step_size': 13, 'gamma': 0.8038359568414476, 'depth': 2, 'dim': 167}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 01:41:15,801][0m Trial 68 finished with value: 0.051039035831178935 and parameters: {'learning_rate': 0.0002837676793387925, 'batch_size': 16, 'step_size': 14, 'gamma': 0.8042011654984231, 'depth': 2, 'dim': 166}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 01:42:43,569][0m Trial 69 finished with value: 0.033248450607061386 and parameters: {'learning_rate': 0.0004865504543659122, 'batch_size': 32, 'step_size': 13, 'gamma': 0.769573232040843, 'depth': 2, 'dim': 128}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 01:44:53,450][0m Trial 70 finished with value: 0.08095602691173553 and parameters: {'learning_rate': 0.0003710645802143078, 'batch_size': 30, 'step_size': 14, 'gamma': 0.818009654239028, 'depth': 3, 'dim': 142}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 01:46:56,626][0m Trial 71 finished with value: 0.026478973616446768 and parameters: {'learning_rate': 0.0008038359077969639, 'batch_size': 23, 'step_size': 14, 'gamma': 0.798655389117344, 'depth': 2, 'dim': 166}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 01:49:48,583][0m Trial 72 finished with value: 0.02097292004951409 and parameters: {'learning_rate': 0.0006442012842178299, 'batch_size': 16, 'step_size': 14, 'gamma': 0.7889612404656287, 'depth': 2, 'dim': 165}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 01:50:48,407][0m Trial 73 finished with value: 0.03557095676660538 and parameters: {'learning_rate': 0.0006379026851294597, 'batch_size': 48, 'step_size': 14, 'gamma': 0.7888875157750114, 'depth': 2, 'dim': 155}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 01:53:44,208][0m Trial 74 finished with value: 0.019810098090342114 and parameters: {'learning_rate': 0.0005961620244226862, 'batch_size': 16, 'step_size': 13, 'gamma': 0.7813075025374738, 'depth': 2, 'dim': 165}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 01:56:39,517][0m Trial 75 finished with value: 0.0689949978675161 and parameters: {'learning_rate': 0.00023648628748870873, 'batch_size': 16, 'step_size': 13, 'gamma': 0.7806212074167505, 'depth': 2, 'dim': 165}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 01:58:41,803][0m Trial 76 finished with value: 0.026614150098924125 and parameters: {'learning_rate': 0.0004896518437794315, 'batch_size': 23, 'step_size': 12, 'gamma': 0.8111773835739805, 'depth': 2, 'dim': 131}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:01:31,983][0m Trial 77 finished with value: 0.04082152619957924 and parameters: {'learning_rate': 0.0004257481688073939, 'batch_size': 34, 'step_size': 12, 'gamma': 0.815643799116321, 'depth': 5, 'dim': 105}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:02:35,403][0m Trial 78 finished with value: 0.05442807078361511 and parameters: {'learning_rate': 0.0003062547114329226, 'batch_size': 45, 'step_size': 12, 'gamma': 0.80557337156885, 'depth': 2, 'dim': 112}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:04:37,664][0m Trial 79 finished with value: 0.02515605783888272 and parameters: {'learning_rate': 0.0005635372615749226, 'batch_size': 23, 'step_size': 13, 'gamma': 0.8108209741560253, 'depth': 2, 'dim': 160}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:04:54,683][0m Trial 80 finished with value: 0.07429981231689453 and parameters: {'learning_rate': 0.00015821584434400475, 'batch_size': 255, 'step_size': 13, 'gamma': 0.8288915519914596, 'depth': 3, 'dim': 143}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:07:00,708][0m Trial 81 finished with value: 0.0254865794309548 and parameters: {'learning_rate': 0.0005802689269865991, 'batch_size': 22, 'step_size': 15, 'gamma': 0.801804581797017, 'depth': 2, 'dim': 133}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:08:56,998][0m Trial 82 finished with value: 0.061141026871544976 and parameters: {'learning_rate': 0.0005846982510494759, 'batch_size': 24, 'step_size': 15, 'gamma': 0.8002963305939007, 'depth': 2, 'dim': 160}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:10:17,827][0m Trial 83 finished with value: 0.03818361461162567 and parameters: {'learning_rate': 0.0006082422209079367, 'batch_size': 35, 'step_size': 14, 'gamma': 0.794207572316371, 'depth': 2, 'dim': 168}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:11:52,359][0m Trial 84 finished with value: 0.030911095440387726 and parameters: {'learning_rate': 0.00039887104889517943, 'batch_size': 30, 'step_size': 15, 'gamma': 0.7866565923186161, 'depth': 2, 'dim': 153}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:14:46,732][0m Trial 85 finished with value: 0.03350526999150004 and parameters: {'learning_rate': 0.0005046920157372293, 'batch_size': 16, 'step_size': 13, 'gamma': 0.7756856148968183, 'depth': 2, 'dim': 175}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:15:03,471][0m Trial 86 finished with value: 0.07867871969938278 and parameters: {'learning_rate': 0.0008455062966332012, 'batch_size': 189, 'step_size': 14, 'gamma': 0.8033269579324346, 'depth': 2, 'dim': 160}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:15:24,343][0m Trial 87 finished with value: 0.3131834864616394 and parameters: {'learning_rate': 7.28307302435394e-06, 'batch_size': 147, 'step_size': 15, 'gamma': 0.7959387548198558, 'depth': 2, 'dim': 134}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:17:27,048][0m Trial 88 finished with value: 0.08128023520112038 and parameters: {'learning_rate': 0.0006805755214021346, 'batch_size': 23, 'step_size': 14, 'gamma': 0.781672392363676, 'depth': 2, 'dim': 146}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:18:50,857][0m Trial 89 finished with value: 0.055556125938892365 and parameters: {'learning_rate': 0.0003492693903195543, 'batch_size': 47, 'step_size': 11, 'gamma': 0.8098888845608602, 'depth': 3, 'dim': 170}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:19:14,724][0m Trial 90 finished with value: 0.1916833072900772 and parameters: {'learning_rate': 0.00017825056269911167, 'batch_size': 125, 'step_size': 14, 'gamma': 0.8198690608636494, 'depth': 2, 'dim': 39}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:21:16,808][0m Trial 91 finished with value: 0.05144400681768145 and parameters: {'learning_rate': 0.0004781169600177067, 'batch_size': 23, 'step_size': 12, 'gamma': 0.8153382654917367, 'depth': 2, 'dim': 132}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:22:57,660][0m Trial 92 finished with value: 0.04961336776614189 and parameters: {'learning_rate': 0.0005494296166649257, 'batch_size': 28, 'step_size': 15, 'gamma': 0.7922239561808357, 'depth': 2, 'dim': 127}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:24:11,671][0m Trial 93 finished with value: 0.04150857403874397 and parameters: {'learning_rate': 0.0007563036949775627, 'batch_size': 38, 'step_size': 13, 'gamma': 0.8106612663390473, 'depth': 2, 'dim': 191}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:26:30,368][0m Trial 94 finished with value: 0.042987485017095296 and parameters: {'learning_rate': 5.01162544166964e-05, 'batch_size': 20, 'step_size': 12, 'gamma': 0.801438164025899, 'depth': 2, 'dim': 178}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:28:14,066][0m Trial 95 finished with value: 0.04990836126463754 and parameters: {'learning_rate': 0.0006744944720326333, 'batch_size': 27, 'step_size': 14, 'gamma': 0.7819564581727982, 'depth': 2, 'dim': 119}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:29:03,094][0m Trial 96 finished with value: 0.04414565861225128 and parameters: {'learning_rate': 0.00045873036807793225, 'batch_size': 57, 'step_size': 13, 'gamma': 0.8459421523962483, 'depth': 2, 'dim': 158}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:32:04,088][0m Trial 97 finished with value: 0.07948081195354462 and parameters: {'learning_rate': 0.0008465211209419297, 'batch_size': 37, 'step_size': 15, 'gamma': 0.8326437896355661, 'depth': 6, 'dim': 152}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:34:17,501][0m Trial 98 finished with value: 0.1908976398408413 and parameters: {'learning_rate': 2.945527192717232e-06, 'batch_size': 21, 'step_size': 11, 'gamma': 0.9090620075597221, 'depth': 2, 'dim': 137}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:35:44,723][0m Trial 99 finished with value: 0.03728605434298515 and parameters: {'learning_rate': 0.0006301205123547558, 'batch_size': 32, 'step_size': 13, 'gamma': 0.7861417390785262, 'depth': 2, 'dim': 172}. Best is trial 65 with value: 0.01510771191013711.[0m
[32m[I 2024-11-06 02:35:44,723][0m A new study created in memory with name: no-name-cf1aff28-764e-4ca3-9ebe-3f0b98d8d040[0m
[32m[I 2024-11-06 02:36:13,909][0m Trial 0 finished with value: 0.035693470388650894 and parameters: {'learning_rate': 0.0001770548664146313, 'batch_size': 222, 'step_size': 12, 'gamma': 0.7928036300753013, 'depth': 5, 'dim': 204}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 02:36:33,822][0m Trial 1 finished with value: 0.03836792707443237 and parameters: {'learning_rate': 0.00013022696273314326, 'batch_size': 226, 'step_size': 6, 'gamma': 0.7741185222643018, 'depth': 3, 'dim': 87}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 02:36:54,759][0m Trial 2 finished with value: 0.2722456157207489 and parameters: {'learning_rate': 6.028783785599666e-06, 'batch_size': 150, 'step_size': 5, 'gamma': 0.9111392902788241, 'depth': 2, 'dim': 148}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 02:42:16,027][0m Trial 3 finished with value: 0.04905490989663771 and parameters: {'learning_rate': 1.4215358967310196e-05, 'batch_size': 18, 'step_size': 8, 'gamma': 0.9446927602611634, 'depth': 5, 'dim': 189}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 02:44:01,966][0m Trial 4 finished with value: 0.0364677757024765 and parameters: {'learning_rate': 0.00016333965838335267, 'batch_size': 64, 'step_size': 2, 'gamma': 0.8555849457483174, 'depth': 6, 'dim': 91}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 02:45:35,289][0m Trial 5 finished with value: 0.04111013561487198 and parameters: {'learning_rate': 0.0006562479499394791, 'batch_size': 63, 'step_size': 3, 'gamma': 0.8279059124933658, 'depth': 5, 'dim': 238}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 02:46:01,424][0m Trial 6 finished with value: 0.042821004986763 and parameters: {'learning_rate': 0.00015809734218475444, 'batch_size': 253, 'step_size': 15, 'gamma': 0.8810229369967152, 'depth': 6, 'dim': 81}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 02:48:58,038][0m Trial 7 finished with value: 0.05464373156428337 and parameters: {'learning_rate': 0.0001370279415851908, 'batch_size': 33, 'step_size': 11, 'gamma': 0.911486367302137, 'depth': 5, 'dim': 173}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 02:50:28,429][0m Trial 8 finished with value: 0.05006888136267662 and parameters: {'learning_rate': 5.720264509846871e-06, 'batch_size': 55, 'step_size': 15, 'gamma': 0.9780637066827284, 'depth': 4, 'dim': 119}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 02:50:49,668][0m Trial 9 finished with value: 0.0415947325527668 and parameters: {'learning_rate': 0.00097813973823129, 'batch_size': 206, 'step_size': 5, 'gamma': 0.8424060029349874, 'depth': 3, 'dim': 218}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 02:51:21,426][0m Trial 10 finished with value: 3.6187920570373535 and parameters: {'learning_rate': 1.3351966982334188e-06, 'batch_size': 162, 'step_size': 11, 'gamma': 0.7517761062820052, 'depth': 4, 'dim': 21}. Best is trial 0 with value: 0.035693470388650894.[0m
Early stopping
[32m[I 2024-11-06 02:52:00,507][0m Trial 11 finished with value: 0.2705284059047699 and parameters: {'learning_rate': 5.35572740852524e-05, 'batch_size': 97, 'step_size': 1, 'gamma': 0.8050741351712266, 'depth': 6, 'dim': 44}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 02:53:07,553][0m Trial 12 finished with value: 0.039130136370658875 and parameters: {'learning_rate': 0.0002962483052555096, 'batch_size': 103, 'step_size': 12, 'gamma': 0.7977509461765787, 'depth': 6, 'dim': 119}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 02:53:40,958][0m Trial 13 finished with value: 0.03940794989466667 and parameters: {'learning_rate': 4.2832093199656765e-05, 'batch_size': 185, 'step_size': 8, 'gamma': 0.8509103416173815, 'depth': 5, 'dim': 196}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 02:54:43,067][0m Trial 14 finished with value: 0.051124949008226395 and parameters: {'learning_rate': 0.0003412043909068786, 'batch_size': 113, 'step_size': 13, 'gamma': 0.8758040958095316, 'depth': 6, 'dim': 76}. Best is trial 0 with value: 0.035693470388650894.[0m
Early stopping
[32m[I 2024-11-06 02:55:05,351][0m Trial 15 finished with value: 0.1775871217250824 and parameters: {'learning_rate': 7.494694270129674e-05, 'batch_size': 137, 'step_size': 1, 'gamma': 0.8090380608762958, 'depth': 4, 'dim': 252}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 02:55:29,435][0m Trial 16 finished with value: 0.15071921050548553 and parameters: {'learning_rate': 2.1182436081153174e-05, 'batch_size': 253, 'step_size': 9, 'gamma': 0.7719523080751458, 'depth': 5, 'dim': 153}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 02:56:55,557][0m Trial 17 finished with value: 0.04996170848608017 and parameters: {'learning_rate': 0.0002669457535801882, 'batch_size': 79, 'step_size': 9, 'gamma': 0.9029910959458339, 'depth': 6, 'dim': 109}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 02:57:28,875][0m Trial 18 finished with value: 0.04466059431433678 and parameters: {'learning_rate': 0.0004698829737210885, 'batch_size': 183, 'step_size': 13, 'gamma': 0.8524102415445934, 'depth': 5, 'dim': 57}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 02:57:48,678][0m Trial 19 finished with value: 0.08297862857580185 and parameters: {'learning_rate': 8.811116118935883e-05, 'batch_size': 222, 'step_size': 3, 'gamma': 0.8225141362377877, 'depth': 3, 'dim': 213}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 02:58:33,101][0m Trial 20 finished with value: 0.24813123047351837 and parameters: {'learning_rate': 1.9220415199138666e-05, 'batch_size': 114, 'step_size': 3, 'gamma': 0.7816936525065867, 'depth': 4, 'dim': 169}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 02:58:52,961][0m Trial 21 finished with value: 0.054116036742925644 and parameters: {'learning_rate': 0.00014690851114947521, 'batch_size': 219, 'step_size': 6, 'gamma': 0.7504068528847979, 'depth': 3, 'dim': 95}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 02:59:06,463][0m Trial 22 finished with value: 0.0689249187707901 and parameters: {'learning_rate': 0.00018161981889230702, 'batch_size': 230, 'step_size': 6, 'gamma': 0.788066038310161, 'depth': 2, 'dim': 60}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 02:59:29,181][0m Trial 23 finished with value: 0.05029613524675369 and parameters: {'learning_rate': 9.845701954257137e-05, 'batch_size': 189, 'step_size': 7, 'gamma': 0.7716578829164465, 'depth': 3, 'dim': 133}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 02:59:42,772][0m Trial 24 finished with value: 0.1975853592157364 and parameters: {'learning_rate': 3.455185824716849e-05, 'batch_size': 235, 'step_size': 4, 'gamma': 0.8322817020372518, 'depth': 2, 'dim': 98}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 03:00:21,809][0m Trial 25 finished with value: 0.039395831525325775 and parameters: {'learning_rate': 0.000255181145076341, 'batch_size': 133, 'step_size': 10, 'gamma': 0.8157898537171525, 'depth': 4, 'dim': 29}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 03:00:57,297][0m Trial 26 finished with value: 0.05654328688979149 and parameters: {'learning_rate': 0.000491580481915665, 'batch_size': 202, 'step_size': 2, 'gamma': 0.8602573115806889, 'depth': 6, 'dim': 76}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 03:01:22,955][0m Trial 27 finished with value: 0.05804390087723732 and parameters: {'learning_rate': 6.35554493039857e-05, 'batch_size': 162, 'step_size': 7, 'gamma': 0.7687883343811104, 'depth': 3, 'dim': 135}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 03:01:50,084][0m Trial 28 finished with value: 0.0628739520907402 and parameters: {'learning_rate': 0.00012883936003933803, 'batch_size': 242, 'step_size': 4, 'gamma': 0.7946109076511275, 'depth': 5, 'dim': 99}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 03:02:08,901][0m Trial 29 finished with value: 0.3038599193096161 and parameters: {'learning_rate': 8.87663765000878e-06, 'batch_size': 160, 'step_size': 5, 'gamma': 0.9023553991192018, 'depth': 2, 'dim': 154}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 03:02:44,399][0m Trial 30 finished with value: 0.06801746785640717 and parameters: {'learning_rate': 3.081649343571946e-05, 'batch_size': 208, 'step_size': 14, 'gamma': 0.9329013755212072, 'depth': 6, 'dim': 58}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 03:04:08,581][0m Trial 31 finished with value: 0.03652461990714073 and parameters: {'learning_rate': 0.00026016620880140264, 'batch_size': 81, 'step_size': 12, 'gamma': 0.7991331681898504, 'depth': 6, 'dim': 122}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 03:06:34,727][0m Trial 32 finished with value: 0.037432216107845306 and parameters: {'learning_rate': 0.00021980569094326216, 'batch_size': 45, 'step_size': 11, 'gamma': 0.7845324673291045, 'depth': 6, 'dim': 122}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 03:09:01,560][0m Trial 33 finished with value: 0.043866097927093506 and parameters: {'learning_rate': 0.0002163317178449032, 'batch_size': 46, 'step_size': 12, 'gamma': 0.8355561483835282, 'depth': 6, 'dim': 117}. Best is trial 0 with value: 0.035693470388650894.[0m
[32m[I 2024-11-06 03:10:28,313][0m Trial 34 finished with value: 0.03315048664808273 and parameters: {'learning_rate': 0.0006695805859500143, 'batch_size': 79, 'step_size': 11, 'gamma': 0.8114066583176176, 'depth': 6, 'dim': 133}. Best is trial 34 with value: 0.03315048664808273.[0m
[32m[I 2024-11-06 03:11:44,311][0m Trial 35 finished with value: 1.8663966655731201 and parameters: {'learning_rate': 0.000925038018301319, 'batch_size': 79, 'step_size': 13, 'gamma': 0.8177592454836946, 'depth': 5, 'dim': 167}. Best is trial 34 with value: 0.03315048664808273.[0m
[32m[I 2024-11-06 03:13:20,665][0m Trial 36 finished with value: 0.03171836584806442 and parameters: {'learning_rate': 0.0004677787373786221, 'batch_size': 71, 'step_size': 10, 'gamma': 0.867669486614165, 'depth': 6, 'dim': 144}. Best is trial 36 with value: 0.03171836584806442.[0m
[32m[I 2024-11-06 03:18:24,424][0m Trial 37 finished with value: 0.056791557265179496 and parameters: {'learning_rate': 0.0005411260166808726, 'batch_size': 22, 'step_size': 10, 'gamma': 0.8680100937496565, 'depth': 6, 'dim': 187}. Best is trial 36 with value: 0.03171836584806442.[0m
[32m[I 2024-11-06 03:19:55,108][0m Trial 38 finished with value: 0.5316957831382751 and parameters: {'learning_rate': 0.0007270671332060137, 'batch_size': 65, 'step_size': 10, 'gamma': 0.8864647331423315, 'depth': 5, 'dim': 223}. Best is trial 36 with value: 0.03171836584806442.[0m
[32m[I 2024-11-06 03:21:25,869][0m Trial 39 finished with value: 0.05914033576846123 and parameters: {'learning_rate': 0.0003868828590122523, 'batch_size': 65, 'step_size': 9, 'gamma': 0.8910336528489501, 'depth': 5, 'dim': 147}. Best is trial 36 with value: 0.03171836584806442.[0m
[32m[I 2024-11-06 03:24:41,893][0m Trial 40 finished with value: 0.06001453474164009 and parameters: {'learning_rate': 0.0006961699809849179, 'batch_size': 34, 'step_size': 14, 'gamma': 0.9308270737093775, 'depth': 6, 'dim': 197}. Best is trial 36 with value: 0.03171836584806442.[0m
[32m[I 2024-11-06 03:26:01,426][0m Trial 41 finished with value: 0.05974208191037178 and parameters: {'learning_rate': 0.00039564914258212355, 'batch_size': 85, 'step_size': 12, 'gamma': 0.8471402019574417, 'depth': 6, 'dim': 141}. Best is trial 36 with value: 0.03171836584806442.[0m
[32m[I 2024-11-06 03:27:15,801][0m Trial 42 finished with value: 0.04054345190525055 and parameters: {'learning_rate': 0.00011398150130195668, 'batch_size': 92, 'step_size': 11, 'gamma': 0.8062414122053997, 'depth': 6, 'dim': 87}. Best is trial 36 with value: 0.03171836584806442.[0m
[32m[I 2024-11-06 03:29:23,701][0m Trial 43 finished with value: 0.2154882401227951 and parameters: {'learning_rate': 2.2677474137230183e-06, 'batch_size': 53, 'step_size': 12, 'gamma': 0.8638977733552194, 'depth': 6, 'dim': 130}. Best is trial 36 with value: 0.03171836584806442.[0m
[32m[I 2024-11-06 03:30:55,391][0m Trial 44 finished with value: 0.049249399453401566 and parameters: {'learning_rate': 0.000611514289458552, 'batch_size': 75, 'step_size': 10, 'gamma': 0.8369003603000551, 'depth': 6, 'dim': 182}. Best is trial 36 with value: 0.03171836584806442.[0m
[32m[I 2024-11-06 03:31:52,122][0m Trial 45 finished with value: 0.0630025640130043 and parameters: {'learning_rate': 0.00017836460387418834, 'batch_size': 105, 'step_size': 11, 'gamma': 0.9798135852335792, 'depth': 5, 'dim': 109}. Best is trial 36 with value: 0.03171836584806442.[0m
[32m[I 2024-11-06 03:32:47,131][0m Trial 46 finished with value: 0.04449962452054024 and parameters: {'learning_rate': 0.00032924155053884674, 'batch_size': 128, 'step_size': 14, 'gamma': 0.7598127010230111, 'depth': 6, 'dim': 161}. Best is trial 36 with value: 0.03171836584806442.[0m
[32m[I 2024-11-06 03:34:13,486][0m Trial 47 finished with value: 0.0747242122888565 and parameters: {'learning_rate': 0.0008588496418419306, 'batch_size': 68, 'step_size': 8, 'gamma': 0.7962105849826355, 'depth': 5, 'dim': 231}. Best is trial 36 with value: 0.03171836584806442.[0m
[32m[I 2024-11-06 03:35:25,368][0m Trial 48 finished with value: 0.11834012717008591 and parameters: {'learning_rate': 0.00046251619169446033, 'batch_size': 95, 'step_size': 13, 'gamma': 0.965010743914658, 'depth': 6, 'dim': 85}. Best is trial 36 with value: 0.03171836584806442.[0m
[32m[I 2024-11-06 03:36:15,714][0m Trial 49 finished with value: 0.0799235850572586 and parameters: {'learning_rate': 0.0002970473851996796, 'batch_size': 122, 'step_size': 15, 'gamma': 0.8244083230044374, 'depth': 5, 'dim': 205}. Best is trial 36 with value: 0.03171836584806442.[0m
[32m[I 2024-11-06 03:39:26,427][0m Trial 50 finished with value: 0.02962680533528328 and parameters: {'learning_rate': 4.828921939912824e-05, 'batch_size': 35, 'step_size': 9, 'gamma': 0.8748749312955543, 'depth': 6, 'dim': 108}. Best is trial 50 with value: 0.02962680533528328.[0m
[32m[I 2024-11-06 03:46:20,215][0m Trial 51 finished with value: 0.06232981596674238 and parameters: {'learning_rate': 5.2049149938906013e-05, 'batch_size': 16, 'step_size': 9, 'gamma': 0.8754562674423556, 'depth': 6, 'dim': 126}. Best is trial 50 with value: 0.02962680533528328.[0m
[32m[I 2024-11-06 03:49:11,587][0m Trial 52 finished with value: 0.036377955228090286 and parameters: {'learning_rate': 7.371377169906624e-05, 'batch_size': 39, 'step_size': 11, 'gamma': 0.8566567278581347, 'depth': 6, 'dim': 111}. Best is trial 50 with value: 0.02962680533528328.[0m
[32m[I 2024-11-06 03:52:07,779][0m Trial 53 finished with value: 0.03301655128598213 and parameters: {'learning_rate': 7.4437412751397e-05, 'batch_size': 38, 'step_size': 11, 'gamma': 0.8565104461012534, 'depth': 6, 'dim': 107}. Best is trial 50 with value: 0.02962680533528328.[0m
[32m[I 2024-11-06 03:55:50,006][0m Trial 54 finished with value: 0.04622752219438553 and parameters: {'learning_rate': 3.30910675525084e-05, 'batch_size': 30, 'step_size': 11, 'gamma': 0.8895855539890095, 'depth': 6, 'dim': 107}. Best is trial 50 with value: 0.02962680533528328.[0m
[32m[I 2024-11-06 03:58:12,642][0m Trial 55 finished with value: 0.030441991984844208 and parameters: {'learning_rate': 7.473064514119269e-05, 'batch_size': 46, 'step_size': 9, 'gamma': 0.8546947071635462, 'depth': 6, 'dim': 69}. Best is trial 50 with value: 0.02962680533528328.[0m
[32m[I 2024-11-06 03:59:59,755][0m Trial 56 finished with value: 0.036241933703422546 and parameters: {'learning_rate': 4.7522074486910357e-05, 'batch_size': 55, 'step_size': 9, 'gamma': 0.8446359481988269, 'depth': 5, 'dim': 65}. Best is trial 50 with value: 0.02962680533528328.[0m
[32m[I 2024-11-06 04:02:21,714][0m Trial 57 finished with value: 0.03701409325003624 and parameters: {'learning_rate': 9.826267751707052e-05, 'batch_size': 47, 'step_size': 7, 'gamma': 0.8766849156160751, 'depth': 6, 'dim': 39}. Best is trial 50 with value: 0.02962680533528328.[0m
[32m[I 2024-11-06 04:07:00,593][0m Trial 58 finished with value: 0.04016602731176785 and parameters: {'learning_rate': 2.3519169347831588e-05, 'batch_size': 24, 'step_size': 10, 'gamma': 0.9017203309743912, 'depth': 6, 'dim': 252}. Best is trial 50 with value: 0.02962680533528328.[0m
[32m[I 2024-11-06 04:09:38,249][0m Trial 59 finished with value: 0.04605963081121445 and parameters: {'learning_rate': 1.3081671446284834e-05, 'batch_size': 37, 'step_size': 8, 'gamma': 0.9169858828347998, 'depth': 5, 'dim': 77}. Best is trial 50 with value: 0.02962680533528328.[0m
[32m[I 2024-11-06 04:10:13,673][0m Trial 60 finished with value: 0.07378016412258148 and parameters: {'learning_rate': 6.099761611617776e-05, 'batch_size': 144, 'step_size': 8, 'gamma': 0.8692903985313643, 'depth': 4, 'dim': 48}. Best is trial 50 with value: 0.02962680533528328.[0m
[32m[I 2024-11-06 04:11:56,770][0m Trial 61 finished with value: 0.04588598385453224 and parameters: {'learning_rate': 4.686328247012595e-05, 'batch_size': 57, 'step_size': 9, 'gamma': 0.8430238912196302, 'depth': 5, 'dim': 71}. Best is trial 50 with value: 0.02962680533528328.[0m
[32m[I 2024-11-06 04:13:52,306][0m Trial 62 finished with value: 0.027239453047513962 and parameters: {'learning_rate': 8.245343143634114e-05, 'batch_size': 58, 'step_size': 10, 'gamma': 0.8535762165169342, 'depth': 6, 'dim': 63}. Best is trial 62 with value: 0.027239453047513962.[0m
[32m[I 2024-11-06 04:15:48,036][0m Trial 63 finished with value: 0.029641328379511833 and parameters: {'learning_rate': 7.056649064072128e-05, 'batch_size': 58, 'step_size': 10, 'gamma': 0.8565403432584254, 'depth': 6, 'dim': 101}. Best is trial 62 with value: 0.027239453047513962.[0m
[32m[I 2024-11-06 04:17:43,742][0m Trial 64 finished with value: 0.027879880741238594 and parameters: {'learning_rate': 7.588798294158178e-05, 'batch_size': 59, 'step_size': 10, 'gamma': 0.855473238512758, 'depth': 6, 'dim': 104}. Best is trial 62 with value: 0.027239453047513962.[0m
[32m[I 2024-11-06 04:21:42,526][0m Trial 65 finished with value: 0.04221241921186447 and parameters: {'learning_rate': 8.020521082222446e-05, 'batch_size': 28, 'step_size': 10, 'gamma': 0.854040277187012, 'depth': 6, 'dim': 100}. Best is trial 62 with value: 0.027239453047513962.[0m
[32m[I 2024-11-06 04:24:21,562][0m Trial 66 finished with value: 0.03991008549928665 and parameters: {'learning_rate': 3.9768174869561e-05, 'batch_size': 42, 'step_size': 9, 'gamma': 0.8815262942757118, 'depth': 6, 'dim': 70}. Best is trial 62 with value: 0.027239453047513962.[0m
[32m[I 2024-11-06 04:26:19,875][0m Trial 67 finished with value: 0.03785796836018562 and parameters: {'learning_rate': 2.675390445819989e-05, 'batch_size': 57, 'step_size': 10, 'gamma': 0.861660658287827, 'depth': 6, 'dim': 89}. Best is trial 62 with value: 0.027239453047513962.[0m
[32m[I 2024-11-06 04:27:55,992][0m Trial 68 finished with value: 0.05871501564979553 and parameters: {'learning_rate': 5.937549635949483e-05, 'batch_size': 71, 'step_size': 8, 'gamma': 0.8303171554154746, 'depth': 6, 'dim': 47}. Best is trial 62 with value: 0.027239453047513962.[0m
[32m[I 2024-11-06 04:30:11,110][0m Trial 69 finished with value: 0.0300985686480999 and parameters: {'learning_rate': 0.00011164217664943213, 'batch_size': 50, 'step_size': 7, 'gamma': 0.8506056440863208, 'depth': 6, 'dim': 94}. Best is trial 62 with value: 0.027239453047513962.[0m
[32m[I 2024-11-06 04:32:23,570][0m Trial 70 finished with value: 0.031139563769102097 and parameters: {'learning_rate': 0.00011586568695111263, 'batch_size': 51, 'step_size': 7, 'gamma': 0.8720866305448315, 'depth': 6, 'dim': 96}. Best is trial 62 with value: 0.027239453047513962.[0m
[32m[I 2024-11-06 04:34:43,217][0m Trial 71 finished with value: 0.03504692018032074 and parameters: {'learning_rate': 0.00012370383420855354, 'batch_size': 48, 'step_size': 7, 'gamma': 0.8721443243622368, 'depth': 6, 'dim': 82}. Best is trial 62 with value: 0.027239453047513962.[0m
[32m[I 2024-11-06 04:36:36,650][0m Trial 72 finished with value: 0.03057529218494892 and parameters: {'learning_rate': 0.00011550009187002728, 'batch_size': 60, 'step_size': 6, 'gamma': 0.8508755979204341, 'depth': 6, 'dim': 94}. Best is trial 62 with value: 0.027239453047513962.[0m
[32m[I 2024-11-06 04:38:29,915][0m Trial 73 finished with value: 0.02979893423616886 and parameters: {'learning_rate': 0.00010116623666466343, 'batch_size': 60, 'step_size': 6, 'gamma': 0.8483104846446158, 'depth': 6, 'dim': 93}. Best is trial 62 with value: 0.027239453047513962.[0m
[32m[I 2024-11-06 04:40:18,352][0m Trial 74 finished with value: 0.033229779452085495 and parameters: {'learning_rate': 0.00015360802211882577, 'batch_size': 62, 'step_size': 6, 'gamma': 0.8494772799141168, 'depth': 6, 'dim': 102}. Best is trial 62 with value: 0.027239453047513962.[0m
[32m[I 2024-11-06 04:41:37,623][0m Trial 75 finished with value: 0.04347091540694237 and parameters: {'learning_rate': 9.215515076295823e-05, 'batch_size': 85, 'step_size': 6, 'gamma': 0.8386891648681595, 'depth': 6, 'dim': 65}. Best is trial 62 with value: 0.027239453047513962.[0m
[32m[I 2024-11-06 04:43:30,957][0m Trial 76 finished with value: 0.0307453665882349 and parameters: {'learning_rate': 6.970463780698703e-05, 'batch_size': 60, 'step_size': 5, 'gamma': 0.8501716792265985, 'depth': 6, 'dim': 93}. Best is trial 62 with value: 0.027239453047513962.[0m
[32m[I 2024-11-06 04:47:20,788][0m Trial 77 finished with value: 0.032514505088329315 and parameters: {'learning_rate': 3.864882207990044e-05, 'batch_size': 29, 'step_size': 4, 'gamma': 0.8614075711064777, 'depth': 6, 'dim': 117}. Best is trial 62 with value: 0.027239453047513962.[0m
[32m[I 2024-11-06 04:50:04,581][0m Trial 78 finished with value: 0.029195697978138924 and parameters: {'learning_rate': 0.00010585914689345148, 'batch_size': 41, 'step_size': 8, 'gamma': 0.8308612301040625, 'depth': 6, 'dim': 80}. Best is trial 62 with value: 0.027239453047513962.[0m
[32m[I 2024-11-06 04:55:07,550][0m Trial 79 finished with value: 0.06002639979124069 and parameters: {'learning_rate': 0.00020368445094313484, 'batch_size': 22, 'step_size': 9, 'gamma': 0.8254104867048266, 'depth': 6, 'dim': 54}. Best is trial 62 with value: 0.027239453047513962.[0m
[32m[I 2024-11-06 04:57:44,954][0m Trial 80 finished with value: 0.030817294493317604 and parameters: {'learning_rate': 8.294142266942063e-05, 'batch_size': 42, 'step_size': 8, 'gamma': 0.8397598892495266, 'depth': 6, 'dim': 79}. Best is trial 62 with value: 0.027239453047513962.[0m
[32m[I 2024-11-06 04:59:55,215][0m Trial 81 finished with value: 0.02736501395702362 and parameters: {'learning_rate': 0.00010540658405594925, 'batch_size': 52, 'step_size': 7, 'gamma': 0.8319489318041485, 'depth': 6, 'dim': 90}. Best is trial 62 with value: 0.027239453047513962.[0m
[32m[I 2024-11-06 05:02:07,719][0m Trial 82 finished with value: 0.02968696877360344 and parameters: {'learning_rate': 0.0001384311798907479, 'batch_size': 51, 'step_size': 7, 'gamma': 0.8176931458527569, 'depth': 6, 'dim': 88}. Best is trial 62 with value: 0.027239453047513962.[0m
[32m[I 2024-11-06 05:03:41,657][0m Trial 83 finished with value: 0.029582113027572632 and parameters: {'learning_rate': 0.00016399299547505285, 'batch_size': 73, 'step_size': 7, 'gamma': 0.8163003564076982, 'depth': 6, 'dim': 86}. Best is trial 62 with value: 0.027239453047513962.[0m
[32m[I 2024-11-06 05:05:13,079][0m Trial 84 finished with value: 0.0247214213013649 and parameters: {'learning_rate': 0.00016423355182706558, 'batch_size': 75, 'step_size': 7, 'gamma': 0.8141235923216185, 'depth': 6, 'dim': 85}. Best is trial 84 with value: 0.0247214213013649.[0m
[32m[I 2024-11-06 05:06:29,909][0m Trial 85 finished with value: 0.03378606587648392 and parameters: {'learning_rate': 0.00013854324232575807, 'batch_size': 88, 'step_size': 7, 'gamma': 0.8171542688955968, 'depth': 6, 'dim': 84}. Best is trial 84 with value: 0.0247214213013649.[0m
[32m[I 2024-11-06 05:07:39,246][0m Trial 86 finished with value: 0.09886611253023148 and parameters: {'learning_rate': 0.00016612756616458585, 'batch_size': 100, 'step_size': 8, 'gamma': 0.811344612911506, 'depth': 6, 'dim': 104}. Best is trial 84 with value: 0.0247214213013649.[0m
[32m[I 2024-11-06 05:09:09,869][0m Trial 87 finished with value: 0.032850585877895355 and parameters: {'learning_rate': 0.00020225101763739033, 'batch_size': 71, 'step_size': 8, 'gamma': 0.8035227144301694, 'depth': 6, 'dim': 77}. Best is trial 84 with value: 0.0247214213013649.[0m
[32m[I 2024-11-06 05:10:38,788][0m Trial 88 finished with value: 0.031518202275037766 and parameters: {'learning_rate': 0.00014319465641937345, 'batch_size': 77, 'step_size': 7, 'gamma': 0.8307052247635072, 'depth': 6, 'dim': 115}. Best is trial 84 with value: 0.0247214213013649.[0m
[32m[I 2024-11-06 05:13:45,272][0m Trial 89 finished with value: 0.03587082028388977 and parameters: {'learning_rate': 6.553780678192945e-05, 'batch_size': 35, 'step_size': 8, 'gamma': 0.8190846538042651, 'depth': 6, 'dim': 62}. Best is trial 84 with value: 0.0247214213013649.[0m
[32m[I 2024-11-06 05:15:22,692][0m Trial 90 finished with value: 0.03212180733680725 and parameters: {'learning_rate': 0.0002458717769700718, 'batch_size': 67, 'step_size': 7, 'gamma': 0.8325388013107372, 'depth': 6, 'dim': 87}. Best is trial 84 with value: 0.0247214213013649.[0m
[32m[I 2024-11-06 05:17:27,765][0m Trial 91 finished with value: 0.035757195204496384 and parameters: {'learning_rate': 9.315274959630063e-05, 'batch_size': 54, 'step_size': 6, 'gamma': 0.8236377843929323, 'depth': 6, 'dim': 88}. Best is trial 84 with value: 0.0247214213013649.[0m
[32m[I 2024-11-06 05:19:15,970][0m Trial 92 finished with value: 0.03383166342973709 and parameters: {'learning_rate': 0.00010534085770977175, 'batch_size': 63, 'step_size': 5, 'gamma': 0.8033841590610411, 'depth': 6, 'dim': 101}. Best is trial 84 with value: 0.0247214213013649.[0m
[32m[I 2024-11-06 05:20:47,409][0m Trial 93 finished with value: 0.04464791715145111 and parameters: {'learning_rate': 5.553685461421062e-05, 'batch_size': 74, 'step_size': 6, 'gamma': 0.8144157953107946, 'depth': 6, 'dim': 73}. Best is trial 84 with value: 0.0247214213013649.[0m
[32m[I 2024-11-06 05:23:27,882][0m Trial 94 finished with value: 0.042287133634090424 and parameters: {'learning_rate': 0.0001585202030356325, 'batch_size': 41, 'step_size': 7, 'gamma': 0.8366686760564116, 'depth': 6, 'dim': 83}. Best is trial 84 with value: 0.0247214213013649.[0m
[32m[I 2024-11-06 05:25:40,447][0m Trial 95 finished with value: 0.037833236157894135 and parameters: {'learning_rate': 0.0001853721826942896, 'batch_size': 51, 'step_size': 9, 'gamma': 0.7891093240733973, 'depth': 6, 'dim': 112}. Best is trial 84 with value: 0.0247214213013649.[0m
[32m[I 2024-11-06 05:27:36,274][0m Trial 96 finished with value: 0.03284488618373871 and parameters: {'learning_rate': 8.888103870688885e-05, 'batch_size': 58, 'step_size': 10, 'gamma': 0.8271149174503653, 'depth': 6, 'dim': 125}. Best is trial 84 with value: 0.0247214213013649.[0m
[32m[I 2024-11-06 05:28:38,327][0m Trial 97 finished with value: 0.048486046493053436 and parameters: {'learning_rate': 0.00013123042062462368, 'batch_size': 109, 'step_size': 7, 'gamma': 0.8439739305861272, 'depth': 6, 'dim': 56}. Best is trial 84 with value: 0.0247214213013649.[0m
[32m[I 2024-11-06 05:31:49,580][0m Trial 98 finished with value: 0.03256918862462044 and parameters: {'learning_rate': 0.00010338296540116352, 'batch_size': 34, 'step_size': 5, 'gamma': 0.8085168757277686, 'depth': 6, 'dim': 92}. Best is trial 84 with value: 0.0247214213013649.[0m
[32m[I 2024-11-06 05:32:58,581][0m Trial 99 finished with value: 0.029679428786039352 and parameters: {'learning_rate': 5.164923832872965e-05, 'batch_size': 84, 'step_size': 8, 'gamma': 0.8641664444401613, 'depth': 5, 'dim': 104}. Best is trial 84 with value: 0.0247214213013649.[0m
Best hyperparameters (trend): {'learning_rate': 0.00019454806514490895, 'batch_size': 73, 'step_size': 9, 'gamma': 0.8130493841839006, 'depth': 6, 'dim': 139}
Best hyperparameters (seasonal): {'learning_rate': 0.0007615323253877758, 'batch_size': 20, 'step_size': 15, 'gamma': 0.7975246603221708, 'depth': 2, 'dim': 146}
Best hyperparameters (resid): {'learning_rate': 0.00016423355182706558, 'batch_size': 75, 'step_size': 7, 'gamma': 0.8141235923216185, 'depth': 6, 'dim': 85}
Epoch 1/1000, (Training | Validation) Trend Loss: 0.1445 | 0.9633, Seasonal Loss: 0.1669 | 0.5050, Residual Loss: 0.6348 | 0.9948
Epoch 2/1000, (Training | Validation) Trend Loss: 0.3215 | 0.2932, Seasonal Loss: 0.0749 | 0.3250, Residual Loss: 0.2970 | 0.1632
Epoch 3/1000, (Training | Validation) Trend Loss: 0.4909 | 0.9143, Seasonal Loss: 0.0653 | 0.2456, Residual Loss: 0.2869 | 0.2067
Epoch 4/1000, (Training | Validation) Trend Loss: 0.4094 | 0.4100, Seasonal Loss: 0.0509 | 0.1752, Residual Loss: 0.1629 | 0.1332
Epoch 5/1000, (Training | Validation) Trend Loss: 0.4317 | 0.1221, Seasonal Loss: 0.0404 | 0.1135, Residual Loss: 0.1363 | 0.1097
Epoch 6/1000, (Training | Validation) Trend Loss: 0.3384 | 0.2552, Seasonal Loss: 0.0378 | 0.1190, Residual Loss: 0.1410 | 0.0921
Epoch 7/1000, (Training | Validation) Trend Loss: 0.1403 | 0.0970, Seasonal Loss: 0.0301 | 0.0965, Residual Loss: 0.1414 | 0.0781
Epoch 8/1000, (Training | Validation) Trend Loss: 0.0786 | 0.0905, Seasonal Loss: 0.0293 | 0.0947, Residual Loss: 0.1262 | 0.0897
Epoch 9/1000, (Training | Validation) Trend Loss: 0.0672 | 0.0312, Seasonal Loss: 0.0404 | 0.0653, Residual Loss: 0.0916 | 0.0708
Epoch 10/1000, (Training | Validation) Trend Loss: 0.0546 | 0.0267, Seasonal Loss: 0.0261 | 0.0701, Residual Loss: 0.0803 | 0.0619
Epoch 11/1000, (Training | Validation) Trend Loss: 0.0874 | 0.0727, Seasonal Loss: 0.0298 | 0.1020, Residual Loss: 0.0812 | 0.0604
Epoch 12/1000, (Training | Validation) Trend Loss: 0.0818 | 0.2142, Seasonal Loss: 0.0355 | 0.1164, Residual Loss: 0.0882 | 0.0799
Epoch 13/1000, (Training | Validation) Trend Loss: 0.0357 | 0.0449, Seasonal Loss: 0.0232 | 0.0698, Residual Loss: 0.0870 | 0.1171
Epoch 14/1000, (Training | Validation) Trend Loss: 0.0400 | 0.0296, Seasonal Loss: 0.0202 | 0.0610, Residual Loss: 0.0707 | 0.0907
Epoch 15/1000, (Training | Validation) Trend Loss: 0.0292 | 0.0215, Seasonal Loss: 0.0187 | 0.0650, Residual Loss: 0.0581 | 0.0682
Epoch 16/1000, (Training | Validation) Trend Loss: 0.0472 | 0.0174, Seasonal Loss: 0.0245 | 0.0781, Residual Loss: 0.0514 | 0.0414
Epoch 17/1000, (Training | Validation) Trend Loss: 0.0906 | 0.1771, Seasonal Loss: 0.0235 | 0.0680, Residual Loss: 0.0536 | 0.0427
Epoch 18/1000, (Training | Validation) Trend Loss: 0.0450 | 0.1045, Seasonal Loss: 0.0229 | 0.0680, Residual Loss: 0.0550 | 0.0420
Epoch 19/1000, (Training | Validation) Trend Loss: 0.0229 | 0.0306, Seasonal Loss: 0.0221 | 0.0740, Residual Loss: 0.0570 | 0.0447
Epoch 20/1000, (Training | Validation) Trend Loss: 0.0245 | 0.0165, Seasonal Loss: 0.0199 | 0.0561, Residual Loss: 0.0611 | 0.0556
Epoch 21/1000, (Training | Validation) Trend Loss: 0.0118 | 0.0253, Seasonal Loss: 0.0195 | 0.0808, Residual Loss: 0.0640 | 0.0795
Epoch 22/1000, (Training | Validation) Trend Loss: 0.0193 | 0.0242, Seasonal Loss: 0.0238 | 0.1012, Residual Loss: 0.0525 | 0.0927
Epoch 23/1000, (Training | Validation) Trend Loss: 0.0223 | 0.0245, Seasonal Loss: 0.0186 | 0.0612, Residual Loss: 0.0412 | 0.0330
Epoch 24/1000, (Training | Validation) Trend Loss: 0.0214 | 0.0293, Seasonal Loss: 0.0180 | 0.0731, Residual Loss: 0.0404 | 0.0415
Epoch 25/1000, (Training | Validation) Trend Loss: 0.0255 | 0.0521, Seasonal Loss: 0.0186 | 0.0567, Residual Loss: 0.0391 | 0.0383
Epoch 26/1000, (Training | Validation) Trend Loss: 0.0293 | 0.1020, Seasonal Loss: 0.0202 | 0.0727, Residual Loss: 0.0388 | 0.0377
Epoch 27/1000, (Training | Validation) Trend Loss: 0.0201 | 0.0861, Seasonal Loss: 0.0179 | 0.0722, Residual Loss: 0.0390 | 0.0391
Epoch 28/1000, (Training | Validation) Trend Loss: 0.0091 | 0.0277, Seasonal Loss: 0.0190 | 0.0656, Residual Loss: 0.0405 | 0.0423
Epoch 29/1000, (Training | Validation) Trend Loss: 0.0125 | 0.0067, Seasonal Loss: 0.0133 | 0.0473, Residual Loss: 0.0411 | 0.0769
Epoch 30/1000, (Training | Validation) Trend Loss: 0.0122 | 0.0061, Seasonal Loss: 0.0159 | 0.0702, Residual Loss: 0.0344 | 0.0434
Epoch 31/1000, (Training | Validation) Trend Loss: 0.0137 | 0.0056, Seasonal Loss: 0.0247 | 0.0699, Residual Loss: 0.0333 | 0.0391
Epoch 32/1000, (Training | Validation) Trend Loss: 0.0143 | 0.0059, Seasonal Loss: 0.0176 | 0.0513, Residual Loss: 0.0327 | 0.0389
Epoch 33/1000, (Training | Validation) Trend Loss: 0.0117 | 0.0064, Seasonal Loss: 0.0118 | 0.0401, Residual Loss: 0.0324 | 0.0395
Epoch 34/1000, (Training | Validation) Trend Loss: 0.0093 | 0.0067, Seasonal Loss: 0.0117 | 0.0423, Residual Loss: 0.0324 | 0.0399
Epoch 35/1000, (Training | Validation) Trend Loss: 0.0078 | 0.0067, Seasonal Loss: 0.0172 | 0.0523, Residual Loss: 0.0328 | 0.0407
Epoch 36/1000, (Training | Validation) Trend Loss: 0.0067 | 0.0063, Seasonal Loss: 0.0200 | 0.1049, Residual Loss: 0.0327 | 0.0573
Epoch 37/1000, (Training | Validation) Trend Loss: 0.0050 | 0.0056, Seasonal Loss: 0.0160 | 0.0549, Residual Loss: 0.0298 | 0.0414
Epoch 38/1000, (Training | Validation) Trend Loss: 0.0041 | 0.0050, Seasonal Loss: 0.0124 | 0.0417, Residual Loss: 0.0289 | 0.0359
Epoch 39/1000, (Training | Validation) Trend Loss: 0.0053 | 0.0086, Seasonal Loss: 0.0179 | 0.1283, Residual Loss: 0.0282 | 0.0335
Epoch 40/1000, (Training | Validation) Trend Loss: 0.0092 | 0.0171, Seasonal Loss: 0.0125 | 0.0568, Residual Loss: 0.0279 | 0.0318
Epoch 41/1000, (Training | Validation) Trend Loss: 0.0178 | 0.0463, Seasonal Loss: 0.0140 | 0.0424, Residual Loss: 0.0279 | 0.0298
Epoch 42/1000, (Training | Validation) Trend Loss: 0.0194 | 0.0826, Seasonal Loss: 0.0099 | 0.0382, Residual Loss: 0.0284 | 0.0277
Epoch 43/1000, (Training | Validation) Trend Loss: 0.0083 | 0.0385, Seasonal Loss: 0.0112 | 0.0497, Residual Loss: 0.0290 | 0.0261
Epoch 44/1000, (Training | Validation) Trend Loss: 0.0046 | 0.0135, Seasonal Loss: 0.0130 | 0.0559, Residual Loss: 0.0278 | 0.0263
Epoch 45/1000, (Training | Validation) Trend Loss: 0.0054 | 0.0060, Seasonal Loss: 0.0185 | 0.0641, Residual Loss: 0.0271 | 0.0276
Epoch 46/1000, (Training | Validation) Trend Loss: 0.0055 | 0.0059, Seasonal Loss: 0.0108 | 0.0711, Residual Loss: 0.0263 | 0.0279
Epoch 47/1000, (Training | Validation) Trend Loss: 0.0049 | 0.0046, Seasonal Loss: 0.0135 | 0.0728, Residual Loss: 0.0257 | 0.0280
Epoch 48/1000, (Training | Validation) Trend Loss: 0.0047 | 0.0045, Seasonal Loss: 0.0173 | 0.1786, Residual Loss: 0.0254 | 0.0282
Epoch 49/1000, (Training | Validation) Trend Loss: 0.0033 | 0.0045, Seasonal Loss: 0.0099 | 0.0841, Residual Loss: 0.0252 | 0.0282
Epoch 50/1000, (Training | Validation) Trend Loss: 0.0031 | 0.0048, Seasonal Loss: 0.0085 | 0.0719, Residual Loss: 0.0249 | 0.0272
Epoch 51/1000, (Training | Validation) Trend Loss: 0.0029 | 0.0060, Seasonal Loss: 0.0132 | 0.1307, Residual Loss: 0.0242 | 0.0288
Epoch 52/1000, (Training | Validation) Trend Loss: 0.0029 | 0.0072, Seasonal Loss: 0.0157 | 0.0477, Residual Loss: 0.0237 | 0.0298
Epoch 53/1000, (Training | Validation) Trend Loss: 0.0030 | 0.0082, Seasonal Loss: 0.0093 | 0.0545, Residual Loss: 0.0233 | 0.0304
Epoch 54/1000, (Training | Validation) Trend Loss: 0.0032 | 0.0091, Seasonal Loss: 0.0141 | 0.0705, Residual Loss: 0.0230 | 0.0307
Epoch 55/1000, (Training | Validation) Trend Loss: 0.0029 | 0.0123, Seasonal Loss: 0.0148 | 0.0996, Residual Loss: 0.0227 | 0.0309
Epoch 56/1000, (Training | Validation) Trend Loss: 0.0024 | 0.0075, Seasonal Loss: 0.0095 | 0.0802, Residual Loss: 0.0224 | 0.0311
Epoch 57/1000, (Training | Validation) Trend Loss: 0.0024 | 0.0057, Seasonal Loss: 0.0093 | 0.1074, Residual Loss: 0.0221 | 0.0311
Epoch 58/1000, (Training | Validation) Trend Loss: 0.0026 | 0.0045, Seasonal Loss: 0.0112 | 0.1337, Residual Loss: 0.0219 | 0.0314
Epoch 59/1000, (Training | Validation) Trend Loss: 0.0029 | 0.0043, Seasonal Loss: 0.0127 | 0.1242, Residual Loss: 0.0216 | 0.0312
Epoch 60/1000, (Training | Validation) Trend Loss: 0.0034 | 0.0049, Seasonal Loss: 0.0090 | 0.0637, Residual Loss: 0.0214 | 0.0308
Epoch 61/1000, (Training | Validation) Trend Loss: 0.0037 | 0.0058, Seasonal Loss: 0.0072 | 0.0563, Residual Loss: 0.0212 | 0.0304
Epoch 62/1000, (Training | Validation) Trend Loss: 0.0035 | 0.0058, Seasonal Loss: 0.0064 | 0.0590, Residual Loss: 0.0210 | 0.0300
Epoch 63/1000, (Training | Validation) Trend Loss: 0.0028 | 0.0049, Seasonal Loss: 0.0101 | 0.1346, Residual Loss: 0.0208 | 0.0294
Epoch 64/1000, (Training | Validation) Trend Loss: 0.0022 | 0.0041, Seasonal Loss: 0.0131 | 0.1364, Residual Loss: 0.0207 | 0.0281
Epoch 65/1000, (Training | Validation) Trend Loss: 0.0024 | 0.0064, Seasonal Loss: 0.0089 | 0.0696, Residual Loss: 0.0203 | 0.0294
Epoch 66/1000, (Training | Validation) Trend Loss: 0.0029 | 0.0097, Seasonal Loss: 0.0068 | 0.0519, Residual Loss: 0.0201 | 0.0295
Epoch 67/1000, (Training | Validation) Trend Loss: 0.0031 | 0.0115, Seasonal Loss: 0.0063 | 0.0583, Residual Loss: 0.0199 | 0.0294
Epoch 68/1000, (Training | Validation) Trend Loss: 0.0029 | 0.0114, Seasonal Loss: 0.0085 | 0.1263, Residual Loss: 0.0198 | 0.0294
Epoch 69/1000, (Training | Validation) Trend Loss: 0.0026 | 0.0103, Seasonal Loss: 0.0079 | 0.0949, Residual Loss: 0.0196 | 0.0292
Epoch 70/1000, (Training | Validation) Trend Loss: 0.0024 | 0.0093, Seasonal Loss: 0.0069 | 0.0963, Residual Loss: 0.0195 | 0.0290
Epoch 71/1000, (Training | Validation) Trend Loss: 0.0022 | 0.0081, Seasonal Loss: 0.0065 | 0.0788, Residual Loss: 0.0193 | 0.0282
Epoch 72/1000, (Training | Validation) Trend Loss: 0.0020 | 0.0069, Seasonal Loss: 0.0059 | 0.0871, Residual Loss: 0.0189 | 0.0298
Epoch 73/1000, (Training | Validation) Trend Loss: 0.0020 | 0.0053, Seasonal Loss: 0.0064 | 0.0629, Residual Loss: 0.0188 | 0.0298
Epoch 74/1000, (Training | Validation) Trend Loss: 0.0022 | 0.0042, Seasonal Loss: 0.0062 | 0.0688, Residual Loss: 0.0186 | 0.0298
Epoch 75/1000, (Training | Validation) Trend Loss: 0.0023 | 0.0042, Seasonal Loss: 0.0066 | 0.0924, Residual Loss: 0.0185 | 0.0297
Epoch 76/1000, (Training | Validation) Trend Loss: 0.0022 | 0.0041, Seasonal Loss: 0.0080 | 0.0764, Residual Loss: 0.0184 | 0.0296
Epoch 77/1000, (Training | Validation) Trend Loss: 0.0021 | 0.0040, Seasonal Loss: 0.0061 | 0.0538, Residual Loss: 0.0182 | 0.0294
Epoch 78/1000, (Training | Validation) Trend Loss: 0.0020 | 0.0041, Seasonal Loss: 0.0054 | 0.0444, Residual Loss: 0.0181 | 0.0288
Epoch 79/1000, (Training | Validation) Trend Loss: 0.0019 | 0.0043, Seasonal Loss: 0.0055 | 0.0416, Residual Loss: 0.0179 | 0.0302
Epoch 80/1000, (Training | Validation) Trend Loss: 0.0019 | 0.0046, Seasonal Loss: 0.0046 | 0.0368, Residual Loss: 0.0178 | 0.0297
Epoch 81/1000, (Training | Validation) Trend Loss: 0.0019 | 0.0050, Seasonal Loss: 0.0046 | 0.0355, Residual Loss: 0.0176 | 0.0298
Epoch 82/1000, (Training | Validation) Trend Loss: 0.0019 | 0.0056, Seasonal Loss: 0.0053 | 0.0404, Residual Loss: 0.0175 | 0.0297
Epoch 83/1000, (Training | Validation) Trend Loss: 0.0018 | 0.0049, Seasonal Loss: 0.0057 | 0.0400, Residual Loss: 0.0174 | 0.0296
Epoch 84/1000, (Training | Validation) Trend Loss: 0.0018 | 0.0046, Seasonal Loss: 0.0107 | 0.0296, Residual Loss: 0.0173 | 0.0294
Epoch 85/1000, (Training | Validation) Trend Loss: 0.0018 | 0.0045, Seasonal Loss: 0.0055 | 0.0316, Residual Loss: 0.0172 | 0.0290
Epoch 86/1000, (Training | Validation) Trend Loss: 0.0018 | 0.0044, Seasonal Loss: 0.0046 | 0.0364, Residual Loss: 0.0170 | 0.0303
Epoch 87/1000, (Training | Validation) Trend Loss: 0.0018 | 0.0044, Seasonal Loss: 0.0035 | 0.0407, Residual Loss: 0.0169 | 0.0295
Epoch 88/1000, (Training | Validation) Trend Loss: 0.0018 | 0.0044, Seasonal Loss: 0.0033 | 0.0464, Residual Loss: 0.0168 | 0.0298
Epoch 89/1000, (Training | Validation) Trend Loss: 0.0018 | 0.0044, Seasonal Loss: 0.0036 | 0.0554, Residual Loss: 0.0167 | 0.0297
Epoch 90/1000, (Training | Validation) Trend Loss: 0.0018 | 0.0044, Seasonal Loss: 0.0038 | 0.0456, Residual Loss: 0.0166 | 0.0296
Epoch 91/1000, (Training | Validation) Trend Loss: 0.0018 | 0.0043, Seasonal Loss: 0.0048 | 0.0317, Residual Loss: 0.0165 | 0.0295
Epoch 92/1000, (Training | Validation) Trend Loss: 0.0018 | 0.0043, Seasonal Loss: 0.0081 | 0.0266, Residual Loss: 0.0164 | 0.0292
Epoch 93/1000, (Training | Validation) Trend Loss: 0.0018 | 0.0043, Seasonal Loss: 0.0059 | 0.0319, Residual Loss: 0.0163 | 0.0303
Epoch 94/1000, (Training | Validation) Trend Loss: 0.0017 | 0.0044, Seasonal Loss: 0.0046 | 0.0404, Residual Loss: 0.0163 | 0.0293
Epoch 95/1000, (Training | Validation) Trend Loss: 0.0017 | 0.0044, Seasonal Loss: 0.0049 | 0.0534, Residual Loss: 0.0162 | 0.0301
Epoch 96/1000, (Training | Validation) Trend Loss: 0.0017 | 0.0044, Seasonal Loss: 0.0058 | 0.0444, Residual Loss: 0.0161 | 0.0295
Epoch 97/1000, (Training | Validation) Trend Loss: 0.0017 | 0.0044, Seasonal Loss: 0.0103 | 0.0409, Residual Loss: 0.0160 | 0.0297
Epoch 98/1000, (Training | Validation) Trend Loss: 0.0017 | 0.0043, Seasonal Loss: 0.0086 | 0.0321, Residual Loss: 0.0159 | 0.0295
Epoch 99/1000, (Training | Validation) Trend Loss: 0.0017 | 0.0043, Seasonal Loss: 0.0108 | 0.0677, Residual Loss: 0.0159 | 0.0293
Epoch 100/1000, (Training | Validation) Trend Loss: 0.0017 | 0.0043, Seasonal Loss: 0.0107 | 0.0288, Residual Loss: 0.0158 | 0.0303
Epoch 101/1000, (Training | Validation) Trend Loss: 0.0017 | 0.0042, Seasonal Loss: 0.0066 | 0.0276, Residual Loss: 0.0157 | 0.0293
Epoch 102/1000, (Training | Validation) Trend Loss: 0.0017 | 0.0042, Seasonal Loss: 0.0042 | 0.0313, Residual Loss: 0.0156 | 0.0304
Epoch 103/1000, (Training | Validation) Trend Loss: 0.0017 | 0.0042, Seasonal Loss: 0.0065 | 0.0402, Residual Loss: 0.0156 | 0.0292
Epoch 104/1000, (Training | Validation) Trend Loss: 0.0017 | 0.0042, Seasonal Loss: 0.0098 | 0.0426, Residual Loss: 0.0155 | 0.0302
Epoch 105/1000, (Training | Validation) Trend Loss: 0.0017 | 0.0042, Seasonal Loss: 0.0067 | 0.0327, Residual Loss: 0.0155 | 0.0293
Epoch 106/1000, (Training | Validation) Trend Loss: 0.0017 | 0.0042, Seasonal Loss: 0.0053 | 0.0324, Residual Loss: 0.0154 | 0.0298
Epoch 107/1000, (Training | Validation) Trend Loss: 0.0017 | 0.0042, Seasonal Loss: 0.0033 | 0.0262, Residual Loss: 0.0153 | 0.0297
Epoch 108/1000, (Training | Validation) Trend Loss: 0.0017 | 0.0042, Seasonal Loss: 0.0030 | 0.0251, Residual Loss: 0.0153 | 0.0298
Epoch 109/1000, (Training | Validation) Trend Loss: 0.0017 | 0.0041, Seasonal Loss: 0.0029 | 0.0250, Residual Loss: 0.0152 | 0.0297
Epoch 110/1000, (Training | Validation) Trend Loss: 0.0017 | 0.0041, Seasonal Loss: 0.0027 | 0.0254, Residual Loss: 0.0152 | 0.0298
Epoch 111/1000, (Training | Validation) Trend Loss: 0.0017 | 0.0041, Seasonal Loss: 0.0027 | 0.0266, Residual Loss: 0.0151 | 0.0296
Epoch 112/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0041, Seasonal Loss: 0.0028 | 0.0291, Residual Loss: 0.0150 | 0.0298
Epoch 113/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0041, Seasonal Loss: 0.0030 | 0.0347, Residual Loss: 0.0150 | 0.0295
Epoch 114/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0041, Seasonal Loss: 0.0029 | 0.0359, Residual Loss: 0.0149 | 0.0304
Epoch 115/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0041, Seasonal Loss: 0.0022 | 0.0285, Residual Loss: 0.0149 | 0.0291
Epoch 116/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0041, Seasonal Loss: 0.0022 | 0.0253, Residual Loss: 0.0148 | 0.0317
Epoch 117/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0041, Seasonal Loss: 0.0023 | 0.0243, Residual Loss: 0.0150 | 0.0285
Epoch 118/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0040, Seasonal Loss: 0.0027 | 0.0265, Residual Loss: 0.0149 | 0.0358
Epoch 119/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0040, Seasonal Loss: 0.0047 | 0.0341, Residual Loss: 0.0155 | 0.0303
Epoch 120/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0040, Seasonal Loss: 0.0083 | 0.0460, Residual Loss: 0.0162 | 0.0503
Epoch 121/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0040, Seasonal Loss: 0.0087 | 0.0297, Residual Loss: 0.0225 | 0.0373
Epoch 122/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0040, Seasonal Loss: 0.0048 | 0.0259, Residual Loss: 0.0375 | 0.0552
Epoch 123/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0040, Seasonal Loss: 0.0032 | 0.0249, Residual Loss: 0.0548 | 0.0484
Epoch 124/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0040, Seasonal Loss: 0.0028 | 0.0244, Residual Loss: 0.0236 | 0.0324
Epoch 125/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0040, Seasonal Loss: 0.0028 | 0.0238, Residual Loss: 0.0190 | 0.0319
Epoch 126/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0040, Seasonal Loss: 0.0025 | 0.0231, Residual Loss: 0.0166 | 0.0301
Epoch 127/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0039, Seasonal Loss: 0.0024 | 0.0236, Residual Loss: 0.0152 | 0.0303
Epoch 128/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0040, Seasonal Loss: 0.0024 | 0.0249, Residual Loss: 0.0149 | 0.0298
Epoch 129/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0040, Seasonal Loss: 0.0026 | 0.0277, Residual Loss: 0.0148 | 0.0298
Epoch 130/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0040, Seasonal Loss: 0.0026 | 0.0315, Residual Loss: 0.0147 | 0.0297
Epoch 131/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0040, Seasonal Loss: 0.0022 | 0.0283, Residual Loss: 0.0147 | 0.0298
Epoch 132/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0039, Seasonal Loss: 0.0021 | 0.0243, Residual Loss: 0.0146 | 0.0298
Epoch 133/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0039, Seasonal Loss: 0.0021 | 0.0224, Residual Loss: 0.0146 | 0.0298
Epoch 134/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0039, Seasonal Loss: 0.0023 | 0.0233, Residual Loss: 0.0145 | 0.0298
Epoch 135/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0039, Seasonal Loss: 0.0034 | 0.0295, Residual Loss: 0.0145 | 0.0299
Epoch 136/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0039, Seasonal Loss: 0.0069 | 0.0354, Residual Loss: 0.0145 | 0.0299
Epoch 137/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0039, Seasonal Loss: 0.0049 | 0.0301, Residual Loss: 0.0145 | 0.0299
Epoch 138/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0039, Seasonal Loss: 0.0058 | 0.0419, Residual Loss: 0.0144 | 0.0299
Epoch 139/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0039, Seasonal Loss: 0.0048 | 0.0261, Residual Loss: 0.0144 | 0.0300
Epoch 140/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0039, Seasonal Loss: 0.0023 | 0.0236, Residual Loss: 0.0144 | 0.0300
Epoch 141/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0039, Seasonal Loss: 0.0024 | 0.0242, Residual Loss: 0.0144 | 0.0300
Epoch 142/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0039, Seasonal Loss: 0.0021 | 0.0226, Residual Loss: 0.0143 | 0.0300
Epoch 143/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0039, Seasonal Loss: 0.0020 | 0.0226, Residual Loss: 0.0143 | 0.0301
Epoch 144/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0039, Seasonal Loss: 0.0019 | 0.0220, Residual Loss: 0.0143 | 0.0301
Epoch 145/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0038, Seasonal Loss: 0.0019 | 0.0219, Residual Loss: 0.0143 | 0.0301
Epoch 146/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0038, Seasonal Loss: 0.0018 | 0.0215, Residual Loss: 0.0143 | 0.0301
Epoch 147/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0038, Seasonal Loss: 0.0018 | 0.0214, Residual Loss: 0.0143 | 0.0301
Epoch 148/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0038, Seasonal Loss: 0.0018 | 0.0211, Residual Loss: 0.0142 | 0.0301
Epoch 149/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0038, Seasonal Loss: 0.0018 | 0.0211, Residual Loss: 0.0142 | 0.0302
Epoch 150/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0038, Seasonal Loss: 0.0019 | 0.0210, Residual Loss: 0.0142 | 0.0302
Epoch 151/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0038, Seasonal Loss: 0.0021 | 0.0224, Residual Loss: 0.0142 | 0.0302
Epoch 152/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0038, Seasonal Loss: 0.0023 | 0.0235, Residual Loss: 0.0142 | 0.0302
Epoch 153/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0038, Seasonal Loss: 0.0025 | 0.0247, Residual Loss: 0.0142 | 0.0302
Epoch 154/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0038, Seasonal Loss: 0.0025 | 0.0248, Residual Loss: 0.0142 | 0.0302
Epoch 155/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0038, Seasonal Loss: 0.0024 | 0.0249, Residual Loss: 0.0141 | 0.0302
Epoch 156/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0038, Seasonal Loss: 0.0027 | 0.0278, Residual Loss: 0.0141 | 0.0302
Epoch 157/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0038, Seasonal Loss: 0.0034 | 0.0338, Residual Loss: 0.0141 | 0.0302
Epoch 158/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0038, Seasonal Loss: 0.0042 | 0.0444, Residual Loss: 0.0141 | 0.0302
Epoch 159/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0038, Seasonal Loss: 0.0038 | 0.0400, Residual Loss: 0.0141 | 0.0303
Epoch 160/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0038, Seasonal Loss: 0.0028 | 0.0314, Residual Loss: 0.0141 | 0.0303
Epoch 161/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0038, Seasonal Loss: 0.0022 | 0.0264, Residual Loss: 0.0141 | 0.0303
Epoch 162/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0038, Seasonal Loss: 0.0019 | 0.0234, Residual Loss: 0.0141 | 0.0303
Epoch 163/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0037, Seasonal Loss: 0.0018 | 0.0215, Residual Loss: 0.0141 | 0.0303
Epoch 164/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0038, Seasonal Loss: 0.0018 | 0.0210, Residual Loss: 0.0140 | 0.0303
Epoch 165/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0037, Seasonal Loss: 0.0018 | 0.0205, Residual Loss: 0.0140 | 0.0303
Epoch 166/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0037, Seasonal Loss: 0.0019 | 0.0216, Residual Loss: 0.0140 | 0.0303
Epoch 167/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0037, Seasonal Loss: 0.0020 | 0.0221, Residual Loss: 0.0140 | 0.0303
Epoch 168/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0037, Seasonal Loss: 0.0021 | 0.0226, Residual Loss: 0.0140 | 0.0303
Epoch 169/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0037, Seasonal Loss: 0.0023 | 0.0229, Residual Loss: 0.0140 | 0.0303
Epoch 170/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0037, Seasonal Loss: 0.0025 | 0.0232, Residual Loss: 0.0140 | 0.0303
Epoch 171/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0037, Seasonal Loss: 0.0026 | 0.0225, Residual Loss: 0.0140 | 0.0303
Epoch 172/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0037, Seasonal Loss: 0.0026 | 0.0218, Residual Loss: 0.0140 | 0.0303
Epoch 173/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0037, Seasonal Loss: 0.0027 | 0.0213, Residual Loss: 0.0140 | 0.0303
Epoch 174/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0037, Seasonal Loss: 0.0026 | 0.0207, Residual Loss: 0.0140 | 0.0303
Epoch 175/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0037, Seasonal Loss: 0.0027 | 0.0206, Residual Loss: 0.0139 | 0.0303
Epoch 176/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0037, Seasonal Loss: 0.0026 | 0.0203, Residual Loss: 0.0139 | 0.0303
Epoch 177/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0037, Seasonal Loss: 0.0027 | 0.0209, Residual Loss: 0.0139 | 0.0303
Epoch 178/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0037, Seasonal Loss: 0.0024 | 0.0207, Residual Loss: 0.0139 | 0.0303
Epoch 179/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0037, Seasonal Loss: 0.0026 | 0.0231, Residual Loss: 0.0139 | 0.0303
Epoch 180/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0037, Seasonal Loss: 0.0027 | 0.0262, Residual Loss: 0.0139 | 0.0303
Epoch 181/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0037, Seasonal Loss: 0.0030 | 0.0307, Residual Loss: 0.0139 | 0.0303
Epoch 182/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0037, Seasonal Loss: 0.0025 | 0.0246, Residual Loss: 0.0139 | 0.0303
Epoch 183/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0037, Seasonal Loss: 0.0022 | 0.0210, Residual Loss: 0.0139 | 0.0303
Epoch 184/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0037, Seasonal Loss: 0.0020 | 0.0208, Residual Loss: 0.0139 | 0.0303
Epoch 185/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0036, Seasonal Loss: 0.0019 | 0.0212, Residual Loss: 0.0139 | 0.0303
Epoch 186/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0037, Seasonal Loss: 0.0018 | 0.0217, Residual Loss: 0.0139 | 0.0303
Epoch 187/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0036, Seasonal Loss: 0.0018 | 0.0224, Residual Loss: 0.0139 | 0.0303
Epoch 188/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0037, Seasonal Loss: 0.0018 | 0.0226, Residual Loss: 0.0139 | 0.0303
Epoch 189/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0036, Seasonal Loss: 0.0018 | 0.0219, Residual Loss: 0.0138 | 0.0303
Epoch 190/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0036, Seasonal Loss: 0.0017 | 0.0206, Residual Loss: 0.0138 | 0.0303
Epoch 191/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0036, Seasonal Loss: 0.0017 | 0.0198, Residual Loss: 0.0138 | 0.0303
Epoch 192/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0036, Seasonal Loss: 0.0017 | 0.0196, Residual Loss: 0.0138 | 0.0303
Epoch 193/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0036, Seasonal Loss: 0.0017 | 0.0197, Residual Loss: 0.0138 | 0.0303
Epoch 194/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0036, Seasonal Loss: 0.0017 | 0.0202, Residual Loss: 0.0138 | 0.0303
Epoch 195/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0036, Seasonal Loss: 0.0017 | 0.0212, Residual Loss: 0.0138 | 0.0303
Epoch 196/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0036, Seasonal Loss: 0.0019 | 0.0253, Residual Loss: 0.0138 | 0.0303
Epoch 197/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0036, Seasonal Loss: 0.0019 | 0.0257, Residual Loss: 0.0138 | 0.0303
Epoch 198/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0036, Seasonal Loss: 0.0018 | 0.0221, Residual Loss: 0.0138 | 0.0303
Epoch 199/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0036, Seasonal Loss: 0.0018 | 0.0202, Residual Loss: 0.0138 | 0.0303
Epoch 200/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0036, Seasonal Loss: 0.0016 | 0.0201, Residual Loss: 0.0138 | 0.0303
Epoch 201/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0036, Seasonal Loss: 0.0016 | 0.0206, Residual Loss: 0.0138 | 0.0303
Epoch 202/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0036, Seasonal Loss: 0.0016 | 0.0221, Residual Loss: 0.0138 | 0.0303
Epoch 203/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0036, Seasonal Loss: 0.0016 | 0.0236, Residual Loss: 0.0138 | 0.0303
Epoch 204/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0036, Seasonal Loss: 0.0016 | 0.0234, Residual Loss: 0.0138 | 0.0303
Epoch 205/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0036, Seasonal Loss: 0.0016 | 0.0209, Residual Loss: 0.0138 | 0.0303
Epoch 206/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0036, Seasonal Loss: 0.0016 | 0.0196, Residual Loss: 0.0138 | 0.0303
Epoch 207/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0036, Seasonal Loss: 0.0016 | 0.0198, Residual Loss: 0.0138 | 0.0303
Epoch 208/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0036, Seasonal Loss: 0.0015 | 0.0204, Residual Loss: 0.0138 | 0.0303
Epoch 209/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0036, Seasonal Loss: 0.0016 | 0.0222, Residual Loss: 0.0138 | 0.0303
Epoch 210/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0017 | 0.0251, Residual Loss: 0.0138 | 0.0303
Epoch 211/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0037, Seasonal Loss: 0.0018 | 0.0232, Residual Loss: 0.0137 | 0.0303
Epoch 212/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0017 | 0.0202, Residual Loss: 0.0137 | 0.0303
Epoch 213/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0037, Seasonal Loss: 0.0015 | 0.0199, Residual Loss: 0.0137 | 0.0303
Epoch 214/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0034, Seasonal Loss: 0.0014 | 0.0203, Residual Loss: 0.0137 | 0.0303
Epoch 215/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0038, Seasonal Loss: 0.0014 | 0.0206, Residual Loss: 0.0137 | 0.0303
Epoch 216/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0033, Seasonal Loss: 0.0014 | 0.0206, Residual Loss: 0.0137 | 0.0303
Epoch 217/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0039, Seasonal Loss: 0.0014 | 0.0202, Residual Loss: 0.0137 | 0.0303
Epoch 218/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0033, Seasonal Loss: 0.0014 | 0.0199, Residual Loss: 0.0137 | 0.0303
Epoch 219/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0043, Seasonal Loss: 0.0014 | 0.0197, Residual Loss: 0.0137 | 0.0303
Epoch 220/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0032, Seasonal Loss: 0.0014 | 0.0198, Residual Loss: 0.0137 | 0.0303
Epoch 221/1000, (Training | Validation) Trend Loss: 0.0016 | 0.0048, Seasonal Loss: 0.0014 | 0.0200, Residual Loss: 0.0137 | 0.0303
Epoch 222/1000, (Training | Validation) Trend Loss: 0.0018 | 0.0032, Seasonal Loss: 0.0014 | 0.0203, Residual Loss: 0.0137 | 0.0303
Epoch 223/1000, (Training | Validation) Trend Loss: 0.0020 | 0.0046, Seasonal Loss: 0.0014 | 0.0204, Residual Loss: 0.0137 | 0.0303
Epoch 224/1000, (Training | Validation) Trend Loss: 0.0022 | 0.0032, Seasonal Loss: 0.0014 | 0.0203, Residual Loss: 0.0137 | 0.0303
Epoch 225/1000, (Training | Validation) Trend Loss: 0.0022 | 0.0039, Seasonal Loss: 0.0014 | 0.0198, Residual Loss: 0.0137 | 0.0303
Epoch 226/1000, (Training | Validation) Trend Loss: 0.0020 | 0.0037, Seasonal Loss: 0.0014 | 0.0195, Residual Loss: 0.0137 | 0.0303
Epoch 227/1000, (Training | Validation) Trend Loss: 0.0017 | 0.0035, Seasonal Loss: 0.0014 | 0.0196, Residual Loss: 0.0137 | 0.0303
Epoch 228/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0036, Seasonal Loss: 0.0014 | 0.0201, Residual Loss: 0.0137 | 0.0303
Epoch 229/1000, (Training | Validation) Trend Loss: 0.0015 | 0.0035, Seasonal Loss: 0.0014 | 0.0205, Residual Loss: 0.0137 | 0.0303
Epoch 230/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0014 | 0.0213, Residual Loss: 0.0137 | 0.0303
Epoch 231/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0013 | 0.0208, Residual Loss: 0.0137 | 0.0303
Epoch 232/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0013 | 0.0198, Residual Loss: 0.0137 | 0.0303
Epoch 233/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0013 | 0.0197, Residual Loss: 0.0137 | 0.0303
Epoch 234/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0014 | 0.0200, Residual Loss: 0.0137 | 0.0303
Epoch 235/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0014 | 0.0202, Residual Loss: 0.0137 | 0.0303
Epoch 236/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0014 | 0.0202, Residual Loss: 0.0137 | 0.0303
Epoch 237/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0014 | 0.0206, Residual Loss: 0.0137 | 0.0303
Epoch 238/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0013 | 0.0203, Residual Loss: 0.0137 | 0.0303
Epoch 239/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0013 | 0.0199, Residual Loss: 0.0137 | 0.0303
Epoch 240/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0013 | 0.0198, Residual Loss: 0.0137 | 0.0303
Epoch 241/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0014 | 0.0203, Residual Loss: 0.0137 | 0.0303
Epoch 242/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0014 | 0.0203, Residual Loss: 0.0137 | 0.0303
Epoch 243/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0015 | 0.0204, Residual Loss: 0.0137 | 0.0303
Epoch 244/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0014 | 0.0203, Residual Loss: 0.0137 | 0.0303
Epoch 245/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0014 | 0.0203, Residual Loss: 0.0137 | 0.0303
Epoch 246/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0015 | 0.0205, Residual Loss: 0.0137 | 0.0303
Epoch 247/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0015 | 0.0206, Residual Loss: 0.0137 | 0.0303
Epoch 248/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0016 | 0.0208, Residual Loss: 0.0137 | 0.0303
Epoch 249/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0016 | 0.0210, Residual Loss: 0.0137 | 0.0303
Epoch 250/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0016 | 0.0214, Residual Loss: 0.0137 | 0.0303
Epoch 251/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0016 | 0.0220, Residual Loss: 0.0137 | 0.0303
Epoch 252/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0015 | 0.0225, Residual Loss: 0.0137 | 0.0303
Epoch 253/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0014 | 0.0228, Residual Loss: 0.0137 | 0.0303
Epoch 254/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0014 | 0.0231, Residual Loss: 0.0137 | 0.0303
Epoch 255/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0013 | 0.0230, Residual Loss: 0.0136 | 0.0303
Epoch 256/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0013 | 0.0239, Residual Loss: 0.0136 | 0.0303
Epoch 257/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0012 | 0.0238, Residual Loss: 0.0136 | 0.0303
Epoch 258/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0012 | 0.0235, Residual Loss: 0.0136 | 0.0303
Epoch 259/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0012 | 0.0232, Residual Loss: 0.0136 | 0.0303
Epoch 260/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0012 | 0.0229, Residual Loss: 0.0136 | 0.0303
Epoch 261/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0012 | 0.0227, Residual Loss: 0.0136 | 0.0303
Epoch 262/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0011 | 0.0224, Residual Loss: 0.0136 | 0.0303
Epoch 263/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0011 | 0.0223, Residual Loss: 0.0136 | 0.0303
Epoch 264/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0011 | 0.0221, Residual Loss: 0.0136 | 0.0303
Epoch 265/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0011 | 0.0220, Residual Loss: 0.0136 | 0.0303
Epoch 266/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0011 | 0.0218, Residual Loss: 0.0136 | 0.0303
Epoch 267/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0011 | 0.0217, Residual Loss: 0.0136 | 0.0303
Epoch 268/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0011 | 0.0216, Residual Loss: 0.0136 | 0.0303
Epoch 269/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0011 | 0.0216, Residual Loss: 0.0136 | 0.0303
Epoch 270/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0011 | 0.0214, Residual Loss: 0.0136 | 0.0303
Epoch 271/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0011 | 0.0215, Residual Loss: 0.0136 | 0.0303
Epoch 272/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0011 | 0.0214, Residual Loss: 0.0136 | 0.0303
Epoch 273/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0011 | 0.0213, Residual Loss: 0.0136 | 0.0303
Epoch 274/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0011 | 0.0213, Residual Loss: 0.0136 | 0.0303
Epoch 275/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0011 | 0.0211, Residual Loss: 0.0136 | 0.0303
Epoch 276/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0011 | 0.0211, Residual Loss: 0.0136 | 0.0303
Epoch 277/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0011 | 0.0210, Residual Loss: 0.0136 | 0.0303
Epoch 278/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0011 | 0.0210, Residual Loss: 0.0136 | 0.0303
Epoch 279/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0011 | 0.0211, Residual Loss: 0.0136 | 0.0303
Epoch 280/1000, (Training | Validation) Trend Loss: 0.0014 | 0.0035, Seasonal Loss: 0.0011 | 0.0212, Residual Loss: 0.0136 | 0.0303
Early stopping
[171.31189275]
