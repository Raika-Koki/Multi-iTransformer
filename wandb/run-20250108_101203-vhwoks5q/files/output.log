[32m[I 2025-01-08 10:12:04,341][0m A new study created in memory with name: no-name-8af41f3c-79bd-48e1-bca1-048ea75d16b7[0m
[32m[I 2025-01-08 10:12:47,866][0m Trial 0 finished with value: 0.2666323737400334 and parameters: {'observation_period_num': 33, 'train_rates': 0.8050025211983757, 'learning_rate': 0.00016793291181480316, 'batch_size': 168, 'step_size': 8, 'gamma': 0.9385766644210742}. Best is trial 0 with value: 0.2666323737400334.[0m
[32m[I 2025-01-08 10:16:12,633][0m Trial 1 finished with value: 1.5103123621507124 and parameters: {'observation_period_num': 141, 'train_rates': 0.9339881683606799, 'learning_rate': 1.321915208984937e-06, 'batch_size': 153, 'step_size': 8, 'gamma': 0.7901923998498862}. Best is trial 0 with value: 0.2666323737400334.[0m
[32m[I 2025-01-08 10:16:46,923][0m Trial 2 finished with value: 0.803913260939755 and parameters: {'observation_period_num': 30, 'train_rates': 0.6510565122951213, 'learning_rate': 0.00042036073257288776, 'batch_size': 182, 'step_size': 4, 'gamma': 0.95618774333795}. Best is trial 0 with value: 0.2666323737400334.[0m
[32m[I 2025-01-08 10:19:12,013][0m Trial 3 finished with value: 1.4421850492686579 and parameters: {'observation_period_num': 33, 'train_rates': 0.7396477726085179, 'learning_rate': 0.0005189084377557033, 'batch_size': 22, 'step_size': 4, 'gamma': 0.7888075898064483}. Best is trial 0 with value: 0.2666323737400334.[0m
[32m[I 2025-01-08 10:19:59,612][0m Trial 4 finished with value: 1.4930757770210887 and parameters: {'observation_period_num': 42, 'train_rates': 0.6822385614583784, 'learning_rate': 2.304014547578683e-06, 'batch_size': 181, 'step_size': 5, 'gamma': 0.9306699509410802}. Best is trial 0 with value: 0.2666323737400334.[0m
[32m[I 2025-01-08 10:24:50,600][0m Trial 5 finished with value: 1.0228746694763917 and parameters: {'observation_period_num': 248, 'train_rates': 0.6150981721437244, 'learning_rate': 3.4400995434948014e-05, 'batch_size': 231, 'step_size': 10, 'gamma': 0.9762039818443654}. Best is trial 0 with value: 0.2666323737400334.[0m
[32m[I 2025-01-08 10:27:57,195][0m Trial 6 finished with value: 0.39789265994877776 and parameters: {'observation_period_num': 138, 'train_rates': 0.8635943713110981, 'learning_rate': 6.112964061188563e-05, 'batch_size': 220, 'step_size': 2, 'gamma': 0.8827448265671075}. Best is trial 0 with value: 0.2666323737400334.[0m
[32m[I 2025-01-08 10:30:13,184][0m Trial 7 finished with value: 0.4464890427630523 and parameters: {'observation_period_num': 110, 'train_rates': 0.8381516960643145, 'learning_rate': 3.3836832432794664e-05, 'batch_size': 247, 'step_size': 11, 'gamma': 0.79028110136118}. Best is trial 0 with value: 0.2666323737400334.[0m
[32m[I 2025-01-08 10:30:44,537][0m Trial 8 finished with value: 0.8584600687026978 and parameters: {'observation_period_num': 21, 'train_rates': 0.8569340550364445, 'learning_rate': 2.4857634380721178e-06, 'batch_size': 172, 'step_size': 8, 'gamma': 0.9643268726049369}. Best is trial 0 with value: 0.2666323737400334.[0m
[32m[I 2025-01-08 10:31:45,671][0m Trial 9 finished with value: 0.6374972218046672 and parameters: {'observation_period_num': 49, 'train_rates': 0.7235505064577596, 'learning_rate': 0.00021075998246263854, 'batch_size': 84, 'step_size': 4, 'gamma': 0.9765292860765452}. Best is trial 0 with value: 0.2666323737400334.[0m
[32m[I 2025-01-08 10:33:54,962][0m Trial 10 finished with value: 0.36773860454559326 and parameters: {'observation_period_num': 92, 'train_rates': 0.979675610323969, 'learning_rate': 8.21846322415857e-06, 'batch_size': 110, 'step_size': 15, 'gamma': 0.8728552694031804}. Best is trial 0 with value: 0.2666323737400334.[0m
[32m[I 2025-01-08 10:36:01,401][0m Trial 11 finished with value: 0.30263057351112366 and parameters: {'observation_period_num': 88, 'train_rates': 0.9856401470871923, 'learning_rate': 9.09970741442716e-06, 'batch_size': 109, 'step_size': 15, 'gamma': 0.8756070292662582}. Best is trial 0 with value: 0.2666323737400334.[0m
[32m[I 2025-01-08 10:37:55,679][0m Trial 12 finished with value: 0.32101031816607223 and parameters: {'observation_period_num': 82, 'train_rates': 0.9246955068726256, 'learning_rate': 8.30314387809123e-06, 'batch_size': 79, 'step_size': 15, 'gamma': 0.8980422471213789}. Best is trial 0 with value: 0.2666323737400334.[0m
[32m[I 2025-01-08 10:41:59,261][0m Trial 13 finished with value: 0.3369248693969649 and parameters: {'observation_period_num': 186, 'train_rates': 0.7880526031330966, 'learning_rate': 0.00012138349606393206, 'batch_size': 127, 'step_size': 12, 'gamma': 0.845506100212688}. Best is trial 0 with value: 0.2666323737400334.[0m
[32m[I 2025-01-08 10:44:21,085][0m Trial 14 finished with value: 0.1647505909204483 and parameters: {'observation_period_num': 5, 'train_rates': 0.9892806309163406, 'learning_rate': 1.0137358198748137e-05, 'batch_size': 34, 'step_size': 13, 'gamma': 0.8363170317710836}. Best is trial 14 with value: 0.1647505909204483.[0m
[32m[I 2025-01-08 10:46:58,767][0m Trial 15 finished with value: 1.5414602629766117 and parameters: {'observation_period_num': 14, 'train_rates': 0.7967890882375126, 'learning_rate': 0.0009328368515670516, 'batch_size': 26, 'step_size': 13, 'gamma': 0.8323744540512259}. Best is trial 14 with value: 0.1647505909204483.[0m
[32m[I 2025-01-08 10:48:12,204][0m Trial 16 finished with value: 0.19429583587240443 and parameters: {'observation_period_num': 6, 'train_rates': 0.9231491136215499, 'learning_rate': 1.5911962474380157e-05, 'batch_size': 61, 'step_size': 9, 'gamma': 0.9127988723372763}. Best is trial 14 with value: 0.1647505909204483.[0m
[32m[I 2025-01-08 10:49:40,206][0m Trial 17 finished with value: 0.23012123006215027 and parameters: {'observation_period_num': 5, 'train_rates': 0.9289786703203698, 'learning_rate': 1.3937186111136448e-05, 'batch_size': 52, 'step_size': 10, 'gamma': 0.8378439797781148}. Best is trial 14 with value: 0.1647505909204483.[0m
[32m[I 2025-01-08 10:51:09,571][0m Trial 18 finished with value: 0.21069508982624655 and parameters: {'observation_period_num': 64, 'train_rates': 0.8932187361210661, 'learning_rate': 1.8047960743315177e-05, 'batch_size': 56, 'step_size': 13, 'gamma': 0.9048296466494418}. Best is trial 14 with value: 0.1647505909204483.[0m
[32m[I 2025-01-08 10:55:26,728][0m Trial 19 finished with value: 0.52407898943303 and parameters: {'observation_period_num': 168, 'train_rates': 0.9580785203388392, 'learning_rate': 4.44608686315018e-06, 'batch_size': 44, 'step_size': 6, 'gamma': 0.8215893382544668}. Best is trial 14 with value: 0.1647505909204483.[0m
[32m[I 2025-01-08 10:56:57,887][0m Trial 20 finished with value: 0.19573089113899034 and parameters: {'observation_period_num': 65, 'train_rates': 0.8938899092995696, 'learning_rate': 6.147726496078498e-05, 'batch_size': 80, 'step_size': 10, 'gamma': 0.9061688711613054}. Best is trial 14 with value: 0.1647505909204483.[0m
[32m[I 2025-01-08 10:58:21,482][0m Trial 21 finished with value: 0.19273357362877386 and parameters: {'observation_period_num': 61, 'train_rates': 0.8996778450957897, 'learning_rate': 7.163374557402019e-05, 'batch_size': 76, 'step_size': 10, 'gamma': 0.9161269648046793}. Best is trial 14 with value: 0.1647505909204483.[0m
[32m[I 2025-01-08 10:59:24,992][0m Trial 22 finished with value: 0.19741710275411606 and parameters: {'observation_period_num': 9, 'train_rates': 0.9031886031872953, 'learning_rate': 1.861263983705605e-05, 'batch_size': 67, 'step_size': 13, 'gamma': 0.9316386215753156}. Best is trial 14 with value: 0.1647505909204483.[0m
[32m[I 2025-01-08 11:01:39,719][0m Trial 23 finished with value: 0.16646499347083177 and parameters: {'observation_period_num': 59, 'train_rates': 0.9458039306867022, 'learning_rate': 6.000352932158981e-05, 'batch_size': 32, 'step_size': 9, 'gamma': 0.8144579243649007}. Best is trial 14 with value: 0.1647505909204483.[0m
[32m[I 2025-01-08 11:05:39,006][0m Trial 24 finished with value: 0.12797654319453883 and parameters: {'observation_period_num': 57, 'train_rates': 0.9621601335399445, 'learning_rate': 7.987055398608287e-05, 'batch_size': 18, 'step_size': 7, 'gamma': 0.760365584243713}. Best is trial 24 with value: 0.12797654319453883.[0m
[32m[I 2025-01-08 11:10:01,734][0m Trial 25 finished with value: 0.13234427349626526 and parameters: {'observation_period_num': 96, 'train_rates': 0.9580141190809142, 'learning_rate': 0.00010018026989826573, 'batch_size': 16, 'step_size': 6, 'gamma': 0.7568610941127303}. Best is trial 24 with value: 0.12797654319453883.[0m
[32m[I 2025-01-08 11:14:39,867][0m Trial 26 finished with value: 0.09877895780148045 and parameters: {'observation_period_num': 115, 'train_rates': 0.9893086342837889, 'learning_rate': 0.00013379416420825657, 'batch_size': 16, 'step_size': 6, 'gamma': 0.7528299103145173}. Best is trial 26 with value: 0.09877895780148045.[0m
[32m[I 2025-01-08 11:18:43,830][0m Trial 27 finished with value: 0.1350027927541518 and parameters: {'observation_period_num': 115, 'train_rates': 0.9612283256250859, 'learning_rate': 0.0001220403878571336, 'batch_size': 19, 'step_size': 6, 'gamma': 0.7553663785502518}. Best is trial 26 with value: 0.09877895780148045.[0m
Early stopping at epoch 56
[32m[I 2025-01-08 11:21:29,091][0m Trial 28 finished with value: 0.2859198108867363 and parameters: {'observation_period_num': 163, 'train_rates': 0.9617987110673136, 'learning_rate': 0.00027919865290774765, 'batch_size': 16, 'step_size': 1, 'gamma': 0.7507447974963813}. Best is trial 26 with value: 0.09877895780148045.[0m
[32m[I 2025-01-08 11:23:46,380][0m Trial 29 finished with value: 0.3306096360763384 and parameters: {'observation_period_num': 109, 'train_rates': 0.8231223554887219, 'learning_rate': 0.00011954188732895616, 'batch_size': 97, 'step_size': 7, 'gamma': 0.7698974253794475}. Best is trial 26 with value: 0.09877895780148045.[0m
[32m[I 2025-01-08 11:29:09,283][0m Trial 30 finished with value: 0.2049240090915661 and parameters: {'observation_period_num': 216, 'train_rates': 0.8709208115676055, 'learning_rate': 0.00020677932962099476, 'batch_size': 43, 'step_size': 6, 'gamma': 0.7676250371434068}. Best is trial 26 with value: 0.09877895780148045.[0m
[32m[I 2025-01-08 11:33:06,735][0m Trial 31 finished with value: 0.1559910613298416 and parameters: {'observation_period_num': 113, 'train_rates': 0.9652992663933522, 'learning_rate': 0.00010692360827505749, 'batch_size': 18, 'step_size': 6, 'gamma': 0.7515523586215133}. Best is trial 26 with value: 0.09877895780148045.[0m
[32m[I 2025-01-08 11:36:11,789][0m Trial 32 finished with value: 0.1894170109574732 and parameters: {'observation_period_num': 124, 'train_rates': 0.9469507140433592, 'learning_rate': 9.305449758566231e-05, 'batch_size': 39, 'step_size': 7, 'gamma': 0.7716969818244027}. Best is trial 26 with value: 0.09877895780148045.[0m
[32m[I 2025-01-08 11:39:56,603][0m Trial 33 finished with value: 0.1761729449033737 and parameters: {'observation_period_num': 79, 'train_rates': 0.9896597343879009, 'learning_rate': 0.0003288030746047249, 'batch_size': 18, 'step_size': 3, 'gamma': 0.802857001710807}. Best is trial 26 with value: 0.09877895780148045.[0m
[32m[I 2025-01-08 11:43:39,703][0m Trial 34 finished with value: 0.5979643750865504 and parameters: {'observation_period_num': 149, 'train_rates': 0.9249373509732794, 'learning_rate': 0.000610216055984971, 'batch_size': 50, 'step_size': 5, 'gamma': 0.7826216855909569}. Best is trial 26 with value: 0.09877895780148045.[0m
[32m[I 2025-01-08 11:45:58,906][0m Trial 35 finished with value: 0.16609753668308258 and parameters: {'observation_period_num': 100, 'train_rates': 0.9686732189085165, 'learning_rate': 0.00020456852930294395, 'batch_size': 152, 'step_size': 7, 'gamma': 0.7566982679588283}. Best is trial 26 with value: 0.09877895780148045.[0m
[32m[I 2025-01-08 11:49:05,514][0m Trial 36 finished with value: 0.22196166623722424 and parameters: {'observation_period_num': 122, 'train_rates': 0.946115130191158, 'learning_rate': 3.5791045855791166e-05, 'batch_size': 32, 'step_size': 5, 'gamma': 0.8003790455142312}. Best is trial 26 with value: 0.09877895780148045.[0m
[32m[I 2025-01-08 11:52:22,061][0m Trial 37 finished with value: 0.5469147155496962 and parameters: {'observation_period_num': 143, 'train_rates': 0.753997062618575, 'learning_rate': 0.000149078248328507, 'batch_size': 30, 'step_size': 8, 'gamma': 0.7662843520979574}. Best is trial 26 with value: 0.09877895780148045.[0m
[32m[I 2025-01-08 11:54:11,778][0m Trial 38 finished with value: 0.30313930213451384 and parameters: {'observation_period_num': 75, 'train_rates': 0.9121981592766667, 'learning_rate': 4.231388157360443e-05, 'batch_size': 61, 'step_size': 3, 'gamma': 0.782093427094132}. Best is trial 26 with value: 0.09877895780148045.[0m
[32m[I 2025-01-08 11:57:47,691][0m Trial 39 finished with value: 0.2935339350315089 and parameters: {'observation_period_num': 36, 'train_rates': 0.8768667074378927, 'learning_rate': 0.00039265890112517686, 'batch_size': 17, 'step_size': 4, 'gamma': 0.7977763537360341}. Best is trial 26 with value: 0.09877895780148045.[0m
[32m[I 2025-01-08 11:59:28,814][0m Trial 40 finished with value: 1.0468781036390384 and parameters: {'observation_period_num': 99, 'train_rates': 0.6049183463570806, 'learning_rate': 2.3812946489553903e-05, 'batch_size': 208, 'step_size': 8, 'gamma': 0.7782817871682468}. Best is trial 26 with value: 0.09877895780148045.[0m
[32m[I 2025-01-08 12:03:27,024][0m Trial 41 finished with value: 0.15415362671017646 and parameters: {'observation_period_num': 115, 'train_rates': 0.9650546641275058, 'learning_rate': 9.373030905367473e-05, 'batch_size': 18, 'step_size': 6, 'gamma': 0.7507115214972816}. Best is trial 26 with value: 0.09877895780148045.[0m
[32m[I 2025-01-08 12:06:26,694][0m Trial 42 finished with value: 0.21355500388768764 and parameters: {'observation_period_num': 122, 'train_rates': 0.9464347320817649, 'learning_rate': 8.693463003572603e-05, 'batch_size': 41, 'step_size': 6, 'gamma': 0.7611185789754363}. Best is trial 26 with value: 0.09877895780148045.[0m
[32m[I 2025-01-08 12:10:13,531][0m Trial 43 finished with value: 0.1595124526174514 and parameters: {'observation_period_num': 138, 'train_rates': 0.9682183363768131, 'learning_rate': 4.786874355139651e-05, 'batch_size': 29, 'step_size': 5, 'gamma': 0.7520037405291015}. Best is trial 26 with value: 0.09877895780148045.[0m
[32m[I 2025-01-08 12:12:13,270][0m Trial 44 finished with value: 0.8249097560262922 and parameters: {'observation_period_num': 104, 'train_rates': 0.656791909208645, 'learning_rate': 0.00015087099677982472, 'batch_size': 50, 'step_size': 3, 'gamma': 0.7901260186095808}. Best is trial 26 with value: 0.09877895780148045.[0m
[32m[I 2025-01-08 12:13:17,166][0m Trial 45 finished with value: 0.1488032341003418 and parameters: {'observation_period_num': 47, 'train_rates': 0.9735963873782052, 'learning_rate': 0.0001704762705092844, 'batch_size': 199, 'step_size': 7, 'gamma': 0.7624989117152705}. Best is trial 26 with value: 0.09877895780148045.[0m
[32m[I 2025-01-08 12:13:55,962][0m Trial 46 finished with value: 0.19266028702259064 and parameters: {'observation_period_num': 25, 'train_rates': 0.9403909031029185, 'learning_rate': 0.00026386440561985313, 'batch_size': 195, 'step_size': 7, 'gamma': 0.8587520673457745}. Best is trial 26 with value: 0.09877895780148045.[0m
[32m[I 2025-01-08 12:14:49,388][0m Trial 47 finished with value: 0.15016239881515503 and parameters: {'observation_period_num': 39, 'train_rates': 0.9765785689282511, 'learning_rate': 0.0005362340350711811, 'batch_size': 244, 'step_size': 9, 'gamma': 0.8118979049596109}. Best is trial 26 with value: 0.09877895780148045.[0m
[32m[I 2025-01-08 12:15:47,585][0m Trial 48 finished with value: 0.6399435484892998 and parameters: {'observation_period_num': 51, 'train_rates': 0.7132128617283312, 'learning_rate': 0.0001729999654271311, 'batch_size': 155, 'step_size': 5, 'gamma': 0.7773848569194848}. Best is trial 26 with value: 0.09877895780148045.[0m
[32m[I 2025-01-08 12:17:48,953][0m Trial 49 finished with value: 0.29259097042714577 and parameters: {'observation_period_num': 90, 'train_rates': 0.9110539455116116, 'learning_rate': 2.7443335054999724e-05, 'batch_size': 136, 'step_size': 8, 'gamma': 0.7621101802264938}. Best is trial 26 with value: 0.09877895780148045.[0m
最適ハイパーパラメータが見つかりました
最適ハイパーパラメータが best_hyperparameters_AAPL_Transformer(nomstl).json に保存されました
Epoch 1/300, Loss: 0.3606 | 0.4121
Epoch 2/300, Loss: 0.3240 | 0.4188
Epoch 3/300, Loss: 0.2924 | 0.3956
Epoch 4/300, Loss: 0.2693 | 0.2903
Epoch 5/300, Loss: 0.2459 | 0.2435
Epoch 6/300, Loss: 0.2316 | 0.3238
Epoch 7/300, Loss: 0.2347 | 0.2990
Epoch 8/300, Loss: 0.2314 | 0.2852
Epoch 9/300, Loss: 0.2029 | 0.2853
Epoch 10/300, Loss: 0.2015 | 0.2670
Epoch 11/300, Loss: 0.1945 | 0.2788
Epoch 12/300, Loss: 0.1735 | 0.2929
Epoch 13/300, Loss: 0.1680 | 0.2546
Epoch 14/300, Loss: 0.1576 | 0.2357
Epoch 15/300, Loss: 0.1505 | 0.2299
Epoch 16/300, Loss: 0.1464 | 0.2224
Epoch 17/300, Loss: 0.1420 | 0.2055
Epoch 18/300, Loss: 0.1387 | 0.2010
Epoch 19/300, Loss: 0.1366 | 0.1932
Epoch 20/300, Loss: 0.1337 | 0.1797
Epoch 21/300, Loss: 0.1318 | 0.1783
Epoch 22/300, Loss: 0.1294 | 0.1781
Epoch 23/300, Loss: 0.1270 | 0.1737
Epoch 24/300, Loss: 0.1250 | 0.1664
Epoch 25/300, Loss: 0.1242 | 0.1628
Epoch 26/300, Loss: 0.1230 | 0.1638
Epoch 27/300, Loss: 0.1225 | 0.1624
Epoch 28/300, Loss: 0.1208 | 0.1551
Epoch 29/300, Loss: 0.1199 | 0.1524
Epoch 30/300, Loss: 0.1196 | 0.1525
Epoch 31/300, Loss: 0.1183 | 0.1518
Epoch 32/300, Loss: 0.1180 | 0.1499
Epoch 33/300, Loss: 0.1172 | 0.1478
Epoch 34/300, Loss: 0.1167 | 0.1481
Epoch 35/300, Loss: 0.1158 | 0.1473
Epoch 36/300, Loss: 0.1153 | 0.1453
Epoch 37/300, Loss: 0.1144 | 0.1446
Epoch 38/300, Loss: 0.1145 | 0.1441
Epoch 39/300, Loss: 0.1142 | 0.1432
Epoch 40/300, Loss: 0.1138 | 0.1432
Epoch 41/300, Loss: 0.1132 | 0.1425
Epoch 42/300, Loss: 0.1132 | 0.1410
Epoch 43/300, Loss: 0.1133 | 0.1402
Epoch 44/300, Loss: 0.1127 | 0.1402
Epoch 45/300, Loss: 0.1129 | 0.1403
Epoch 46/300, Loss: 0.1123 | 0.1397
Epoch 47/300, Loss: 0.1126 | 0.1395
Epoch 48/300, Loss: 0.1124 | 0.1391
Epoch 49/300, Loss: 0.1123 | 0.1385
Epoch 50/300, Loss: 0.1123 | 0.1384
Epoch 51/300, Loss: 0.1115 | 0.1383
Epoch 52/300, Loss: 0.1112 | 0.1381
Epoch 53/300, Loss: 0.1116 | 0.1377
Epoch 54/300, Loss: 0.1112 | 0.1377
Epoch 55/300, Loss: 0.1113 | 0.1375
Epoch 56/300, Loss: 0.1112 | 0.1374
Epoch 57/300, Loss: 0.1110 | 0.1371
Epoch 58/300, Loss: 0.1112 | 0.1370
Epoch 59/300, Loss: 0.1118 | 0.1368
Epoch 60/300, Loss: 0.1107 | 0.1367
Epoch 61/300, Loss: 0.1104 | 0.1366
Epoch 62/300, Loss: 0.1117 | 0.1364
Epoch 63/300, Loss: 0.1116 | 0.1364
Epoch 64/300, Loss: 0.1111 | 0.1363
Epoch 65/300, Loss: 0.1111 | 0.1363
Epoch 66/300, Loss: 0.1104 | 0.1363
Epoch 67/300, Loss: 0.1110 | 0.1363
Epoch 68/300, Loss: 0.1112 | 0.1362
Epoch 69/300, Loss: 0.1110 | 0.1362
Epoch 70/300, Loss: 0.1116 | 0.1362
Epoch 71/300, Loss: 0.1110 | 0.1362
Epoch 72/300, Loss: 0.1109 | 0.1361
Epoch 73/300, Loss: 0.1099 | 0.1361
Epoch 74/300, Loss: 0.1102 | 0.1360
Epoch 75/300, Loss: 0.1109 | 0.1360
Epoch 76/300, Loss: 0.1109 | 0.1359
Epoch 77/300, Loss: 0.1108 | 0.1359
Epoch 78/300, Loss: 0.1101 | 0.1359
Epoch 79/300, Loss: 0.1107 | 0.1359
Epoch 80/300, Loss: 0.1112 | 0.1359
Epoch 81/300, Loss: 0.1115 | 0.1358
Epoch 82/300, Loss: 0.1112 | 0.1358
Epoch 83/300, Loss: 0.1102 | 0.1358
Epoch 84/300, Loss: 0.1109 | 0.1358
Epoch 85/300, Loss: 0.1107 | 0.1358
Epoch 86/300, Loss: 0.1109 | 0.1357
Epoch 87/300, Loss: 0.1108 | 0.1357
Epoch 88/300, Loss: 0.1102 | 0.1357
Epoch 89/300, Loss: 0.1107 | 0.1357
Epoch 90/300, Loss: 0.1105 | 0.1357
Epoch 91/300, Loss: 0.1104 | 0.1357
Epoch 92/300, Loss: 0.1102 | 0.1357
Epoch 93/300, Loss: 0.1110 | 0.1357
Epoch 94/300, Loss: 0.1108 | 0.1357
Epoch 95/300, Loss: 0.1107 | 0.1357
Epoch 96/300, Loss: 0.1106 | 0.1357
Epoch 97/300, Loss: 0.1107 | 0.1357
Epoch 98/300, Loss: 0.1104 | 0.1357
Epoch 99/300, Loss: 0.1107 | 0.1357
Epoch 100/300, Loss: 0.1107 | 0.1357
Epoch 101/300, Loss: 0.1111 | 0.1357
Epoch 102/300, Loss: 0.1106 | 0.1357
Epoch 103/300, Loss: 0.1107 | 0.1357
Epoch 104/300, Loss: 0.1107 | 0.1357
Epoch 105/300, Loss: 0.1107 | 0.1357
Epoch 106/300, Loss: 0.1112 | 0.1357
Epoch 107/300, Loss: 0.1107 | 0.1357
Epoch 108/300, Loss: 0.1107 | 0.1357
Epoch 109/300, Loss: 0.1115 | 0.1357
Epoch 110/300, Loss: 0.1112 | 0.1357
Epoch 111/300, Loss: 0.1107 | 0.1357
Epoch 112/300, Loss: 0.1106 | 0.1357
Epoch 113/300, Loss: 0.1110 | 0.1357
Epoch 114/300, Loss: 0.1111 | 0.1357
Epoch 115/300, Loss: 0.1105 | 0.1357
Epoch 116/300, Loss: 0.1109 | 0.1357
Epoch 117/300, Loss: 0.1105 | 0.1357
Epoch 118/300, Loss: 0.1104 | 0.1357
Epoch 119/300, Loss: 0.1109 | 0.1357
Epoch 120/300, Loss: 0.1103 | 0.1357
Epoch 121/300, Loss: 0.1107 | 0.1357
Epoch 122/300, Loss: 0.1107 | 0.1357
Epoch 123/300, Loss: 0.1105 | 0.1357
Epoch 124/300, Loss: 0.1107 | 0.1357
Epoch 125/300, Loss: 0.1104 | 0.1357
Epoch 126/300, Loss: 0.1110 | 0.1357
Epoch 127/300, Loss: 0.1106 | 0.1357
Epoch 128/300, Loss: 0.1106 | 0.1357
Epoch 129/300, Loss: 0.1105 | 0.1357
Epoch 130/300, Loss: 0.1105 | 0.1357
Epoch 131/300, Loss: 0.1112 | 0.1357
Epoch 132/300, Loss: 0.1104 | 0.1357
Epoch 133/300, Loss: 0.1103 | 0.1357
Epoch 134/300, Loss: 0.1104 | 0.1357
Epoch 135/300, Loss: 0.1106 | 0.1357
Epoch 136/300, Loss: 0.1102 | 0.1357
Early stopping
Runtime (seconds): 403.3862347602844
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)
MSE: 600.2410278655589
RMSE: 24.49981689453125
MAE: 24.49981689453125
R-squared: nan
[231.09018]
