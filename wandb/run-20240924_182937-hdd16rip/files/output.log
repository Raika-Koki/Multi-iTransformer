[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
/home/raikakoki/.local/lib/python3.10/site-packages/torch/backends/cuda/__init__.py:342: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
Dataset created successfully.
Epoch 1/100, Training Loss: 0.3419, Validation Loss: 0.2421
Epoch 2/100, Training Loss: 0.2050, Validation Loss: 0.1835
Epoch 3/100, Training Loss: 0.1187, Validation Loss: 0.1904
Epoch 4/100, Training Loss: 0.1193, Validation Loss: 0.1855
Epoch 5/100, Training Loss: 0.0972, Validation Loss: 0.1126
Epoch 6/100, Training Loss: 0.0690, Validation Loss: 0.0827
Epoch 7/100, Training Loss: 0.0597, Validation Loss: 0.1047
Epoch 8/100, Training Loss: 0.0551, Validation Loss: 0.0621
Epoch 9/100, Training Loss: 0.0447, Validation Loss: 0.0520
Epoch 10/100, Training Loss: 0.0401, Validation Loss: 0.0569
Epoch 11/100, Training Loss: 0.0381, Validation Loss: 0.0412
Epoch 12/100, Training Loss: 0.0351, Validation Loss: 0.0481
Epoch 13/100, Training Loss: 0.0372, Validation Loss: 0.0520
Epoch 14/100, Training Loss: 0.0310, Validation Loss: 0.0295
Epoch 15/100, Training Loss: 0.0342, Validation Loss: 0.0590
Epoch 16/100, Training Loss: 0.0423, Validation Loss: 0.0352
Epoch 17/100, Training Loss: 0.0319, Validation Loss: 0.0411
Epoch 18/100, Training Loss: 0.0297, Validation Loss: 0.0322
Epoch 19/100, Training Loss: 0.0232, Validation Loss: 0.0292
Epoch 20/100, Training Loss: 0.0231, Validation Loss: 0.0360
Epoch 21/100, Training Loss: 0.0221, Validation Loss: 0.0253
Epoch 22/100, Training Loss: 0.0217, Validation Loss: 0.0377
Epoch 23/100, Training Loss: 0.0234, Validation Loss: 0.0215
Epoch 24/100, Training Loss: 0.0248, Validation Loss: 0.0536
Epoch 25/100, Training Loss: 0.0303, Validation Loss: 0.0253
Epoch 26/100, Training Loss: 0.0360, Validation Loss: 0.1103
Epoch 27/100, Training Loss: 0.0604, Validation Loss: 0.0607
Epoch 28/100, Training Loss: 0.0596, Validation Loss: 0.1535
Epoch 29/100, Training Loss: 0.0590, Validation Loss: 0.0527
Epoch 30/100, Training Loss: 0.0456, Validation Loss: 0.0788
Epoch 31/100, Training Loss: 0.0299, Validation Loss: 0.0348
Epoch 32/100, Training Loss: 0.0248, Validation Loss: 0.0454
Epoch 33/100, Training Loss: 0.0214, Validation Loss: 0.0338
Epoch 34/100, Training Loss: 0.0207, Validation Loss: 0.0365
Epoch 35/100, Training Loss: 0.0199, Validation Loss: 0.0328
Epoch 36/100, Training Loss: 0.0195, Validation Loss: 0.0329
Epoch 37/100, Training Loss: 0.0190, Validation Loss: 0.0315
Epoch 38/100, Training Loss: 0.0187, Validation Loss: 0.0311
Epoch 39/100, Training Loss: 0.0184, Validation Loss: 0.0303
Epoch 40/100, Training Loss: 0.0182, Validation Loss: 0.0299
Epoch 41/100, Training Loss: 0.0179, Validation Loss: 0.0294
Epoch 42/100, Training Loss: 0.0177, Validation Loss: 0.0290
Epoch 43/100, Training Loss: 0.0175, Validation Loss: 0.0287
Epoch 44/100, Training Loss: 0.0173, Validation Loss: 0.0284
Epoch 45/100, Training Loss: 0.0172, Validation Loss: 0.0281
Epoch 46/100, Training Loss: 0.0170, Validation Loss: 0.0278
Epoch 47/100, Training Loss: 0.0169, Validation Loss: 0.0276
Epoch 48/100, Training Loss: 0.0167, Validation Loss: 0.0274
Epoch 49/100, Training Loss: 0.0166, Validation Loss: 0.0271
Epoch 50/100, Training Loss: 0.0165, Validation Loss: 0.0270
Epoch 51/100, Training Loss: 0.0164, Validation Loss: 0.0268
Epoch 52/100, Training Loss: 0.0163, Validation Loss: 0.0266
Epoch 53/100, Training Loss: 0.0162, Validation Loss: 0.0265
Epoch 54/100, Training Loss: 0.0161, Validation Loss: 0.0263
Epoch 55/100, Training Loss: 0.0160, Validation Loss: 0.0262
Epoch 56/100, Training Loss: 0.0159, Validation Loss: 0.0261
Epoch 57/100, Training Loss: 0.0158, Validation Loss: 0.0259
Epoch 58/100, Training Loss: 0.0157, Validation Loss: 0.0258
Epoch 59/100, Training Loss: 0.0157, Validation Loss: 0.0257
Epoch 60/100, Training Loss: 0.0156, Validation Loss: 0.0256
Epoch 61/100, Training Loss: 0.0155, Validation Loss: 0.0255
Epoch 62/100, Training Loss: 0.0155, Validation Loss: 0.0254
Epoch 63/100, Training Loss: 0.0154, Validation Loss: 0.0253
Epoch 64/100, Training Loss: 0.0154, Validation Loss: 0.0252
Epoch 65/100, Training Loss: 0.0153, Validation Loss: 0.0252
Epoch 66/100, Training Loss: 0.0153, Validation Loss: 0.0251
Epoch 67/100, Training Loss: 0.0152, Validation Loss: 0.0250
Epoch 68/100, Training Loss: 0.0152, Validation Loss: 0.0250
Epoch 69/100, Training Loss: 0.0151, Validation Loss: 0.0249
Epoch 70/100, Training Loss: 0.0151, Validation Loss: 0.0248
Epoch 71/100, Training Loss: 0.0151, Validation Loss: 0.0248
Epoch 72/100, Training Loss: 0.0150, Validation Loss: 0.0247
Epoch 73/100, Training Loss: 0.0150, Validation Loss: 0.0247
Epoch 74/100, Training Loss: 0.0150, Validation Loss: 0.0246
Epoch 75/100, Training Loss: 0.0149, Validation Loss: 0.0246
Epoch 76/100, Training Loss: 0.0149, Validation Loss: 0.0245
Epoch 77/100, Training Loss: 0.0149, Validation Loss: 0.0245
Epoch 78/100, Training Loss: 0.0148, Validation Loss: 0.0244
Epoch 79/100, Training Loss: 0.0148, Validation Loss: 0.0244
Epoch 80/100, Training Loss: 0.0148, Validation Loss: 0.0243
Epoch 81/100, Training Loss: 0.0148, Validation Loss: 0.0243
Epoch 82/100, Training Loss: 0.0147, Validation Loss: 0.0243
Epoch 83/100, Training Loss: 0.0147, Validation Loss: 0.0242
Epoch 84/100, Training Loss: 0.0147, Validation Loss: 0.0242
Epoch 85/100, Training Loss: 0.0147, Validation Loss: 0.0242
Epoch 86/100, Training Loss: 0.0147, Validation Loss: 0.0242
Epoch 87/100, Training Loss: 0.0146, Validation Loss: 0.0241
Epoch 88/100, Training Loss: 0.0146, Validation Loss: 0.0241
Epoch 89/100, Training Loss: 0.0146, Validation Loss: 0.0241
Epoch 90/100, Training Loss: 0.0146, Validation Loss: 0.0240
Epoch 91/100, Training Loss: 0.0146, Validation Loss: 0.0240
Epoch 92/100, Training Loss: 0.0146, Validation Loss: 0.0240
Epoch 93/100, Training Loss: 0.0146, Validation Loss: 0.0240
Epoch 94/100, Training Loss: 0.0145, Validation Loss: 0.0240
Epoch 95/100, Training Loss: 0.0145, Validation Loss: 0.0239
Epoch 96/100, Training Loss: 0.0145, Validation Loss: 0.0239
Epoch 97/100, Training Loss: 0.0145, Validation Loss: 0.0239
/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/demo.py:110: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  predicted_stock_price = predicted_stock_prices.cpu().numpy().flatten()[0] * std_list[1] + mean_list[1]
Traceback (most recent call last):
  File "/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/demo.py", line 117, in <module>
    predicted_stock_price = predicted_stock_price.cpu().numpy().flatten() * std_list[-1] + mean_list[-1]
AttributeError: 'numpy.float64' object has no attribute 'cpu'
Traceback (most recent call last):
  File "/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/demo.py", line 117, in <module>
    predicted_stock_price = predicted_stock_price.cpu().numpy().flatten() * std_list[-1] + mean_list[-1]
AttributeError: 'numpy.float64' object has no attribute 'cpu'
Epoch 98/100, Training Loss: 0.0145, Validation Loss: 0.0239
Epoch 99/100, Training Loss: 0.0145, Validation Loss: 0.0239
Epoch 100/100, Training Loss: 0.0145, Validation Loss: 0.0239