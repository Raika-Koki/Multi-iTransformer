[32m[I 2025-02-02 04:36:52,866][0m A new study created in memory with name: no-name-131c7a33-6941-4449-9692-33517aa72059[0m
[32m[I 2025-02-02 04:37:16,336][0m Trial 0 finished with value: 0.21473753992028125 and parameters: {'observation_period_num': 242, 'train_rates': 0.67203425689884, 'learning_rate': 0.0005643053635709129, 'batch_size': 222, 'step_size': 4, 'gamma': 0.8492505313251879}. Best is trial 0 with value: 0.21473753992028125.[0m
[32m[I 2025-02-02 04:37:47,413][0m Trial 1 finished with value: 0.1514053981961079 and parameters: {'observation_period_num': 74, 'train_rates': 0.6054996411215788, 'learning_rate': 0.00028569384663293526, 'batch_size': 153, 'step_size': 13, 'gamma': 0.7522339107693721}. Best is trial 1 with value: 0.1514053981961079.[0m
[32m[I 2025-02-02 04:38:45,715][0m Trial 2 finished with value: 0.19973155811429025 and parameters: {'observation_period_num': 58, 'train_rates': 0.9312112632917917, 'learning_rate': 0.0008281532237756742, 'batch_size': 102, 'step_size': 7, 'gamma': 0.8633542143983428}. Best is trial 1 with value: 0.1514053981961079.[0m
[32m[I 2025-02-02 04:40:52,562][0m Trial 3 finished with value: 0.10111074877276831 and parameters: {'observation_period_num': 15, 'train_rates': 0.6719372559117613, 'learning_rate': 2.1701528690978618e-05, 'batch_size': 37, 'step_size': 10, 'gamma': 0.8008945367381868}. Best is trial 3 with value: 0.10111074877276831.[0m
[32m[I 2025-02-02 04:42:52,613][0m Trial 4 finished with value: 0.12412244799089975 and parameters: {'observation_period_num': 108, 'train_rates': 0.7377759972219093, 'learning_rate': 0.0005425211453943825, 'batch_size': 41, 'step_size': 5, 'gamma': 0.8311797018021067}. Best is trial 3 with value: 0.10111074877276831.[0m
[32m[I 2025-02-02 04:43:17,701][0m Trial 5 finished with value: 0.18906709303458533 and parameters: {'observation_period_num': 247, 'train_rates': 0.7606725449168776, 'learning_rate': 0.00021356788121382658, 'batch_size': 216, 'step_size': 15, 'gamma': 0.812809684416004}. Best is trial 3 with value: 0.10111074877276831.[0m
[32m[I 2025-02-02 04:43:42,214][0m Trial 6 finished with value: 0.6131062109723727 and parameters: {'observation_period_num': 184, 'train_rates': 0.8676216835755901, 'learning_rate': 1.5302791763854356e-06, 'batch_size': 254, 'step_size': 10, 'gamma': 0.935219231959581}. Best is trial 3 with value: 0.10111074877276831.[0m
[32m[I 2025-02-02 04:44:39,218][0m Trial 7 finished with value: 0.49823878527457544 and parameters: {'observation_period_num': 7, 'train_rates': 0.6848287851745318, 'learning_rate': 1.0190956322841787e-06, 'batch_size': 87, 'step_size': 2, 'gamma': 0.9685672886366388}. Best is trial 3 with value: 0.10111074877276831.[0m
[32m[I 2025-02-02 04:45:02,762][0m Trial 8 finished with value: 0.7379532487768876 and parameters: {'observation_period_num': 55, 'train_rates': 0.6068332142104292, 'learning_rate': 1.6441938334928195e-06, 'batch_size': 213, 'step_size': 11, 'gamma': 0.9326381192472811}. Best is trial 3 with value: 0.10111074877276831.[0m
[32m[I 2025-02-02 04:45:24,550][0m Trial 9 finished with value: 0.1682338123768568 and parameters: {'observation_period_num': 195, 'train_rates': 0.7100835308970423, 'learning_rate': 0.00011792430047829796, 'batch_size': 234, 'step_size': 14, 'gamma': 0.9056192604558206}. Best is trial 3 with value: 0.10111074877276831.[0m
[32m[I 2025-02-02 04:50:18,723][0m Trial 10 finished with value: 0.1067597488729866 and parameters: {'observation_period_num': 13, 'train_rates': 0.8338721534616663, 'learning_rate': 1.469869443128076e-05, 'batch_size': 18, 'step_size': 9, 'gamma': 0.7555811461582478}. Best is trial 3 with value: 0.10111074877276831.[0m
[32m[I 2025-02-02 04:55:30,275][0m Trial 11 finished with value: 0.10370862547914306 and parameters: {'observation_period_num': 5, 'train_rates': 0.8291398654312689, 'learning_rate': 1.3510116582654157e-05, 'batch_size': 17, 'step_size': 8, 'gamma': 0.7564542837946397}. Best is trial 3 with value: 0.10111074877276831.[0m
[32m[I 2025-02-02 04:57:19,277][0m Trial 12 finished with value: 0.06840179115533829 and parameters: {'observation_period_num': 5, 'train_rates': 0.987255339919106, 'learning_rate': 1.3709324114291873e-05, 'batch_size': 57, 'step_size': 7, 'gamma': 0.78678457370602}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 04:58:42,259][0m Trial 13 finished with value: 0.09104792773723602 and parameters: {'observation_period_num': 124, 'train_rates': 0.9845764128652092, 'learning_rate': 4.639521141228131e-05, 'batch_size': 73, 'step_size': 12, 'gamma': 0.8054895779737873}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 04:59:53,530][0m Trial 14 finished with value: 0.2750668221098535 and parameters: {'observation_period_num': 147, 'train_rates': 0.9517449685758272, 'learning_rate': 5.1881687205830476e-05, 'batch_size': 82, 'step_size': 12, 'gamma': 0.7928494595956997}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:00:37,879][0m Trial 15 finished with value: 0.4287704825401306 and parameters: {'observation_period_num': 126, 'train_rates': 0.9880866782883189, 'learning_rate': 5.100774192653931e-06, 'batch_size': 144, 'step_size': 6, 'gamma': 0.7942802591716764}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:02:11,804][0m Trial 16 finished with value: 0.18686209824578515 and parameters: {'observation_period_num': 92, 'train_rates': 0.8986512059124162, 'learning_rate': 4.575750087039364e-05, 'batch_size': 60, 'step_size': 3, 'gamma': 0.8934685882234336}. Best is trial 12 with value: 0.06840179115533829.[0m
Early stopping at epoch 58
[32m[I 2025-02-02 05:02:43,510][0m Trial 17 finished with value: 0.5023260712623596 and parameters: {'observation_period_num': 152, 'train_rates': 0.9848774395008566, 'learning_rate': 5.781134137033719e-06, 'batch_size': 117, 'step_size': 1, 'gamma': 0.835340655389022}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:04:17,785][0m Trial 18 finished with value: 0.1644093053168561 and parameters: {'observation_period_num': 45, 'train_rates': 0.9144598889992903, 'learning_rate': 8.1602843126888e-05, 'batch_size': 61, 'step_size': 8, 'gamma': 0.771768090983266}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:04:51,973][0m Trial 19 finished with value: 0.6488004326820374 and parameters: {'observation_period_num': 207, 'train_rates': 0.957725130814588, 'learning_rate': 7.547245992594598e-06, 'batch_size': 178, 'step_size': 12, 'gamma': 0.8151462261185688}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:06:12,438][0m Trial 20 finished with value: 0.4882893247165899 and parameters: {'observation_period_num': 163, 'train_rates': 0.8754981497935259, 'learning_rate': 3.3649560134363253e-06, 'batch_size': 67, 'step_size': 6, 'gamma': 0.780010671393297}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:08:16,191][0m Trial 21 finished with value: 0.10407934002168887 and parameters: {'observation_period_num': 23, 'train_rates': 0.7828170323762326, 'learning_rate': 2.156075387360338e-05, 'batch_size': 41, 'step_size': 10, 'gamma': 0.806869326878742}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:08:59,002][0m Trial 22 finished with value: 0.1429165892498867 and parameters: {'observation_period_num': 30, 'train_rates': 0.6486299468046196, 'learning_rate': 2.8646115296030213e-05, 'batch_size': 116, 'step_size': 10, 'gamma': 0.7836814352855762}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:11:07,664][0m Trial 23 finished with value: 0.1564681492241485 and parameters: {'observation_period_num': 81, 'train_rates': 0.820022449479191, 'learning_rate': 1.248463487749375e-05, 'batch_size': 41, 'step_size': 12, 'gamma': 0.8307896806443955}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:12:18,468][0m Trial 24 finished with value: 0.19892867208324014 and parameters: {'observation_period_num': 32, 'train_rates': 0.9360514609714492, 'learning_rate': 5.63845995407815e-05, 'batch_size': 84, 'step_size': 9, 'gamma': 0.8728089201997676}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:14:34,880][0m Trial 25 finished with value: 0.16086160246191955 and parameters: {'observation_period_num': 124, 'train_rates': 0.8840432634390607, 'learning_rate': 2.5212061645642375e-05, 'batch_size': 40, 'step_size': 14, 'gamma': 0.8063031246899255}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:15:32,999][0m Trial 26 finished with value: 0.3600062429904938 and parameters: {'observation_period_num': 105, 'train_rates': 0.9667539435167485, 'learning_rate': 0.0001316008792713904, 'batch_size': 105, 'step_size': 7, 'gamma': 0.8511653201128166}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:16:51,991][0m Trial 27 finished with value: 0.21906057430721407 and parameters: {'observation_period_num': 67, 'train_rates': 0.724413598323712, 'learning_rate': 9.592371445813109e-06, 'batch_size': 63, 'step_size': 11, 'gamma': 0.7798768269664543}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:19:55,451][0m Trial 28 finished with value: 0.11452017056179188 and parameters: {'observation_period_num': 40, 'train_rates': 0.855948415111256, 'learning_rate': 3.747769463295171e-05, 'batch_size': 29, 'step_size': 9, 'gamma': 0.8238340969424117}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:20:22,675][0m Trial 29 finished with value: 0.3857287161044458 and parameters: {'observation_period_num': 230, 'train_rates': 0.6480325046251979, 'learning_rate': 1.8678478163491535e-05, 'batch_size': 176, 'step_size': 5, 'gamma': 0.8481766939461838}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:21:30,989][0m Trial 30 finished with value: 0.9401950479741904 and parameters: {'observation_period_num': 90, 'train_rates': 0.7897014025122528, 'learning_rate': 3.569367221969702e-06, 'batch_size': 76, 'step_size': 4, 'gamma': 0.7674816985488807}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:26:23,540][0m Trial 31 finished with value: 0.11590638068650873 and parameters: {'observation_period_num': 5, 'train_rates': 0.8360607412449779, 'learning_rate': 1.0326571073809634e-05, 'batch_size': 18, 'step_size': 8, 'gamma': 0.764224518851965}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:28:12,892][0m Trial 32 finished with value: 0.22300898940080688 and parameters: {'observation_period_num': 22, 'train_rates': 0.9283936613208746, 'learning_rate': 1.653946759489485e-05, 'batch_size': 53, 'step_size': 7, 'gamma': 0.7961295688229896}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:30:59,979][0m Trial 33 finished with value: 0.10196797673007567 and parameters: {'observation_period_num': 49, 'train_rates': 0.760676312717232, 'learning_rate': 8.431946333630773e-05, 'batch_size': 30, 'step_size': 11, 'gamma': 0.75439827010117}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:32:33,139][0m Trial 34 finished with value: 0.09258270523001476 and parameters: {'observation_period_num': 47, 'train_rates': 0.6888065332903487, 'learning_rate': 7.709901472748068e-05, 'batch_size': 50, 'step_size': 13, 'gamma': 0.795505262779398}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:33:22,445][0m Trial 35 finished with value: 0.1067682777900048 and parameters: {'observation_period_num': 73, 'train_rates': 0.7037098795745909, 'learning_rate': 6.681103371954362e-05, 'batch_size': 97, 'step_size': 13, 'gamma': 0.8491347678050911}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:34:48,558][0m Trial 36 finished with value: 0.08803909928316161 and parameters: {'observation_period_num': 35, 'train_rates': 0.6259576735620038, 'learning_rate': 0.00015248120489424252, 'batch_size': 52, 'step_size': 15, 'gamma': 0.8189836314372972}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:35:27,028][0m Trial 37 finished with value: 0.10162624565375208 and parameters: {'observation_period_num': 66, 'train_rates': 0.6301088531037039, 'learning_rate': 0.0002851822336881208, 'batch_size': 127, 'step_size': 15, 'gamma': 0.8214648738173045}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:36:58,117][0m Trial 38 finished with value: 0.08579419469007982 and parameters: {'observation_period_num': 38, 'train_rates': 0.6754466290825382, 'learning_rate': 0.00014271434958909238, 'batch_size': 51, 'step_size': 14, 'gamma': 0.8708234542427069}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:37:57,125][0m Trial 39 finished with value: 0.10385250233017836 and parameters: {'observation_period_num': 32, 'train_rates': 0.6012046669280764, 'learning_rate': 0.0005567193624616801, 'batch_size': 74, 'step_size': 14, 'gamma': 0.8760739914991682}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:39:23,572][0m Trial 40 finished with value: 0.1873620798190435 and parameters: {'observation_period_num': 114, 'train_rates': 0.6303271067912585, 'learning_rate': 0.00017786380507003036, 'batch_size': 50, 'step_size': 15, 'gamma': 0.8890880839676369}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:40:54,896][0m Trial 41 finished with value: 0.10803544852297661 and parameters: {'observation_period_num': 57, 'train_rates': 0.6657038316861293, 'learning_rate': 0.0003190037290173935, 'batch_size': 52, 'step_size': 13, 'gamma': 0.8625035898267409}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:41:44,610][0m Trial 42 finished with value: 0.07895731679193534 and parameters: {'observation_period_num': 18, 'train_rates': 0.678965574783683, 'learning_rate': 0.00010821584922208425, 'batch_size': 97, 'step_size': 13, 'gamma': 0.833964748653611}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:42:36,648][0m Trial 43 finished with value: 0.09802257135996352 and parameters: {'observation_period_num': 22, 'train_rates': 0.6233877695693117, 'learning_rate': 0.00012391180577749812, 'batch_size': 90, 'step_size': 14, 'gamma': 0.8404429751193493}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:43:23,854][0m Trial 44 finished with value: 0.08181407241842897 and parameters: {'observation_period_num': 17, 'train_rates': 0.6618979707574985, 'learning_rate': 0.0003916846918921225, 'batch_size': 100, 'step_size': 15, 'gamma': 0.9835854709685345}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:44:09,083][0m Trial 45 finished with value: 0.1127550821150984 and parameters: {'observation_period_num': 20, 'train_rates': 0.6595434397357783, 'learning_rate': 0.000802814791582993, 'batch_size': 106, 'step_size': 15, 'gamma': 0.9753660255008056}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:44:46,104][0m Trial 46 finished with value: 0.0883007678404401 and parameters: {'observation_period_num': 40, 'train_rates': 0.6900263832731486, 'learning_rate': 0.000385707804572464, 'batch_size': 135, 'step_size': 14, 'gamma': 0.9512896755329484}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:45:44,843][0m Trial 47 finished with value: 0.09511105303304741 and parameters: {'observation_period_num': 34, 'train_rates': 0.7443442051869853, 'learning_rate': 0.00020279456724087288, 'batch_size': 90, 'step_size': 15, 'gamma': 0.9200996283164641}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:46:16,968][0m Trial 48 finished with value: 0.07429708959485068 and parameters: {'observation_period_num': 15, 'train_rates': 0.6810173619186339, 'learning_rate': 0.0004112000038369441, 'batch_size': 163, 'step_size': 15, 'gamma': 0.9582053159856316}. Best is trial 12 with value: 0.06840179115533829.[0m
[32m[I 2025-02-02 05:46:44,520][0m Trial 49 finished with value: 0.07524341882395828 and parameters: {'observation_period_num': 14, 'train_rates': 0.7104063450422976, 'learning_rate': 0.0004514813228654183, 'batch_size': 190, 'step_size': 13, 'gamma': 0.9611567658934977}. Best is trial 12 with value: 0.06840179115533829.[0m
ÊúÄÈÅ©„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åó„Åü
ÊúÄÈÅ©„Å™„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„Åå best_hyperparameters_SBUX_iTransformer_noMSTL.json „Å´‰øùÂ≠ò„Åï„Çå„Åæ„Åó„Åü
Epoch 1/300, Loss: 0.3491 | 0.2786
Epoch 2/300, Loss: 0.2490 | 0.2026
Epoch 3/300, Loss: 0.1909 | 0.1649
Epoch 4/300, Loss: 0.1683 | 0.1476
Epoch 5/300, Loss: 0.1597 | 0.1391
Epoch 6/300, Loss: 0.1543 | 0.1318
Epoch 7/300, Loss: 0.1501 | 0.1263
Epoch 8/300, Loss: 0.1469 | 0.1198
Epoch 9/300, Loss: 0.1447 | 0.1164
Epoch 10/300, Loss: 0.1427 | 0.1133
Epoch 11/300, Loss: 0.1408 | 0.1104
Epoch 12/300, Loss: 0.1389 | 0.1065
Epoch 13/300, Loss: 0.1376 | 0.1045
Epoch 14/300, Loss: 0.1362 | 0.1026
Epoch 15/300, Loss: 0.1349 | 0.1001
Epoch 16/300, Loss: 0.1339 | 0.0987
Epoch 17/300, Loss: 0.1329 | 0.0972
Epoch 18/300, Loss: 0.1320 | 0.0958
Epoch 19/300, Loss: 0.1310 | 0.0941
Epoch 20/300, Loss: 0.1303 | 0.0931
Epoch 21/300, Loss: 0.1296 | 0.0920
Epoch 22/300, Loss: 0.1288 | 0.0908
Epoch 23/300, Loss: 0.1283 | 0.0900
Epoch 24/300, Loss: 0.1277 | 0.0892
Epoch 25/300, Loss: 0.1272 | 0.0884
Epoch 26/300, Loss: 0.1266 | 0.0876
Epoch 27/300, Loss: 0.1262 | 0.0869
Epoch 28/300, Loss: 0.1258 | 0.0863
Epoch 29/300, Loss: 0.1254 | 0.0857
Epoch 30/300, Loss: 0.1251 | 0.0853
Epoch 31/300, Loss: 0.1248 | 0.0848
Epoch 32/300, Loss: 0.1244 | 0.0843
Epoch 33/300, Loss: 0.1241 | 0.0839
Epoch 34/300, Loss: 0.1239 | 0.0835
Epoch 35/300, Loss: 0.1236 | 0.0832
Epoch 36/300, Loss: 0.1234 | 0.0828
Epoch 37/300, Loss: 0.1232 | 0.0826
Epoch 38/300, Loss: 0.1230 | 0.0823
Epoch 39/300, Loss: 0.1228 | 0.0820
Epoch 40/300, Loss: 0.1226 | 0.0818
Epoch 41/300, Loss: 0.1224 | 0.0815
Epoch 42/300, Loss: 0.1223 | 0.0813
Epoch 43/300, Loss: 0.1221 | 0.0811
Epoch 44/300, Loss: 0.1220 | 0.0810
Epoch 45/300, Loss: 0.1219 | 0.0808
Epoch 46/300, Loss: 0.1218 | 0.0806
Epoch 47/300, Loss: 0.1217 | 0.0805
Epoch 48/300, Loss: 0.1216 | 0.0803
Epoch 49/300, Loss: 0.1215 | 0.0802
Epoch 50/300, Loss: 0.1214 | 0.0801
Epoch 51/300, Loss: 0.1213 | 0.0800
Epoch 52/300, Loss: 0.1212 | 0.0799
Epoch 53/300, Loss: 0.1212 | 0.0798
Epoch 54/300, Loss: 0.1211 | 0.0797
Epoch 55/300, Loss: 0.1210 | 0.0796
Epoch 56/300, Loss: 0.1210 | 0.0795
Epoch 57/300, Loss: 0.1209 | 0.0795
Epoch 58/300, Loss: 0.1209 | 0.0794
Epoch 59/300, Loss: 0.1208 | 0.0793
Epoch 60/300, Loss: 0.1208 | 0.0793
Epoch 61/300, Loss: 0.1207 | 0.0792
Epoch 62/300, Loss: 0.1207 | 0.0791
Epoch 63/300, Loss: 0.1207 | 0.0791
Epoch 64/300, Loss: 0.1206 | 0.0791
Epoch 65/300, Loss: 0.1206 | 0.0790
Epoch 66/300, Loss: 0.1206 | 0.0790
Epoch 67/300, Loss: 0.1205 | 0.0789
Epoch 68/300, Loss: 0.1205 | 0.0789
Epoch 69/300, Loss: 0.1205 | 0.0789
Epoch 70/300, Loss: 0.1205 | 0.0788
Epoch 71/300, Loss: 0.1204 | 0.0788
Epoch 72/300, Loss: 0.1204 | 0.0788
Epoch 73/300, Loss: 0.1204 | 0.0788
Epoch 74/300, Loss: 0.1204 | 0.0787
Epoch 75/300, Loss: 0.1204 | 0.0787
Epoch 76/300, Loss: 0.1203 | 0.0787
Epoch 77/300, Loss: 0.1203 | 0.0787
Epoch 78/300, Loss: 0.1203 | 0.0787
Epoch 79/300, Loss: 0.1203 | 0.0786
Epoch 80/300, Loss: 0.1203 | 0.0786
Epoch 81/300, Loss: 0.1203 | 0.0786
Epoch 82/300, Loss: 0.1203 | 0.0786
Epoch 83/300, Loss: 0.1203 | 0.0786
Epoch 84/300, Loss: 0.1202 | 0.0786
Epoch 85/300, Loss: 0.1202 | 0.0786
Epoch 86/300, Loss: 0.1202 | 0.0785
Epoch 87/300, Loss: 0.1202 | 0.0785
Epoch 88/300, Loss: 0.1202 | 0.0785
Epoch 89/300, Loss: 0.1202 | 0.0785
Epoch 90/300, Loss: 0.1202 | 0.0785
Epoch 91/300, Loss: 0.1202 | 0.0785
Epoch 92/300, Loss: 0.1202 | 0.0785
Epoch 93/300, Loss: 0.1202 | 0.0785
Epoch 94/300, Loss: 0.1202 | 0.0785
Epoch 95/300, Loss: 0.1202 | 0.0785
Epoch 96/300, Loss: 0.1202 | 0.0785
Epoch 97/300, Loss: 0.1202 | 0.0785
Epoch 98/300, Loss: 0.1202 | 0.0785
Epoch 99/300, Loss: 0.1202 | 0.0785
Epoch 100/300, Loss: 0.1202 | 0.0785
Epoch 101/300, Loss: 0.1202 | 0.0784
Epoch 102/300, Loss: 0.1202 | 0.0784
Epoch 103/300, Loss: 0.1202 | 0.0784
Epoch 104/300, Loss: 0.1202 | 0.0784
Epoch 105/300, Loss: 0.1201 | 0.0784
Epoch 106/300, Loss: 0.1201 | 0.0784
Epoch 107/300, Loss: 0.1201 | 0.0784
Epoch 108/300, Loss: 0.1201 | 0.0784
Epoch 109/300, Loss: 0.1201 | 0.0784
Epoch 110/300, Loss: 0.1201 | 0.0784
Epoch 111/300, Loss: 0.1201 | 0.0784
Epoch 112/300, Loss: 0.1201 | 0.0784
Epoch 113/300, Loss: 0.1201 | 0.0784
Epoch 114/300, Loss: 0.1201 | 0.0784
Epoch 115/300, Loss: 0.1201 | 0.0784
Epoch 116/300, Loss: 0.1201 | 0.0784
Epoch 117/300, Loss: 0.1201 | 0.0784
Epoch 118/300, Loss: 0.1201 | 0.0784
Epoch 119/300, Loss: 0.1201 | 0.0784
Epoch 120/300, Loss: 0.1201 | 0.0784
Epoch 121/300, Loss: 0.1201 | 0.0784
Epoch 122/300, Loss: 0.1201 | 0.0784
Epoch 123/300, Loss: 0.1201 | 0.0784
Epoch 124/300, Loss: 0.1201 | 0.0784
Epoch 125/300, Loss: 0.1201 | 0.0784
Epoch 126/300, Loss: 0.1201 | 0.0784
Epoch 127/300, Loss: 0.1201 | 0.0784
Epoch 128/300, Loss: 0.1201 | 0.0784
Epoch 129/300, Loss: 0.1201 | 0.0784
Epoch 130/300, Loss: 0.1201 | 0.0784
Epoch 131/300, Loss: 0.1201 | 0.0784
Epoch 132/300, Loss: 0.1201 | 0.0784
Epoch 133/300, Loss: 0.1201 | 0.0784
Epoch 134/300, Loss: 0.1201 | 0.0784
Epoch 135/300, Loss: 0.1201 | 0.0784
Epoch 136/300, Loss: 0.1201 | 0.0784
Epoch 137/300, Loss: 0.1201 | 0.0784
Epoch 138/300, Loss: 0.1201 | 0.0784
Epoch 139/300, Loss: 0.1201 | 0.0784
Epoch 140/300, Loss: 0.1201 | 0.0784
Epoch 141/300, Loss: 0.1201 | 0.0784
Epoch 142/300, Loss: 0.1201 | 0.0784
Epoch 143/300, Loss: 0.1201 | 0.0784
Epoch 144/300, Loss: 0.1201 | 0.0784
Epoch 145/300, Loss: 0.1201 | 0.0784
Epoch 146/300, Loss: 0.1201 | 0.0784
Epoch 147/300, Loss: 0.1201 | 0.0784
Epoch 148/300, Loss: 0.1201 | 0.0784
Epoch 149/300, Loss: 0.1201 | 0.0784
Epoch 150/300, Loss: 0.1201 | 0.0784
Epoch 151/300, Loss: 0.1201 | 0.0784
Epoch 152/300, Loss: 0.1201 | 0.0784
Epoch 153/300, Loss: 0.1201 | 0.0784
Epoch 154/300, Loss: 0.1201 | 0.0784
Epoch 155/300, Loss: 0.1201 | 0.0784
Early stopping
Runtime (seconds): 168.21452522277832
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)
MSE: 2.847012556216214
RMSE: 1.6873092651367188
MAE: 1.6873092651367188
R-squared: nan
[102.36731]
