[32m[I 2025-02-06 23:46:27,236][0m A new study created in memory with name: no-name-f11f3c5f-c887-4234-b2b3-94684886352b[0m
[32m[I 2025-02-06 23:47:09,435][0m Trial 0 finished with value: 0.285579417253724 and parameters: {'observation_period_num': 199, 'train_rates': 0.607578819667636, 'learning_rate': 0.0005036551720421011, 'batch_size': 103, 'step_size': 1, 'gamma': 0.89318600546095}. Best is trial 0 with value: 0.285579417253724.[0m
[32m[I 2025-02-06 23:47:32,557][0m Trial 1 finished with value: 0.6950024016336961 and parameters: {'observation_period_num': 127, 'train_rates': 0.6170472873534719, 'learning_rate': 2.8433747780803016e-06, 'batch_size': 219, 'step_size': 14, 'gamma': 0.839923734327708}. Best is trial 0 with value: 0.285579417253724.[0m
[32m[I 2025-02-06 23:48:23,483][0m Trial 2 finished with value: 0.17946868886550268 and parameters: {'observation_period_num': 155, 'train_rates': 0.855658512274851, 'learning_rate': 6.12733239279701e-05, 'batch_size': 113, 'step_size': 6, 'gamma': 0.8236557373295237}. Best is trial 2 with value: 0.17946868886550268.[0m
[32m[I 2025-02-06 23:48:47,187][0m Trial 3 finished with value: 0.475828268556215 and parameters: {'observation_period_num': 200, 'train_rates': 0.6679137181978541, 'learning_rate': 1.9754530263792332e-05, 'batch_size': 214, 'step_size': 14, 'gamma': 0.8147348485391988}. Best is trial 2 with value: 0.17946868886550268.[0m
[32m[I 2025-02-06 23:49:07,000][0m Trial 4 finished with value: 0.7754371253628397 and parameters: {'observation_period_num': 202, 'train_rates': 0.7294147981869956, 'learning_rate': 2.7613926890996322e-06, 'batch_size': 256, 'step_size': 5, 'gamma': 0.9534357164037315}. Best is trial 2 with value: 0.17946868886550268.[0m
[32m[I 2025-02-06 23:49:58,838][0m Trial 5 finished with value: 0.08285279625804846 and parameters: {'observation_period_num': 98, 'train_rates': 0.809232667504359, 'learning_rate': 0.0002869837428957529, 'batch_size': 107, 'step_size': 6, 'gamma': 0.7565496957650824}. Best is trial 5 with value: 0.08285279625804846.[0m
[32m[I 2025-02-06 23:50:34,528][0m Trial 6 finished with value: 0.2739039361476898 and parameters: {'observation_period_num': 7, 'train_rates': 0.9761734423384433, 'learning_rate': 3.4973256591555385e-06, 'batch_size': 188, 'step_size': 6, 'gamma': 0.9245571532160046}. Best is trial 5 with value: 0.08285279625804846.[0m
Early stopping at epoch 92
[32m[I 2025-02-06 23:51:01,858][0m Trial 7 finished with value: 2.3318402767181396 and parameters: {'observation_period_num': 59, 'train_rates': 0.9490187119800132, 'learning_rate': 3.722671781914956e-06, 'batch_size': 232, 'step_size': 2, 'gamma': 0.8029912259105261}. Best is trial 5 with value: 0.08285279625804846.[0m
[32m[I 2025-02-06 23:51:35,900][0m Trial 8 finished with value: 0.898438263448838 and parameters: {'observation_period_num': 243, 'train_rates': 0.6731882660700809, 'learning_rate': 1.3176240629376449e-06, 'batch_size': 137, 'step_size': 13, 'gamma': 0.8422027840216378}. Best is trial 5 with value: 0.08285279625804846.[0m
[32m[I 2025-02-06 23:52:18,547][0m Trial 9 finished with value: 1.0495043513567552 and parameters: {'observation_period_num': 166, 'train_rates': 0.8702492690217594, 'learning_rate': 1.0409509202765742e-06, 'batch_size': 134, 'step_size': 12, 'gamma': 0.9346348039524437}. Best is trial 5 with value: 0.08285279625804846.[0m
[32m[I 2025-02-06 23:56:59,502][0m Trial 10 finished with value: 0.14498946327984946 and parameters: {'observation_period_num': 87, 'train_rates': 0.8000786838650664, 'learning_rate': 0.0008400899104906177, 'batch_size': 18, 'step_size': 10, 'gamma': 0.7541253078915933}. Best is trial 5 with value: 0.08285279625804846.[0m
[32m[I 2025-02-07 00:00:24,059][0m Trial 11 finished with value: 0.12114634064733491 and parameters: {'observation_period_num': 88, 'train_rates': 0.7914833212348091, 'learning_rate': 0.0008589820558429489, 'batch_size': 25, 'step_size': 10, 'gamma': 0.755702785961298}. Best is trial 5 with value: 0.08285279625804846.[0m
[32m[I 2025-02-07 00:03:44,638][0m Trial 12 finished with value: 0.24193074073375995 and parameters: {'observation_period_num': 83, 'train_rates': 0.7746412954523466, 'learning_rate': 0.00021268010557317065, 'batch_size': 25, 'step_size': 9, 'gamma': 0.7636870196492912}. Best is trial 5 with value: 0.08285279625804846.[0m
[32m[I 2025-02-07 00:05:16,531][0m Trial 13 finished with value: 0.06010633108095018 and parameters: {'observation_period_num': 39, 'train_rates': 0.8528786153015386, 'learning_rate': 0.00016337586425324625, 'batch_size': 61, 'step_size': 8, 'gamma': 0.7830924324288523}. Best is trial 13 with value: 0.06010633108095018.[0m
[32m[I 2025-02-07 00:06:44,970][0m Trial 14 finished with value: 0.05015564044105246 and parameters: {'observation_period_num': 16, 'train_rates': 0.8740451288922371, 'learning_rate': 0.00012166738093237576, 'batch_size': 64, 'step_size': 4, 'gamma': 0.785152548532604}. Best is trial 14 with value: 0.05015564044105246.[0m
[32m[I 2025-02-07 00:08:07,765][0m Trial 15 finished with value: 0.07447788893994206 and parameters: {'observation_period_num': 16, 'train_rates': 0.8903873928893156, 'learning_rate': 0.00010213151258016626, 'batch_size': 71, 'step_size': 3, 'gamma': 0.7918641238703119}. Best is trial 14 with value: 0.05015564044105246.[0m
[32m[I 2025-02-07 00:09:39,886][0m Trial 16 finished with value: 0.17027738504111767 and parameters: {'observation_period_num': 41, 'train_rates': 0.9296738760925609, 'learning_rate': 1.600371733681883e-05, 'batch_size': 65, 'step_size': 4, 'gamma': 0.8720761721411872}. Best is trial 14 with value: 0.05015564044105246.[0m
[32m[I 2025-02-07 00:11:04,391][0m Trial 17 finished with value: 0.06994661706544104 and parameters: {'observation_period_num': 42, 'train_rates': 0.9005470964375484, 'learning_rate': 5.7102537927165915e-05, 'batch_size': 70, 'step_size': 7, 'gamma': 0.7845256192531321}. Best is trial 14 with value: 0.05015564044105246.[0m
[32m[I 2025-02-07 00:12:49,433][0m Trial 18 finished with value: 0.11076882812355099 and parameters: {'observation_period_num': 37, 'train_rates': 0.8432910995073862, 'learning_rate': 0.00013560724946037886, 'batch_size': 52, 'step_size': 8, 'gamma': 0.9794213486464738}. Best is trial 14 with value: 0.05015564044105246.[0m
[32m[I 2025-02-07 00:13:24,146][0m Trial 19 finished with value: 0.32334216140412 and parameters: {'observation_period_num': 60, 'train_rates': 0.7480984564807188, 'learning_rate': 3.181304291959422e-05, 'batch_size': 164, 'step_size': 4, 'gamma': 0.857517378832618}. Best is trial 14 with value: 0.05015564044105246.[0m
[32m[I 2025-02-07 00:15:23,524][0m Trial 20 finished with value: 0.0714197375611934 and parameters: {'observation_period_num': 6, 'train_rates': 0.8333972033603294, 'learning_rate': 9.168074987443285e-06, 'batch_size': 46, 'step_size': 11, 'gamma': 0.7822395991032725}. Best is trial 14 with value: 0.05015564044105246.[0m
[32m[I 2025-02-07 00:16:26,815][0m Trial 21 finished with value: 0.06600285237272309 and parameters: {'observation_period_num': 32, 'train_rates': 0.9017329211192925, 'learning_rate': 5.901002381403768e-05, 'batch_size': 94, 'step_size': 8, 'gamma': 0.7864907725987323}. Best is trial 14 with value: 0.05015564044105246.[0m
[32m[I 2025-02-07 00:17:36,610][0m Trial 22 finished with value: 0.059570348798865226 and parameters: {'observation_period_num': 28, 'train_rates': 0.9172418826080766, 'learning_rate': 7.736554149720163e-05, 'batch_size': 87, 'step_size': 8, 'gamma': 0.7812615314279037}. Best is trial 14 with value: 0.05015564044105246.[0m
[32m[I 2025-02-07 00:18:41,135][0m Trial 23 finished with value: 0.07950730804564818 and parameters: {'observation_period_num': 65, 'train_rates': 0.9460608034102668, 'learning_rate': 0.00029025947733685067, 'batch_size': 93, 'step_size': 8, 'gamma': 0.827792303186224}. Best is trial 14 with value: 0.05015564044105246.[0m
[32m[I 2025-02-07 00:20:57,039][0m Trial 24 finished with value: 0.18222735822200775 and parameters: {'observation_period_num': 120, 'train_rates': 0.9864873030881762, 'learning_rate': 0.0001312013619810931, 'batch_size': 44, 'step_size': 10, 'gamma': 0.8066512899840624}. Best is trial 14 with value: 0.05015564044105246.[0m
[32m[I 2025-02-07 00:22:07,961][0m Trial 25 finished with value: 0.1047647401946297 and parameters: {'observation_period_num': 26, 'train_rates': 0.9217573534669502, 'learning_rate': 3.4438327039313e-05, 'batch_size': 83, 'step_size': 7, 'gamma': 0.7686592533497125}. Best is trial 14 with value: 0.05015564044105246.[0m
[32m[I 2025-02-07 00:22:52,905][0m Trial 26 finished with value: 0.08520839626881037 and parameters: {'observation_period_num': 58, 'train_rates': 0.8722761871843416, 'learning_rate': 9.186831505543528e-05, 'batch_size': 129, 'step_size': 5, 'gamma': 0.8844648725702463}. Best is trial 14 with value: 0.05015564044105246.[0m
Early stopping at epoch 50
[32m[I 2025-02-07 00:23:12,514][0m Trial 27 finished with value: 0.12133616174241448 and parameters: {'observation_period_num': 5, 'train_rates': 0.8282089141591912, 'learning_rate': 0.00020909085294389246, 'batch_size': 156, 'step_size': 1, 'gamma': 0.7744320875751006}. Best is trial 14 with value: 0.05015564044105246.[0m
[32m[I 2025-02-07 00:24:47,323][0m Trial 28 finished with value: 0.16180528584700912 and parameters: {'observation_period_num': 110, 'train_rates': 0.8840711622976848, 'learning_rate': 0.0003630952417599612, 'batch_size': 58, 'step_size': 3, 'gamma': 0.801955966406646}. Best is trial 14 with value: 0.05015564044105246.[0m
[32m[I 2025-02-07 00:26:00,237][0m Trial 29 finished with value: 0.16790885214520768 and parameters: {'observation_period_num': 144, 'train_rates': 0.9209649629072119, 'learning_rate': 0.0003944490664191119, 'batch_size': 78, 'step_size': 9, 'gamma': 0.842080296820494}. Best is trial 14 with value: 0.05015564044105246.[0m
[32m[I 2025-02-07 00:26:52,066][0m Trial 30 finished with value: 0.20167233049869537 and parameters: {'observation_period_num': 70, 'train_rates': 0.9603558188231454, 'learning_rate': 0.000172904606851175, 'batch_size': 118, 'step_size': 1, 'gamma': 0.9110731533131604}. Best is trial 14 with value: 0.05015564044105246.[0m
[32m[I 2025-02-07 00:27:57,115][0m Trial 31 finished with value: 0.0689192801036618 and parameters: {'observation_period_num': 29, 'train_rates': 0.9076059143175431, 'learning_rate': 6.0399064528522996e-05, 'batch_size': 90, 'step_size': 7, 'gamma': 0.7876928290990688}. Best is trial 14 with value: 0.05015564044105246.[0m
[32m[I 2025-02-07 00:28:59,653][0m Trial 32 finished with value: 0.058913024582175746 and parameters: {'observation_period_num': 24, 'train_rates': 0.8549270279813161, 'learning_rate': 7.419155944336226e-05, 'batch_size': 93, 'step_size': 9, 'gamma': 0.7941347058707493}. Best is trial 14 with value: 0.05015564044105246.[0m
[32m[I 2025-02-07 00:31:22,358][0m Trial 33 finished with value: 0.08794071857372056 and parameters: {'observation_period_num': 46, 'train_rates': 0.8597809851613157, 'learning_rate': 8.793538993931435e-05, 'batch_size': 39, 'step_size': 15, 'gamma': 0.8209537659114642}. Best is trial 14 with value: 0.05015564044105246.[0m
[32m[I 2025-02-07 00:32:13,817][0m Trial 34 finished with value: 0.0754118358308915 and parameters: {'observation_period_num': 21, 'train_rates': 0.828213361797349, 'learning_rate': 4.119146552919581e-05, 'batch_size': 111, 'step_size': 9, 'gamma': 0.8041853350941089}. Best is trial 14 with value: 0.05015564044105246.[0m
[32m[I 2025-02-07 00:33:48,690][0m Trial 35 finished with value: 0.07616219032160584 and parameters: {'observation_period_num': 50, 'train_rates': 0.8500035787322615, 'learning_rate': 2.0893638142693427e-05, 'batch_size': 58, 'step_size': 11, 'gamma': 0.8315933184872482}. Best is trial 14 with value: 0.05015564044105246.[0m
[32m[I 2025-02-07 00:34:44,212][0m Trial 36 finished with value: 0.03232895667737412 and parameters: {'observation_period_num': 19, 'train_rates': 0.8195829578932098, 'learning_rate': 0.0006038810827576445, 'batch_size': 99, 'step_size': 6, 'gamma': 0.8572206078842384}. Best is trial 36 with value: 0.03232895667737412.[0m
[32m[I 2025-02-07 00:35:38,820][0m Trial 37 finished with value: 0.16703446885879092 and parameters: {'observation_period_num': 21, 'train_rates': 0.7666483538149229, 'learning_rate': 0.0004919639476490092, 'batch_size': 97, 'step_size': 5, 'gamma': 0.8575684508688661}. Best is trial 36 with value: 0.03232895667737412.[0m
[32m[I 2025-02-07 00:36:15,119][0m Trial 38 finished with value: 0.07159349685812842 and parameters: {'observation_period_num': 73, 'train_rates': 0.8169969774981369, 'learning_rate': 0.0006352128579560782, 'batch_size': 151, 'step_size': 6, 'gamma': 0.8902753384248748}. Best is trial 36 with value: 0.03232895667737412.[0m
[32m[I 2025-02-07 00:36:58,077][0m Trial 39 finished with value: 0.521374238807647 and parameters: {'observation_period_num': 172, 'train_rates': 0.7193523080517777, 'learning_rate': 1.556302144620897e-05, 'batch_size': 117, 'step_size': 4, 'gamma': 0.8131925877805288}. Best is trial 36 with value: 0.03232895667737412.[0m
[32m[I 2025-02-07 00:37:54,540][0m Trial 40 finished with value: 0.04903360501782078 and parameters: {'observation_period_num': 18, 'train_rates': 0.876699494409514, 'learning_rate': 7.872944117281544e-05, 'batch_size': 103, 'step_size': 7, 'gamma': 0.848775089140421}. Best is trial 36 with value: 0.03232895667737412.[0m
[32m[I 2025-02-07 00:38:50,740][0m Trial 41 finished with value: 0.06082768738269806 and parameters: {'observation_period_num': 20, 'train_rates': 0.8759639839433597, 'learning_rate': 4.523296693005953e-05, 'batch_size': 104, 'step_size': 7, 'gamma': 0.8567908086530724}. Best is trial 36 with value: 0.03232895667737412.[0m
[32m[I 2025-02-07 00:40:07,714][0m Trial 42 finished with value: 0.043475216690530165 and parameters: {'observation_period_num': 11, 'train_rates': 0.9370531705270754, 'learning_rate': 8.328391779534941e-05, 'batch_size': 79, 'step_size': 6, 'gamma': 0.8809116784305961}. Best is trial 36 with value: 0.03232895667737412.[0m
[32m[I 2025-02-07 00:41:23,123][0m Trial 43 finished with value: 0.0663662555186372 and parameters: {'observation_period_num': 13, 'train_rates': 0.9365814836107069, 'learning_rate': 2.2616634344784808e-05, 'batch_size': 78, 'step_size': 6, 'gamma': 0.9101977475491563}. Best is trial 36 with value: 0.03232895667737412.[0m
[32m[I 2025-02-07 00:42:04,745][0m Trial 44 finished with value: 0.21331114208740395 and parameters: {'observation_period_num': 231, 'train_rates': 0.7955316680340273, 'learning_rate': 0.00011554492581330258, 'batch_size': 126, 'step_size': 5, 'gamma': 0.8742088630442839}. Best is trial 36 with value: 0.03232895667737412.[0m
[32m[I 2025-02-07 00:44:54,110][0m Trial 45 finished with value: 0.054884184151887894 and parameters: {'observation_period_num': 52, 'train_rates': 0.9619703440682854, 'learning_rate': 0.00022885213408534933, 'batch_size': 35, 'step_size': 6, 'gamma': 0.8388906838277852}. Best is trial 36 with value: 0.03232895667737412.[0m
[32m[I 2025-02-07 00:48:12,801][0m Trial 46 finished with value: 0.07083358243107796 and parameters: {'observation_period_num': 52, 'train_rates': 0.9696894798404296, 'learning_rate': 0.0002469335915097879, 'batch_size': 30, 'step_size': 6, 'gamma': 0.9013387421617088}. Best is trial 36 with value: 0.03232895667737412.[0m
[32m[I 2025-02-07 00:50:56,464][0m Trial 47 finished with value: 0.022885055852032477 and parameters: {'observation_period_num': 9, 'train_rates': 0.9587765427632469, 'learning_rate': 0.0005919130165528953, 'batch_size': 37, 'step_size': 3, 'gamma': 0.8519527544704599}. Best is trial 47 with value: 0.022885055852032477.[0m
[32m[I 2025-02-07 00:52:00,523][0m Trial 48 finished with value: 0.13204299265688116 and parameters: {'observation_period_num': 12, 'train_rates': 0.613346173605366, 'learning_rate': 0.0005281617228071874, 'batch_size': 72, 'step_size': 3, 'gamma': 0.8500878837378772}. Best is trial 47 with value: 0.022885055852032477.[0m
[32m[I 2025-02-07 00:52:33,620][0m Trial 49 finished with value: 0.05542641505599022 and parameters: {'observation_period_num': 5, 'train_rates': 0.9432381870832859, 'learning_rate': 0.0008124792343525729, 'batch_size': 197, 'step_size': 2, 'gamma': 0.8800183189520379}. Best is trial 47 with value: 0.022885055852032477.[0m
最適ハイパーパラメータが見つかりました
最適なハイパーパラメータが best_hyperparameters_GOOG_iTransformer_noMSTL.json に保存されました
Epoch 1/300, Loss: 0.2200 | 0.1163
Epoch 2/300, Loss: 0.1143 | 0.0858
Epoch 3/300, Loss: 0.1044 | 0.0706
Epoch 4/300, Loss: 0.0962 | 0.0674
Epoch 5/300, Loss: 0.0944 | 0.0609
Epoch 6/300, Loss: 0.0938 | 0.0621
Epoch 7/300, Loss: 0.0912 | 0.0530
Epoch 8/300, Loss: 0.0855 | 0.0455
Epoch 9/300, Loss: 0.0808 | 0.0456
Epoch 10/300, Loss: 0.0782 | 0.0438
Epoch 11/300, Loss: 0.0775 | 0.0440
Epoch 12/300, Loss: 0.0775 | 0.0469
Epoch 13/300, Loss: 0.0742 | 0.0456
Epoch 14/300, Loss: 0.0717 | 0.0418
Epoch 15/300, Loss: 0.0692 | 0.0396
Epoch 16/300, Loss: 0.0688 | 0.0407
Epoch 17/300, Loss: 0.0676 | 0.0373
Epoch 18/300, Loss: 0.0665 | 0.0366
Epoch 19/300, Loss: 0.0658 | 0.0358
Epoch 20/300, Loss: 0.0653 | 0.0352
Epoch 21/300, Loss: 0.0648 | 0.0348
Epoch 22/300, Loss: 0.0643 | 0.0344
Epoch 23/300, Loss: 0.0640 | 0.0339
Epoch 24/300, Loss: 0.0636 | 0.0336
Epoch 25/300, Loss: 0.0633 | 0.0335
Epoch 26/300, Loss: 0.0630 | 0.0332
Epoch 27/300, Loss: 0.0627 | 0.0331
Epoch 28/300, Loss: 0.0624 | 0.0330
Epoch 29/300, Loss: 0.0623 | 0.0327
Epoch 30/300, Loss: 0.0621 | 0.0326
Epoch 31/300, Loss: 0.0619 | 0.0325
Epoch 32/300, Loss: 0.0618 | 0.0324
Epoch 33/300, Loss: 0.0616 | 0.0324
Epoch 34/300, Loss: 0.0615 | 0.0325
Epoch 35/300, Loss: 0.0614 | 0.0323
Epoch 36/300, Loss: 0.0612 | 0.0325
Epoch 37/300, Loss: 0.0611 | 0.0325
Epoch 38/300, Loss: 0.0610 | 0.0324
Epoch 39/300, Loss: 0.0609 | 0.0323
Epoch 40/300, Loss: 0.0608 | 0.0322
Epoch 41/300, Loss: 0.0607 | 0.0321
Epoch 42/300, Loss: 0.0606 | 0.0320
Epoch 43/300, Loss: 0.0606 | 0.0318
Epoch 44/300, Loss: 0.0605 | 0.0318
Epoch 45/300, Loss: 0.0605 | 0.0317
Epoch 46/300, Loss: 0.0604 | 0.0317
Epoch 47/300, Loss: 0.0604 | 0.0317
Epoch 48/300, Loss: 0.0603 | 0.0316
Epoch 49/300, Loss: 0.0602 | 0.0316
Epoch 50/300, Loss: 0.0602 | 0.0316
Epoch 51/300, Loss: 0.0602 | 0.0316
Epoch 52/300, Loss: 0.0602 | 0.0316
Epoch 53/300, Loss: 0.0601 | 0.0316
Epoch 54/300, Loss: 0.0601 | 0.0316
Epoch 55/300, Loss: 0.0601 | 0.0316
Epoch 56/300, Loss: 0.0600 | 0.0316
Epoch 57/300, Loss: 0.0600 | 0.0317
Epoch 58/300, Loss: 0.0599 | 0.0317
Epoch 59/300, Loss: 0.0599 | 0.0317
Epoch 60/300, Loss: 0.0599 | 0.0317
Epoch 61/300, Loss: 0.0598 | 0.0317
Epoch 62/300, Loss: 0.0598 | 0.0317
Epoch 63/300, Loss: 0.0598 | 0.0317
Epoch 64/300, Loss: 0.0597 | 0.0317
Epoch 65/300, Loss: 0.0597 | 0.0317
Epoch 66/300, Loss: 0.0597 | 0.0317
Epoch 67/300, Loss: 0.0597 | 0.0317
Epoch 68/300, Loss: 0.0597 | 0.0317
Epoch 69/300, Loss: 0.0597 | 0.0317
Epoch 70/300, Loss: 0.0597 | 0.0317
Epoch 71/300, Loss: 0.0597 | 0.0317
Epoch 72/300, Loss: 0.0596 | 0.0317
Epoch 73/300, Loss: 0.0596 | 0.0317
Epoch 74/300, Loss: 0.0596 | 0.0317
Epoch 75/300, Loss: 0.0596 | 0.0316
Epoch 76/300, Loss: 0.0596 | 0.0316
Epoch 77/300, Loss: 0.0596 | 0.0316
Epoch 78/300, Loss: 0.0596 | 0.0316
Epoch 79/300, Loss: 0.0596 | 0.0316
Epoch 80/300, Loss: 0.0596 | 0.0316
Epoch 81/300, Loss: 0.0596 | 0.0316
Epoch 82/300, Loss: 0.0596 | 0.0316
Epoch 83/300, Loss: 0.0596 | 0.0316
Epoch 84/300, Loss: 0.0596 | 0.0316
Epoch 85/300, Loss: 0.0596 | 0.0316
Epoch 86/300, Loss: 0.0596 | 0.0316
Epoch 87/300, Loss: 0.0596 | 0.0316
Epoch 88/300, Loss: 0.0596 | 0.0316
Epoch 89/300, Loss: 0.0596 | 0.0316
Epoch 90/300, Loss: 0.0596 | 0.0316
Epoch 91/300, Loss: 0.0596 | 0.0316
Epoch 92/300, Loss: 0.0596 | 0.0316
Epoch 93/300, Loss: 0.0596 | 0.0316
Epoch 94/300, Loss: 0.0596 | 0.0316
Epoch 95/300, Loss: 0.0596 | 0.0316
Epoch 96/300, Loss: 0.0596 | 0.0316
Epoch 97/300, Loss: 0.0596 | 0.0316
Epoch 98/300, Loss: 0.0596 | 0.0316
Epoch 99/300, Loss: 0.0596 | 0.0316
Epoch 100/300, Loss: 0.0596 | 0.0316
Epoch 101/300, Loss: 0.0596 | 0.0316
Epoch 102/300, Loss: 0.0596 | 0.0316
Epoch 103/300, Loss: 0.0596 | 0.0316
Epoch 104/300, Loss: 0.0596 | 0.0316
Epoch 105/300, Loss: 0.0596 | 0.0316
Epoch 106/300, Loss: 0.0596 | 0.0316
Epoch 107/300, Loss: 0.0596 | 0.0316
Epoch 108/300, Loss: 0.0596 | 0.0316
Epoch 109/300, Loss: 0.0596 | 0.0316
Epoch 110/300, Loss: 0.0596 | 0.0316
Epoch 111/300, Loss: 0.0596 | 0.0316
Epoch 112/300, Loss: 0.0596 | 0.0316
Epoch 113/300, Loss: 0.0596 | 0.0316
Epoch 114/300, Loss: 0.0596 | 0.0316
Epoch 115/300, Loss: 0.0596 | 0.0316
Epoch 116/300, Loss: 0.0596 | 0.0316
Epoch 117/300, Loss: 0.0596 | 0.0316
Epoch 118/300, Loss: 0.0596 | 0.0316
Epoch 119/300, Loss: 0.0596 | 0.0316
Epoch 120/300, Loss: 0.0596 | 0.0316
Epoch 121/300, Loss: 0.0596 | 0.0316
Epoch 122/300, Loss: 0.0596 | 0.0316
Epoch 123/300, Loss: 0.0596 | 0.0316
Epoch 124/300, Loss: 0.0596 | 0.0316
Epoch 125/300, Loss: 0.0596 | 0.0316
Epoch 126/300, Loss: 0.0596 | 0.0316
Epoch 127/300, Loss: 0.0596 | 0.0316
Epoch 128/300, Loss: 0.0596 | 0.0316
Epoch 129/300, Loss: 0.0596 | 0.0316
Epoch 130/300, Loss: 0.0596 | 0.0316
Epoch 131/300, Loss: 0.0596 | 0.0316
Epoch 132/300, Loss: 0.0596 | 0.0316
Epoch 133/300, Loss: 0.0596 | 0.0316
Epoch 134/300, Loss: 0.0596 | 0.0316
Epoch 135/300, Loss: 0.0596 | 0.0316
Epoch 136/300, Loss: 0.0596 | 0.0316
Epoch 137/300, Loss: 0.0596 | 0.0316
Epoch 138/300, Loss: 0.0596 | 0.0316
Epoch 139/300, Loss: 0.0596 | 0.0316
Epoch 140/300, Loss: 0.0596 | 0.0316
Epoch 141/300, Loss: 0.0596 | 0.0316
Epoch 142/300, Loss: 0.0596 | 0.0316
Epoch 143/300, Loss: 0.0596 | 0.0316
Early stopping
Runtime (seconds): 233.05769658088684
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)
MSE: 83.29208202683367
RMSE: 9.126449584960938
MAE: 9.126449584960938
R-squared: nan
[198.58356]
