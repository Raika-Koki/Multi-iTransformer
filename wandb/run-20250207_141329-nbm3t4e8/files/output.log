[32m[I 2025-02-07 14:13:37,214][0m A new study created in memory with name: no-name-9402ce40-d2e7-460d-84f9-5a3aef848426[0m
[32m[I 2025-02-07 14:14:01,175][0m Trial 0 finished with value: 0.08916504588268256 and parameters: {'observation_period_num': 50, 'train_rates': 0.7825687957574029, 'learning_rate': 0.0005385131745690966, 'batch_size': 235, 'step_size': 9, 'gamma': 0.9406715972673494}. Best is trial 0 with value: 0.08916504588268256.[0m
[32m[I 2025-02-07 14:14:46,069][0m Trial 1 finished with value: 0.1836675776951555 and parameters: {'observation_period_num': 198, 'train_rates': 0.8523537957298031, 'learning_rate': 0.0004233767756067475, 'batch_size': 120, 'step_size': 3, 'gamma': 0.9396646143005117}. Best is trial 0 with value: 0.08916504588268256.[0m
[32m[I 2025-02-07 14:15:10,700][0m Trial 2 finished with value: 0.19945416298712262 and parameters: {'observation_period_num': 169, 'train_rates': 0.829342678234125, 'learning_rate': 0.0003677221991495391, 'batch_size': 248, 'step_size': 13, 'gamma': 0.8259391308746904}. Best is trial 0 with value: 0.08916504588268256.[0m
[32m[I 2025-02-07 14:15:36,677][0m Trial 3 finished with value: 0.5478599175810814 and parameters: {'observation_period_num': 212, 'train_rates': 0.6125280331992493, 'learning_rate': 3.3890838882580834e-05, 'batch_size': 189, 'step_size': 4, 'gamma': 0.8038290610111659}. Best is trial 0 with value: 0.08916504588268256.[0m
[32m[I 2025-02-07 14:15:57,677][0m Trial 4 finished with value: 0.48876160786415795 and parameters: {'observation_period_num': 214, 'train_rates': 0.6205005065278056, 'learning_rate': 4.9488336817779015e-05, 'batch_size': 242, 'step_size': 14, 'gamma': 0.9575238026338853}. Best is trial 0 with value: 0.08916504588268256.[0m
[32m[I 2025-02-07 14:16:48,056][0m Trial 5 finished with value: 0.2942210296092675 and parameters: {'observation_period_num': 101, 'train_rates': 0.7050735697171526, 'learning_rate': 1.3537233507536423e-05, 'batch_size': 98, 'step_size': 13, 'gamma': 0.930966660802451}. Best is trial 0 with value: 0.08916504588268256.[0m
[32m[I 2025-02-07 14:17:27,988][0m Trial 6 finished with value: 0.055471550379144516 and parameters: {'observation_period_num': 24, 'train_rates': 0.8853395319421951, 'learning_rate': 0.00022954447370262206, 'batch_size': 147, 'step_size': 7, 'gamma': 0.7608732647481483}. Best is trial 6 with value: 0.055471550379144516.[0m
[32m[I 2025-02-07 14:18:33,492][0m Trial 7 finished with value: 0.6372815327762623 and parameters: {'observation_period_num': 95, 'train_rates': 0.6044083871165545, 'learning_rate': 3.1758051742743257e-06, 'batch_size': 65, 'step_size': 4, 'gamma': 0.7574214979222532}. Best is trial 6 with value: 0.055471550379144516.[0m
[32m[I 2025-02-07 14:19:13,565][0m Trial 8 finished with value: 0.2785308483660864 and parameters: {'observation_period_num': 119, 'train_rates': 0.7748369570874272, 'learning_rate': 0.0001863166516183208, 'batch_size': 138, 'step_size': 3, 'gamma': 0.8532608934621407}. Best is trial 6 with value: 0.055471550379144516.[0m
[32m[I 2025-02-07 14:21:46,057][0m Trial 9 finished with value: 0.31742482468468486 and parameters: {'observation_period_num': 148, 'train_rates': 0.6988746693237246, 'learning_rate': 5.410414067713991e-05, 'batch_size': 30, 'step_size': 1, 'gamma': 0.8995513451755877}. Best is trial 6 with value: 0.055471550379144516.[0m
[32m[I 2025-02-07 14:22:24,020][0m Trial 10 finished with value: 0.6720311641693115 and parameters: {'observation_period_num': 13, 'train_rates': 0.9740247914902493, 'learning_rate': 2.399951578817555e-06, 'batch_size': 180, 'step_size': 7, 'gamma': 0.7513778761304434}. Best is trial 6 with value: 0.055471550379144516.[0m
[32m[I 2025-02-07 14:22:59,277][0m Trial 11 finished with value: 0.03869303570853339 and parameters: {'observation_period_num': 11, 'train_rates': 0.9247187281003852, 'learning_rate': 0.0008040583176815517, 'batch_size': 191, 'step_size': 9, 'gamma': 0.8902991568665348}. Best is trial 11 with value: 0.03869303570853339.[0m
[32m[I 2025-02-07 14:23:34,637][0m Trial 12 finished with value: 0.03353867936626222 and parameters: {'observation_period_num': 7, 'train_rates': 0.931368713038085, 'learning_rate': 0.0009321967157574111, 'batch_size': 176, 'step_size': 9, 'gamma': 0.8931960711227682}. Best is trial 12 with value: 0.03353867936626222.[0m
[32m[I 2025-02-07 14:24:10,117][0m Trial 13 finished with value: 0.18570974469184875 and parameters: {'observation_period_num': 68, 'train_rates': 0.9843699552673622, 'learning_rate': 0.000997045286512095, 'batch_size': 191, 'step_size': 10, 'gamma': 0.9893911395455892}. Best is trial 12 with value: 0.03353867936626222.[0m
[32m[I 2025-02-07 14:24:41,427][0m Trial 14 finished with value: 0.04674420790459082 and parameters: {'observation_period_num': 8, 'train_rates': 0.9179048883149753, 'learning_rate': 0.00013134101940294528, 'batch_size': 208, 'step_size': 11, 'gamma': 0.8788260755877332}. Best is trial 12 with value: 0.03353867936626222.[0m
[32m[I 2025-02-07 14:25:19,775][0m Trial 15 finished with value: 0.302504046194589 and parameters: {'observation_period_num': 52, 'train_rates': 0.9320812372096724, 'learning_rate': 1.025098708437454e-05, 'batch_size': 165, 'step_size': 8, 'gamma': 0.9043786595255712}. Best is trial 12 with value: 0.03353867936626222.[0m
[32m[I 2025-02-07 14:25:49,206][0m Trial 16 finished with value: 0.1815416543407643 and parameters: {'observation_period_num': 75, 'train_rates': 0.9198532686658447, 'learning_rate': 0.000956740434778535, 'batch_size': 211, 'step_size': 11, 'gamma': 0.8585400121543191}. Best is trial 12 with value: 0.03353867936626222.[0m
[32m[I 2025-02-07 14:26:49,221][0m Trial 17 finished with value: 0.052493078297417554 and parameters: {'observation_period_num': 31, 'train_rates': 0.8530180129201923, 'learning_rate': 9.380056915783999e-05, 'batch_size': 94, 'step_size': 6, 'gamma': 0.8956089340916575}. Best is trial 12 with value: 0.03353867936626222.[0m
[32m[I 2025-02-07 14:27:30,360][0m Trial 18 finished with value: 0.2549830377101898 and parameters: {'observation_period_num': 48, 'train_rates': 0.9514528714863169, 'learning_rate': 1.3688968777481948e-05, 'batch_size': 153, 'step_size': 15, 'gamma': 0.8299982670033792}. Best is trial 12 with value: 0.03353867936626222.[0m
[32m[I 2025-02-07 14:27:59,795][0m Trial 19 finished with value: 0.6171836246010716 and parameters: {'observation_period_num': 5, 'train_rates': 0.8914061988268517, 'learning_rate': 1.268423955098244e-06, 'batch_size': 212, 'step_size': 11, 'gamma': 0.9152928508379445}. Best is trial 12 with value: 0.03353867936626222.[0m
[32m[I 2025-02-07 14:28:41,859][0m Trial 20 finished with value: 0.3564810435659384 and parameters: {'observation_period_num': 239, 'train_rates': 0.7470729047107819, 'learning_rate': 0.0005730089314717984, 'batch_size': 120, 'step_size': 9, 'gamma': 0.8760723039059637}. Best is trial 12 with value: 0.03353867936626222.[0m
[32m[I 2025-02-07 14:29:12,713][0m Trial 21 finished with value: 0.05305091768809377 and parameters: {'observation_period_num': 6, 'train_rates': 0.9027192737660977, 'learning_rate': 0.00010225774380028347, 'batch_size': 215, 'step_size': 12, 'gamma': 0.8779455191384975}. Best is trial 12 with value: 0.03353867936626222.[0m
[32m[I 2025-02-07 14:29:50,420][0m Trial 22 finished with value: 0.07791372388601303 and parameters: {'observation_period_num': 33, 'train_rates': 0.9424047058889584, 'learning_rate': 0.00018906915231704669, 'batch_size': 174, 'step_size': 10, 'gamma': 0.8453686328776864}. Best is trial 12 with value: 0.03353867936626222.[0m
[32m[I 2025-02-07 14:30:21,285][0m Trial 23 finished with value: 0.09026340454078789 and parameters: {'observation_period_num': 74, 'train_rates': 0.8552108199614213, 'learning_rate': 0.0002592525478161353, 'batch_size': 201, 'step_size': 6, 'gamma': 0.8802020171441498}. Best is trial 12 with value: 0.03353867936626222.[0m
[32m[I 2025-02-07 14:30:50,873][0m Trial 24 finished with value: 0.08242896944284439 and parameters: {'observation_period_num': 41, 'train_rates': 0.9601381199614932, 'learning_rate': 0.00010358328038764629, 'batch_size': 225, 'step_size': 9, 'gamma': 0.9206870976961371}. Best is trial 12 with value: 0.03353867936626222.[0m
[32m[I 2025-02-07 14:31:13,855][0m Trial 25 finished with value: 0.040047084803090376 and parameters: {'observation_period_num': 21, 'train_rates': 0.828862638449689, 'learning_rate': 0.000672180622523302, 'batch_size': 256, 'step_size': 11, 'gamma': 0.8012564973019203}. Best is trial 12 with value: 0.03353867936626222.[0m
[32m[I 2025-02-07 14:31:38,270][0m Trial 26 finished with value: 0.0732718802691637 and parameters: {'observation_period_num': 64, 'train_rates': 0.8207498843830485, 'learning_rate': 0.0007490583145467478, 'batch_size': 250, 'step_size': 8, 'gamma': 0.7929377200580112}. Best is trial 12 with value: 0.03353867936626222.[0m
[32m[I 2025-02-07 14:32:14,660][0m Trial 27 finished with value: 0.10621563894386143 and parameters: {'observation_period_num': 95, 'train_rates': 0.8666616719777028, 'learning_rate': 0.0003843429050004733, 'batch_size': 164, 'step_size': 12, 'gamma': 0.8158484346412627}. Best is trial 12 with value: 0.03353867936626222.[0m
[32m[I 2025-02-07 14:32:40,522][0m Trial 28 finished with value: 0.044307407966239554 and parameters: {'observation_period_num': 25, 'train_rates': 0.8187817379688929, 'learning_rate': 0.0005886803119175927, 'batch_size': 228, 'step_size': 10, 'gamma': 0.7829479381844396}. Best is trial 12 with value: 0.03353867936626222.[0m
[32m[I 2025-02-07 14:33:04,811][0m Trial 29 finished with value: 0.11602907631329876 and parameters: {'observation_period_num': 54, 'train_rates': 0.7839271113894133, 'learning_rate': 0.00031833216688737214, 'batch_size': 256, 'step_size': 7, 'gamma': 0.9703194084003669}. Best is trial 12 with value: 0.03353867936626222.[0m
[32m[I 2025-02-07 14:33:29,502][0m Trial 30 finished with value: 0.2723185330082903 and parameters: {'observation_period_num': 136, 'train_rates': 0.7523619199267312, 'learning_rate': 0.0007022356021573549, 'batch_size': 232, 'step_size': 9, 'gamma': 0.8359029714975467}. Best is trial 12 with value: 0.03353867936626222.[0m
[32m[I 2025-02-07 14:33:57,582][0m Trial 31 finished with value: 0.04503182876137418 and parameters: {'observation_period_num': 24, 'train_rates': 0.8168746059453038, 'learning_rate': 0.0005703195917204019, 'batch_size': 226, 'step_size': 10, 'gamma': 0.7910383741983732}. Best is trial 12 with value: 0.03353867936626222.[0m
[32m[I 2025-02-07 14:34:31,510][0m Trial 32 finished with value: 0.041133341139980725 and parameters: {'observation_period_num': 22, 'train_rates': 0.8824688874917418, 'learning_rate': 0.0004766891205579685, 'batch_size': 195, 'step_size': 10, 'gamma': 0.7736630790159604}. Best is trial 12 with value: 0.03353867936626222.[0m
[32m[I 2025-02-07 14:35:04,400][0m Trial 33 finished with value: 0.05037339319191549 and parameters: {'observation_period_num': 43, 'train_rates': 0.8758268027032633, 'learning_rate': 0.0003915658030550639, 'batch_size': 188, 'step_size': 12, 'gamma': 0.7735686589619788}. Best is trial 12 with value: 0.03353867936626222.[0m
[32m[I 2025-02-07 14:35:35,914][0m Trial 34 finished with value: 0.03321373550330892 and parameters: {'observation_period_num': 18, 'train_rates': 0.9146920500738893, 'learning_rate': 0.0009727451518366711, 'batch_size': 195, 'step_size': 13, 'gamma': 0.8122076712157882}. Best is trial 34 with value: 0.03321373550330892.[0m
[32m[I 2025-02-07 14:36:24,205][0m Trial 35 finished with value: 0.2128556852796638 and parameters: {'observation_period_num': 162, 'train_rates': 0.911698123735248, 'learning_rate': 0.0009831601113121178, 'batch_size': 123, 'step_size': 14, 'gamma': 0.8178286606919156}. Best is trial 34 with value: 0.03321373550330892.[0m
[32m[I 2025-02-07 14:36:58,389][0m Trial 36 finished with value: 0.05629109959853323 and parameters: {'observation_period_num': 38, 'train_rates': 0.8397648236173515, 'learning_rate': 0.00030677689210842184, 'batch_size': 170, 'step_size': 13, 'gamma': 0.863499120800571}. Best is trial 34 with value: 0.03321373550330892.[0m
[32m[I 2025-02-07 14:37:42,354][0m Trial 37 finished with value: 0.04238594323396683 and parameters: {'observation_period_num': 20, 'train_rates': 0.9665967544575252, 'learning_rate': 0.00046173317892984114, 'batch_size': 151, 'step_size': 14, 'gamma': 0.8090527260541993}. Best is trial 34 with value: 0.03321373550330892.[0m
[32m[I 2025-02-07 14:38:33,497][0m Trial 38 finished with value: 0.2306072782967391 and parameters: {'observation_period_num': 185, 'train_rates': 0.6503452754641827, 'learning_rate': 0.0007401125196125052, 'batch_size': 89, 'step_size': 15, 'gamma': 0.9467786394296653}. Best is trial 34 with value: 0.03321373550330892.[0m
[32m[I 2025-02-07 14:39:00,534][0m Trial 39 finished with value: 0.21022146940231323 and parameters: {'observation_period_num': 91, 'train_rates': 0.9373811843557456, 'learning_rate': 0.00016336563989953937, 'batch_size': 242, 'step_size': 13, 'gamma': 0.8910472919594904}. Best is trial 34 with value: 0.03321373550330892.[0m
[32m[I 2025-02-07 14:39:33,851][0m Trial 40 finished with value: 0.06221318403057915 and parameters: {'observation_period_num': 58, 'train_rates': 0.9057135178275101, 'learning_rate': 0.00026780941836278873, 'batch_size': 179, 'step_size': 11, 'gamma': 0.8419681644492983}. Best is trial 34 with value: 0.03321373550330892.[0m
[32m[I 2025-02-07 14:40:05,321][0m Trial 41 finished with value: 0.039450444345701635 and parameters: {'observation_period_num': 17, 'train_rates': 0.8840446555729131, 'learning_rate': 0.00046398263056845156, 'batch_size': 198, 'step_size': 9, 'gamma': 0.7678807446257738}. Best is trial 34 with value: 0.03321373550330892.[0m
[32m[I 2025-02-07 14:40:33,378][0m Trial 42 finished with value: 0.04260652210059668 and parameters: {'observation_period_num': 15, 'train_rates': 0.7995881481872735, 'learning_rate': 0.0007432501705451727, 'batch_size': 201, 'step_size': 9, 'gamma': 0.768758952720178}. Best is trial 34 with value: 0.03321373550330892.[0m
[32m[I 2025-02-07 14:41:05,907][0m Trial 43 finished with value: 0.04860632488360772 and parameters: {'observation_period_num': 34, 'train_rates': 0.8687573684267678, 'learning_rate': 0.00047687887571046787, 'batch_size': 186, 'step_size': 8, 'gamma': 0.803691504405976}. Best is trial 34 with value: 0.03321373550330892.[0m
[32m[I 2025-02-07 14:41:50,496][0m Trial 44 finished with value: 0.03246959867568973 and parameters: {'observation_period_num': 15, 'train_rates': 0.8933234162990925, 'learning_rate': 0.0009718997979862895, 'batch_size': 135, 'step_size': 12, 'gamma': 0.794642440577683}. Best is trial 44 with value: 0.03246959867568973.[0m
[32m[I 2025-02-07 14:42:37,414][0m Trial 45 finished with value: 0.03035106137394905 and parameters: {'observation_period_num': 6, 'train_rates': 0.9899276660031593, 'learning_rate': 0.0009548827227772849, 'batch_size': 138, 'step_size': 6, 'gamma': 0.7849860255296318}. Best is trial 45 with value: 0.03035106137394905.[0m
[32m[I 2025-02-07 14:43:22,664][0m Trial 46 finished with value: 0.10815192759037018 and parameters: {'observation_period_num': 111, 'train_rates': 0.988163782954219, 'learning_rate': 0.0009508556920956049, 'batch_size': 141, 'step_size': 4, 'gamma': 0.7856919710524974}. Best is trial 45 with value: 0.03035106137394905.[0m
[32m[I 2025-02-07 14:44:10,566][0m Trial 47 finished with value: 0.08073446165392364 and parameters: {'observation_period_num': 7, 'train_rates': 0.9539010929985143, 'learning_rate': 4.176847660440977e-05, 'batch_size': 134, 'step_size': 5, 'gamma': 0.8227117136676999}. Best is trial 45 with value: 0.03035106137394905.[0m
[32m[I 2025-02-07 14:45:06,434][0m Trial 48 finished with value: 0.09724049028998988 and parameters: {'observation_period_num': 80, 'train_rates': 0.9293543888343454, 'learning_rate': 0.0009100826493669484, 'batch_size': 107, 'step_size': 1, 'gamma': 0.9064691572322572}. Best is trial 45 with value: 0.03035106137394905.[0m
[32m[I 2025-02-07 14:45:48,174][0m Trial 49 finished with value: 0.132424995303154 and parameters: {'observation_period_num': 31, 'train_rates': 0.9711134952940333, 'learning_rate': 2.7474636865265865e-05, 'batch_size': 159, 'step_size': 6, 'gamma': 0.923151946439055}. Best is trial 45 with value: 0.03035106137394905.[0m
最適ハイパーパラメータが見つかりました
最適なハイパーパラメータが best_hyperparameters_GOOG_iTransformer_noMSTL.json に保存されました
Epoch 1/300, Loss: 0.4503 | 0.1579
Epoch 2/300, Loss: 0.1711 | 0.1138
Epoch 3/300, Loss: 0.1564 | 0.1369
Epoch 4/300, Loss: 0.1662 | 0.0952
Epoch 5/300, Loss: 0.1726 | 0.1076
Epoch 6/300, Loss: 0.1687 | 0.1131
Epoch 7/300, Loss: 0.1474 | 0.2326
Epoch 8/300, Loss: 0.1796 | 0.4385
Epoch 9/300, Loss: 0.1474 | 0.1807
Epoch 10/300, Loss: 0.1296 | 0.0855
Epoch 11/300, Loss: 0.1444 | 0.0611
Epoch 12/300, Loss: 0.1202 | 0.0614
Epoch 13/300, Loss: 0.1121 | 0.0695
Epoch 14/300, Loss: 0.1152 | 0.0479
Epoch 15/300, Loss: 0.1041 | 0.0396
Epoch 16/300, Loss: 0.1003 | 0.0458
Epoch 17/300, Loss: 0.1050 | 0.0497
Epoch 18/300, Loss: 0.1137 | 0.0525
Epoch 19/300, Loss: 0.1025 | 0.0357
Epoch 20/300, Loss: 0.0911 | 0.0333
Epoch 21/300, Loss: 0.0927 | 0.0330
Epoch 22/300, Loss: 0.0864 | 0.0358
Epoch 23/300, Loss: 0.0848 | 0.0336
Epoch 24/300, Loss: 0.0837 | 0.0323
Epoch 25/300, Loss: 0.0837 | 0.0312
Epoch 26/300, Loss: 0.0855 | 0.0316
Epoch 27/300, Loss: 0.0860 | 0.0341
Epoch 28/300, Loss: 0.0813 | 0.0336
Epoch 29/300, Loss: 0.0803 | 0.0322
Epoch 30/300, Loss: 0.0798 | 0.0316
Epoch 31/300, Loss: 0.0792 | 0.0315
Epoch 32/300, Loss: 0.0787 | 0.0311
Epoch 33/300, Loss: 0.0783 | 0.0307
Epoch 34/300, Loss: 0.0779 | 0.0306
Epoch 35/300, Loss: 0.0776 | 0.0304
Epoch 36/300, Loss: 0.0773 | 0.0302
Epoch 37/300, Loss: 0.0770 | 0.0301
Epoch 38/300, Loss: 0.0768 | 0.0300
Epoch 39/300, Loss: 0.0765 | 0.0299
Epoch 40/300, Loss: 0.0763 | 0.0299
Epoch 41/300, Loss: 0.0762 | 0.0298
Epoch 42/300, Loss: 0.0760 | 0.0298
Epoch 43/300, Loss: 0.0758 | 0.0298
Epoch 44/300, Loss: 0.0757 | 0.0297
Epoch 45/300, Loss: 0.0756 | 0.0297
Epoch 46/300, Loss: 0.0754 | 0.0297
Epoch 47/300, Loss: 0.0753 | 0.0297
Epoch 48/300, Loss: 0.0752 | 0.0297
Epoch 49/300, Loss: 0.0751 | 0.0296
Epoch 50/300, Loss: 0.0750 | 0.0296
Epoch 51/300, Loss: 0.0749 | 0.0296
Epoch 52/300, Loss: 0.0749 | 0.0296
Epoch 53/300, Loss: 0.0748 | 0.0296
Epoch 54/300, Loss: 0.0747 | 0.0296
Epoch 55/300, Loss: 0.0747 | 0.0296
Epoch 56/300, Loss: 0.0746 | 0.0296
Epoch 57/300, Loss: 0.0746 | 0.0296
Epoch 58/300, Loss: 0.0745 | 0.0296
Epoch 59/300, Loss: 0.0745 | 0.0296
Epoch 60/300, Loss: 0.0744 | 0.0296
Epoch 61/300, Loss: 0.0744 | 0.0296
Epoch 62/300, Loss: 0.0743 | 0.0296
Epoch 63/300, Loss: 0.0743 | 0.0296
Epoch 64/300, Loss: 0.0743 | 0.0296
Epoch 65/300, Loss: 0.0742 | 0.0296
Epoch 66/300, Loss: 0.0742 | 0.0296
Epoch 67/300, Loss: 0.0742 | 0.0296
Epoch 68/300, Loss: 0.0742 | 0.0296
Epoch 69/300, Loss: 0.0741 | 0.0296
Epoch 70/300, Loss: 0.0741 | 0.0296
Epoch 71/300, Loss: 0.0741 | 0.0296
Epoch 72/300, Loss: 0.0741 | 0.0296
Epoch 73/300, Loss: 0.0741 | 0.0296
Epoch 74/300, Loss: 0.0741 | 0.0296
Epoch 75/300, Loss: 0.0740 | 0.0296
Epoch 76/300, Loss: 0.0740 | 0.0296
Epoch 77/300, Loss: 0.0740 | 0.0296
Epoch 78/300, Loss: 0.0740 | 0.0296
Epoch 79/300, Loss: 0.0740 | 0.0296
Epoch 80/300, Loss: 0.0740 | 0.0296
Epoch 81/300, Loss: 0.0740 | 0.0296
Epoch 82/300, Loss: 0.0740 | 0.0296
Epoch 83/300, Loss: 0.0740 | 0.0296
Epoch 84/300, Loss: 0.0739 | 0.0296
Epoch 85/300, Loss: 0.0739 | 0.0296
Epoch 86/300, Loss: 0.0739 | 0.0296
Epoch 87/300, Loss: 0.0739 | 0.0296
Epoch 88/300, Loss: 0.0739 | 0.0296
Epoch 89/300, Loss: 0.0739 | 0.0296
Epoch 90/300, Loss: 0.0739 | 0.0296
Epoch 91/300, Loss: 0.0739 | 0.0296
Epoch 92/300, Loss: 0.0739 | 0.0296
Epoch 93/300, Loss: 0.0739 | 0.0296
Epoch 94/300, Loss: 0.0739 | 0.0296
Epoch 95/300, Loss: 0.0739 | 0.0296
Epoch 96/300, Loss: 0.0739 | 0.0296
Epoch 97/300, Loss: 0.0739 | 0.0296
Epoch 98/300, Loss: 0.0739 | 0.0296
Epoch 99/300, Loss: 0.0739 | 0.0296
Epoch 100/300, Loss: 0.0739 | 0.0296
Epoch 101/300, Loss: 0.0739 | 0.0296
Epoch 102/300, Loss: 0.0739 | 0.0296
Epoch 103/300, Loss: 0.0739 | 0.0296
Epoch 104/300, Loss: 0.0739 | 0.0296
Epoch 105/300, Loss: 0.0739 | 0.0296
Epoch 106/300, Loss: 0.0739 | 0.0296
Epoch 107/300, Loss: 0.0739 | 0.0296
Epoch 108/300, Loss: 0.0739 | 0.0296
Epoch 109/300, Loss: 0.0739 | 0.0296
Epoch 110/300, Loss: 0.0739 | 0.0296
Epoch 111/300, Loss: 0.0739 | 0.0296
Epoch 112/300, Loss: 0.0739 | 0.0296
Epoch 113/300, Loss: 0.0739 | 0.0296
Epoch 114/300, Loss: 0.0739 | 0.0296
Epoch 115/300, Loss: 0.0739 | 0.0296
Epoch 116/300, Loss: 0.0739 | 0.0296
Epoch 117/300, Loss: 0.0739 | 0.0296
Epoch 118/300, Loss: 0.0739 | 0.0296
Epoch 119/300, Loss: 0.0739 | 0.0296
Epoch 120/300, Loss: 0.0739 | 0.0296
Epoch 121/300, Loss: 0.0739 | 0.0296
Epoch 122/300, Loss: 0.0739 | 0.0296
Epoch 123/300, Loss: 0.0739 | 0.0296
Epoch 124/300, Loss: 0.0739 | 0.0296
Epoch 125/300, Loss: 0.0739 | 0.0296
Epoch 126/300, Loss: 0.0739 | 0.0296
Epoch 127/300, Loss: 0.0739 | 0.0296
Epoch 128/300, Loss: 0.0739 | 0.0296
Epoch 129/300, Loss: 0.0739 | 0.0296
Epoch 130/300, Loss: 0.0739 | 0.0296
Epoch 131/300, Loss: 0.0739 | 0.0296
Epoch 132/300, Loss: 0.0739 | 0.0296
Epoch 133/300, Loss: 0.0739 | 0.0296
Epoch 134/300, Loss: 0.0739 | 0.0296
Epoch 135/300, Loss: 0.0739 | 0.0296
Epoch 136/300, Loss: 0.0739 | 0.0296
Epoch 137/300, Loss: 0.0739 | 0.0296
Epoch 138/300, Loss: 0.0739 | 0.0296
Epoch 139/300, Loss: 0.0739 | 0.0296
Epoch 140/300, Loss: 0.0739 | 0.0296
Epoch 141/300, Loss: 0.0739 | 0.0296
Epoch 142/300, Loss: 0.0739 | 0.0296
Epoch 143/300, Loss: 0.0739 | 0.0296
Epoch 144/300, Loss: 0.0739 | 0.0296
Epoch 145/300, Loss: 0.0739 | 0.0296
Epoch 146/300, Loss: 0.0739 | 0.0296
Epoch 147/300, Loss: 0.0739 | 0.0296
Epoch 148/300, Loss: 0.0739 | 0.0296
Epoch 149/300, Loss: 0.0739 | 0.0296
Epoch 150/300, Loss: 0.0739 | 0.0296
Epoch 151/300, Loss: 0.0739 | 0.0296
Epoch 152/300, Loss: 0.0739 | 0.0296
Epoch 153/300, Loss: 0.0739 | 0.0296
Epoch 154/300, Loss: 0.0739 | 0.0296
Epoch 155/300, Loss: 0.0739 | 0.0296
Epoch 156/300, Loss: 0.0739 | 0.0296
Epoch 157/300, Loss: 0.0739 | 0.0296
Early stopping
Runtime (seconds): 74.13425779342651
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)
MSE: 119.81690157414414
RMSE: 10.946090698242188
MAE: 10.946090698242188
R-squared: nan
[204.25609]
