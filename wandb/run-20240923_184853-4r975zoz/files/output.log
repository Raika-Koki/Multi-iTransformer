[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
/home/raikakoki/.local/lib/python3.10/site-packages/torch/backends/cuda/__init__.py:342: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
Dataset created successfully.
Epoch 1/100, Training Loss: 1.0597, Validation Loss: 0.4259
Epoch 2/100, Training Loss: 0.3390, Validation Loss: 0.2477
Epoch 3/100, Training Loss: 0.1915, Validation Loss: 0.1924
Epoch 4/100, Training Loss: 0.1555, Validation Loss: 0.1467
Epoch 5/100, Training Loss: 0.1159, Validation Loss: 0.1659
Epoch 6/100, Training Loss: 0.0972, Validation Loss: 0.1133
Epoch 7/100, Training Loss: 0.0795, Validation Loss: 0.1041
Epoch 8/100, Training Loss: 0.0667, Validation Loss: 0.0847
Epoch 9/100, Training Loss: 0.0568, Validation Loss: 0.0753
Epoch 10/100, Training Loss: 0.0511, Validation Loss: 0.0617
Epoch 11/100, Training Loss: 0.0452, Validation Loss: 0.0536
Epoch 12/100, Training Loss: 0.0408, Validation Loss: 0.0503
Epoch 13/100, Training Loss: 0.0375, Validation Loss: 0.0460
Epoch 14/100, Training Loss: 0.0344, Validation Loss: 0.0425
Epoch 15/100, Training Loss: 0.0323, Validation Loss: 0.0418
Epoch 16/100, Training Loss: 0.0302, Validation Loss: 0.0391
Epoch 17/100, Training Loss: 0.0278, Validation Loss: 0.0346
Epoch 18/100, Training Loss: 0.0267, Validation Loss: 0.0333
Epoch 19/100, Training Loss: 0.0275, Validation Loss: 0.0316
Epoch 20/100, Training Loss: 0.0273, Validation Loss: 0.0281
Epoch 21/100, Training Loss: 0.0245, Validation Loss: 0.0287
Epoch 22/100, Training Loss: 0.0227, Validation Loss: 0.0290
Epoch 23/100, Training Loss: 0.0233, Validation Loss: 0.0279
Epoch 24/100, Training Loss: 0.0219, Validation Loss: 0.0317
Epoch 25/100, Training Loss: 0.0218, Validation Loss: 0.0293
Epoch 26/100, Training Loss: 0.0219, Validation Loss: 0.0224
Epoch 27/100, Training Loss: 0.0201, Validation Loss: 0.0282
Epoch 28/100, Training Loss: 0.0207, Validation Loss: 0.0268
Epoch 29/100, Training Loss: 0.0191, Validation Loss: 0.0237
Epoch 30/100, Training Loss: 0.0193, Validation Loss: 0.0339
Epoch 31/100, Training Loss: 0.0216, Validation Loss: 0.0198
Epoch 32/100, Training Loss: 0.0233, Validation Loss: 0.0400
Epoch 33/100, Training Loss: 0.0233, Validation Loss: 0.0223
Epoch 34/100, Training Loss: 0.0252, Validation Loss: 0.0650
Epoch 35/100, Training Loss: 0.0369, Validation Loss: 0.0401
Epoch 36/100, Training Loss: 0.0455, Validation Loss: 0.1640
Epoch 37/100, Training Loss: 0.0789, Validation Loss: 0.0734
Epoch 38/100, Training Loss: 0.0615, Validation Loss: 0.1153
Epoch 39/100, Training Loss: 0.0541, Validation Loss: 0.0349
Epoch 40/100, Training Loss: 0.0349, Validation Loss: 0.0415
Epoch 41/100, Training Loss: 0.0292, Validation Loss: 0.0374
Epoch 42/100, Training Loss: 0.0325, Validation Loss: 0.0306
Epoch 43/100, Training Loss: 0.0335, Validation Loss: 0.0413
Epoch 44/100, Training Loss: 0.0449, Validation Loss: 0.0289
Epoch 45/100, Training Loss: 0.0424, Validation Loss: 0.0378
Epoch 46/100, Training Loss: 0.0484, Validation Loss: 0.0273
Epoch 47/100, Training Loss: 0.0334, Validation Loss: 0.0319
Epoch 48/100, Training Loss: 0.0286, Validation Loss: 0.0282
Epoch 49/100, Training Loss: 0.0220, Validation Loss: 0.0292
Epoch 50/100, Training Loss: 0.0203, Validation Loss: 0.0279
Epoch 51/100, Training Loss: 0.0189, Validation Loss: 0.0276
Epoch 52/100, Training Loss: 0.0185, Validation Loss: 0.0269
Epoch 53/100, Training Loss: 0.0181, Validation Loss: 0.0265
Epoch 54/100, Training Loss: 0.0179, Validation Loss: 0.0260
Epoch 55/100, Training Loss: 0.0177, Validation Loss: 0.0256
Epoch 56/100, Training Loss: 0.0175, Validation Loss: 0.0253
Epoch 57/100, Training Loss: 0.0174, Validation Loss: 0.0250
Epoch 58/100, Training Loss: 0.0173, Validation Loss: 0.0247
Epoch 59/100, Training Loss: 0.0172, Validation Loss: 0.0245
Epoch 60/100, Training Loss: 0.0171, Validation Loss: 0.0243
Epoch 61/100, Training Loss: 0.0170, Validation Loss: 0.0241
Epoch 62/100, Training Loss: 0.0169, Validation Loss: 0.0239
Epoch 63/100, Training Loss: 0.0168, Validation Loss: 0.0238
Epoch 64/100, Training Loss: 0.0168, Validation Loss: 0.0236
Epoch 65/100, Training Loss: 0.0167, Validation Loss: 0.0235
Epoch 66/100, Training Loss: 0.0166, Validation Loss: 0.0234
Epoch 67/100, Training Loss: 0.0166, Validation Loss: 0.0233
Epoch 68/100, Training Loss: 0.0165, Validation Loss: 0.0232
Epoch 69/100, Training Loss: 0.0165, Validation Loss: 0.0231
Epoch 70/100, Training Loss: 0.0164, Validation Loss: 0.0230
Epoch 71/100, Training Loss: 0.0164, Validation Loss: 0.0230
Epoch 72/100, Training Loss: 0.0164, Validation Loss: 0.0229
Epoch 73/100, Training Loss: 0.0163, Validation Loss: 0.0228
Epoch 74/100, Training Loss: 0.0163, Validation Loss: 0.0228
Epoch 75/100, Training Loss: 0.0163, Validation Loss: 0.0227
Epoch 76/100, Training Loss: 0.0162, Validation Loss: 0.0226
Epoch 77/100, Training Loss: 0.0162, Validation Loss: 0.0226
Epoch 78/100, Training Loss: 0.0162, Validation Loss: 0.0225
Epoch 79/100, Training Loss: 0.0162, Validation Loss: 0.0225
Epoch 80/100, Training Loss: 0.0161, Validation Loss: 0.0225
Epoch 81/100, Training Loss: 0.0161, Validation Loss: 0.0224
Epoch 82/100, Training Loss: 0.0161, Validation Loss: 0.0224
Epoch 83/100, Training Loss: 0.0161, Validation Loss: 0.0223
Epoch 84/100, Training Loss: 0.0161, Validation Loss: 0.0223
Epoch 85/100, Training Loss: 0.0160, Validation Loss: 0.0223
Epoch 86/100, Training Loss: 0.0160, Validation Loss: 0.0222
Epoch 87/100, Training Loss: 0.0160, Validation Loss: 0.0222
Epoch 88/100, Training Loss: 0.0160, Validation Loss: 0.0222
Epoch 89/100, Training Loss: 0.0160, Validation Loss: 0.0222
Epoch 90/100, Training Loss: 0.0160, Validation Loss: 0.0221
Epoch 91/100, Training Loss: 0.0159, Validation Loss: 0.0221
Epoch 92/100, Training Loss: 0.0159, Validation Loss: 0.0221
Epoch 93/100, Training Loss: 0.0159, Validation Loss: 0.0221
Epoch 94/100, Training Loss: 0.0159, Validation Loss: 0.0220
Epoch 95/100, Training Loss: 0.0159, Validation Loss: 0.0220
Epoch 96/100, Training Loss: 0.0159, Validation Loss: 0.0220
Epoch 97/100, Training Loss: 0.0159, Validation Loss: 0.0220
Epoch 98/100, Training Loss: 0.0159, Validation Loss: 0.0220
Epoch 99/100, Training Loss: 0.0158, Validation Loss: 0.0220
Epoch 100/100, Training Loss: 0.0158, Validation Loss: 0.0219
/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/demo.py:108: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  predicted_stock_price = predicted_stock_price.cpu().numpy().flatten() * std_list[-1] + mean_list[-1]
Traceback (most recent call last):
  File "/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/demo.py", line 121, in <module>
    plt.plot(predicted_dates, add_predicted_stock_price, linestyle='dotted', color='red', label='Predicted Price')
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/pyplot.py", line 3708, in plot
    return gca().plot(
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/axes/_axes.py", line 1779, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/axes/_base.py", line 296, in __call__
    yield from self._plot_args(
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/axes/_base.py", line 486, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "
ValueError: x and y must have same first dimension, but have shapes (10,) and (14,)
Traceback (most recent call last):
  File "/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/demo.py", line 121, in <module>
    plt.plot(predicted_dates, add_predicted_stock_price, linestyle='dotted', color='red', label='Predicted Price')
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/pyplot.py", line 3708, in plot
    return gca().plot(
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/axes/_axes.py", line 1779, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/axes/_base.py", line 296, in __call__
    yield from self._plot_args(
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/axes/_base.py", line 486, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "
ValueError: x and y must have same first dimension, but have shapes (10,) and (14,)