[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[32m[I 2024-10-25 02:58:10,598][0m A new study created in memory with name: no-name-d6a8f1ae-39dd-42d7-8f84-111db7fcf0fb[0m
/mnt/c/Users/RAIKA KOKI/B4Á†îÁ©∂/Multi_iTransformer/optunademo.py:82: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.
  learning_rate = trial.suggest_loguniform('learning_rate', 1e-6, 1e-3)
/home/raikakoki/.local/lib/python3.10/site-packages/torch/backends/cuda/__init__.py:342: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
[32m[I 2024-10-25 02:58:11,426][0m Trial 0 finished with value: 1.8422637581825256 and parameters: {'learning_rate': 1.1462611717303586e-06, 'batch_size': 101, 'step_size': 1, 'gamma': 0.957323006228622, 'depth': 4, 'dim': 33}. Best is trial 0 with value: 1.8422637581825256.[0m
[32m[I 2024-10-25 02:58:13,806][0m Trial 1 finished with value: 0.3351671792639112 and parameters: {'learning_rate': 9.113281386689964e-05, 'batch_size': 69, 'step_size': 8, 'gamma': 0.9184619903991849, 'depth': 3, 'dim': 224}. Best is trial 1 with value: 0.3351671792639112.[0m
[32m[I 2024-10-25 02:58:15,648][0m Trial 2 finished with value: 2.7962324110049646 and parameters: {'learning_rate': 1.4398352872503435e-06, 'batch_size': 248, 'step_size': 13, 'gamma': 0.8981089535834446, 'depth': 4, 'dim': 154}. Best is trial 1 with value: 0.3351671792639112.[0m
[32m[I 2024-10-25 02:58:17,109][0m Trial 3 finished with value: 8.312373858053707 and parameters: {'learning_rate': 5.732321084908306e-06, 'batch_size': 70, 'step_size': 7, 'gamma': 0.8491841654666556, 'depth': 2, 'dim': 175}. Best is trial 1 with value: 0.3351671792639112.[0m
[32m[I 2024-10-25 02:58:17,742][0m Trial 4 finished with value: 1.3770232125393396 and parameters: {'learning_rate': 5.557652048777085e-05, 'batch_size': 231, 'step_size': 12, 'gamma': 0.8076788082801558, 'depth': 3, 'dim': 46}. Best is trial 1 with value: 0.3351671792639112.[0m
[32m[I 2024-10-25 02:58:18,652][0m Trial 5 finished with value: 5.9903005072214075 and parameters: {'learning_rate': 2.155527577637764e-06, 'batch_size': 144, 'step_size': 11, 'gamma': 0.7698346642506678, 'depth': 6, 'dim': 26}. Best is trial 1 with value: 0.3351671792639112.[0m
[32m[I 2024-10-25 02:58:19,590][0m Trial 6 finished with value: 1.00908040783359 and parameters: {'learning_rate': 0.00019673442383164364, 'batch_size': 109, 'step_size': 14, 'gamma': 0.7775560629689077, 'depth': 6, 'dim': 24}. Best is trial 1 with value: 0.3351671792639112.[0m
[33m[W 2024-10-25 02:58:21,222][0m Trial 7 failed with parameters: {'learning_rate': 3.630195146601304e-05, 'batch_size': 161, 'step_size': 11, 'gamma': 0.8865842804210047, 'depth': 6, 'dim': 138} because of the following error: KeyboardInterrupt().[0m
Traceback (most recent call last):
  File "/home/raikakoki/.local/lib/python3.10/site-packages/optuna/study/_optimize.py", line 196, in _run_trial
    value_or_values = func(trial)
  File "/mnt/c/Users/RAIKA KOKI/B4Á†îÁ©∂/Multi_iTransformer/optunademo.py", line 116, in <lambda>
    study_trend.optimize(lambda trial: objective(trial, "trend"), n_trials=50)
  File "/mnt/c/Users/RAIKA KOKI/B4Á†îÁ©∂/Multi_iTransformer/optunademo.py", line 109, in objective
    model, train_loss, valid_loss = train(
  File "/mnt/c/Users/RAIKA KOKI/B4Á†îÁ©∂/Multi_iTransformer/src/train.py", line 40, in train
    optimizer.step()  # Èáç„Åø„ÅÆÊõ¥Êñ∞
  File "/home/raikakoki/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 75, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/raikakoki/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 391, in wrapper
    out = func(*args, **kwargs)
  File "/home/raikakoki/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/raikakoki/.local/lib/python3.10/site-packages/torch/optim/adamw.py", line 188, in step
    adamw(
  File "/home/raikakoki/.local/lib/python3.10/site-packages/torch/optim/adamw.py", line 340, in adamw
    func(
  File "/home/raikakoki/.local/lib/python3.10/site-packages/torch/optim/adamw.py", line 473, in _single_tensor_adamw
    param.addcdiv_(exp_avg, denom, value=-step_size)
KeyboardInterrupt
[33m[W 2024-10-25 02:58:21,231][0m Trial 7 failed with value None.[0m
Traceback (most recent call last):
  File "/mnt/c/Users/RAIKA KOKI/B4Á†îÁ©∂/Multi_iTransformer/optunademo.py", line 116, in <module>
    study_trend.optimize(lambda trial: objective(trial, "trend"), n_trials=50)
  File "/home/raikakoki/.local/lib/python3.10/site-packages/optuna/study/study.py", line 451, in optimize
    _optimize(
  File "/home/raikakoki/.local/lib/python3.10/site-packages/optuna/study/_optimize.py", line 62, in _optimize
    _optimize_sequential(
  File "/home/raikakoki/.local/lib/python3.10/site-packages/optuna/study/_optimize.py", line 159, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
  File "/home/raikakoki/.local/lib/python3.10/site-packages/optuna/study/_optimize.py", line 247, in _run_trial
    raise func_err
  File "/home/raikakoki/.local/lib/python3.10/site-packages/optuna/study/_optimize.py", line 196, in _run_trial
    value_or_values = func(trial)
  File "/mnt/c/Users/RAIKA KOKI/B4Á†îÁ©∂/Multi_iTransformer/optunademo.py", line 116, in <lambda>
    study_trend.optimize(lambda trial: objective(trial, "trend"), n_trials=50)
  File "/mnt/c/Users/RAIKA KOKI/B4Á†îÁ©∂/Multi_iTransformer/optunademo.py", line 109, in objective
    model, train_loss, valid_loss = train(
  File "/mnt/c/Users/RAIKA KOKI/B4Á†îÁ©∂/Multi_iTransformer/src/train.py", line 40, in train
    optimizer.step()  # Èáç„Åø„ÅÆÊõ¥Êñ∞
  File "/home/raikakoki/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 75, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/raikakoki/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 391, in wrapper
    out = func(*args, **kwargs)
  File "/home/raikakoki/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/raikakoki/.local/lib/python3.10/site-packages/torch/optim/adamw.py", line 188, in step
    adamw(
  File "/home/raikakoki/.local/lib/python3.10/site-packages/torch/optim/adamw.py", line 340, in adamw
    func(
  File "/home/raikakoki/.local/lib/python3.10/site-packages/torch/optim/adamw.py", line 473, in _single_tensor_adamw
    param.addcdiv_(exp_avg, denom, value=-step_size)
KeyboardInterrupt
Traceback (most recent call last):
  File "/mnt/c/Users/RAIKA KOKI/B4Á†îÁ©∂/Multi_iTransformer/optunademo.py", line 116, in <module>
    study_trend.optimize(lambda trial: objective(trial, "trend"), n_trials=50)
  File "/home/raikakoki/.local/lib/python3.10/site-packages/optuna/study/study.py", line 451, in optimize
    _optimize(
  File "/home/raikakoki/.local/lib/python3.10/site-packages/optuna/study/_optimize.py", line 62, in _optimize
    _optimize_sequential(
  File "/home/raikakoki/.local/lib/python3.10/site-packages/optuna/study/_optimize.py", line 159, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
  File "/home/raikakoki/.local/lib/python3.10/site-packages/optuna/study/_optimize.py", line 247, in _run_trial
    raise func_err
  File "/home/raikakoki/.local/lib/python3.10/site-packages/optuna/study/_optimize.py", line 196, in _run_trial
    value_or_values = func(trial)
  File "/mnt/c/Users/RAIKA KOKI/B4Á†îÁ©∂/Multi_iTransformer/optunademo.py", line 116, in <lambda>
    study_trend.optimize(lambda trial: objective(trial, "trend"), n_trials=50)
  File "/mnt/c/Users/RAIKA KOKI/B4Á†îÁ©∂/Multi_iTransformer/optunademo.py", line 109, in objective
    model, train_loss, valid_loss = train(
  File "/mnt/c/Users/RAIKA KOKI/B4Á†îÁ©∂/Multi_iTransformer/src/train.py", line 40, in train
    optimizer.step()  # Èáç„Åø„ÅÆÊõ¥Êñ∞
  File "/home/raikakoki/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py", line 75, in wrapper
    return wrapped(*args, **kwargs)
  File "/home/raikakoki/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 391, in wrapper
    out = func(*args, **kwargs)
  File "/home/raikakoki/.local/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/home/raikakoki/.local/lib/python3.10/site-packages/torch/optim/adamw.py", line 188, in step
    adamw(
  File "/home/raikakoki/.local/lib/python3.10/site-packages/torch/optim/adamw.py", line 340, in adamw
    func(
  File "/home/raikakoki/.local/lib/python3.10/site-packages/torch/optim/adamw.py", line 473, in _single_tensor_adamw
    param.addcdiv_(exp_avg, denom, value=-step_size)
KeyboardInterrupt
