[32m[I 2025-02-06 22:37:57,821][0m A new study created in memory with name: no-name-b9a9d04b-1526-4003-bd6a-fc6d996d3ca3[0m
[32m[I 2025-02-06 22:39:22,199][0m Trial 0 finished with value: 0.3257806869532099 and parameters: {'observation_period_num': 238, 'train_rates': 0.9455312615522169, 'learning_rate': 0.0002250129464594649, 'batch_size': 66, 'step_size': 2, 'gamma': 0.7640681900156279}. Best is trial 0 with value: 0.3257806869532099.[0m
[32m[I 2025-02-06 22:39:45,441][0m Trial 1 finished with value: 0.3438516800044053 and parameters: {'observation_period_num': 233, 'train_rates': 0.6847249274578697, 'learning_rate': 0.0002685928878161741, 'batch_size': 213, 'step_size': 1, 'gamma': 0.9596659192731329}. Best is trial 0 with value: 0.3257806869532099.[0m
[32m[I 2025-02-06 22:40:06,134][0m Trial 2 finished with value: 0.2797139703418857 and parameters: {'observation_period_num': 133, 'train_rates': 0.6848927567458857, 'learning_rate': 0.00040669375548481925, 'batch_size': 245, 'step_size': 10, 'gamma': 0.9191492851050383}. Best is trial 2 with value: 0.2797139703418857.[0m
[32m[I 2025-02-06 22:40:38,912][0m Trial 3 finished with value: 0.5455537184775333 and parameters: {'observation_period_num': 17, 'train_rates': 0.7814797007554369, 'learning_rate': 3.728198520335921e-06, 'batch_size': 170, 'step_size': 10, 'gamma': 0.8150150216017833}. Best is trial 2 with value: 0.2797139703418857.[0m
[32m[I 2025-02-06 22:41:04,856][0m Trial 4 finished with value: 0.7397028911725365 and parameters: {'observation_period_num': 118, 'train_rates': 0.6413979454121858, 'learning_rate': 5.126932987807038e-06, 'batch_size': 202, 'step_size': 12, 'gamma': 0.8748878426090912}. Best is trial 2 with value: 0.2797139703418857.[0m
[32m[I 2025-02-06 22:41:38,269][0m Trial 5 finished with value: 1.11066734790802 and parameters: {'observation_period_num': 40, 'train_rates': 0.9425945102393518, 'learning_rate': 1.5688614792824152e-06, 'batch_size': 187, 'step_size': 14, 'gamma': 0.9289565700023391}. Best is trial 2 with value: 0.2797139703418857.[0m
[32m[I 2025-02-06 22:42:31,105][0m Trial 6 finished with value: 0.13597286973330538 and parameters: {'observation_period_num': 86, 'train_rates': 0.8665122174007707, 'learning_rate': 0.0008826221165947146, 'batch_size': 106, 'step_size': 13, 'gamma': 0.7588391408733925}. Best is trial 6 with value: 0.13597286973330538.[0m
[32m[I 2025-02-06 22:43:08,936][0m Trial 7 finished with value: 0.13227086119792042 and parameters: {'observation_period_num': 149, 'train_rates': 0.8987412688116925, 'learning_rate': 0.0008117298916681103, 'batch_size': 153, 'step_size': 3, 'gamma': 0.8423160408626889}. Best is trial 7 with value: 0.13227086119792042.[0m
[32m[I 2025-02-06 22:43:29,446][0m Trial 8 finished with value: 0.3126017270463236 and parameters: {'observation_period_num': 188, 'train_rates': 0.6832494202285516, 'learning_rate': 0.0004107432730157018, 'batch_size': 240, 'step_size': 12, 'gamma': 0.7746959442846041}. Best is trial 7 with value: 0.13227086119792042.[0m
[32m[I 2025-02-06 22:44:18,257][0m Trial 9 finished with value: 0.8344171659366505 and parameters: {'observation_period_num': 140, 'train_rates': 0.8706060725635334, 'learning_rate': 1.5876817098789884e-06, 'batch_size': 118, 'step_size': 4, 'gamma': 0.9212992642376909}. Best is trial 7 with value: 0.13227086119792042.[0m
[32m[I 2025-02-06 22:46:04,410][0m Trial 10 finished with value: 0.2466212938908363 and parameters: {'observation_period_num': 185, 'train_rates': 0.7763009473402458, 'learning_rate': 2.274455494027172e-05, 'batch_size': 46, 'step_size': 6, 'gamma': 0.8297049055325986}. Best is trial 7 with value: 0.13227086119792042.[0m
[32m[I 2025-02-06 22:46:52,733][0m Trial 11 finished with value: 0.10911614512785887 and parameters: {'observation_period_num': 73, 'train_rates': 0.8668937688457333, 'learning_rate': 0.0009641183304155246, 'batch_size': 116, 'step_size': 7, 'gamma': 0.8190897968157004}. Best is trial 11 with value: 0.10911614512785887.[0m
[32m[I 2025-02-06 22:47:32,427][0m Trial 12 finished with value: 0.10778873469861387 and parameters: {'observation_period_num': 69, 'train_rates': 0.8593600573630711, 'learning_rate': 7.427562913667006e-05, 'batch_size': 147, 'step_size': 6, 'gamma': 0.844970445589091}. Best is trial 12 with value: 0.10778873469861387.[0m
[32m[I 2025-02-06 22:48:32,708][0m Trial 13 finished with value: 0.07072628882696044 and parameters: {'observation_period_num': 67, 'train_rates': 0.8192725200701961, 'learning_rate': 7.72078058469282e-05, 'batch_size': 91, 'step_size': 7, 'gamma': 0.8741608241250997}. Best is trial 13 with value: 0.07072628882696044.[0m
[32m[I 2025-02-06 22:49:40,988][0m Trial 14 finished with value: 0.06724703875916631 and parameters: {'observation_period_num': 62, 'train_rates': 0.8172803452106034, 'learning_rate': 7.808291130275705e-05, 'batch_size': 81, 'step_size': 5, 'gamma': 0.8779212569294494}. Best is trial 14 with value: 0.06724703875916631.[0m
[32m[I 2025-02-06 22:54:30,543][0m Trial 15 finished with value: 0.05476628796293818 and parameters: {'observation_period_num': 33, 'train_rates': 0.8045614120545893, 'learning_rate': 4.6892476317929534e-05, 'batch_size': 18, 'step_size': 9, 'gamma': 0.8919331683222232}. Best is trial 15 with value: 0.05476628796293818.[0m
[32m[I 2025-02-06 22:58:42,358][0m Trial 16 finished with value: 0.15515594050369738 and parameters: {'observation_period_num': 9, 'train_rates': 0.7553062421605686, 'learning_rate': 2.6154322834311998e-05, 'batch_size': 20, 'step_size': 10, 'gamma': 0.8969583927170555}. Best is trial 15 with value: 0.05476628796293818.[0m
[32m[I 2025-02-06 23:02:44,731][0m Trial 17 finished with value: 0.1892689409728008 and parameters: {'observation_period_num': 46, 'train_rates': 0.7311934980102128, 'learning_rate': 6.668826098750274e-05, 'batch_size': 20, 'step_size': 4, 'gamma': 0.9822802958798609}. Best is trial 15 with value: 0.05476628796293818.[0m
[32m[I 2025-02-06 23:04:47,542][0m Trial 18 finished with value: 0.18788626790046692 and parameters: {'observation_period_num': 105, 'train_rates': 0.9898813252869343, 'learning_rate': 1.2692234133344116e-05, 'batch_size': 49, 'step_size': 9, 'gamma': 0.8956871315198524}. Best is trial 15 with value: 0.05476628796293818.[0m
[32m[I 2025-02-06 23:06:03,119][0m Trial 19 finished with value: 0.05688838756450728 and parameters: {'observation_period_num': 37, 'train_rates': 0.818545714401547, 'learning_rate': 0.00011949059491584655, 'batch_size': 72, 'step_size': 5, 'gamma': 0.9475538220022475}. Best is trial 15 with value: 0.05476628796293818.[0m
[32m[I 2025-02-06 23:07:53,260][0m Trial 20 finished with value: 0.16598954073145378 and parameters: {'observation_period_num': 30, 'train_rates': 0.7273803590314448, 'learning_rate': 0.00016771807557228313, 'batch_size': 45, 'step_size': 8, 'gamma': 0.9482797751636969}. Best is trial 15 with value: 0.05476628796293818.[0m
[32m[I 2025-02-06 23:08:53,127][0m Trial 21 finished with value: 0.05686492044154403 and parameters: {'observation_period_num': 48, 'train_rates': 0.8248141143083423, 'learning_rate': 0.00011031983300827485, 'batch_size': 93, 'step_size': 5, 'gamma': 0.9061029442743137}. Best is trial 15 with value: 0.05476628796293818.[0m
[32m[I 2025-02-06 23:10:03,797][0m Trial 22 finished with value: 0.03694288568185256 and parameters: {'observation_period_num': 9, 'train_rates': 0.8143944105325556, 'learning_rate': 0.0001326583889920428, 'batch_size': 77, 'step_size': 5, 'gamma': 0.9850236605248376}. Best is trial 22 with value: 0.03694288568185256.[0m
[32m[I 2025-02-06 23:10:48,557][0m Trial 23 finished with value: 0.06446733738982653 and parameters: {'observation_period_num': 9, 'train_rates': 0.8318020416575945, 'learning_rate': 4.051356425250887e-05, 'batch_size': 128, 'step_size': 8, 'gamma': 0.9867828404248085}. Best is trial 22 with value: 0.03694288568185256.[0m
[32m[I 2025-02-06 23:11:44,249][0m Trial 24 finished with value: 0.4364882220643433 and parameters: {'observation_period_num': 94, 'train_rates': 0.7543266229895854, 'learning_rate': 1.134431333357083e-05, 'batch_size': 95, 'step_size': 4, 'gamma': 0.8971936356113781}. Best is trial 22 with value: 0.03694288568185256.[0m
[32m[I 2025-02-06 23:13:21,822][0m Trial 25 finished with value: 0.06758277398263308 and parameters: {'observation_period_num': 52, 'train_rates': 0.9043203501230548, 'learning_rate': 4.3982131466297985e-05, 'batch_size': 58, 'step_size': 6, 'gamma': 0.9640569641611573}. Best is trial 22 with value: 0.03694288568185256.[0m
[32m[I 2025-02-06 23:16:00,026][0m Trial 26 finished with value: 0.19483925650129094 and parameters: {'observation_period_num': 26, 'train_rates': 0.7847554348664944, 'learning_rate': 0.00012858662167112425, 'batch_size': 33, 'step_size': 2, 'gamma': 0.7897184406696683}. Best is trial 22 with value: 0.03694288568185256.[0m
[32m[I 2025-02-06 23:17:09,729][0m Trial 27 finished with value: 0.07807577956678732 and parameters: {'observation_period_num': 7, 'train_rates': 0.8404238030047343, 'learning_rate': 1.4769085848292917e-05, 'batch_size': 81, 'step_size': 9, 'gamma': 0.8582563342773689}. Best is trial 22 with value: 0.03694288568185256.[0m
[32m[I 2025-02-06 23:19:34,331][0m Trial 28 finished with value: 0.07089682141175636 and parameters: {'observation_period_num': 51, 'train_rates': 0.8015979038765657, 'learning_rate': 0.0004090416678270625, 'batch_size': 36, 'step_size': 7, 'gamma': 0.9311390538519592}. Best is trial 22 with value: 0.03694288568185256.[0m
[32m[I 2025-02-06 23:21:03,854][0m Trial 29 finished with value: 0.04598499933614376 and parameters: {'observation_period_num': 27, 'train_rates': 0.8894402393609985, 'learning_rate': 0.000255517376615027, 'batch_size': 64, 'step_size': 2, 'gamma': 0.9059630104403495}. Best is trial 22 with value: 0.03694288568185256.[0m
[32m[I 2025-02-06 23:22:26,541][0m Trial 30 finished with value: 0.04271717486319257 and parameters: {'observation_period_num': 25, 'train_rates': 0.9100927784622941, 'learning_rate': 0.0002737386499833777, 'batch_size': 70, 'step_size': 1, 'gamma': 0.9734209141179251}. Best is trial 22 with value: 0.03694288568185256.[0m
[32m[I 2025-02-06 23:24:08,141][0m Trial 31 finished with value: 0.04021715917266332 and parameters: {'observation_period_num': 23, 'train_rates': 0.9171177183498098, 'learning_rate': 0.0002422002200278388, 'batch_size': 57, 'step_size': 1, 'gamma': 0.9728255409309228}. Best is trial 22 with value: 0.03694288568185256.[0m
[32m[I 2025-02-06 23:25:44,186][0m Trial 32 finished with value: 0.042460693293536196 and parameters: {'observation_period_num': 22, 'train_rates': 0.9340986859287926, 'learning_rate': 0.00020194786754565135, 'batch_size': 62, 'step_size': 1, 'gamma': 0.973406079450086}. Best is trial 22 with value: 0.03694288568185256.[0m
[32m[I 2025-02-06 23:27:03,885][0m Trial 33 finished with value: 0.041884944811894025 and parameters: {'observation_period_num': 19, 'train_rates': 0.9420861059166987, 'learning_rate': 0.00018586333914201217, 'batch_size': 77, 'step_size': 1, 'gamma': 0.9670529906652499}. Best is trial 22 with value: 0.03694288568185256.[0m
[32m[I 2025-02-06 23:28:42,484][0m Trial 34 finished with value: 0.19929125304990167 and parameters: {'observation_period_num': 240, 'train_rates': 0.9460714059662207, 'learning_rate': 0.0002008635164508872, 'batch_size': 57, 'step_size': 1, 'gamma': 0.9537412470735971}. Best is trial 22 with value: 0.03694288568185256.[0m
[32m[I 2025-02-06 23:29:43,555][0m Trial 35 finished with value: 0.03918039798736572 and parameters: {'observation_period_num': 16, 'train_rates': 0.9892445348884448, 'learning_rate': 0.0003591497416969559, 'batch_size': 106, 'step_size': 3, 'gamma': 0.969841868775367}. Best is trial 22 with value: 0.03694288568185256.[0m
[32m[I 2025-02-06 23:30:45,735][0m Trial 36 finished with value: 0.08655321598052979 and parameters: {'observation_period_num': 5, 'train_rates': 0.9851292287735229, 'learning_rate': 0.0005234123555522996, 'batch_size': 105, 'step_size': 3, 'gamma': 0.9896984689545864}. Best is trial 22 with value: 0.03694288568185256.[0m
[32m[I 2025-02-06 23:31:30,953][0m Trial 37 finished with value: 0.10763143748044968 and parameters: {'observation_period_num': 81, 'train_rates': 0.9570455775982359, 'learning_rate': 0.0005799677922756844, 'batch_size': 137, 'step_size': 3, 'gamma': 0.9360637499530504}. Best is trial 22 with value: 0.03694288568185256.[0m
[32m[I 2025-02-06 23:32:48,729][0m Trial 38 finished with value: 0.03517460137746244 and parameters: {'observation_period_num': 18, 'train_rates': 0.9644895622967915, 'learning_rate': 0.00029150193285386447, 'batch_size': 79, 'step_size': 2, 'gamma': 0.968300700994338}. Best is trial 38 with value: 0.03517460137746244.[0m
[32m[I 2025-02-06 23:33:44,617][0m Trial 39 finished with value: 0.1598997414112091 and parameters: {'observation_period_num': 167, 'train_rates': 0.9689259967741415, 'learning_rate': 0.00029290558749414685, 'batch_size': 107, 'step_size': 2, 'gamma': 0.9417485287856974}. Best is trial 38 with value: 0.03517460137746244.[0m
[32m[I 2025-02-06 23:34:20,389][0m Trial 40 finished with value: 0.15766277216968283 and parameters: {'observation_period_num': 113, 'train_rates': 0.9216323007726587, 'learning_rate': 0.0006752166771798094, 'batch_size': 173, 'step_size': 3, 'gamma': 0.9615634420146546}. Best is trial 38 with value: 0.03517460137746244.[0m
[32m[I 2025-02-06 23:35:36,438][0m Trial 41 finished with value: 0.03169651625677943 and parameters: {'observation_period_num': 16, 'train_rates': 0.9665720707889969, 'learning_rate': 0.00033872167338547466, 'batch_size': 81, 'step_size': 1, 'gamma': 0.9716217040382498}. Best is trial 41 with value: 0.03169651625677943.[0m
[32m[I 2025-02-06 23:36:42,239][0m Trial 42 finished with value: 0.24365490104289764 and parameters: {'observation_period_num': 212, 'train_rates': 0.9665920219012644, 'learning_rate': 0.0004033164178107386, 'batch_size': 88, 'step_size': 2, 'gamma': 0.9747108668333506}. Best is trial 41 with value: 0.03169651625677943.[0m
[32m[I 2025-02-06 23:37:27,190][0m Trial 43 finished with value: 0.13004183672279526 and parameters: {'observation_period_num': 16, 'train_rates': 0.6070289251181529, 'learning_rate': 0.0003723624963347688, 'batch_size': 103, 'step_size': 2, 'gamma': 0.9801035823861212}. Best is trial 41 with value: 0.03169651625677943.[0m
[32m[I 2025-02-06 23:38:20,542][0m Trial 44 finished with value: 0.06271854043006897 and parameters: {'observation_period_num': 38, 'train_rates': 0.9718988088070715, 'learning_rate': 0.0001289272925402977, 'batch_size': 119, 'step_size': 3, 'gamma': 0.9567204605163333}. Best is trial 41 with value: 0.03169651625677943.[0m
[32m[I 2025-02-06 23:39:33,153][0m Trial 45 finished with value: 0.04021574179171969 and parameters: {'observation_period_num': 17, 'train_rates': 0.927008842067864, 'learning_rate': 0.0005674710298414935, 'batch_size': 82, 'step_size': 4, 'gamma': 0.9656774810924189}. Best is trial 41 with value: 0.03169651625677943.[0m
[32m[I 2025-02-06 23:40:19,707][0m Trial 46 finished with value: 0.07041759023795256 and parameters: {'observation_period_num': 52, 'train_rates': 0.8869178947047343, 'learning_rate': 0.000595593679265746, 'batch_size': 126, 'step_size': 4, 'gamma': 0.9217642206196599}. Best is trial 41 with value: 0.03169651625677943.[0m
[32m[I 2025-02-06 23:41:28,908][0m Trial 47 finished with value: 0.14129837635737746 and parameters: {'observation_period_num': 59, 'train_rates': 0.9315853520673366, 'learning_rate': 0.0009558638938662662, 'batch_size': 86, 'step_size': 15, 'gamma': 0.9897620351749894}. Best is trial 41 with value: 0.03169651625677943.[0m
[32m[I 2025-02-06 23:42:31,996][0m Trial 48 finished with value: 0.05214373584812051 and parameters: {'observation_period_num': 37, 'train_rates': 0.9490765174950241, 'learning_rate': 0.0003206971476328478, 'batch_size': 98, 'step_size': 5, 'gamma': 0.9424337767845821}. Best is trial 41 with value: 0.03169651625677943.[0m
[32m[I 2025-02-06 23:43:15,246][0m Trial 49 finished with value: 0.040390074253082275 and parameters: {'observation_period_num': 14, 'train_rates': 0.9788317417752712, 'learning_rate': 0.0004965466435539833, 'batch_size': 150, 'step_size': 4, 'gamma': 0.9576678332097237}. Best is trial 41 with value: 0.03169651625677943.[0m
最適ハイパーパラメータが見つかりました
最適なハイパーパラメータが best_hyperparameters_GOOG_iTransformer_noMSTL.json に保存されました
Epoch 1/300, Loss: 0.4815 | 0.2592
Epoch 2/300, Loss: 0.1890 | 0.1862
Epoch 3/300, Loss: 0.1562 | 0.1581
Epoch 4/300, Loss: 0.1397 | 0.1522
Epoch 5/300, Loss: 0.1429 | 0.1514
Epoch 6/300, Loss: 0.1676 | 0.1318
Epoch 7/300, Loss: 0.2070 | 0.1620
Epoch 8/300, Loss: 0.1849 | 0.2929
Epoch 9/300, Loss: 0.1960 | 0.5665
Epoch 10/300, Loss: 0.1430 | 0.2173
Epoch 11/300, Loss: 0.1185 | 0.1826
Epoch 12/300, Loss: 0.1133 | 0.1488
Epoch 13/300, Loss: 0.1161 | 0.1325
Epoch 14/300, Loss: 0.1133 | 0.1174
Epoch 15/300, Loss: 0.1084 | 0.0984
Epoch 16/300, Loss: 0.1057 | 0.0876
Epoch 17/300, Loss: 0.1033 | 0.0848
Epoch 18/300, Loss: 0.1018 | 0.0859
Epoch 19/300, Loss: 0.0982 | 0.0832
Epoch 20/300, Loss: 0.0932 | 0.0782
Epoch 21/300, Loss: 0.0924 | 0.0737
Epoch 22/300, Loss: 0.0957 | 0.0698
Epoch 23/300, Loss: 0.0985 | 0.0678
Epoch 24/300, Loss: 0.0960 | 0.0660
Epoch 25/300, Loss: 0.0915 | 0.0651
Epoch 26/300, Loss: 0.0886 | 0.0636
Epoch 27/300, Loss: 0.0872 | 0.0618
Epoch 28/300, Loss: 0.0870 | 0.0605
Epoch 29/300, Loss: 0.0868 | 0.0590
Epoch 30/300, Loss: 0.0849 | 0.0573
Epoch 31/300, Loss: 0.0830 | 0.0566
Epoch 32/300, Loss: 0.0824 | 0.0565
Epoch 33/300, Loss: 0.0818 | 0.0560
Epoch 34/300, Loss: 0.0810 | 0.0553
Epoch 35/300, Loss: 0.0803 | 0.0546
Epoch 36/300, Loss: 0.0794 | 0.0539
Epoch 37/300, Loss: 0.0786 | 0.0533
Epoch 38/300, Loss: 0.0778 | 0.0528
Epoch 39/300, Loss: 0.0772 | 0.0526
Epoch 40/300, Loss: 0.0769 | 0.0528
Epoch 41/300, Loss: 0.0766 | 0.0527
Epoch 42/300, Loss: 0.0762 | 0.0518
Epoch 43/300, Loss: 0.0758 | 0.0510
Epoch 44/300, Loss: 0.0755 | 0.0505
Epoch 45/300, Loss: 0.0751 | 0.0502
Epoch 46/300, Loss: 0.0748 | 0.0499
Epoch 47/300, Loss: 0.0746 | 0.0498
Epoch 48/300, Loss: 0.0744 | 0.0496
Epoch 49/300, Loss: 0.0741 | 0.0493
Epoch 50/300, Loss: 0.0739 | 0.0490
Epoch 51/300, Loss: 0.0736 | 0.0486
Epoch 52/300, Loss: 0.0733 | 0.0483
Epoch 53/300, Loss: 0.0731 | 0.0481
Epoch 54/300, Loss: 0.0729 | 0.0478
Epoch 55/300, Loss: 0.0728 | 0.0475
Epoch 56/300, Loss: 0.0727 | 0.0473
Epoch 57/300, Loss: 0.0728 | 0.0471
Epoch 58/300, Loss: 0.0730 | 0.0470
Epoch 59/300, Loss: 0.0731 | 0.0468
Epoch 60/300, Loss: 0.0732 | 0.0467
Epoch 61/300, Loss: 0.0730 | 0.0465
Epoch 62/300, Loss: 0.0726 | 0.0463
Epoch 63/300, Loss: 0.0722 | 0.0463
Epoch 64/300, Loss: 0.0720 | 0.0462
Epoch 65/300, Loss: 0.0718 | 0.0462
Epoch 66/300, Loss: 0.0717 | 0.0461
Epoch 67/300, Loss: 0.0716 | 0.0461
Epoch 68/300, Loss: 0.0715 | 0.0460
Epoch 69/300, Loss: 0.0715 | 0.0460
Epoch 70/300, Loss: 0.0714 | 0.0459
Epoch 71/300, Loss: 0.0713 | 0.0458
Epoch 72/300, Loss: 0.0713 | 0.0458
Epoch 73/300, Loss: 0.0712 | 0.0457
Epoch 74/300, Loss: 0.0712 | 0.0457
Epoch 75/300, Loss: 0.0712 | 0.0456
Epoch 76/300, Loss: 0.0711 | 0.0456
Epoch 77/300, Loss: 0.0711 | 0.0455
Epoch 78/300, Loss: 0.0710 | 0.0455
Epoch 79/300, Loss: 0.0710 | 0.0454
Epoch 80/300, Loss: 0.0710 | 0.0454
Epoch 81/300, Loss: 0.0709 | 0.0454
Epoch 82/300, Loss: 0.0709 | 0.0453
Epoch 83/300, Loss: 0.0709 | 0.0453
Epoch 84/300, Loss: 0.0709 | 0.0453
Epoch 85/300, Loss: 0.0708 | 0.0452
Epoch 86/300, Loss: 0.0708 | 0.0452
Epoch 87/300, Loss: 0.0708 | 0.0452
Epoch 88/300, Loss: 0.0708 | 0.0451
Epoch 89/300, Loss: 0.0707 | 0.0451
Epoch 90/300, Loss: 0.0707 | 0.0451
Epoch 91/300, Loss: 0.0707 | 0.0451
Epoch 92/300, Loss: 0.0707 | 0.0451
Epoch 93/300, Loss: 0.0707 | 0.0450
Epoch 94/300, Loss: 0.0707 | 0.0450
Epoch 95/300, Loss: 0.0706 | 0.0450
Epoch 96/300, Loss: 0.0706 | 0.0450
Epoch 97/300, Loss: 0.0706 | 0.0450
Epoch 98/300, Loss: 0.0706 | 0.0450
Epoch 99/300, Loss: 0.0706 | 0.0449
Epoch 100/300, Loss: 0.0706 | 0.0449
Epoch 101/300, Loss: 0.0706 | 0.0449
Epoch 102/300, Loss: 0.0706 | 0.0449
Epoch 103/300, Loss: 0.0705 | 0.0449
Epoch 104/300, Loss: 0.0705 | 0.0449
Epoch 105/300, Loss: 0.0705 | 0.0449
Epoch 106/300, Loss: 0.0705 | 0.0449
Epoch 107/300, Loss: 0.0705 | 0.0448
Epoch 108/300, Loss: 0.0705 | 0.0448
Epoch 109/300, Loss: 0.0705 | 0.0448
Epoch 110/300, Loss: 0.0705 | 0.0448
Epoch 111/300, Loss: 0.0705 | 0.0448
Epoch 112/300, Loss: 0.0705 | 0.0448
Epoch 113/300, Loss: 0.0705 | 0.0448
Epoch 114/300, Loss: 0.0705 | 0.0448
Epoch 115/300, Loss: 0.0705 | 0.0448
Epoch 116/300, Loss: 0.0705 | 0.0448
Epoch 117/300, Loss: 0.0705 | 0.0448
Epoch 118/300, Loss: 0.0704 | 0.0448
Epoch 119/300, Loss: 0.0704 | 0.0448
Epoch 120/300, Loss: 0.0704 | 0.0448
Epoch 121/300, Loss: 0.0704 | 0.0448
Epoch 122/300, Loss: 0.0704 | 0.0447
Epoch 123/300, Loss: 0.0704 | 0.0447
Epoch 124/300, Loss: 0.0704 | 0.0447
Epoch 125/300, Loss: 0.0704 | 0.0447
Epoch 126/300, Loss: 0.0704 | 0.0447
Epoch 127/300, Loss: 0.0704 | 0.0447
Epoch 128/300, Loss: 0.0704 | 0.0447
Epoch 129/300, Loss: 0.0704 | 0.0447
Epoch 130/300, Loss: 0.0704 | 0.0447
Epoch 131/300, Loss: 0.0704 | 0.0447
Epoch 132/300, Loss: 0.0704 | 0.0447
Epoch 133/300, Loss: 0.0704 | 0.0447
Epoch 134/300, Loss: 0.0704 | 0.0447
Epoch 135/300, Loss: 0.0704 | 0.0447
Epoch 136/300, Loss: 0.0704 | 0.0447
Epoch 137/300, Loss: 0.0704 | 0.0447
Epoch 138/300, Loss: 0.0704 | 0.0447
Epoch 139/300, Loss: 0.0704 | 0.0447
Epoch 140/300, Loss: 0.0704 | 0.0447
Epoch 141/300, Loss: 0.0704 | 0.0447
Epoch 142/300, Loss: 0.0704 | 0.0447
Epoch 143/300, Loss: 0.0704 | 0.0447
Epoch 144/300, Loss: 0.0704 | 0.0447
Epoch 145/300, Loss: 0.0704 | 0.0447
Epoch 146/300, Loss: 0.0704 | 0.0447
Epoch 147/300, Loss: 0.0704 | 0.0447
Epoch 148/300, Loss: 0.0704 | 0.0447
Epoch 149/300, Loss: 0.0704 | 0.0447
Epoch 150/300, Loss: 0.0704 | 0.0447
Epoch 151/300, Loss: 0.0704 | 0.0447
Epoch 152/300, Loss: 0.0704 | 0.0447
Epoch 153/300, Loss: 0.0704 | 0.0447
Epoch 154/300, Loss: 0.0704 | 0.0447
Epoch 155/300, Loss: 0.0704 | 0.0447
Epoch 156/300, Loss: 0.0704 | 0.0447
Epoch 157/300, Loss: 0.0704 | 0.0447
Epoch 158/300, Loss: 0.0704 | 0.0447
Epoch 159/300, Loss: 0.0704 | 0.0447
Epoch 160/300, Loss: 0.0704 | 0.0447
Epoch 161/300, Loss: 0.0704 | 0.0447
Epoch 162/300, Loss: 0.0704 | 0.0447
Epoch 163/300, Loss: 0.0704 | 0.0447
Epoch 164/300, Loss: 0.0704 | 0.0447
Epoch 165/300, Loss: 0.0704 | 0.0447
Epoch 166/300, Loss: 0.0704 | 0.0447
Epoch 167/300, Loss: 0.0704 | 0.0447
Epoch 168/300, Loss: 0.0704 | 0.0447
Epoch 169/300, Loss: 0.0704 | 0.0447
Epoch 170/300, Loss: 0.0704 | 0.0447
Epoch 171/300, Loss: 0.0704 | 0.0447
Epoch 172/300, Loss: 0.0704 | 0.0447
Epoch 173/300, Loss: 0.0704 | 0.0447
Epoch 174/300, Loss: 0.0704 | 0.0447
Epoch 175/300, Loss: 0.0704 | 0.0447
Epoch 176/300, Loss: 0.0704 | 0.0447
Epoch 177/300, Loss: 0.0704 | 0.0447
Epoch 178/300, Loss: 0.0704 | 0.0447
Epoch 179/300, Loss: 0.0704 | 0.0447
Epoch 180/300, Loss: 0.0704 | 0.0447
Epoch 181/300, Loss: 0.0704 | 0.0447
Epoch 182/300, Loss: 0.0704 | 0.0447
Epoch 183/300, Loss: 0.0704 | 0.0447
Epoch 184/300, Loss: 0.0704 | 0.0447
Epoch 185/300, Loss: 0.0704 | 0.0447
Epoch 186/300, Loss: 0.0704 | 0.0447
Epoch 187/300, Loss: 0.0704 | 0.0447
Epoch 188/300, Loss: 0.0704 | 0.0447
Epoch 189/300, Loss: 0.0704 | 0.0447
Epoch 190/300, Loss: 0.0704 | 0.0447
Epoch 191/300, Loss: 0.0704 | 0.0447
Epoch 192/300, Loss: 0.0704 | 0.0447
Epoch 193/300, Loss: 0.0704 | 0.0447
Epoch 194/300, Loss: 0.0704 | 0.0447
Epoch 195/300, Loss: 0.0704 | 0.0447
Epoch 196/300, Loss: 0.0704 | 0.0447
Epoch 197/300, Loss: 0.0704 | 0.0447
Epoch 198/300, Loss: 0.0704 | 0.0447
Epoch 199/300, Loss: 0.0704 | 0.0447
Epoch 200/300, Loss: 0.0704 | 0.0447
Epoch 201/300, Loss: 0.0704 | 0.0447
Epoch 202/300, Loss: 0.0704 | 0.0447
Epoch 203/300, Loss: 0.0704 | 0.0447
Epoch 204/300, Loss: 0.0704 | 0.0447
Epoch 205/300, Loss: 0.0704 | 0.0447
Epoch 206/300, Loss: 0.0704 | 0.0447
Epoch 207/300, Loss: 0.0704 | 0.0447
Epoch 208/300, Loss: 0.0704 | 0.0447
Epoch 209/300, Loss: 0.0704 | 0.0447
Epoch 210/300, Loss: 0.0704 | 0.0447
Epoch 211/300, Loss: 0.0704 | 0.0447
Epoch 212/300, Loss: 0.0704 | 0.0447
Epoch 213/300, Loss: 0.0704 | 0.0447
Epoch 214/300, Loss: 0.0704 | 0.0447
Epoch 215/300, Loss: 0.0704 | 0.0447
Epoch 216/300, Loss: 0.0704 | 0.0447
Epoch 217/300, Loss: 0.0704 | 0.0447
Epoch 218/300, Loss: 0.0704 | 0.0447
Epoch 219/300, Loss: 0.0704 | 0.0447
Epoch 220/300, Loss: 0.0704 | 0.0447
Epoch 221/300, Loss: 0.0704 | 0.0447
Epoch 222/300, Loss: 0.0704 | 0.0447
Early stopping
Runtime (seconds): 168.46171593666077
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)
MSE: 3.27493129321374
RMSE: 1.8096771240234375
MAE: 1.8096771240234375
R-squared: nan
[200.83032]
