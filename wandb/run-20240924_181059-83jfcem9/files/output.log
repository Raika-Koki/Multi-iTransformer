[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
[*********************100%%**********************]  1 of 1 completed
/home/raikakoki/.local/lib/python3.10/site-packages/torch/backends/cuda/__init__.py:342: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(
Dataset created successfully.
Epoch 1/100, Training Loss: 0.3739, Validation Loss: 0.3495
Epoch 2/100, Training Loss: 0.1986, Validation Loss: 0.2525
Epoch 3/100, Training Loss: 0.1458, Validation Loss: 0.2279
Epoch 4/100, Training Loss: 0.1178, Validation Loss: 0.1767
Epoch 5/100, Training Loss: 0.0867, Validation Loss: 0.1621
Epoch 6/100, Training Loss: 0.0772, Validation Loss: 0.1036
Epoch 7/100, Training Loss: 0.0614, Validation Loss: 0.1270
Epoch 8/100, Training Loss: 0.0668, Validation Loss: 0.0706
Epoch 9/100, Training Loss: 0.0555, Validation Loss: 0.0888
Epoch 10/100, Training Loss: 0.0578, Validation Loss: 0.0587
Epoch 11/100, Training Loss: 0.0439, Validation Loss: 0.0659
Epoch 12/100, Training Loss: 0.0395, Validation Loss: 0.0500
Epoch 13/100, Training Loss: 0.0432, Validation Loss: 0.0590
Epoch 14/100, Training Loss: 0.0346, Validation Loss: 0.0568
Epoch 15/100, Training Loss: 0.0338, Validation Loss: 0.0392
Epoch 16/100, Training Loss: 0.0296, Validation Loss: 0.0432
Epoch 17/100, Training Loss: 0.0275, Validation Loss: 0.0362
Epoch 18/100, Training Loss: 0.0259, Validation Loss: 0.0369
Epoch 19/100, Training Loss: 0.0236, Validation Loss: 0.0392
Epoch 20/100, Training Loss: 0.0281, Validation Loss: 0.0332
Epoch 21/100, Training Loss: 0.0227, Validation Loss: 0.0327
Epoch 22/100, Training Loss: 0.0226, Validation Loss: 0.0345
Epoch 23/100, Training Loss: 0.0208, Validation Loss: 0.0257
Epoch 24/100, Training Loss: 0.0208, Validation Loss: 0.0400
Epoch 25/100, Training Loss: 0.0244, Validation Loss: 0.0241
Epoch 26/100, Training Loss: 0.0240, Validation Loss: 0.0453
Epoch 27/100, Training Loss: 0.0249, Validation Loss: 0.0238
Epoch 28/100, Training Loss: 0.0260, Validation Loss: 0.0654
Epoch 29/100, Training Loss: 0.0361, Validation Loss: 0.0382
Epoch 30/100, Training Loss: 0.0429, Validation Loss: 0.1326
Epoch 31/100, Training Loss: 0.0588, Validation Loss: 0.0625
Epoch 32/100, Training Loss: 0.0526, Validation Loss: 0.0951
Epoch 33/100, Training Loss: 0.0347, Validation Loss: 0.0363
Epoch 34/100, Training Loss: 0.0269, Validation Loss: 0.0484
Epoch 35/100, Training Loss: 0.0215, Validation Loss: 0.0337
Epoch 36/100, Training Loss: 0.0203, Validation Loss: 0.0369
Epoch 37/100, Training Loss: 0.0195, Validation Loss: 0.0330
Epoch 38/100, Training Loss: 0.0190, Validation Loss: 0.0329
Epoch 39/100, Training Loss: 0.0187, Validation Loss: 0.0317
Epoch 40/100, Training Loss: 0.0184, Validation Loss: 0.0310
Epoch 41/100, Training Loss: 0.0182, Validation Loss: 0.0305
Epoch 42/100, Training Loss: 0.0179, Validation Loss: 0.0299
Epoch 43/100, Training Loss: 0.0177, Validation Loss: 0.0295
Epoch 44/100, Training Loss: 0.0176, Validation Loss: 0.0290
Epoch 45/100, Training Loss: 0.0174, Validation Loss: 0.0287
Epoch 46/100, Training Loss: 0.0172, Validation Loss: 0.0283
Epoch 47/100, Training Loss: 0.0171, Validation Loss: 0.0281
Epoch 48/100, Training Loss: 0.0170, Validation Loss: 0.0278
Epoch 49/100, Training Loss: 0.0169, Validation Loss: 0.0276
Epoch 50/100, Training Loss: 0.0167, Validation Loss: 0.0273
Epoch 51/100, Training Loss: 0.0166, Validation Loss: 0.0271
Epoch 52/100, Training Loss: 0.0165, Validation Loss: 0.0268
Epoch 53/100, Training Loss: 0.0164, Validation Loss: 0.0267
Epoch 54/100, Training Loss: 0.0163, Validation Loss: 0.0264
Epoch 55/100, Training Loss: 0.0163, Validation Loss: 0.0264
Epoch 56/100, Training Loss: 0.0161, Validation Loss: 0.0261
Epoch 57/100, Training Loss: 0.0162, Validation Loss: 0.0261
Epoch 58/100, Training Loss: 0.0160, Validation Loss: 0.0258
Epoch 59/100, Training Loss: 0.0161, Validation Loss: 0.0259
Epoch 60/100, Training Loss: 0.0159, Validation Loss: 0.0255
Epoch 61/100, Training Loss: 0.0160, Validation Loss: 0.0257
Epoch 62/100, Training Loss: 0.0159, Validation Loss: 0.0253
Epoch 63/100, Training Loss: 0.0160, Validation Loss: 0.0255
Epoch 64/100, Training Loss: 0.0158, Validation Loss: 0.0251
Epoch 65/100, Training Loss: 0.0160, Validation Loss: 0.0253
Epoch 66/100, Training Loss: 0.0157, Validation Loss: 0.0249
Epoch 67/100, Training Loss: 0.0158, Validation Loss: 0.0250
Epoch 68/100, Training Loss: 0.0156, Validation Loss: 0.0248
Epoch 69/100, Training Loss: 0.0156, Validation Loss: 0.0248
Epoch 70/100, Training Loss: 0.0154, Validation Loss: 0.0247
Epoch 71/100, Training Loss: 0.0154, Validation Loss: 0.0246
Epoch 72/100, Training Loss: 0.0153, Validation Loss: 0.0245
Epoch 73/100, Training Loss: 0.0153, Validation Loss: 0.0245
Epoch 74/100, Training Loss: 0.0152, Validation Loss: 0.0244
Epoch 75/100, Training Loss: 0.0152, Validation Loss: 0.0244
Epoch 76/100, Training Loss: 0.0152, Validation Loss: 0.0243
Epoch 77/100, Training Loss: 0.0151, Validation Loss: 0.0243
Epoch 78/100, Training Loss: 0.0151, Validation Loss: 0.0242
Epoch 79/100, Training Loss: 0.0151, Validation Loss: 0.0242
Epoch 80/100, Training Loss: 0.0151, Validation Loss: 0.0241
Epoch 81/100, Training Loss: 0.0150, Validation Loss: 0.0241
Epoch 82/100, Training Loss: 0.0150, Validation Loss: 0.0240
Epoch 83/100, Training Loss: 0.0150, Validation Loss: 0.0240
Epoch 84/100, Training Loss: 0.0150, Validation Loss: 0.0240
Epoch 85/100, Training Loss: 0.0150, Validation Loss: 0.0239
Epoch 86/100, Training Loss: 0.0149, Validation Loss: 0.0239
Epoch 87/100, Training Loss: 0.0149, Validation Loss: 0.0238
Epoch 88/100, Training Loss: 0.0149, Validation Loss: 0.0238
Epoch 89/100, Training Loss: 0.0149, Validation Loss: 0.0238
Epoch 90/100, Training Loss: 0.0149, Validation Loss: 0.0238
Epoch 91/100, Training Loss: 0.0149, Validation Loss: 0.0237
Epoch 92/100, Training Loss: 0.0148, Validation Loss: 0.0237
Epoch 93/100, Training Loss: 0.0148, Validation Loss: 0.0237
Epoch 94/100, Training Loss: 0.0148, Validation Loss: 0.0237
Epoch 95/100, Training Loss: 0.0148, Validation Loss: 0.0236
Epoch 96/100, Training Loss: 0.0148, Validation Loss: 0.0236
Epoch 97/100, Training Loss: 0.0148, Validation Loss: 0.0236
Epoch 98/100, Training Loss: 0.0148, Validation Loss: 0.0236
/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/demo.py:108: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
  predicted_stock_price = predicted_stock_price.cpu().numpy().flatten() * std_list[-1] + mean_list[-1]
Traceback (most recent call last):
  File "/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/demo.py", line 126, in <module>
    plt.plot(predicted_dates, add_predicted_stock_price, linestyle='dotted', color='red', label='Predicted Price')
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/pyplot.py", line 3708, in plot
    return gca().plot(
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/axes/_axes.py", line 1779, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/axes/_base.py", line 296, in __call__
    yield from self._plot_args(
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/axes/_base.py", line 486, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "
ValueError: x and y must have same first dimension, but have shapes (10,) and (14,)
Traceback (most recent call last):
  File "/mnt/c/Users/RAIKA KOKI/B4研究/Multi_iTransformer/demo.py", line 126, in <module>
    plt.plot(predicted_dates, add_predicted_stock_price, linestyle='dotted', color='red', label='Predicted Price')
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/pyplot.py", line 3708, in plot
    return gca().plot(
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/axes/_axes.py", line 1779, in plot
    lines = [*self._get_lines(self, *args, data=data, **kwargs)]
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/axes/_base.py", line 296, in __call__
    yield from self._plot_args(
  File "/home/raikakoki/.local/lib/python3.10/site-packages/matplotlib/axes/_base.py", line 486, in _plot_args
    raise ValueError(f"x and y must have same first dimension, but "
ValueError: x and y must have same first dimension, but have shapes (10,) and (14,)
Epoch 99/100, Training Loss: 0.0148, Validation Loss: 0.0235
Epoch 100/100, Training Loss: 0.0148, Validation Loss: 0.0235
['2023-05-17', '2023-05-18', '2023-05-19', '2023-05-22', '2023-05-23', '2023-05-24', '2023-05-25', '2023-05-26', '2023-05-30', '2023-05-31']
[276.35867 303.0958  248.64584 208.01662 316.8801 ]
[171.57913208 173.9239502  174.0332489  173.07940674 170.45640564
 170.73458862 171.87719727 174.30149841 176.1594696  276.3586731
 303.09579468 248.64584351 208.01661682 316.88009644]
[171.57913208 173.9239502  174.0332489  173.07940674 170.45640564
 170.73458862 171.87719727 174.30149841 176.1594696  176.10980225]