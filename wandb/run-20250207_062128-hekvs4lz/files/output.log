[32m[I 2025-02-07 06:21:34,139][0m A new study created in memory with name: no-name-79b97e63-3bfe-4564-bd04-49c4350b0107[0m
[32m[I 2025-02-07 06:26:14,639][0m Trial 0 finished with value: 0.40344645520093864 and parameters: {'observation_period_num': 164, 'train_rates': 0.8353669069618551, 'learning_rate': 1.3977574134658046e-06, 'batch_size': 18, 'step_size': 13, 'gamma': 0.8179485045140085}. Best is trial 0 with value: 0.40344645520093864.[0m
[32m[I 2025-02-07 06:27:20,387][0m Trial 1 finished with value: 0.13731749453137268 and parameters: {'observation_period_num': 6, 'train_rates': 0.8008488142675977, 'learning_rate': 4.471035668886033e-06, 'batch_size': 84, 'step_size': 9, 'gamma': 0.8510284903491657}. Best is trial 1 with value: 0.13731749453137268.[0m
[32m[I 2025-02-07 06:29:02,159][0m Trial 2 finished with value: 0.28316978123681297 and parameters: {'observation_period_num': 207, 'train_rates': 0.6884819127855395, 'learning_rate': 0.0002905631965253853, 'batch_size': 44, 'step_size': 7, 'gamma': 0.8322450438017461}. Best is trial 1 with value: 0.13731749453137268.[0m
[32m[I 2025-02-07 06:29:24,381][0m Trial 3 finished with value: 0.2947280658159219 and parameters: {'observation_period_num': 208, 'train_rates': 0.7196259990868445, 'learning_rate': 0.0007199470741006616, 'batch_size': 250, 'step_size': 6, 'gamma': 0.9022416831180204}. Best is trial 1 with value: 0.13731749453137268.[0m
[32m[I 2025-02-07 06:30:46,659][0m Trial 4 finished with value: 1.7616151156220792 and parameters: {'observation_period_num': 115, 'train_rates': 0.7822305388848685, 'learning_rate': 1.9873832584780915e-06, 'batch_size': 61, 'step_size': 2, 'gamma': 0.7836746619822696}. Best is trial 1 with value: 0.13731749453137268.[0m
[32m[I 2025-02-07 06:31:24,849][0m Trial 5 finished with value: 0.26683644654292477 and parameters: {'observation_period_num': 135, 'train_rates': 0.7838952253945131, 'learning_rate': 1.1478213313304147e-05, 'batch_size': 146, 'step_size': 13, 'gamma': 0.9495733440470427}. Best is trial 1 with value: 0.13731749453137268.[0m
Early stopping at epoch 50
[32m[I 2025-02-07 06:31:38,007][0m Trial 6 finished with value: 0.7285190099579175 and parameters: {'observation_period_num': 224, 'train_rates': 0.8095181312776036, 'learning_rate': 2.6347213597745892e-05, 'batch_size': 239, 'step_size': 1, 'gamma': 0.7941976538695099}. Best is trial 1 with value: 0.13731749453137268.[0m
[32m[I 2025-02-07 06:32:01,308][0m Trial 7 finished with value: 0.4120764668075202 and parameters: {'observation_period_num': 245, 'train_rates': 0.6535622375051697, 'learning_rate': 3.7872841283639716e-05, 'batch_size': 224, 'step_size': 6, 'gamma': 0.8838474701631265}. Best is trial 1 with value: 0.13731749453137268.[0m
[32m[I 2025-02-07 06:32:34,439][0m Trial 8 finished with value: 0.19645300934858181 and parameters: {'observation_period_num': 17, 'train_rates': 0.7722411893515688, 'learning_rate': 2.8083489072851738e-05, 'batch_size': 166, 'step_size': 14, 'gamma': 0.9764963934408959}. Best is trial 1 with value: 0.13731749453137268.[0m
[32m[I 2025-02-07 06:33:02,466][0m Trial 9 finished with value: 0.8521179033391936 and parameters: {'observation_period_num': 216, 'train_rates': 0.6225897690306109, 'learning_rate': 2.919140279201008e-06, 'batch_size': 162, 'step_size': 7, 'gamma': 0.8311684615990899}. Best is trial 1 with value: 0.13731749453137268.[0m
[32m[I 2025-02-07 06:34:07,637][0m Trial 10 finished with value: 0.10506026146901866 and parameters: {'observation_period_num': 8, 'train_rates': 0.9212763156971397, 'learning_rate': 5.497795580431757e-06, 'batch_size': 93, 'step_size': 10, 'gamma': 0.9185552333239634}. Best is trial 10 with value: 0.10506026146901866.[0m
[32m[I 2025-02-07 06:35:17,386][0m Trial 11 finished with value: 0.14423930644989014 and parameters: {'observation_period_num': 14, 'train_rates': 0.9741274469315551, 'learning_rate': 6.790607274476334e-06, 'batch_size': 89, 'step_size': 10, 'gamma': 0.9199090729292836}. Best is trial 10 with value: 0.10506026146901866.[0m
[32m[I 2025-02-07 06:36:15,755][0m Trial 12 finished with value: 0.31599894870621287 and parameters: {'observation_period_num': 56, 'train_rates': 0.9126362326592955, 'learning_rate': 5.9749137289442e-06, 'batch_size': 103, 'step_size': 10, 'gamma': 0.8561139140083522}. Best is trial 10 with value: 0.10506026146901866.[0m
[32m[I 2025-02-07 06:37:08,556][0m Trial 13 finished with value: 0.06858164182131234 and parameters: {'observation_period_num': 62, 'train_rates': 0.9012487708609688, 'learning_rate': 8.720999746326247e-05, 'batch_size': 112, 'step_size': 10, 'gamma': 0.9327442699862392}. Best is trial 13 with value: 0.06858164182131234.[0m
[32m[I 2025-02-07 06:37:59,634][0m Trial 14 finished with value: 0.11824570993582408 and parameters: {'observation_period_num': 66, 'train_rates': 0.8928020381482301, 'learning_rate': 0.00011359461419739968, 'batch_size': 119, 'step_size': 11, 'gamma': 0.9391726427405435}. Best is trial 13 with value: 0.06858164182131234.[0m
[32m[I 2025-02-07 06:38:32,604][0m Trial 15 finished with value: 0.14238832890987396 and parameters: {'observation_period_num': 60, 'train_rates': 0.9797331035357242, 'learning_rate': 8.771539994945406e-05, 'batch_size': 200, 'step_size': 4, 'gamma': 0.9828006268238095}. Best is trial 13 with value: 0.06858164182131234.[0m
[32m[I 2025-02-07 06:39:20,896][0m Trial 16 finished with value: 0.3293451451592975 and parameters: {'observation_period_num': 85, 'train_rates': 0.8982504448281412, 'learning_rate': 1.435168289977714e-05, 'batch_size': 123, 'step_size': 12, 'gamma': 0.7526028981854929}. Best is trial 13 with value: 0.06858164182131234.[0m
[32m[I 2025-02-07 06:40:58,279][0m Trial 17 finished with value: 0.06506931164767593 and parameters: {'observation_period_num': 40, 'train_rates': 0.9351798276698744, 'learning_rate': 9.451353964846854e-05, 'batch_size': 61, 'step_size': 15, 'gamma': 0.8901399022652994}. Best is trial 17 with value: 0.06506931164767593.[0m
[32m[I 2025-02-07 06:42:45,270][0m Trial 18 finished with value: 0.4113739750089025 and parameters: {'observation_period_num': 101, 'train_rates': 0.9418153472119131, 'learning_rate': 0.00012874070744113244, 'batch_size': 54, 'step_size': 15, 'gamma': 0.8851682028939221}. Best is trial 17 with value: 0.06506931164767593.[0m
[32m[I 2025-02-07 06:47:20,062][0m Trial 19 finished with value: 0.10517363257838873 and parameters: {'observation_period_num': 36, 'train_rates': 0.8675300959669502, 'learning_rate': 0.00023250558089653856, 'batch_size': 20, 'step_size': 15, 'gamma': 0.9432805190029008}. Best is trial 17 with value: 0.06506931164767593.[0m
[32m[I 2025-02-07 06:48:38,816][0m Trial 20 finished with value: 0.19420645740425702 and parameters: {'observation_period_num': 146, 'train_rates': 0.8558372742657654, 'learning_rate': 0.00087943928101855, 'batch_size': 69, 'step_size': 4, 'gamma': 0.9605123176772988}. Best is trial 17 with value: 0.06506931164767593.[0m
[32m[I 2025-02-07 06:49:36,604][0m Trial 21 finished with value: 0.06279446330407391 and parameters: {'observation_period_num': 35, 'train_rates': 0.9382569627865014, 'learning_rate': 5.5630779765990724e-05, 'batch_size': 106, 'step_size': 9, 'gamma': 0.9150613191239296}. Best is trial 21 with value: 0.06279446330407391.[0m
[32m[I 2025-02-07 06:50:24,005][0m Trial 22 finished with value: 0.08189892243236711 and parameters: {'observation_period_num': 40, 'train_rates': 0.9506742500208141, 'learning_rate': 5.832135795568869e-05, 'batch_size': 132, 'step_size': 8, 'gamma': 0.9032750569776008}. Best is trial 21 with value: 0.06279446330407391.[0m
[32m[I 2025-02-07 06:51:21,974][0m Trial 23 finished with value: 0.13817085775752996 and parameters: {'observation_period_num': 77, 'train_rates': 0.9491174246089661, 'learning_rate': 0.00031077275777377354, 'batch_size': 106, 'step_size': 12, 'gamma': 0.9155472056027821}. Best is trial 21 with value: 0.06279446330407391.[0m
[32m[I 2025-02-07 06:52:37,507][0m Trial 24 finished with value: 0.05320723424783818 and parameters: {'observation_period_num': 39, 'train_rates': 0.8672035591179357, 'learning_rate': 6.018183173867089e-05, 'batch_size': 74, 'step_size': 9, 'gamma': 0.8699213180727311}. Best is trial 24 with value: 0.05320723424783818.[0m
[32m[I 2025-02-07 06:55:11,770][0m Trial 25 finished with value: 0.05417838862538338 and parameters: {'observation_period_num': 36, 'train_rates': 0.8736082929793603, 'learning_rate': 4.6690190022184255e-05, 'batch_size': 36, 'step_size': 4, 'gamma': 0.8744050416235785}. Best is trial 24 with value: 0.05320723424783818.[0m
[32m[I 2025-02-07 06:57:21,852][0m Trial 26 finished with value: 0.16833326161066267 and parameters: {'observation_period_num': 90, 'train_rates': 0.8709987936484007, 'learning_rate': 1.9875101660547492e-05, 'batch_size': 42, 'step_size': 4, 'gamma': 0.865608492120861}. Best is trial 24 with value: 0.05320723424783818.[0m
[32m[I 2025-02-07 06:58:33,789][0m Trial 27 finished with value: 0.062099921151332046 and parameters: {'observation_period_num': 32, 'train_rates': 0.8336681293314298, 'learning_rate': 4.909373321705315e-05, 'batch_size': 77, 'step_size': 8, 'gamma': 0.8703887889377573}. Best is trial 24 with value: 0.05320723424783818.[0m
[32m[I 2025-02-07 07:01:06,325][0m Trial 28 finished with value: 0.1464316061856341 and parameters: {'observation_period_num': 170, 'train_rates': 0.8299617328235741, 'learning_rate': 4.393644870707595e-05, 'batch_size': 34, 'step_size': 3, 'gamma': 0.8424809428785804}. Best is trial 24 with value: 0.05320723424783818.[0m
[32m[I 2025-02-07 07:05:32,815][0m Trial 29 finished with value: 0.05315732664388159 and parameters: {'observation_period_num': 30, 'train_rates': 0.8297266629655685, 'learning_rate': 0.00019164631627960913, 'batch_size': 20, 'step_size': 5, 'gamma': 0.8136709346996951}. Best is trial 29 with value: 0.05315732664388159.[0m
[32m[I 2025-02-07 07:10:15,671][0m Trial 30 finished with value: 0.2627577909804655 and parameters: {'observation_period_num': 110, 'train_rates': 0.748903780278765, 'learning_rate': 0.00016499742400655936, 'batch_size': 17, 'step_size': 5, 'gamma': 0.8076966243593486}. Best is trial 29 with value: 0.05315732664388159.[0m
[32m[I 2025-02-07 07:11:30,775][0m Trial 31 finished with value: 0.07042422732414026 and parameters: {'observation_period_num': 25, 'train_rates': 0.8348049390589332, 'learning_rate': 0.00039284486991669423, 'batch_size': 73, 'step_size': 6, 'gamma': 0.869751734046673}. Best is trial 29 with value: 0.05315732664388159.[0m
[32m[I 2025-02-07 07:14:32,029][0m Trial 32 finished with value: 0.12837160182739957 and parameters: {'observation_period_num': 50, 'train_rates': 0.8240498704280727, 'learning_rate': 0.0002001130827985522, 'batch_size': 29, 'step_size': 7, 'gamma': 0.8173928047659265}. Best is trial 29 with value: 0.05315732664388159.[0m
[32m[I 2025-02-07 07:15:45,640][0m Trial 33 finished with value: 0.04237390911539659 and parameters: {'observation_period_num': 6, 'train_rates': 0.8488108369211393, 'learning_rate': 6.752765110581716e-05, 'batch_size': 76, 'step_size': 8, 'gamma': 0.8438566674671774}. Best is trial 33 with value: 0.04237390911539659.[0m
[32m[I 2025-02-07 07:17:43,715][0m Trial 34 finished with value: 0.36314986811743843 and parameters: {'observation_period_num': 5, 'train_rates': 0.8589438899890001, 'learning_rate': 1.050739834020142e-06, 'batch_size': 47, 'step_size': 5, 'gamma': 0.8358528727873457}. Best is trial 33 with value: 0.04237390911539659.[0m
[32m[I 2025-02-07 07:20:24,164][0m Trial 35 finished with value: 0.03868487734724296 and parameters: {'observation_period_num': 25, 'train_rates': 0.8805812717244359, 'learning_rate': 0.0004549999905918195, 'batch_size': 35, 'step_size': 3, 'gamma': 0.8531448323637164}. Best is trial 35 with value: 0.03868487734724296.[0m
[32m[I 2025-02-07 07:22:02,944][0m Trial 36 finished with value: 0.1674353344183739 and parameters: {'observation_period_num': 21, 'train_rates': 0.7530964279425967, 'learning_rate': 0.0005463625211449433, 'batch_size': 52, 'step_size': 2, 'gamma': 0.8530798411544297}. Best is trial 35 with value: 0.03868487734724296.[0m
[32m[I 2025-02-07 07:25:48,727][0m Trial 37 finished with value: 0.15898707784159444 and parameters: {'observation_period_num': 168, 'train_rates': 0.8003669433495472, 'learning_rate': 0.0004901904182644336, 'batch_size': 22, 'step_size': 2, 'gamma': 0.7936146671268764}. Best is trial 35 with value: 0.03868487734724296.[0m
[32m[I 2025-02-07 07:26:51,481][0m Trial 38 finished with value: 0.06022934526016441 and parameters: {'observation_period_num': 70, 'train_rates': 0.8114714308981427, 'learning_rate': 0.00015468185085047592, 'batch_size': 85, 'step_size': 9, 'gamma': 0.817429402660516}. Best is trial 35 with value: 0.03868487734724296.[0m
[32m[I 2025-02-07 07:28:05,343][0m Trial 39 finished with value: 0.16935496543200665 and parameters: {'observation_period_num': 47, 'train_rates': 0.7259453075798695, 'learning_rate': 0.0002803390752153111, 'batch_size': 67, 'step_size': 7, 'gamma': 0.7672308702023368}. Best is trial 35 with value: 0.03868487734724296.[0m
Early stopping at epoch 86
[32m[I 2025-02-07 07:30:01,928][0m Trial 40 finished with value: 0.0803145477983439 and parameters: {'observation_period_num': 5, 'train_rates': 0.8573347327654248, 'learning_rate': 7.107563059433416e-05, 'batch_size': 42, 'step_size': 1, 'gamma': 0.8308922246876873}. Best is trial 35 with value: 0.03868487734724296.[0m
[32m[I 2025-02-07 07:32:42,470][0m Trial 41 finished with value: 0.07005372680523382 and parameters: {'observation_period_num': 22, 'train_rates': 0.8753702892475953, 'learning_rate': 3.2501934400819095e-05, 'batch_size': 35, 'step_size': 3, 'gamma': 0.8465302428412275}. Best is trial 35 with value: 0.03868487734724296.[0m
[32m[I 2025-02-07 07:34:23,038][0m Trial 42 finished with value: 0.08808291018698257 and parameters: {'observation_period_num': 23, 'train_rates': 0.8839799229923874, 'learning_rate': 2.00531707579093e-05, 'batch_size': 57, 'step_size': 5, 'gamma': 0.862533748792974}. Best is trial 35 with value: 0.03868487734724296.[0m
[32m[I 2025-02-07 07:37:15,694][0m Trial 43 finished with value: 0.05833456113206859 and parameters: {'observation_period_num': 48, 'train_rates': 0.8404883812136426, 'learning_rate': 6.930002883020303e-05, 'batch_size': 31, 'step_size': 3, 'gamma': 0.875893994469397}. Best is trial 35 with value: 0.03868487734724296.[0m
[32m[I 2025-02-07 07:42:18,541][0m Trial 44 finished with value: 0.1660097293251401 and parameters: {'observation_period_num': 15, 'train_rates': 0.7786287540944336, 'learning_rate': 0.0005984616321698821, 'batch_size': 16, 'step_size': 6, 'gamma': 0.8963997497179772}. Best is trial 35 with value: 0.03868487734724296.[0m
[32m[I 2025-02-07 07:42:57,308][0m Trial 45 finished with value: 0.1465137934488524 and parameters: {'observation_period_num': 188, 'train_rates': 0.9139024790122656, 'learning_rate': 0.00036525311156206135, 'batch_size': 148, 'step_size': 8, 'gamma': 0.8008715009385132}. Best is trial 35 with value: 0.03868487734724296.[0m
[32m[I 2025-02-07 07:43:52,232][0m Trial 46 finished with value: 0.11148132061936114 and parameters: {'observation_period_num': 130, 'train_rates': 0.8131308454944122, 'learning_rate': 0.0009711533533211605, 'batch_size': 94, 'step_size': 2, 'gamma': 0.824772732074126}. Best is trial 35 with value: 0.03868487734724296.[0m
[32m[I 2025-02-07 07:45:56,970][0m Trial 47 finished with value: 0.09161282581554954 and parameters: {'observation_period_num': 28, 'train_rates': 0.8466456614805338, 'learning_rate': 9.620118045655659e-06, 'batch_size': 43, 'step_size': 7, 'gamma': 0.8430784697157102}. Best is trial 35 with value: 0.03868487734724296.[0m
[32m[I 2025-02-07 07:47:05,384][0m Trial 48 finished with value: 0.12327457305169508 and parameters: {'observation_period_num': 51, 'train_rates': 0.8792637317131959, 'learning_rate': 2.3906352949440997e-05, 'batch_size': 79, 'step_size': 6, 'gamma': 0.8567977373703215}. Best is trial 35 with value: 0.03868487734724296.[0m
[32m[I 2025-02-07 07:47:33,630][0m Trial 49 finished with value: 0.11299688213261831 and parameters: {'observation_period_num': 79, 'train_rates': 0.7887684200102709, 'learning_rate': 0.00012195153359468136, 'batch_size': 203, 'step_size': 9, 'gamma': 0.8786385190253121}. Best is trial 35 with value: 0.03868487734724296.[0m
ÊúÄÈÅ©„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åó„Åü
ÊúÄÈÅ©„Å™„Éè„Ç§„Éë„Éº„Éë„É©„É°„Éº„Çø„Åå best_hyperparameters_GOOG_iTransformer_noMSTL.json „Å´‰øùÂ≠ò„Åï„Çå„Åæ„Åó„Åü
Epoch 1/300, Loss: 0.2990 | 0.2052
Epoch 2/300, Loss: 0.1372 | 0.1528
Epoch 3/300, Loss: 0.1132 | 0.0926
Epoch 4/300, Loss: 0.1034 | 0.0758
Epoch 5/300, Loss: 0.0988 | 0.0676
Epoch 6/300, Loss: 0.0975 | 0.0642
Epoch 7/300, Loss: 0.0929 | 0.0661
Epoch 8/300, Loss: 0.0941 | 0.0608
Epoch 9/300, Loss: 0.0901 | 0.0581
Epoch 10/300, Loss: 0.0889 | 0.0613
Epoch 11/300, Loss: 0.0852 | 0.0572
Epoch 12/300, Loss: 0.0839 | 0.0628
Epoch 13/300, Loss: 0.0805 | 0.0597
Epoch 14/300, Loss: 0.0790 | 0.0572
Epoch 15/300, Loss: 0.0788 | 0.0539
Epoch 16/300, Loss: 0.0782 | 0.0513
Epoch 17/300, Loss: 0.0767 | 0.0507
Epoch 18/300, Loss: 0.0754 | 0.0492
Epoch 19/300, Loss: 0.0748 | 0.0518
Epoch 20/300, Loss: 0.0756 | 0.0562
Epoch 21/300, Loss: 0.0759 | 0.0571
Epoch 22/300, Loss: 0.0752 | 0.0501
Epoch 23/300, Loss: 0.0742 | 0.0478
Epoch 24/300, Loss: 0.0735 | 0.0471
Epoch 25/300, Loss: 0.0730 | 0.0476
Epoch 26/300, Loss: 0.0723 | 0.0478
Epoch 27/300, Loss: 0.0713 | 0.0473
Epoch 28/300, Loss: 0.0705 | 0.0463
Epoch 29/300, Loss: 0.0698 | 0.0467
Epoch 30/300, Loss: 0.0693 | 0.0458
Epoch 31/300, Loss: 0.0689 | 0.0451
Epoch 32/300, Loss: 0.0685 | 0.0452
Epoch 33/300, Loss: 0.0683 | 0.0445
Epoch 34/300, Loss: 0.0680 | 0.0441
Epoch 35/300, Loss: 0.0677 | 0.0441
Epoch 36/300, Loss: 0.0675 | 0.0439
Epoch 37/300, Loss: 0.0673 | 0.0440
Epoch 38/300, Loss: 0.0671 | 0.0442
Epoch 39/300, Loss: 0.0669 | 0.0444
Epoch 40/300, Loss: 0.0668 | 0.0448
Epoch 41/300, Loss: 0.0667 | 0.0448
Epoch 42/300, Loss: 0.0666 | 0.0449
Epoch 43/300, Loss: 0.0665 | 0.0449
Epoch 44/300, Loss: 0.0664 | 0.0447
Epoch 45/300, Loss: 0.0663 | 0.0447
Epoch 46/300, Loss: 0.0662 | 0.0445
Epoch 47/300, Loss: 0.0661 | 0.0444
Epoch 48/300, Loss: 0.0661 | 0.0444
Epoch 49/300, Loss: 0.0660 | 0.0443
Epoch 50/300, Loss: 0.0659 | 0.0442
Epoch 51/300, Loss: 0.0659 | 0.0442
Epoch 52/300, Loss: 0.0658 | 0.0441
Epoch 53/300, Loss: 0.0658 | 0.0441
Epoch 54/300, Loss: 0.0658 | 0.0441
Epoch 55/300, Loss: 0.0657 | 0.0440
Epoch 56/300, Loss: 0.0657 | 0.0440
Epoch 57/300, Loss: 0.0657 | 0.0440
Epoch 58/300, Loss: 0.0657 | 0.0440
Epoch 59/300, Loss: 0.0657 | 0.0439
Epoch 60/300, Loss: 0.0656 | 0.0439
Epoch 61/300, Loss: 0.0656 | 0.0439
Epoch 62/300, Loss: 0.0656 | 0.0439
Epoch 63/300, Loss: 0.0656 | 0.0439
Epoch 64/300, Loss: 0.0656 | 0.0439
Epoch 65/300, Loss: 0.0656 | 0.0439
Epoch 66/300, Loss: 0.0656 | 0.0438
Epoch 67/300, Loss: 0.0655 | 0.0438
Epoch 68/300, Loss: 0.0655 | 0.0438
Epoch 69/300, Loss: 0.0655 | 0.0438
Epoch 70/300, Loss: 0.0655 | 0.0438
Epoch 71/300, Loss: 0.0655 | 0.0438
Epoch 72/300, Loss: 0.0655 | 0.0438
Epoch 73/300, Loss: 0.0655 | 0.0438
Epoch 74/300, Loss: 0.0655 | 0.0438
Epoch 75/300, Loss: 0.0655 | 0.0438
Epoch 76/300, Loss: 0.0655 | 0.0438
Epoch 77/300, Loss: 0.0655 | 0.0438
Epoch 78/300, Loss: 0.0655 | 0.0438
Epoch 79/300, Loss: 0.0655 | 0.0438
Epoch 80/300, Loss: 0.0655 | 0.0438
Epoch 81/300, Loss: 0.0655 | 0.0438
Epoch 82/300, Loss: 0.0655 | 0.0438
Epoch 83/300, Loss: 0.0655 | 0.0438
Epoch 84/300, Loss: 0.0655 | 0.0438
Epoch 85/300, Loss: 0.0655 | 0.0438
Epoch 86/300, Loss: 0.0655 | 0.0438
Epoch 87/300, Loss: 0.0655 | 0.0438
Epoch 88/300, Loss: 0.0655 | 0.0438
Epoch 89/300, Loss: 0.0655 | 0.0438
Epoch 90/300, Loss: 0.0655 | 0.0438
Epoch 91/300, Loss: 0.0655 | 0.0438
Epoch 92/300, Loss: 0.0655 | 0.0438
Epoch 93/300, Loss: 0.0655 | 0.0438
Epoch 94/300, Loss: 0.0655 | 0.0438
Epoch 95/300, Loss: 0.0655 | 0.0438
Epoch 96/300, Loss: 0.0655 | 0.0438
Epoch 97/300, Loss: 0.0655 | 0.0438
Epoch 98/300, Loss: 0.0655 | 0.0438
Epoch 99/300, Loss: 0.0655 | 0.0438
Epoch 100/300, Loss: 0.0655 | 0.0438
Epoch 101/300, Loss: 0.0655 | 0.0438
Epoch 102/300, Loss: 0.0655 | 0.0438
Epoch 103/300, Loss: 0.0655 | 0.0438
Epoch 104/300, Loss: 0.0655 | 0.0438
Epoch 105/300, Loss: 0.0655 | 0.0438
Epoch 106/300, Loss: 0.0655 | 0.0438
Epoch 107/300, Loss: 0.0655 | 0.0438
Epoch 108/300, Loss: 0.0655 | 0.0438
Epoch 109/300, Loss: 0.0655 | 0.0438
Epoch 110/300, Loss: 0.0655 | 0.0438
Epoch 111/300, Loss: 0.0655 | 0.0438
Epoch 112/300, Loss: 0.0655 | 0.0438
Epoch 113/300, Loss: 0.0655 | 0.0438
Epoch 114/300, Loss: 0.0655 | 0.0437
Epoch 115/300, Loss: 0.0655 | 0.0437
Epoch 116/300, Loss: 0.0655 | 0.0437
Epoch 117/300, Loss: 0.0655 | 0.0437
Epoch 118/300, Loss: 0.0655 | 0.0437
Epoch 119/300, Loss: 0.0655 | 0.0437
Epoch 120/300, Loss: 0.0655 | 0.0437
Epoch 121/300, Loss: 0.0655 | 0.0437
Epoch 122/300, Loss: 0.0655 | 0.0437
Epoch 123/300, Loss: 0.0655 | 0.0437
Epoch 124/300, Loss: 0.0655 | 0.0437
Epoch 125/300, Loss: 0.0655 | 0.0437
Epoch 126/300, Loss: 0.0655 | 0.0437
Epoch 127/300, Loss: 0.0655 | 0.0437
Epoch 128/300, Loss: 0.0655 | 0.0437
Epoch 129/300, Loss: 0.0655 | 0.0437
Epoch 130/300, Loss: 0.0655 | 0.0437
Epoch 131/300, Loss: 0.0655 | 0.0437
Epoch 132/300, Loss: 0.0655 | 0.0437
Epoch 133/300, Loss: 0.0655 | 0.0437
Epoch 134/300, Loss: 0.0655 | 0.0437
Epoch 135/300, Loss: 0.0655 | 0.0437
Epoch 136/300, Loss: 0.0655 | 0.0437
Epoch 137/300, Loss: 0.0655 | 0.0437
Epoch 138/300, Loss: 0.0655 | 0.0437
Epoch 139/300, Loss: 0.0655 | 0.0437
Epoch 140/300, Loss: 0.0655 | 0.0437
Epoch 141/300, Loss: 0.0655 | 0.0437
Epoch 142/300, Loss: 0.0655 | 0.0437
Epoch 143/300, Loss: 0.0655 | 0.0437
Epoch 144/300, Loss: 0.0655 | 0.0437
Epoch 145/300, Loss: 0.0655 | 0.0437
Epoch 146/300, Loss: 0.0655 | 0.0437
Epoch 147/300, Loss: 0.0655 | 0.0437
Epoch 148/300, Loss: 0.0655 | 0.0437
Epoch 149/300, Loss: 0.0655 | 0.0437
Epoch 150/300, Loss: 0.0655 | 0.0437
Epoch 151/300, Loss: 0.0655 | 0.0437
Epoch 152/300, Loss: 0.0655 | 0.0437
Epoch 153/300, Loss: 0.0655 | 0.0437
Epoch 154/300, Loss: 0.0655 | 0.0437
Epoch 155/300, Loss: 0.0655 | 0.0437
Epoch 156/300, Loss: 0.0655 | 0.0437
Epoch 157/300, Loss: 0.0655 | 0.0437
Epoch 158/300, Loss: 0.0655 | 0.0437
Epoch 159/300, Loss: 0.0655 | 0.0437
Epoch 160/300, Loss: 0.0655 | 0.0437
Epoch 161/300, Loss: 0.0655 | 0.0437
Epoch 162/300, Loss: 0.0655 | 0.0437
Epoch 163/300, Loss: 0.0655 | 0.0437
Epoch 164/300, Loss: 0.0655 | 0.0437
Epoch 165/300, Loss: 0.0655 | 0.0437
Epoch 166/300, Loss: 0.0655 | 0.0437
Epoch 167/300, Loss: 0.0655 | 0.0437
Epoch 168/300, Loss: 0.0655 | 0.0437
Epoch 169/300, Loss: 0.0655 | 0.0437
Epoch 170/300, Loss: 0.0655 | 0.0437
Epoch 171/300, Loss: 0.0655 | 0.0437
Epoch 172/300, Loss: 0.0655 | 0.0437
Epoch 173/300, Loss: 0.0655 | 0.0437
Epoch 174/300, Loss: 0.0655 | 0.0437
Epoch 175/300, Loss: 0.0655 | 0.0437
Epoch 176/300, Loss: 0.0655 | 0.0437
Epoch 177/300, Loss: 0.0655 | 0.0437
Epoch 178/300, Loss: 0.0655 | 0.0437
Epoch 179/300, Loss: 0.0655 | 0.0437
Epoch 180/300, Loss: 0.0655 | 0.0437
Epoch 181/300, Loss: 0.0655 | 0.0437
Epoch 182/300, Loss: 0.0655 | 0.0437
Epoch 183/300, Loss: 0.0655 | 0.0437
Epoch 184/300, Loss: 0.0655 | 0.0437
Epoch 185/300, Loss: 0.0655 | 0.0437
Epoch 186/300, Loss: 0.0655 | 0.0437
Epoch 187/300, Loss: 0.0655 | 0.0437
Epoch 188/300, Loss: 0.0655 | 0.0437
Epoch 189/300, Loss: 0.0655 | 0.0437
Early stopping
Runtime (seconds): 302.70563650131226
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)
MSE: 7.027158975601196
RMSE: 2.65087890625
MAE: 2.65087890625
R-squared: nan
[195.96088]
