[32m[I 2025-01-07 01:51:07,756][0m A new study created in memory with name: no-name-826ea404-d537-4f5a-a4bf-2e7cfc915813[0m
[32m[I 2025-01-07 01:53:38,030][0m Trial 0 finished with value: 0.2783425748348236 and parameters: {'observation_period_num': 109, 'train_rates': 0.9557353781817355, 'learning_rate': 2.5846094148049172e-05, 'batch_size': 144, 'step_size': 8, 'gamma': 0.9524159481145158}. Best is trial 0 with value: 0.2783425748348236.[0m
[32m[I 2025-01-07 01:57:23,894][0m Trial 1 finished with value: 0.579811480366954 and parameters: {'observation_period_num': 170, 'train_rates': 0.8327528002960096, 'learning_rate': 7.419953102202592e-05, 'batch_size': 149, 'step_size': 2, 'gamma': 0.8366442182279616}. Best is trial 0 with value: 0.2783425748348236.[0m
[32m[I 2025-01-07 02:01:00,062][0m Trial 2 finished with value: 0.28475398294284904 and parameters: {'observation_period_num': 159, 'train_rates': 0.8527459794359135, 'learning_rate': 0.00022085799808955982, 'batch_size': 155, 'step_size': 5, 'gamma': 0.8576401519216983}. Best is trial 0 with value: 0.2783425748348236.[0m
[32m[I 2025-01-07 02:01:56,922][0m Trial 3 finished with value: 0.675132155418396 and parameters: {'observation_period_num': 24, 'train_rates': 0.9764354966596298, 'learning_rate': 0.0007854302464603469, 'batch_size': 78, 'step_size': 14, 'gamma': 0.760090608818847}. Best is trial 0 with value: 0.2783425748348236.[0m
[32m[I 2025-01-07 02:02:22,941][0m Trial 4 finished with value: 0.8355867661549986 and parameters: {'observation_period_num': 16, 'train_rates': 0.6450146683314343, 'learning_rate': 2.1759471291347795e-05, 'batch_size': 146, 'step_size': 5, 'gamma': 0.8820316385422305}. Best is trial 0 with value: 0.2783425748348236.[0m
[32m[I 2025-01-07 02:02:59,055][0m Trial 5 finished with value: 0.7984788514373599 and parameters: {'observation_period_num': 34, 'train_rates': 0.6100968027872122, 'learning_rate': 8.606467448444273e-05, 'batch_size': 202, 'step_size': 6, 'gamma': 0.975900771658174}. Best is trial 0 with value: 0.2783425748348236.[0m
[32m[I 2025-01-07 02:04:34,503][0m Trial 6 finished with value: 1.0368468538316757 and parameters: {'observation_period_num': 92, 'train_rates': 0.6006019520946664, 'learning_rate': 0.0001736500130148817, 'batch_size': 98, 'step_size': 13, 'gamma': 0.8446591412195185}. Best is trial 0 with value: 0.2783425748348236.[0m
Early stopping at epoch 80
[32m[I 2025-01-07 02:08:32,010][0m Trial 7 finished with value: 0.8250842973009332 and parameters: {'observation_period_num': 223, 'train_rates': 0.746900111634853, 'learning_rate': 9.779481902970543e-05, 'batch_size': 153, 'step_size': 1, 'gamma': 0.8464815013057015}. Best is trial 0 with value: 0.2783425748348236.[0m
[32m[I 2025-01-07 02:11:49,540][0m Trial 8 finished with value: 0.15142686116807866 and parameters: {'observation_period_num': 112, 'train_rates': 0.9073142551662026, 'learning_rate': 3.441120576596653e-05, 'batch_size': 21, 'step_size': 15, 'gamma': 0.7536984399776044}. Best is trial 8 with value: 0.15142686116807866.[0m
[32m[I 2025-01-07 02:15:03,961][0m Trial 9 finished with value: 1.6150672763680456 and parameters: {'observation_period_num': 169, 'train_rates': 0.6608394828199864, 'learning_rate': 1.026350187731587e-06, 'batch_size': 249, 'step_size': 7, 'gamma': 0.920163005666752}. Best is trial 8 with value: 0.15142686116807866.[0m
[32m[I 2025-01-07 02:17:04,466][0m Trial 10 finished with value: 0.34919430691837855 and parameters: {'observation_period_num': 72, 'train_rates': 0.8987059517092937, 'learning_rate': 5.361660034278822e-06, 'batch_size': 35, 'step_size': 11, 'gamma': 0.7511194726751428}. Best is trial 8 with value: 0.15142686116807866.[0m
[32m[I 2025-01-07 02:20:47,562][0m Trial 11 finished with value: 0.12889304757118225 and parameters: {'observation_period_num': 116, 'train_rates': 0.9669217643228583, 'learning_rate': 1.6000106765361823e-05, 'batch_size': 19, 'step_size': 10, 'gamma': 0.9832645293534882}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 02:24:24,841][0m Trial 12 finished with value: 0.22003856937256816 and parameters: {'observation_period_num': 129, 'train_rates': 0.9156855308337274, 'learning_rate': 6.720187202801653e-06, 'batch_size': 21, 'step_size': 11, 'gamma': 0.7912131365439687}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 02:25:54,150][0m Trial 13 finished with value: 0.4896408536075475 and parameters: {'observation_period_num': 66, 'train_rates': 0.7694751976806448, 'learning_rate': 1.0727311649855893e-05, 'batch_size': 57, 'step_size': 15, 'gamma': 0.9089299717866866}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 02:31:17,930][0m Trial 14 finished with value: 1.1328349447649393 and parameters: {'observation_period_num': 217, 'train_rates': 0.9131052826708527, 'learning_rate': 1.2074077952142314e-06, 'batch_size': 96, 'step_size': 11, 'gamma': 0.8073590747804259}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 02:35:15,122][0m Trial 15 finished with value: 0.2739491735202104 and parameters: {'observation_period_num': 137, 'train_rates': 0.8604920014961968, 'learning_rate': 3.897370256380573e-06, 'batch_size': 17, 'step_size': 10, 'gamma': 0.9896087524834143}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 02:40:26,812][0m Trial 16 finished with value: 0.1309645880352367 and parameters: {'observation_period_num': 196, 'train_rates': 0.9762246899317374, 'learning_rate': 1.4577322926865666e-05, 'batch_size': 48, 'step_size': 13, 'gamma': 0.9202896286957089}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 02:47:16,804][0m Trial 17 finished with value: 0.4796157479286194 and parameters: {'observation_period_num': 249, 'train_rates': 0.9843773678049039, 'learning_rate': 2.52388849711038e-06, 'batch_size': 59, 'step_size': 9, 'gamma': 0.9422806980669806}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 02:51:47,452][0m Trial 18 finished with value: 0.6455746862553988 and parameters: {'observation_period_num': 212, 'train_rates': 0.7227668555550631, 'learning_rate': 1.300940025142896e-05, 'batch_size': 110, 'step_size': 13, 'gamma': 0.8884066063034612}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 02:56:53,183][0m Trial 19 finished with value: 0.21621783567886604 and parameters: {'observation_period_num': 195, 'train_rates': 0.9453950865105025, 'learning_rate': 1.3873708534484128e-05, 'batch_size': 53, 'step_size': 12, 'gamma': 0.9527814486750671}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 03:00:07,354][0m Trial 20 finished with value: 0.3641646244498186 and parameters: {'observation_period_num': 149, 'train_rates': 0.8167161816556786, 'learning_rate': 4.3448526028237734e-05, 'batch_size': 122, 'step_size': 9, 'gamma': 0.9187972353170439}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 03:02:46,636][0m Trial 21 finished with value: 0.17172937290471735 and parameters: {'observation_period_num': 110, 'train_rates': 0.8919167501932189, 'learning_rate': 3.340708992146747e-05, 'batch_size': 39, 'step_size': 15, 'gamma': 0.8027967638424726}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 03:05:14,850][0m Trial 22 finished with value: 0.20871366686131582 and parameters: {'observation_period_num': 106, 'train_rates': 0.9421155182633792, 'learning_rate': 4.378260076238497e-05, 'batch_size': 80, 'step_size': 13, 'gamma': 0.9705496886904383}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 03:10:10,315][0m Trial 23 finished with value: 0.14696495980024338 and parameters: {'observation_period_num': 187, 'train_rates': 0.9821258117741649, 'learning_rate': 8.984484823787686e-06, 'batch_size': 37, 'step_size': 15, 'gamma': 0.8979605398202285}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 03:14:53,442][0m Trial 24 finished with value: 0.5144784450531006 and parameters: {'observation_period_num': 185, 'train_rates': 0.9860010378041387, 'learning_rate': 2.7861856954910487e-06, 'batch_size': 74, 'step_size': 12, 'gamma': 0.9051211319749716}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 03:21:27,960][0m Trial 25 finished with value: 0.5547524094581604 and parameters: {'observation_period_num': 250, 'train_rates': 0.9509405579434698, 'learning_rate': 6.778922778058726e-06, 'batch_size': 183, 'step_size': 14, 'gamma': 0.934170171009831}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 03:26:19,523][0m Trial 26 finished with value: 0.26335699371027327 and parameters: {'observation_period_num': 193, 'train_rates': 0.8748970863534871, 'learning_rate': 1.4170329077740159e-05, 'batch_size': 40, 'step_size': 12, 'gamma': 0.8865816635459701}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 03:32:16,529][0m Trial 27 finished with value: 0.2483904387881147 and parameters: {'observation_period_num': 230, 'train_rates': 0.9315222181368912, 'learning_rate': 8.872281049816972e-06, 'batch_size': 63, 'step_size': 14, 'gamma': 0.964728130159244}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 03:36:01,135][0m Trial 28 finished with value: 0.13303625583648682 and parameters: {'observation_period_num': 141, 'train_rates': 0.9893474081993362, 'learning_rate': 2.1235395729288374e-05, 'batch_size': 37, 'step_size': 9, 'gamma': 0.8709699210100192}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 03:39:39,127][0m Trial 29 finished with value: 0.306752405812343 and parameters: {'observation_period_num': 147, 'train_rates': 0.9574668673096073, 'learning_rate': 2.1312107403201267e-05, 'batch_size': 91, 'step_size': 8, 'gamma': 0.8712691245563084}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 03:41:46,270][0m Trial 30 finished with value: 0.1813625108836026 and parameters: {'observation_period_num': 81, 'train_rates': 0.9599274315895185, 'learning_rate': 2.2111527030966112e-05, 'batch_size': 41, 'step_size': 9, 'gamma': 0.9310098472413754}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 03:46:35,892][0m Trial 31 finished with value: 0.136665177922095 and parameters: {'observation_period_num': 178, 'train_rates': 0.9889512656644193, 'learning_rate': 1.6984175982763178e-05, 'batch_size': 30, 'step_size': 7, 'gamma': 0.9012270777835552}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 03:51:07,829][0m Trial 32 finished with value: 0.14536281752175298 and parameters: {'observation_period_num': 176, 'train_rates': 0.9272739221529882, 'learning_rate': 5.628517937096938e-05, 'batch_size': 28, 'step_size': 7, 'gamma': 0.8619093182729263}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 03:55:12,167][0m Trial 33 finished with value: 0.19658526529868445 and parameters: {'observation_period_num': 158, 'train_rates': 0.9657720954442298, 'learning_rate': 1.7749567302097892e-05, 'batch_size': 52, 'step_size': 7, 'gamma': 0.8709695902247917}. Best is trial 11 with value: 0.12889304757118225.[0m
[32m[I 2025-01-07 03:58:12,856][0m Trial 34 finished with value: 0.12539245188236237 and parameters: {'observation_period_num': 122, 'train_rates': 0.9882901875890874, 'learning_rate': 0.00013235537128043832, 'batch_size': 70, 'step_size': 5, 'gamma': 0.8301079585222833}. Best is trial 34 with value: 0.12539245188236237.[0m
[32m[I 2025-01-07 03:59:20,019][0m Trial 35 finished with value: 0.8251279843480963 and parameters: {'observation_period_num': 49, 'train_rates': 0.8240906156388057, 'learning_rate': 0.0007129096037013035, 'batch_size': 72, 'step_size': 5, 'gamma': 0.8259514829936275}. Best is trial 34 with value: 0.12539245188236237.[0m
[32m[I 2025-01-07 04:02:07,730][0m Trial 36 finished with value: 0.21444942634932848 and parameters: {'observation_period_num': 122, 'train_rates': 0.8792209658720261, 'learning_rate': 0.00014094669279385245, 'batch_size': 52, 'step_size': 4, 'gamma': 0.8289528287442348}. Best is trial 34 with value: 0.12539245188236237.[0m
[32m[I 2025-01-07 04:04:21,210][0m Trial 37 finished with value: 0.18297545611858368 and parameters: {'observation_period_num': 97, 'train_rates': 0.9634576163527858, 'learning_rate': 0.0002939448372313476, 'batch_size': 133, 'step_size': 10, 'gamma': 0.7745975428632266}. Best is trial 34 with value: 0.12539245188236237.[0m
[32m[I 2025-01-07 04:07:34,435][0m Trial 38 finished with value: 0.23696811908767337 and parameters: {'observation_period_num': 136, 'train_rates': 0.9258310150541404, 'learning_rate': 0.0003685507756028972, 'batch_size': 86, 'step_size': 3, 'gamma': 0.816416728860551}. Best is trial 34 with value: 0.12539245188236237.[0m
[32m[I 2025-01-07 04:10:23,697][0m Trial 39 finished with value: 0.14271967647931513 and parameters: {'observation_period_num': 117, 'train_rates': 0.9727562511100465, 'learning_rate': 6.986122764437099e-05, 'batch_size': 68, 'step_size': 6, 'gamma': 0.8485873144980275}. Best is trial 34 with value: 0.12539245188236237.[0m
[32m[I 2025-01-07 04:12:28,714][0m Trial 40 finished with value: 0.36920958972639506 and parameters: {'observation_period_num': 91, 'train_rates': 0.9374750215633132, 'learning_rate': 2.5021618422051093e-05, 'batch_size': 167, 'step_size': 2, 'gamma': 0.9478043290333177}. Best is trial 34 with value: 0.12539245188236237.[0m
[32m[I 2025-01-07 04:16:57,853][0m Trial 41 finished with value: 0.08900492503994802 and parameters: {'observation_period_num': 167, 'train_rates': 0.978196440874268, 'learning_rate': 0.0001137152922493383, 'batch_size': 28, 'step_size': 4, 'gamma': 0.8594627139945358}. Best is trial 41 with value: 0.08900492503994802.[0m
[32m[I 2025-01-07 04:21:50,572][0m Trial 42 finished with value: 0.12924473941326142 and parameters: {'observation_period_num': 161, 'train_rates': 0.9643907837986312, 'learning_rate': 0.00013048783045005466, 'batch_size': 16, 'step_size': 4, 'gamma': 0.8572192515842247}. Best is trial 41 with value: 0.08900492503994802.[0m
[32m[I 2025-01-07 04:26:09,554][0m Trial 43 finished with value: 0.14317785925471904 and parameters: {'observation_period_num': 159, 'train_rates': 0.9654404762784348, 'learning_rate': 0.00012608037146621945, 'batch_size': 27, 'step_size': 4, 'gamma': 0.8562984743307858}. Best is trial 41 with value: 0.08900492503994802.[0m
[32m[I 2025-01-07 04:31:57,163][0m Trial 44 finished with value: 0.16102776774450353 and parameters: {'observation_period_num': 202, 'train_rates': 0.9450535575682284, 'learning_rate': 0.00022778668126384146, 'batch_size': 17, 'step_size': 3, 'gamma': 0.8356983936796157}. Best is trial 41 with value: 0.08900492503994802.[0m
Early stopping at epoch 83
[32m[I 2025-01-07 04:34:50,453][0m Trial 45 finished with value: 0.5029720601138719 and parameters: {'observation_period_num': 155, 'train_rates': 0.8447045302117087, 'learning_rate': 0.0004523031519160384, 'batch_size': 220, 'step_size': 1, 'gamma': 0.8519992821805122}. Best is trial 41 with value: 0.08900492503994802.[0m
[32m[I 2025-01-07 04:39:04,496][0m Trial 46 finished with value: 0.18127853138786224 and parameters: {'observation_period_num': 172, 'train_rates': 0.8968354182042437, 'learning_rate': 0.00017356094139818994, 'batch_size': 47, 'step_size': 4, 'gamma': 0.8396197500247593}. Best is trial 41 with value: 0.08900492503994802.[0m
[32m[I 2025-01-07 04:42:51,299][0m Trial 47 finished with value: 0.18022803034065132 and parameters: {'observation_period_num': 128, 'train_rates': 0.9167384610197665, 'learning_rate': 0.00010163547688829843, 'batch_size': 18, 'step_size': 5, 'gamma': 0.9833075130182277}. Best is trial 41 with value: 0.08900492503994802.[0m
[32m[I 2025-01-07 04:46:19,984][0m Trial 48 finished with value: 0.6253280388576359 and parameters: {'observation_period_num': 165, 'train_rates': 0.6802522675852086, 'learning_rate': 7.697532372043738e-05, 'batch_size': 28, 'step_size': 6, 'gamma': 0.8823177244622401}. Best is trial 41 with value: 0.08900492503994802.[0m
[32m[I 2025-01-07 04:49:08,947][0m Trial 49 finished with value: 0.48473962859527486 and parameters: {'observation_period_num': 129, 'train_rates': 0.8042485670218984, 'learning_rate': 4.452863830424883e-05, 'batch_size': 105, 'step_size': 3, 'gamma': 0.8164180278706308}. Best is trial 41 with value: 0.08900492503994802.[0m
最適ハイパーパラメータが見つかりました
最適ハイパーパラメータが best_hyperparameters_AAPL_Transformer(nomstl).json に保存されました
Epoch 1/300, Loss: 0.5126 | 0.5479
Epoch 2/300, Loss: 0.4354 | 0.4209
Epoch 3/300, Loss: 0.3475 | 0.3443
Epoch 4/300, Loss: 0.3048 | 0.3551
Epoch 5/300, Loss: 0.3046 | 0.3437
Epoch 6/300, Loss: 0.3183 | 0.3658
Epoch 7/300, Loss: 0.2713 | 0.3349
Epoch 8/300, Loss: 0.2614 | 0.3018
Epoch 9/300, Loss: 0.2424 | 0.2817
Epoch 10/300, Loss: 0.2198 | 0.2629
Epoch 11/300, Loss: 0.1976 | 0.2458
Epoch 12/300, Loss: 0.1916 | 0.2227
Epoch 13/300, Loss: 0.1874 | 0.2218
Epoch 14/300, Loss: 0.1804 | 0.2025
Epoch 15/300, Loss: 0.1743 | 0.2032
Epoch 16/300, Loss: 0.1662 | 0.1936
Epoch 17/300, Loss: 0.1610 | 0.1821
Epoch 18/300, Loss: 0.1560 | 0.1791
Epoch 19/300, Loss: 0.1529 | 0.1755
Epoch 20/300, Loss: 0.1507 | 0.1689
Epoch 21/300, Loss: 0.1480 | 0.1641
Epoch 22/300, Loss: 0.1467 | 0.1623
Epoch 23/300, Loss: 0.1453 | 0.1593
Epoch 24/300, Loss: 0.1431 | 0.1557
Epoch 25/300, Loss: 0.1426 | 0.1525
Epoch 26/300, Loss: 0.1418 | 0.1511
Epoch 27/300, Loss: 0.1404 | 0.1482
Epoch 28/300, Loss: 0.1392 | 0.1464
Epoch 29/300, Loss: 0.1386 | 0.1448
Epoch 30/300, Loss: 0.1377 | 0.1433
Epoch 31/300, Loss: 0.1371 | 0.1407
Epoch 32/300, Loss: 0.1361 | 0.1405
Epoch 33/300, Loss: 0.1353 | 0.1385
Epoch 34/300, Loss: 0.1350 | 0.1373
Epoch 35/300, Loss: 0.1334 | 0.1357
Epoch 36/300, Loss: 0.1334 | 0.1347
Epoch 37/300, Loss: 0.1334 | 0.1334
Epoch 38/300, Loss: 0.1328 | 0.1328
Epoch 39/300, Loss: 0.1323 | 0.1316
Epoch 40/300, Loss: 0.1312 | 0.1312
Epoch 41/300, Loss: 0.1311 | 0.1298
Epoch 42/300, Loss: 0.1307 | 0.1296
Epoch 43/300, Loss: 0.1307 | 0.1286
Epoch 44/300, Loss: 0.1310 | 0.1282
Epoch 45/300, Loss: 0.1304 | 0.1275
Epoch 46/300, Loss: 0.1299 | 0.1268
Epoch 47/300, Loss: 0.1300 | 0.1266
Epoch 48/300, Loss: 0.1287 | 0.1260
Epoch 49/300, Loss: 0.1291 | 0.1256
Epoch 50/300, Loss: 0.1282 | 0.1250
Epoch 51/300, Loss: 0.1288 | 0.1248
Epoch 52/300, Loss: 0.1284 | 0.1244
Epoch 53/300, Loss: 0.1277 | 0.1237
Epoch 54/300, Loss: 0.1284 | 0.1236
Epoch 55/300, Loss: 0.1284 | 0.1233
Epoch 56/300, Loss: 0.1275 | 0.1230
Epoch 57/300, Loss: 0.1282 | 0.1226
Epoch 58/300, Loss: 0.1269 | 0.1223
Epoch 59/300, Loss: 0.1272 | 0.1223
Epoch 60/300, Loss: 0.1274 | 0.1221
Epoch 61/300, Loss: 0.1277 | 0.1217
Epoch 62/300, Loss: 0.1272 | 0.1216
Epoch 63/300, Loss: 0.1268 | 0.1215
Epoch 64/300, Loss: 0.1269 | 0.1213
Epoch 65/300, Loss: 0.1268 | 0.1211
Epoch 66/300, Loss: 0.1263 | 0.1210
Epoch 67/300, Loss: 0.1263 | 0.1209
Epoch 68/300, Loss: 0.1271 | 0.1209
Epoch 69/300, Loss: 0.1267 | 0.1207
Epoch 70/300, Loss: 0.1268 | 0.1205
Epoch 71/300, Loss: 0.1262 | 0.1205
Epoch 72/300, Loss: 0.1264 | 0.1206
Epoch 73/300, Loss: 0.1267 | 0.1205
Epoch 74/300, Loss: 0.1260 | 0.1204
Epoch 75/300, Loss: 0.1263 | 0.1203
Epoch 76/300, Loss: 0.1265 | 0.1202
Epoch 77/300, Loss: 0.1268 | 0.1202
Epoch 78/300, Loss: 0.1265 | 0.1202
Epoch 79/300, Loss: 0.1263 | 0.1201
Epoch 80/300, Loss: 0.1261 | 0.1201
Epoch 81/300, Loss: 0.1264 | 0.1199
Epoch 82/300, Loss: 0.1259 | 0.1199
Epoch 83/300, Loss: 0.1266 | 0.1199
Epoch 84/300, Loss: 0.1261 | 0.1198
Epoch 85/300, Loss: 0.1267 | 0.1198
Epoch 86/300, Loss: 0.1260 | 0.1198
Epoch 87/300, Loss: 0.1263 | 0.1198
Epoch 88/300, Loss: 0.1261 | 0.1197
Epoch 89/300, Loss: 0.1260 | 0.1197
Epoch 90/300, Loss: 0.1258 | 0.1197
Epoch 91/300, Loss: 0.1261 | 0.1197
Epoch 92/300, Loss: 0.1260 | 0.1197
Epoch 93/300, Loss: 0.1260 | 0.1196
Epoch 94/300, Loss: 0.1261 | 0.1196
Epoch 95/300, Loss: 0.1255 | 0.1196
Epoch 96/300, Loss: 0.1259 | 0.1196
Epoch 97/300, Loss: 0.1257 | 0.1196
Epoch 98/300, Loss: 0.1260 | 0.1196
Epoch 99/300, Loss: 0.1257 | 0.1196
Epoch 100/300, Loss: 0.1269 | 0.1196
Epoch 101/300, Loss: 0.1262 | 0.1196
Epoch 102/300, Loss: 0.1257 | 0.1196
Epoch 103/300, Loss: 0.1257 | 0.1196
Epoch 104/300, Loss: 0.1256 | 0.1196
Epoch 105/300, Loss: 0.1262 | 0.1196
Epoch 106/300, Loss: 0.1263 | 0.1195
Epoch 107/300, Loss: 0.1263 | 0.1195
Epoch 108/300, Loss: 0.1258 | 0.1195
Epoch 109/300, Loss: 0.1259 | 0.1195
Epoch 110/300, Loss: 0.1256 | 0.1195
Epoch 111/300, Loss: 0.1261 | 0.1195
Epoch 112/300, Loss: 0.1263 | 0.1195
Epoch 113/300, Loss: 0.1260 | 0.1195
Epoch 114/300, Loss: 0.1262 | 0.1195
Epoch 115/300, Loss: 0.1257 | 0.1195
Epoch 116/300, Loss: 0.1257 | 0.1195
Epoch 117/300, Loss: 0.1259 | 0.1195
Epoch 118/300, Loss: 0.1262 | 0.1195
Epoch 119/300, Loss: 0.1266 | 0.1195
Epoch 120/300, Loss: 0.1263 | 0.1195
Epoch 121/300, Loss: 0.1264 | 0.1195
Epoch 122/300, Loss: 0.1263 | 0.1195
Epoch 123/300, Loss: 0.1269 | 0.1195
Epoch 124/300, Loss: 0.1260 | 0.1195
Epoch 125/300, Loss: 0.1264 | 0.1195
Epoch 126/300, Loss: 0.1265 | 0.1195
Epoch 127/300, Loss: 0.1255 | 0.1195
Epoch 128/300, Loss: 0.1262 | 0.1195
Epoch 129/300, Loss: 0.1264 | 0.1195
Epoch 130/300, Loss: 0.1261 | 0.1195
Epoch 131/300, Loss: 0.1261 | 0.1195
Epoch 132/300, Loss: 0.1262 | 0.1195
Epoch 133/300, Loss: 0.1262 | 0.1195
Epoch 134/300, Loss: 0.1265 | 0.1195
Epoch 135/300, Loss: 0.1263 | 0.1195
Epoch 136/300, Loss: 0.1263 | 0.1195
Epoch 137/300, Loss: 0.1250 | 0.1195
Epoch 138/300, Loss: 0.1259 | 0.1195
Epoch 139/300, Loss: 0.1260 | 0.1195
Epoch 140/300, Loss: 0.1259 | 0.1195
Epoch 141/300, Loss: 0.1257 | 0.1195
Epoch 142/300, Loss: 0.1260 | 0.1195
Epoch 143/300, Loss: 0.1265 | 0.1195
Epoch 144/300, Loss: 0.1261 | 0.1195
Epoch 145/300, Loss: 0.1266 | 0.1195
Epoch 146/300, Loss: 0.1257 | 0.1195
Epoch 147/300, Loss: 0.1258 | 0.1195
Epoch 148/300, Loss: 0.1261 | 0.1195
Epoch 149/300, Loss: 0.1261 | 0.1195
Epoch 150/300, Loss: 0.1263 | 0.1195
Epoch 151/300, Loss: 0.1260 | 0.1195
Epoch 152/300, Loss: 0.1265 | 0.1195
Epoch 153/300, Loss: 0.1259 | 0.1195
Epoch 154/300, Loss: 0.1260 | 0.1195
Epoch 155/300, Loss: 0.1258 | 0.1195
Epoch 156/300, Loss: 0.1265 | 0.1195
Epoch 157/300, Loss: 0.1259 | 0.1195
Epoch 158/300, Loss: 0.1260 | 0.1195
Epoch 159/300, Loss: 0.1264 | 0.1195
Epoch 160/300, Loss: 0.1261 | 0.1195
Epoch 161/300, Loss: 0.1257 | 0.1195
Epoch 162/300, Loss: 0.1261 | 0.1195
Epoch 163/300, Loss: 0.1263 | 0.1195
Epoch 164/300, Loss: 0.1255 | 0.1195
Epoch 165/300, Loss: 0.1258 | 0.1195
Epoch 166/300, Loss: 0.1258 | 0.1195
Epoch 167/300, Loss: 0.1256 | 0.1195
Epoch 168/300, Loss: 0.1263 | 0.1195
Epoch 169/300, Loss: 0.1266 | 0.1195
Epoch 170/300, Loss: 0.1261 | 0.1195
Epoch 171/300, Loss: 0.1263 | 0.1195
Epoch 172/300, Loss: 0.1266 | 0.1195
Early stopping
Runtime (seconds): 458.57755041122437
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)
MSE: 1808.1142655781005
RMSE: 42.52192687988281
MAE: 42.52192687988281
R-squared: nan
[205.24808]
