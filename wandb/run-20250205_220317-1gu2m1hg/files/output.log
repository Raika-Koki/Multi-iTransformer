[32m[I 2025-02-05 22:03:23,104][0m A new study created in memory with name: no-name-8d7fc3cd-8e85-4832-a0bc-01a4553dd183[0m
[32m[I 2025-02-05 22:04:02,298][0m Trial 0 finished with value: 0.38635363113589405 and parameters: {'observation_period_num': 48, 'train_rates': 0.6498129861870475, 'learning_rate': 9.907266367996115e-06, 'batch_size': 120, 'step_size': 7, 'gamma': 0.9059600853602376}. Best is trial 0 with value: 0.38635363113589405.[0m
[32m[I 2025-02-05 22:04:38,402][0m Trial 1 finished with value: 0.2624896069292922 and parameters: {'observation_period_num': 247, 'train_rates': 0.8784922505837152, 'learning_rate': 0.0005717819489495629, 'batch_size': 159, 'step_size': 15, 'gamma': 0.9381462344989342}. Best is trial 1 with value: 0.2624896069292922.[0m
[32m[I 2025-02-05 22:05:11,645][0m Trial 2 finished with value: 0.8427956876683325 and parameters: {'observation_period_num': 109, 'train_rates': 0.9070817600185754, 'learning_rate': 1.030734267861212e-06, 'batch_size': 179, 'step_size': 12, 'gamma': 0.9225482516705146}. Best is trial 1 with value: 0.2624896069292922.[0m
[32m[I 2025-02-05 22:07:28,451][0m Trial 3 finished with value: 0.19458126730102598 and parameters: {'observation_period_num': 22, 'train_rates': 0.7692899076977582, 'learning_rate': 6.644299898497508e-05, 'batch_size': 37, 'step_size': 3, 'gamma': 0.7711143541026397}. Best is trial 3 with value: 0.19458126730102598.[0m
[32m[I 2025-02-05 22:07:56,774][0m Trial 4 finished with value: 0.7720215501156629 and parameters: {'observation_period_num': 237, 'train_rates': 0.7397531658713696, 'learning_rate': 2.6468723591482916e-06, 'batch_size': 183, 'step_size': 11, 'gamma': 0.8661716651541596}. Best is trial 3 with value: 0.19458126730102598.[0m
[32m[I 2025-02-05 22:08:36,114][0m Trial 5 finished with value: 0.08486668692642929 and parameters: {'observation_period_num': 37, 'train_rates': 0.826186632572164, 'learning_rate': 2.3707935451299266e-05, 'batch_size': 148, 'step_size': 14, 'gamma': 0.9451476285765834}. Best is trial 5 with value: 0.08486668692642929.[0m
[32m[I 2025-02-05 22:09:47,800][0m Trial 6 finished with value: 0.11521561028128931 and parameters: {'observation_period_num': 112, 'train_rates': 0.78601712591359, 'learning_rate': 0.00022997450170461674, 'batch_size': 72, 'step_size': 8, 'gamma': 0.9639567656096619}. Best is trial 5 with value: 0.08486668692642929.[0m
Early stopping at epoch 86
[32m[I 2025-02-05 22:10:39,077][0m Trial 7 finished with value: 0.45227371492792207 and parameters: {'observation_period_num': 45, 'train_rates': 0.667607155559005, 'learning_rate': 2.3001500306395534e-05, 'batch_size': 81, 'step_size': 2, 'gamma': 0.7537399626567753}. Best is trial 5 with value: 0.08486668692642929.[0m
[32m[I 2025-02-05 22:11:01,775][0m Trial 8 finished with value: 0.1625323065424997 and parameters: {'observation_period_num': 34, 'train_rates': 0.6896641058968107, 'learning_rate': 0.0002877802065943663, 'batch_size': 237, 'step_size': 14, 'gamma': 0.8084034420875346}. Best is trial 5 with value: 0.08486668692642929.[0m
[32m[I 2025-02-05 22:13:01,156][0m Trial 9 finished with value: 0.5662717884989186 and parameters: {'observation_period_num': 122, 'train_rates': 0.692127352450674, 'learning_rate': 2.3565756651386548e-06, 'batch_size': 38, 'step_size': 9, 'gamma': 0.8283546772453385}. Best is trial 5 with value: 0.08486668692642929.[0m
[32m[I 2025-02-05 22:13:25,927][0m Trial 10 finished with value: 0.3191777467727661 and parameters: {'observation_period_num': 174, 'train_rates': 0.9679755094070438, 'learning_rate': 4.737930843483262e-05, 'batch_size': 256, 'step_size': 5, 'gamma': 0.9770520288308877}. Best is trial 5 with value: 0.08486668692642929.[0m
[32m[I 2025-02-05 22:14:19,038][0m Trial 11 finished with value: 0.09765536995495067 and parameters: {'observation_period_num': 87, 'train_rates': 0.8469534866837389, 'learning_rate': 0.00015110298850142545, 'batch_size': 104, 'step_size': 8, 'gamma': 0.9896148493170458}. Best is trial 5 with value: 0.08486668692642929.[0m
[32m[I 2025-02-05 22:15:05,324][0m Trial 12 finished with value: 0.07059413150879919 and parameters: {'observation_period_num': 79, 'train_rates': 0.8504148847429467, 'learning_rate': 0.00012086999372739726, 'batch_size': 121, 'step_size': 11, 'gamma': 0.9897952369106513}. Best is trial 12 with value: 0.07059413150879919.[0m
[32m[I 2025-02-05 22:15:44,080][0m Trial 13 finished with value: 0.17388405251984645 and parameters: {'observation_period_num': 74, 'train_rates': 0.8296005258938655, 'learning_rate': 1.5788156245983815e-05, 'batch_size': 145, 'step_size': 12, 'gamma': 0.8861658242694062}. Best is trial 12 with value: 0.07059413150879919.[0m
[32m[I 2025-02-05 22:16:13,747][0m Trial 14 finished with value: 0.052334535866975784 and parameters: {'observation_period_num': 6, 'train_rates': 0.9370185716255754, 'learning_rate': 9.083903685502903e-05, 'batch_size': 214, 'step_size': 13, 'gamma': 0.9489685323038137}. Best is trial 14 with value: 0.052334535866975784.[0m
[32m[I 2025-02-05 22:16:46,856][0m Trial 15 finished with value: 0.049228060990571976 and parameters: {'observation_period_num': 7, 'train_rates': 0.9777419443463328, 'learning_rate': 0.0009098671985769944, 'batch_size': 204, 'step_size': 10, 'gamma': 0.953859931813802}. Best is trial 15 with value: 0.049228060990571976.[0m
[32m[I 2025-02-05 22:17:17,574][0m Trial 16 finished with value: 0.04648003354668617 and parameters: {'observation_period_num': 7, 'train_rates': 0.9856244576622057, 'learning_rate': 0.000847840536386188, 'batch_size': 213, 'step_size': 10, 'gamma': 0.8580389326283557}. Best is trial 16 with value: 0.04648003354668617.[0m
[32m[I 2025-02-05 22:17:48,355][0m Trial 17 finished with value: 0.2985447645187378 and parameters: {'observation_period_num': 156, 'train_rates': 0.9817506153313221, 'learning_rate': 0.000875860759474869, 'batch_size': 208, 'step_size': 10, 'gamma': 0.8510196536517989}. Best is trial 16 with value: 0.04648003354668617.[0m
[32m[I 2025-02-05 22:18:19,521][0m Trial 18 finished with value: 0.0392716291258816 and parameters: {'observation_period_num': 12, 'train_rates': 0.919742559613148, 'learning_rate': 0.00045664438230710603, 'batch_size': 200, 'step_size': 6, 'gamma': 0.9067974603196125}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:18:54,191][0m Trial 19 finished with value: 0.17147072044111067 and parameters: {'observation_period_num': 179, 'train_rates': 0.9226081692435211, 'learning_rate': 0.0003690781850724916, 'batch_size': 177, 'step_size': 6, 'gamma': 0.8922301290643317}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:19:22,341][0m Trial 20 finished with value: 0.08968886241366968 and parameters: {'observation_period_num': 55, 'train_rates': 0.8983658498549961, 'learning_rate': 0.00046231581597670703, 'batch_size': 229, 'step_size': 4, 'gamma': 0.8299357532271945}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:19:53,294][0m Trial 21 finished with value: 0.03952277824282646 and parameters: {'observation_period_num': 7, 'train_rates': 0.9502769615644099, 'learning_rate': 0.0009584049925682389, 'batch_size': 203, 'step_size': 9, 'gamma': 0.9120242136280524}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:20:20,543][0m Trial 22 finished with value: 0.040095362812280655 and parameters: {'observation_period_num': 6, 'train_rates': 0.9422994917521905, 'learning_rate': 0.0009901567685475711, 'batch_size': 249, 'step_size': 6, 'gamma': 0.9157964196557024}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:20:45,415][0m Trial 23 finished with value: 0.1168096512556076 and parameters: {'observation_period_num': 66, 'train_rates': 0.9385746878243459, 'learning_rate': 0.00019712663758853128, 'batch_size': 255, 'step_size': 6, 'gamma': 0.9181024176804519}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:21:12,831][0m Trial 24 finished with value: 0.05253273993730545 and parameters: {'observation_period_num': 23, 'train_rates': 0.9441589623852398, 'learning_rate': 0.0004642714293170275, 'batch_size': 236, 'step_size': 5, 'gamma': 0.8853236415078933}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:21:38,223][0m Trial 25 finished with value: 0.29575890797159793 and parameters: {'observation_period_num': 92, 'train_rates': 0.6091093885979524, 'learning_rate': 0.0005110749743979765, 'batch_size': 188, 'step_size': 7, 'gamma': 0.9280361338539941}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:22:05,467][0m Trial 26 finished with value: 0.05401613923964227 and parameters: {'observation_period_num': 26, 'train_rates': 0.8935958124952512, 'learning_rate': 0.0009791463872407661, 'batch_size': 228, 'step_size': 4, 'gamma': 0.9045871015075337}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:22:42,005][0m Trial 27 finished with value: 0.15301797432558878 and parameters: {'observation_period_num': 58, 'train_rates': 0.875263076450021, 'learning_rate': 0.00023910904695402144, 'batch_size': 164, 'step_size': 1, 'gamma': 0.9041918952251553}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:23:12,844][0m Trial 28 finished with value: 0.2105475217103958 and parameters: {'observation_period_num': 225, 'train_rates': 0.9510684380951125, 'learning_rate': 0.0006318615186514179, 'batch_size': 198, 'step_size': 7, 'gamma': 0.8837575279063956}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:23:38,074][0m Trial 29 finished with value: 0.4535577893257141 and parameters: {'observation_period_num': 48, 'train_rates': 0.9244174536097538, 'learning_rate': 5.8950628658143095e-06, 'batch_size': 246, 'step_size': 6, 'gamma': 0.9105992922595759}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:24:05,370][0m Trial 30 finished with value: 0.06419512068898213 and parameters: {'observation_period_num': 20, 'train_rates': 0.8615497486762359, 'learning_rate': 0.0003200903594239216, 'batch_size': 219, 'step_size': 9, 'gamma': 0.9315407098195206}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:24:36,565][0m Trial 31 finished with value: 0.05211414769291878 and parameters: {'observation_period_num': 5, 'train_rates': 0.9878036647403263, 'learning_rate': 0.0006639140365833809, 'batch_size': 214, 'step_size': 9, 'gamma': 0.8590174214592693}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:25:10,052][0m Trial 32 finished with value: 0.048575207591056824 and parameters: {'observation_period_num': 17, 'train_rates': 0.9643310971772971, 'learning_rate': 0.0006545199553145548, 'batch_size': 191, 'step_size': 8, 'gamma': 0.8989670966264225}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:25:47,162][0m Trial 33 finished with value: 0.04632281778114183 and parameters: {'observation_period_num': 37, 'train_rates': 0.9118998876907811, 'learning_rate': 0.0003642876726208404, 'batch_size': 163, 'step_size': 10, 'gamma': 0.8410116758565374}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:26:24,398][0m Trial 34 finished with value: 0.07191211957740419 and parameters: {'observation_period_num': 35, 'train_rates': 0.9109175163658908, 'learning_rate': 0.00016402042890724614, 'batch_size': 165, 'step_size': 5, 'gamma': 0.8374376624080587}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:27:00,364][0m Trial 35 finished with value: 0.05157445876494698 and parameters: {'observation_period_num': 43, 'train_rates': 0.8823581108703269, 'learning_rate': 0.0003696072954750614, 'batch_size': 164, 'step_size': 7, 'gamma': 0.8744836250148996}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:27:43,715][0m Trial 36 finished with value: 0.16806152895573648 and parameters: {'observation_period_num': 139, 'train_rates': 0.8143391663385209, 'learning_rate': 5.8760672142323915e-05, 'batch_size': 130, 'step_size': 11, 'gamma': 0.7947935318897871}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:28:25,119][0m Trial 37 finished with value: 0.04361188625003777 and parameters: {'observation_period_num': 29, 'train_rates': 0.9135785081152282, 'learning_rate': 0.0004484247004793758, 'batch_size': 148, 'step_size': 8, 'gamma': 0.918410785115838}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:29:25,287][0m Trial 38 finished with value: 0.05829267021744771 and parameters: {'observation_period_num': 22, 'train_rates': 0.955223970705559, 'learning_rate': 0.00010948960229306364, 'batch_size': 101, 'step_size': 3, 'gamma': 0.9413398184099241}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:30:02,249][0m Trial 39 finished with value: 0.22305097208870506 and parameters: {'observation_period_num': 59, 'train_rates': 0.7701727996259529, 'learning_rate': 0.0006621690765530393, 'batch_size': 147, 'step_size': 8, 'gamma': 0.9188977265326423}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:30:35,854][0m Trial 40 finished with value: 0.15521566174468215 and parameters: {'observation_period_num': 102, 'train_rates': 0.8806244931702193, 'learning_rate': 0.0002445728645547498, 'batch_size': 174, 'step_size': 6, 'gamma': 0.9651601252206073}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:31:21,246][0m Trial 41 finished with value: 0.04377570865636176 and parameters: {'observation_period_num': 31, 'train_rates': 0.9202768095586426, 'learning_rate': 0.00045061469856845683, 'batch_size': 132, 'step_size': 9, 'gamma': 0.8718176639533749}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:32:04,067][0m Trial 42 finished with value: 0.04470419955171951 and parameters: {'observation_period_num': 29, 'train_rates': 0.9257781064790045, 'learning_rate': 0.0004916435412394869, 'batch_size': 138, 'step_size': 9, 'gamma': 0.8733670148012117}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:33:01,158][0m Trial 43 finished with value: 0.06719038699063831 and parameters: {'observation_period_num': 18, 'train_rates': 0.9012134727181396, 'learning_rate': 0.0006993314081128486, 'batch_size': 106, 'step_size': 7, 'gamma': 0.934920606037956}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:34:17,454][0m Trial 44 finished with value: 0.09393878938915494 and parameters: {'observation_period_num': 46, 'train_rates': 0.9621462292174228, 'learning_rate': 0.0009860039021406999, 'batch_size': 80, 'step_size': 8, 'gamma': 0.9170013773652854}. Best is trial 18 with value: 0.0392716291258816.[0m
[32m[I 2025-02-05 22:35:04,157][0m Trial 45 finished with value: 0.0392047358771502 and parameters: {'observation_period_num': 15, 'train_rates': 0.8608008697454974, 'learning_rate': 0.0002947321072020758, 'batch_size': 124, 'step_size': 4, 'gamma': 0.897261686075488}. Best is trial 45 with value: 0.0392047358771502.[0m
[32m[I 2025-02-05 22:36:41,508][0m Trial 46 finished with value: 0.03716218699701131 and parameters: {'observation_period_num': 15, 'train_rates': 0.8651085547944027, 'learning_rate': 0.0001836785686995131, 'batch_size': 58, 'step_size': 4, 'gamma': 0.8923222908202098}. Best is trial 46 with value: 0.03716218699701131.[0m
[32m[I 2025-02-05 22:41:34,325][0m Trial 47 finished with value: 0.03099069391895911 and parameters: {'observation_period_num': 13, 'train_rates': 0.8309352736636951, 'learning_rate': 8.583299115308112e-05, 'batch_size': 18, 'step_size': 3, 'gamma': 0.8984199540353397}. Best is trial 47 with value: 0.03099069391895911.[0m
[32m[I 2025-02-05 22:45:06,654][0m Trial 48 finished with value: 0.06533569654211738 and parameters: {'observation_period_num': 15, 'train_rates': 0.8205914217519753, 'learning_rate': 4.188383583808157e-05, 'batch_size': 25, 'step_size': 2, 'gamma': 0.8945323430373185}. Best is trial 47 with value: 0.03099069391895911.[0m
[32m[I 2025-02-05 22:46:39,547][0m Trial 49 finished with value: 0.14534003549824662 and parameters: {'observation_period_num': 209, 'train_rates': 0.7938611890999693, 'learning_rate': 8.06664916677766e-05, 'batch_size': 53, 'step_size': 3, 'gamma': 0.883110226782219}. Best is trial 47 with value: 0.03099069391895911.[0m
最適ハイパーパラメータが見つかりました
最適なハイパーパラメータが best_hyperparameters_GOOG_iTransformer_noMSTL.json に保存されました
Epoch 1/300, Loss: 0.2290 | 0.1535
Epoch 2/300, Loss: 0.1308 | 0.1089
Epoch 3/300, Loss: 0.1167 | 0.0921
Epoch 4/300, Loss: 0.1107 | 0.0825
Epoch 5/300, Loss: 0.1071 | 0.0775
Epoch 6/300, Loss: 0.1038 | 0.0748
Epoch 7/300, Loss: 0.1010 | 0.0737
Epoch 8/300, Loss: 0.0990 | 0.0721
Epoch 9/300, Loss: 0.0969 | 0.0683
Epoch 10/300, Loss: 0.0949 | 0.0638
Epoch 11/300, Loss: 0.0934 | 0.0616
Epoch 12/300, Loss: 0.0918 | 0.0580
Epoch 13/300, Loss: 0.0904 | 0.0560
Epoch 14/300, Loss: 0.0889 | 0.0542
Epoch 15/300, Loss: 0.0871 | 0.0528
Epoch 16/300, Loss: 0.0856 | 0.0516
Epoch 17/300, Loss: 0.0840 | 0.0503
Epoch 18/300, Loss: 0.0825 | 0.0491
Epoch 19/300, Loss: 0.0811 | 0.0482
Epoch 20/300, Loss: 0.0800 | 0.0471
Epoch 21/300, Loss: 0.0791 | 0.0466
Epoch 22/300, Loss: 0.0785 | 0.0467
Epoch 23/300, Loss: 0.0780 | 0.0462
Epoch 24/300, Loss: 0.0776 | 0.0462
Epoch 25/300, Loss: 0.0773 | 0.0460
Epoch 26/300, Loss: 0.0770 | 0.0452
Epoch 27/300, Loss: 0.0766 | 0.0450
Epoch 28/300, Loss: 0.0763 | 0.0448
Epoch 29/300, Loss: 0.0760 | 0.0442
Epoch 30/300, Loss: 0.0757 | 0.0441
Epoch 31/300, Loss: 0.0754 | 0.0438
Epoch 32/300, Loss: 0.0752 | 0.0435
Epoch 33/300, Loss: 0.0749 | 0.0432
Epoch 34/300, Loss: 0.0747 | 0.0428
Epoch 35/300, Loss: 0.0745 | 0.0426
Epoch 36/300, Loss: 0.0743 | 0.0422
Epoch 37/300, Loss: 0.0741 | 0.0418
Epoch 38/300, Loss: 0.0739 | 0.0417
Epoch 39/300, Loss: 0.0737 | 0.0414
Epoch 40/300, Loss: 0.0736 | 0.0411
Epoch 41/300, Loss: 0.0735 | 0.0410
Epoch 42/300, Loss: 0.0733 | 0.0408
Epoch 43/300, Loss: 0.0732 | 0.0407
Epoch 44/300, Loss: 0.0731 | 0.0406
Epoch 45/300, Loss: 0.0730 | 0.0405
Epoch 46/300, Loss: 0.0729 | 0.0404
Epoch 47/300, Loss: 0.0729 | 0.0403
Epoch 48/300, Loss: 0.0728 | 0.0402
Epoch 49/300, Loss: 0.0727 | 0.0401
Epoch 50/300, Loss: 0.0727 | 0.0400
Epoch 51/300, Loss: 0.0726 | 0.0400
Epoch 52/300, Loss: 0.0725 | 0.0399
Epoch 53/300, Loss: 0.0725 | 0.0399
Epoch 54/300, Loss: 0.0724 | 0.0399
Epoch 55/300, Loss: 0.0723 | 0.0399
Epoch 56/300, Loss: 0.0723 | 0.0398
Epoch 57/300, Loss: 0.0722 | 0.0398
Epoch 58/300, Loss: 0.0722 | 0.0398
Epoch 59/300, Loss: 0.0721 | 0.0398
Epoch 60/300, Loss: 0.0721 | 0.0398
Epoch 61/300, Loss: 0.0720 | 0.0397
Epoch 62/300, Loss: 0.0720 | 0.0397
Epoch 63/300, Loss: 0.0719 | 0.0397
Epoch 64/300, Loss: 0.0719 | 0.0397
Epoch 65/300, Loss: 0.0719 | 0.0396
Epoch 66/300, Loss: 0.0718 | 0.0396
Epoch 67/300, Loss: 0.0718 | 0.0396
Epoch 68/300, Loss: 0.0718 | 0.0396
Epoch 69/300, Loss: 0.0717 | 0.0396
Epoch 70/300, Loss: 0.0717 | 0.0396
Epoch 71/300, Loss: 0.0717 | 0.0395
Epoch 72/300, Loss: 0.0717 | 0.0395
Epoch 73/300, Loss: 0.0717 | 0.0395
Epoch 74/300, Loss: 0.0716 | 0.0395
Epoch 75/300, Loss: 0.0716 | 0.0395
Epoch 76/300, Loss: 0.0716 | 0.0395
Epoch 77/300, Loss: 0.0716 | 0.0395
Epoch 78/300, Loss: 0.0716 | 0.0395
Epoch 79/300, Loss: 0.0716 | 0.0394
Epoch 80/300, Loss: 0.0716 | 0.0394
Epoch 81/300, Loss: 0.0716 | 0.0394
Epoch 82/300, Loss: 0.0715 | 0.0394
Epoch 83/300, Loss: 0.0715 | 0.0394
Epoch 84/300, Loss: 0.0715 | 0.0394
Epoch 85/300, Loss: 0.0715 | 0.0394
Epoch 86/300, Loss: 0.0715 | 0.0394
Epoch 87/300, Loss: 0.0715 | 0.0394
Epoch 88/300, Loss: 0.0715 | 0.0394
Epoch 89/300, Loss: 0.0715 | 0.0394
Epoch 90/300, Loss: 0.0715 | 0.0394
Epoch 91/300, Loss: 0.0715 | 0.0394
Epoch 92/300, Loss: 0.0715 | 0.0394
Epoch 93/300, Loss: 0.0715 | 0.0394
Epoch 94/300, Loss: 0.0715 | 0.0394
Epoch 95/300, Loss: 0.0715 | 0.0394
Epoch 96/300, Loss: 0.0715 | 0.0394
Epoch 97/300, Loss: 0.0715 | 0.0394
Epoch 98/300, Loss: 0.0715 | 0.0394
Epoch 99/300, Loss: 0.0715 | 0.0394
Epoch 100/300, Loss: 0.0714 | 0.0394
Epoch 101/300, Loss: 0.0714 | 0.0394
Epoch 102/300, Loss: 0.0714 | 0.0394
Epoch 103/300, Loss: 0.0714 | 0.0394
Epoch 104/300, Loss: 0.0714 | 0.0394
Epoch 105/300, Loss: 0.0714 | 0.0394
Epoch 106/300, Loss: 0.0714 | 0.0394
Epoch 107/300, Loss: 0.0714 | 0.0394
Epoch 108/300, Loss: 0.0714 | 0.0394
Epoch 109/300, Loss: 0.0714 | 0.0394
Epoch 110/300, Loss: 0.0714 | 0.0394
Epoch 111/300, Loss: 0.0714 | 0.0394
Epoch 112/300, Loss: 0.0714 | 0.0394
Epoch 113/300, Loss: 0.0714 | 0.0394
Epoch 114/300, Loss: 0.0714 | 0.0394
Epoch 115/300, Loss: 0.0714 | 0.0394
Epoch 116/300, Loss: 0.0714 | 0.0394
Epoch 117/300, Loss: 0.0714 | 0.0394
Epoch 118/300, Loss: 0.0714 | 0.0394
Epoch 119/300, Loss: 0.0714 | 0.0394
Epoch 120/300, Loss: 0.0714 | 0.0394
Epoch 121/300, Loss: 0.0714 | 0.0394
Epoch 122/300, Loss: 0.0714 | 0.0394
Epoch 123/300, Loss: 0.0714 | 0.0394
Epoch 124/300, Loss: 0.0714 | 0.0394
Epoch 125/300, Loss: 0.0714 | 0.0394
Epoch 126/300, Loss: 0.0714 | 0.0394
Epoch 127/300, Loss: 0.0714 | 0.0394
Epoch 128/300, Loss: 0.0714 | 0.0394
Epoch 129/300, Loss: 0.0714 | 0.0394
Epoch 130/300, Loss: 0.0714 | 0.0394
Epoch 131/300, Loss: 0.0714 | 0.0394
Epoch 132/300, Loss: 0.0714 | 0.0394
Epoch 133/300, Loss: 0.0714 | 0.0394
Epoch 134/300, Loss: 0.0714 | 0.0394
Epoch 135/300, Loss: 0.0714 | 0.0394
Epoch 136/300, Loss: 0.0714 | 0.0394
Epoch 137/300, Loss: 0.0714 | 0.0394
Epoch 138/300, Loss: 0.0714 | 0.0394
Epoch 139/300, Loss: 0.0714 | 0.0394
Epoch 140/300, Loss: 0.0714 | 0.0394
Epoch 141/300, Loss: 0.0714 | 0.0394
Epoch 142/300, Loss: 0.0714 | 0.0394
Epoch 143/300, Loss: 0.0714 | 0.0394
Epoch 144/300, Loss: 0.0714 | 0.0394
Epoch 145/300, Loss: 0.0714 | 0.0394
Epoch 146/300, Loss: 0.0714 | 0.0394
Epoch 147/300, Loss: 0.0714 | 0.0394
Epoch 148/300, Loss: 0.0714 | 0.0394
Epoch 149/300, Loss: 0.0714 | 0.0394
Epoch 150/300, Loss: 0.0714 | 0.0394
Epoch 151/300, Loss: 0.0714 | 0.0394
Epoch 152/300, Loss: 0.0714 | 0.0394
Epoch 153/300, Loss: 0.0714 | 0.0394
Epoch 154/300, Loss: 0.0714 | 0.0394
Epoch 155/300, Loss: 0.0714 | 0.0394
Epoch 156/300, Loss: 0.0714 | 0.0394
Epoch 157/300, Loss: 0.0714 | 0.0394
Epoch 158/300, Loss: 0.0714 | 0.0394
Epoch 159/300, Loss: 0.0714 | 0.0394
Epoch 160/300, Loss: 0.0714 | 0.0394
Epoch 161/300, Loss: 0.0714 | 0.0394
Epoch 162/300, Loss: 0.0714 | 0.0394
Epoch 163/300, Loss: 0.0714 | 0.0394
Epoch 164/300, Loss: 0.0714 | 0.0394
Epoch 165/300, Loss: 0.0714 | 0.0394
Epoch 166/300, Loss: 0.0714 | 0.0394
Epoch 167/300, Loss: 0.0714 | 0.0394
Epoch 168/300, Loss: 0.0714 | 0.0394
Epoch 169/300, Loss: 0.0714 | 0.0394
Epoch 170/300, Loss: 0.0714 | 0.0394
Epoch 171/300, Loss: 0.0714 | 0.0394
Epoch 172/300, Loss: 0.0714 | 0.0394
Epoch 173/300, Loss: 0.0714 | 0.0394
Epoch 174/300, Loss: 0.0714 | 0.0394
Epoch 175/300, Loss: 0.0714 | 0.0394
Epoch 176/300, Loss: 0.0714 | 0.0394
Epoch 177/300, Loss: 0.0714 | 0.0394
Epoch 178/300, Loss: 0.0714 | 0.0394
Epoch 179/300, Loss: 0.0714 | 0.0394
Epoch 180/300, Loss: 0.0714 | 0.0394
Epoch 181/300, Loss: 0.0714 | 0.0394
Epoch 182/300, Loss: 0.0714 | 0.0394
Epoch 183/300, Loss: 0.0714 | 0.0394
Epoch 184/300, Loss: 0.0714 | 0.0394
Epoch 185/300, Loss: 0.0714 | 0.0394
Epoch 186/300, Loss: 0.0714 | 0.0394
Epoch 187/300, Loss: 0.0714 | 0.0394
Epoch 188/300, Loss: 0.0714 | 0.0394
Epoch 189/300, Loss: 0.0714 | 0.0394
Epoch 190/300, Loss: 0.0714 | 0.0394
Epoch 191/300, Loss: 0.0714 | 0.0394
Epoch 192/300, Loss: 0.0714 | 0.0394
Epoch 193/300, Loss: 0.0714 | 0.0394
Epoch 194/300, Loss: 0.0714 | 0.0394
Epoch 195/300, Loss: 0.0714 | 0.0394
Epoch 196/300, Loss: 0.0714 | 0.0394
Epoch 197/300, Loss: 0.0714 | 0.0394
Epoch 198/300, Loss: 0.0714 | 0.0394
Epoch 199/300, Loss: 0.0714 | 0.0394
Epoch 200/300, Loss: 0.0714 | 0.0394
Epoch 201/300, Loss: 0.0714 | 0.0394
Epoch 202/300, Loss: 0.0714 | 0.0394
Epoch 203/300, Loss: 0.0714 | 0.0394
Epoch 204/300, Loss: 0.0714 | 0.0394
Epoch 205/300, Loss: 0.0714 | 0.0394
Epoch 206/300, Loss: 0.0714 | 0.0394
Epoch 207/300, Loss: 0.0714 | 0.0394
Epoch 208/300, Loss: 0.0714 | 0.0394
Epoch 209/300, Loss: 0.0714 | 0.0394
Epoch 210/300, Loss: 0.0714 | 0.0394
Epoch 211/300, Loss: 0.0714 | 0.0394
Epoch 212/300, Loss: 0.0714 | 0.0394
Epoch 213/300, Loss: 0.0714 | 0.0394
Epoch 214/300, Loss: 0.0714 | 0.0394
Epoch 215/300, Loss: 0.0714 | 0.0394
Epoch 216/300, Loss: 0.0714 | 0.0394
Epoch 217/300, Loss: 0.0714 | 0.0394
Epoch 218/300, Loss: 0.0714 | 0.0394
Epoch 219/300, Loss: 0.0714 | 0.0394
Epoch 220/300, Loss: 0.0714 | 0.0394
Epoch 221/300, Loss: 0.0714 | 0.0394
Epoch 222/300, Loss: 0.0714 | 0.0394
Epoch 223/300, Loss: 0.0714 | 0.0394
Epoch 224/300, Loss: 0.0714 | 0.0394
Epoch 225/300, Loss: 0.0714 | 0.0394
Epoch 226/300, Loss: 0.0714 | 0.0394
Epoch 227/300, Loss: 0.0714 | 0.0394
Epoch 228/300, Loss: 0.0714 | 0.0394
Epoch 229/300, Loss: 0.0714 | 0.0394
Epoch 230/300, Loss: 0.0714 | 0.0394
Epoch 231/300, Loss: 0.0714 | 0.0394
Epoch 232/300, Loss: 0.0714 | 0.0394
Epoch 233/300, Loss: 0.0714 | 0.0394
Epoch 234/300, Loss: 0.0714 | 0.0394
Epoch 235/300, Loss: 0.0714 | 0.0394
Epoch 236/300, Loss: 0.0714 | 0.0394
Epoch 237/300, Loss: 0.0714 | 0.0394
Epoch 238/300, Loss: 0.0714 | 0.0394
Epoch 239/300, Loss: 0.0714 | 0.0394
Epoch 240/300, Loss: 0.0714 | 0.0394
Epoch 241/300, Loss: 0.0714 | 0.0394
Epoch 242/300, Loss: 0.0714 | 0.0394
Epoch 243/300, Loss: 0.0714 | 0.0394
Epoch 244/300, Loss: 0.0714 | 0.0394
Epoch 245/300, Loss: 0.0714 | 0.0394
Epoch 246/300, Loss: 0.0714 | 0.0394
Epoch 247/300, Loss: 0.0714 | 0.0394
Epoch 248/300, Loss: 0.0714 | 0.0394
Epoch 249/300, Loss: 0.0714 | 0.0394
Epoch 250/300, Loss: 0.0714 | 0.0394
Epoch 251/300, Loss: 0.0714 | 0.0394
Epoch 252/300, Loss: 0.0714 | 0.0394
Early stopping
Runtime (seconds): 742.7223465442657
/home2/y2021/k2110261/.conda/envs/tensorflow/lib/python3.11/site-packages/sklearn/metrics/_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.
  warnings.warn(msg, UndefinedMetricWarning)
MSE: 48.554970160126686
RMSE: 6.9681396484375
MAE: 6.9681396484375
R-squared: nan
[197.40814]
